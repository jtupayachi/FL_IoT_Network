[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da227a5d-f1b5-4d6c-9259-76e24439fa96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf997450-b99f-4e05-9cd5-cb222fc93892
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c763679a-bec9-4103-a96e-4597416b2b0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e0ed314-cc78-410f-b453-b6663d02cd77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 830ea947-0ddd-4b6e-af20-db3523e1c8a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cba4e0b5-b068-4ae5-9b4c-023dc189de86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7eaa68fd-7f6b-4496-80cf-331a136ccd9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0c8e9bd-572d-49c9-86e9-84df92b8a9e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1d6fcf4-f339-4ded-9c3b-ed69ac58f69e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1e0fe38-e5f0-4e7d-98c1-67aa8fd15b79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 820d15f9-796e-4188-b244-1ee00b3725f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad70bca7-dbc4-47c5-b074-72562d5ae6ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c361a52f-915b-4177-85f5-871d653961d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb7444ca-a687-42ed-b236-361eba806ea0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dcc3eb59-e4a0-4251-b7c8-7bf822891c94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74ffa401-5bab-4309-aa6e-98535f1557e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 940fb834-ab88-4511-8796-6c9e63b92073
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99568ee3-94c3-40c8-ae08-3ce9261ddf4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e7aee32-828e-4b5b-bfe0-084cb30fdc84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ee1a9e6-748c-48d3-b322-45f181c3ba30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cac935f8-d1d6-4fbc-883e-5cbc7583b49b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5acd0848-b4e4-47bf-a765-63a77dc1a83f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c62bf84-92e2-40db-a98f-18f53d16ef0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01bb1df9-7c00-4928-af22-3456329b0bbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 123999cf-bb0f-4fc6-b085-06e293b0d31a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 902323c4-3bdf-4e0f-a651-51e425fe166e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e883a45f-cf38-4d89-9a98-7f8516c7ba8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ccaa7d02-ff94-496a-ab39-0314cb1bac3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aeab9abd-cde2-43c8-98b0-adb32a6d0ea6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4f9724b-c3eb-4ffd-a734-b861a04518df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6fb4d83a-b715-4d41-8f4a-da1bee2898aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed4eb57b-fc22-4c93-9a35-c8481510aadb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d432d006-717d-4ed4-b05d-abba9d7b9d3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11239d3d-0eb7-4c4a-972e-321b5011758a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f48eda0-9014-4e4a-8372-f03f350756ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f43923ab-1226-4af1-b133-3dccbaecd749
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31803ce6-b1df-4251-982f-4d4c037644ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a44cbc68-de09-4322-ab72-d64a845a2ced
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88d19320-3259-4739-b0ac-f5f58465bd1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf357076-369b-414d-90d4-14bef3309cd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3dacc663-c3ce-4ff6-8877-2a898ab15dea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d3efecc-a237-46a8-93c7-7abc328dbe39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d9e0d9c-4aa2-469f-9a2e-2aca1d5dd703
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 715c73a3-712a-4f6b-8ee8-17a98203d9ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 049a7bfa-ebf3-4bfb-9c88-bf93710f4101
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 968af21d-6521-4238-82d8-9cec53a1b5e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ac79661-031a-4b11-a9b6-c0bd8dc2ff62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e50d89df-44de-43c5-9285-482c0f248c56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c3f1393-78e5-45d9-b08e-78e1a50820c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b55d8f28-2777-40b3-a565-51a5a0e1fb09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 158b4d61-e0de-4470-9420-5ef6f02a5416
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 458b5086-fc04-403c-a255-b145a31e0a5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28b7de87-55a6-4a55-b96e-062361861825
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39adaf29-9a37-431f-9e98-838cded6fc41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af5befd6-440e-4025-b80c-6fceffe725b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e744f46-d50d-4784-8225-6c759db6ea88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4611f98d-1590-497c-b957-5de495caffe9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d56b3f9-f641-4758-8940-5069f108327f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 569c81da-50cd-49b9-9bf5-faa45418be5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97f5c80a-aefa-449f-adbf-8262364d2019
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41d88232-6248-4702-82d6-6ad674c20d7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc9fdb8e-d1eb-4d32-92e1-a21f036c1ddf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0382ce4-2d43-4390-8335-8b20ee3d2750
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98809b69-e8b0-46bc-b408-ed0fb4861e98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b6c0542-143a-4752-8abe-0be5f278803e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce0b40ea-b1b6-45f2-8924-be0babfcdb63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba7af1d3-434e-449b-83b3-2577cbc64210
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43d363e5-158e-4abe-87ae-35117c4cac3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 515da5ec-6d11-485d-aa07-1a8a2d105399
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a27239b-cc94-423d-8d63-4add9d45555a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88ae3adc-ec3c-4b69-86f5-bf04c3216c25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3655a4ba-5e6c-436d-a64d-ca9e7bd7c0e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5257e444-c566-4d12-81d0-082eacea5fc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1e117d6-a9e5-4740-a523-fb6b1b5c83de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c194104-ef8c-4f31-879b-22689be969a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1faed3e-2646-407d-8e62-a5548f67e5d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b79bd86c-59c2-43be-bd63-0c48b38ca94d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 917c92fb-426c-4b3e-9e0a-45552ea22451
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93e8363e-c2ba-44ed-bf7d-087ec9d6f739
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 029472e5-895c-4484-87d9-0b8f68ff36a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53f8b02c-d8b6-4754-aa53-380bc58f21e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9f8f3ec-9f7e-450f-b88a-9f3c11b44682
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b92395c-9d81-4411-9244-2c9b585ec147
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1275ea71-a011-4413-9f1a-26db4abe1430
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b852f7f-451c-4dbd-addc-98a8ff99258b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee077325-b71f-4651-94e6-363d3c721126
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7305de5f-4de7-4c92-814a-4fc3dd8b66e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5676118d-b301-4fec-9f13-9e731ba14ffd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c438c333-385b-4920-81ba-bd1b5f5daf92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be2b75b3-4792-4232-ba86-d5ec218f2c0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc64a000-ef1c-4f73-94e2-433777984c4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c1e7230-63ca-41a8-ab46-dd2edc7fad12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eeca7c0d-0717-4949-8730-ee4c7a8d28a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79b3a29d-3365-4578-a615-93dfdc38cd58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e999970-f652-493b-b22e-4c66c9d6b7c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34d4498a-5ba4-46e9-8308-ea6fc22b8ad2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3700f28e-96fc-43d4-9aae-acbee865af44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40278380-f22a-40f0-bf95-08ca68854a72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41d1e4ee-d780-46e9-bd0e-8e118f4d9b79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2759f4af-33a1-423a-8f4b-c6543cd765a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58a8728b-a72a-439b-b042-28b73753b92a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8799592e-82ad-464d-a394-e7fe516be8aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76f4afcc-646f-4f56-bc83-da74c5776b56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 814cb023-c701-45a4-9a48-0d800aadb521
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6e3fdc7-538a-4f52-a8a8-3578a2d6d3b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63415d89-85ef-4e44-a2b2-beaee6e7f979
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd6ab4d8-9700-4591-a472-b9b759425e88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8bab4157-4058-4c59-80ce-e914f2cb2d54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5450bb31-9106-4848-9eb8-927f50b8a0cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67318a2c-9365-4dd1-8b8d-e80dc00c6033
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cac8c5ad-2a65-490b-8203-f6c55c70a397
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb5ac3fa-5473-4402-8398-6d2ab0cbaeca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41f40d0e-f806-469a-9be8-e2b0d968ae35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef6d2805-2e43-4658-a776-21ae9976a628
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c45b46b8-66e0-4dbd-8849-0b86e6d4eee0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 266b9e15-87e1-4e9a-a9b0-2ff10678314a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b4dbd08-f1e5-4261-b1dd-072f18af2044
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67bda186-f09a-4db3-bff3-b93ccbd6e9d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d71b432-674e-4eed-9dbb-10e8135b413e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e9b60fe-32e2-49a2-960f-b17e3dbc79e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e78a7a5-580e-4e49-b066-838603cbd8fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0702e79-00b9-47ba-88e4-c446b9a4433b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b38afbdc-05d4-413d-860b-a231f0e40e27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ea3c8f9-2019-43c6-bac9-11799a71afe6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4ff58db-e63f-4a63-b197-a7fa0e6d1e1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94025f8e-4ac7-44ca-9c93-6af09d1fc8ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e12fafac-d936-424e-83c6-b04e860c0e69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0672bb7e-26a9-4356-9176-fc62770046e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 186aaf9b-0202-471b-9a57-74f2476b3c66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6db17547-c775-4438-a759-7358bcfcec30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9dd397e4-6137-4c90-8953-5dbbd91d8453
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58b1d408-de02-4f0a-9e1e-fe0f92f0a3a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64cca468-2670-4b5c-a784-27d76256d3b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed7c3d5c-f001-4bd8-8032-9aa15852d60c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2eb27229-cb91-44aa-bc93-8c715c80ca3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32621d09-6c23-4705-8d37-e1ccc12453ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 409c1024-1c41-435b-817e-bb71a05dd2e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aaea209e-5af9-4380-a002-b279d944a976
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81d653a3-eebe-42b4-afa5-4b1e6e044eac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9b4bf75-2f35-4a49-9184-245b1dce7840
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48aaa17e-cef9-42f2-9fdf-80864c724c72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a059a6d-a3d4-476f-9851-cb8c822f1971
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2f68945-4e03-41b0-b776-f38944a5f5e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14c3754f-e13e-43ab-bfc7-3278d04d3a70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1483b2bc-f25f-48c3-af92-4a9324a15e76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92b1c94b-b3a5-4884-9d66-1f0358c75e4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88633628-1a56-4295-9d60-50322fab9b9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5c2f85a-334e-4079-b14a-7b3b0ff9aee5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87d6cd0c-e11c-42d8-8c02-65e8ce2f8b3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed8bcb8d-3aa3-4e7e-a8e2-3bd95de2f2fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 663dc3fb-3e4d-43e5-97b8-4431fcb24b79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b566ad8-1807-4a24-9d05-33404b3955fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c42dfeb2-c908-43fe-819b-b12ede492b86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6089306-cd76-4d2d-8cd0-8f8cfc4cfd5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64b0dbb0-5297-45c5-9142-6d91d841f740
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67a5480b-ae43-4b67-9d1b-d787011169d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72998119-909e-4033-99cb-2781998336f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 422c6d9a-14ad-4765-b5f8-88803a997054
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a82c23fe-bdba-4ecc-bd1b-d3f0cc3ec362
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bcd9e986-5100-4e73-b401-f2a05c6c7f1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec0795dc-9fc2-46c8-b335-aac54e31f17a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2cb0f2d5-2be1-4977-a778-cea1cb861346
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8efd1187-e858-4273-9a01-47f16bf9a0fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1bdc715c-52ed-40b2-b60a-0e2aecd4776f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c2b8f2f-af92-488c-9588-d0d165605882
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b64c4de9-f374-456d-8c34-3c8ce924900b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2cc5e9d-7ccb-46a7-a3b1-306aa9fc44d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42fa2510-115f-4b36-8a13-256b0754a2cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77b82ea4-d7e8-465d-93a5-7e3afe52ee8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49260e84-c0a8-4b84-9696-e124fb8ad38d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4597c0f-2286-41f4-bf3a-43fb708d1934
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81482cbf-cd6f-40ac-ac93-96b11ce04b25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4170a757-fe56-458b-8367-fd87336071f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 591f17bc-d14e-4a34-8475-20b3b2864671
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77f1504f-0e0f-402d-ac87-6cf55dc715b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d8dc3a8-37b1-4284-a9a0-9be940e74a79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62b5a805-86af-4278-850e-e6b014c326fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3fc3ba53-8ca1-4fbd-85be-70f92dd15ea4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4887824-9ad8-439f-8ffb-a49f3db2f890
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ecbb2b9-42b8-4770-8a62-91807b404813
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70f8b15f-b13c-424a-a938-adcf1eecde1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42f38c1d-18fa-406f-aadf-e2c9c7e51b28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01fdd982-e5f5-444e-ade0-4f2824e43efd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd137260-b723-4869-893f-9f9d0138cca7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18cb65e9-c44d-4b3f-9180-0744f0108189
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ab9e9ed-2070-4855-9886-ac9c7d292b7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16f2f4c1-e042-40af-bdcd-2c6034d426d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab60bb97-d4db-4ac2-9a62-13f781bc2b79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba3d2696-7083-4da3-b894-e2821bfab213
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ebdce45f-9fa3-444a-ab48-c44ebe6c7d1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 134c5481-2f8a-4e28-affd-4f1aab3af363
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9834c952-ab88-405f-abbf-c5ec4f134e69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c5b6731-db47-479d-8ec3-9b0d14d93e73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb4d9e4f-bbf6-4a90-94f0-ba899a08580d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b33d3d4-1710-42de-a6ce-e1300bdab828
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1be9e14f-4990-4864-8f2a-3258f67f894f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5235574-65ea-4b6c-be70-240b6738ae3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1ecc7f7-ac0b-4614-b170-40a682367909
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e872da11-e918-4268-bf34-3b2986235c68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b965d37-54f1-4b0b-b7e3-4ce57b9d001d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7932b09e-0d7f-4a1f-81aa-5135431ac012
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40d4e486-aae4-4e56-8270-ba91398b36f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b606fdc5-26cc-4ed0-a290-18c4417b19a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6f211de-1582-44d2-a4e1-08e349cfd37f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a739d9e8-ea9b-47ae-8d74-d852b38e0abb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b43daeb-a93c-4037-baf2-fad50b2b918f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 198a1b70-f414-4aff-9982-1412b14d53f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e43b8ef-ff6d-46b9-9eec-8b8ef25c9bb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e5a2695-783f-4a79-8dcb-a137e3ddd56d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a50f870-edf0-4964-a152-e3ea9c079680
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46ec7768-a880-4c21-aa1f-a8ba7f430761
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04bfcca9-adfb-42ce-9271-1e6554eb8010
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 977c5293-e24c-4d33-a21f-97bcc007b32d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c1cc698-14ff-4a37-a71b-e4cab2177f8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8f9b31d-7b00-4572-81ef-a17b1adfea85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 203bd974-731a-4084-bb60-b3696c7a1aba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50ad4969-d424-44d1-a642-bdbe3b1ec098
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1279a60-a083-4c72-acde-3f54c252e247
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19366127-3def-415c-ab55-35d98b79d5e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10fbba18-a899-46ac-bad7-286d96c673b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 915a0c2f-7bfc-4818-8b85-49989580e908
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b9fd9c6-fe49-4aa3-961e-4c1bae044253
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff927b50-e3d3-4463-bd49-beac007a9c52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4daa0603-3dec-4cbf-a304-bae81e6f066a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6308ef20-b8b6-42ac-bef5-cba00ecd9ab7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6249ccb0-d7de-456f-9e06-64cbc3b5c801
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ed87be4-25e0-4d70-bcc3-491f125e593a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 265513cd-8f95-478f-982b-89e9a085603a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 598ea4e1-da2d-4290-8589-dfb4b8cf9975
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 104cce9a-1e61-4b27-a671-d0450ae5a16f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43247c8d-b759-4805-a174-92c22ff0ce33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aeaeb5a1-6f86-4495-8eec-b357675008af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9328a550-313d-4f57-aeb9-99a1b6d9335c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 884176a6-851c-4005-8eca-20a230f91b35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1fd5abdd-475a-4960-befa-d5494089d54f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b5aef85-1d84-4dcc-9423-4baf1a967589
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3c522bd-d624-4bad-9b81-0bdbac54cfb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c626fca0-0260-413d-a592-b00dcc5c7ac8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3af754a9-1df9-477b-b016-86cc5841e442
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e48686d3-433c-41f7-9339-17f018e985ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1b4afe9-5e74-40e1-a3e0-dc22d74e73fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c909392e-dde2-4276-9ce4-c52c779d1360
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4be313bd-4b9e-42cc-95f8-f255f6069621
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 102a0e07-6260-4180-a38e-0ef94ab88a7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2952b546-2d86-410f-a1c0-d78d0deb2b46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a497c6e-9e04-45c4-a4a5-21cf160eab1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80020d82-1067-41fb-aa30-54b4c25662a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1612dac-ebc6-4c34-bca4-4aa175de444f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31d2884a-d560-4a7f-8770-33fa327b6fd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83993a03-a3d4-497d-bed5-fb06f2e126ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84f1e7ef-a1b8-4917-8b58-fa3bccfdf289
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 673a9705-7e22-452a-8eee-8c818a5ae1e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a360c89-8727-4a20-a7c0-6419c69bdfc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5745c770-8ccb-4c24-8cc7-54e3a2842754
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 776856d0-962e-4ec7-ae5f-30402231b091
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9621caff-cf95-46b1-be12-1a83b41673a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c23164ee-4d8a-4d64-88de-48a104c538c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9dc381c0-359f-4295-bb5e-6164f6630bce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c770a514-bae6-4b4e-8c3f-9cdb20039620
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17898747-19fa-4ea0-a62c-5739bb52bda1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf6dd192-5b73-4e5d-8439-2236a43ca594
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59367e9f-5491-4d13-815a-78e7680cf0f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 155f1401-1b3f-4a72-b412-78a723c7b53f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96d4d4dc-ca5b-4ba1-86da-a62dd16b7ea0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1146f8f-6ed3-41bd-936c-431e23f2a62b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c879205-fe50-4912-ab6e-855fd6ff336b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50f1af60-8fc6-41c1-95b3-42c5586c2eb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da7c7eab-63a2-4b7c-9d41-88d3b8f1127e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7474d38d-08c6-47e4-9523-084f9c5a6fcd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfa24b4b-eacb-4cd0-ae2a-b47331db5e34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b8d1c0d-db02-4566-a5d9-f99e8f32b4a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c8eb899-ac34-46f8-92fb-73ffdf97bcf7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa497b44-c7bd-42a9-be71-a5c0901b9b92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6c934f6-6f70-4245-b05f-7588ebb2cec6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 588f2dff-2256-444f-861c-5ad59b8d12fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4515e1a1-f837-4bf3-b373-a9bb8063739f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c77e4267-97ac-4fce-ae3b-3f628cf48929
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89f0c6f7-4bdd-42e1-a532-092f2b746578
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2735c77a-8880-4bfe-878a-1b3302cabd05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6616f6b7-1854-46c9-ab83-23a9d55f67c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message efef3729-7c80-49a8-b3d6-d0b3d8164091
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ef4b156-57f8-4a95-af6f-cdc3caa2e81b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4bac1ef2-65ba-4be0-bb69-9a2aef94dfb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b16977e0-631b-44b7-a4c1-0ce69f028f6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7bca95fd-9572-4a48-9655-0808c9072b78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 564225e2-d05a-4140-a38b-3296c71e0147
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3cc638c5-a721-42dd-8f09-a157b4d42d56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96ac6882-00b5-49c2-91b8-868cfa90a42d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e2b3584-88e4-429f-9418-a2c5a6154a81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8acebb62-7f67-42f5-b5ec-2cc76ad571ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 349224cc-9fbc-4cc0-b59b-2001d0d3205d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72682cbb-2595-4ca8-aa03-9badc5703cd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 092d9076-af91-4ed7-ab1d-ec25521e17de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c2a599b-ba43-4756-84d1-97cbc72b8ff8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c8b7dcb-ada8-433c-838d-f1a2b3517df3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message baaeeb37-9dc4-4711-b7e4-f75bb2a6b439
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07387dd3-2fdf-4aa1-bf91-145ca83e629c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3fdbb28a-11bb-454a-a41a-6000486536d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d998b91-c544-4cb8-bda1-7a9e015776a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 844d4659-283e-4d65-b57d-88e471c7c3e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 145d5810-1f4d-476e-85e6-14c32dd70b1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 250e349d-d772-44b1-98b4-40fd89613937
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2148ba3-9a59-4aea-9110-f44761a324cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0e9762b-d8a9-47e2-9680-5a87f3950e2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0fa1918a-f380-43a6-9af7-cfdf8d3d06b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5df20abf-10bb-4a63-9de2-e4e143228dc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 511f9677-97e4-498f-a2ec-493dfa52f08a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58c9d750-3d1e-4c74-beef-e9fa0bc34614
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 921f41c6-35eb-49de-b3ee-4e1285fd0c18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ee9c387-fec3-44a0-9033-88bda51e7d1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 537810be-e21a-438f-8116-54c3ba2c0f6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8d9bf38-ed57-4228-97a8-f8a9ddda1317
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a97fbc13-da53-4eaa-b6dd-010579268746
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4c6c1cc-1b90-4663-918b-e9edb842e192
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17849aca-800e-44db-a73e-947384e6fe7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2736e361-bf6e-49a6-9c44-c22ba4fdeca4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6a2e040-6c83-4640-bd68-1b13350606b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe565d40-d603-415b-806a-7bc5ce75e4e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7c43cb4-a8af-4cfb-bb9b-5e047eb8f38b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 620074c7-77b7-455b-9375-5f95cbed35c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3aae6a4a-ef88-4644-a1be-647e60397e69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6839504-d607-4b67-9d4c-e362eeff1f1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c14065a3-68a4-45e8-b3f4-22f171caf138
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd0ab6a9-b586-4a86-a913-b1135dcb4322
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14703380-4c18-4eb6-bedd-ebcf30959d1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09c4fddf-31cd-4cc3-96fe-3f93b06dcf13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 341133c6-db69-466f-a4cc-a6590523d4f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 900a245d-98ee-4f19-987b-f3cefe99fdf7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dfaaf818-49a6-40f1-bd2c-29bb21df3b7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b8893e8-aaa9-4493-8245-16f490dac76a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c32dfb54-99d8-41ad-b2be-327d6ccad84a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e59455d8-f5d6-4092-aebf-86f13e14abc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed1b7a74-a466-4618-b064-0d5504b471de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b1503c6-d0b3-485f-8ee6-75366531e55a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92dec40c-dfd2-424e-b286-35bb99d64e2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd5bf780-d221-4ce9-9a89-2d55a84ccbcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab4178d4-8939-4ad0-b804-ed7119f6d83d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a41386e-1efa-4844-a4a7-7135c86e0efd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42bf3cb4-2adb-49a9-ad9a-32231aaba55b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86e8be87-31cc-4145-a928-c179992c42bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a295913-b1c1-4147-be87-bcdcc93d8d2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fdafa2a0-40cd-4e52-864e-a4bd58c2bea3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7052c7c-87ef-4397-a8c8-195b0d5561f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ccf7f3b5-b2c6-458c-95ef-679940df042c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4727e325-fae6-4ac7-b7b0-ffd9408591f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 440e82eb-837d-4078-8d28-9931f96b099f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3cd567d6-adc3-49ee-84bf-dd93935bafb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3c0c570-2bfc-4ad1-9b18-9b4d24377a80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78b40b61-aefb-40c5-8b4a-2345c9c937ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14dfbc8a-55ee-4b3e-9ba8-602b29c6e4af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ecdd38d6-452d-45a3-afb8-8740c6986c98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41ccf7b5-4743-4508-9721-457fb77a068a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 077e1718-93fb-4527-b739-0ec6f859dc65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1de98985-7d38-430b-a87e-25b56428554c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b40b7931-5f1c-40ea-b1e1-6582d91b1b5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05ed9a69-13f5-4f56-bed6-a9fc0766f84c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a5cd856-b68f-4e81-a888-96d7b17f7c85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55e900e2-63f1-46bd-8dad-fd1c39460d85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 230262c6-a0db-45df-a367-7cc97db89cd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b87acbf-9c36-429b-b1cf-458ba9a5d785
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2dcab59a-dac9-4f29-a1fc-a9d7d8f93d2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9e32be4-6529-49db-8f1e-8c8b0538037b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3befdfb9-9d48-49b3-85a8-cf3ccaf45508
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 147376ca-8c79-407d-b1c1-fc044f189311
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08d9028f-9867-4123-9f8b-02ae7fa1846f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a31d40b1-bfd7-4305-9a0e-cc67c4391a01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ceb338e0-bc65-4db0-a14e-812267461c81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1724b1f5-9726-436f-8931-1baafb1e8ac7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47842657-5c4b-43a9-8405-21cfa10ed060
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ecd6cf38-2922-4d79-94fb-c59a3e24bb67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2dd103a-c6df-4f9c-bb87-d1ccdd6ad3da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48ba77ae-5169-49e0-b8c0-5e0984b540d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0715ea74-a9a4-400e-9d07-226dba32e7b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ec14bf0-8aac-4df4-a73b-36ab540e538d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb741abd-a15b-4214-92e9-9abaaacf678f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba719529-86fd-45d0-8633-15bcf41aba08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60c76cee-adcf-42d9-ba23-fcc4f57e5943
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e36ee442-b76c-49ef-9225-b95d58c3b261
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f345e7e8-b497-4ffb-8654-a7cc779c17df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8fe07f8a-bbc2-4191-9ba2-45222b38eff3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81f48b15-2ac2-43ef-b24c-85fd7f1b896d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa2dae09-6505-4ac7-8d5d-4224f94a610f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f4f80ef-636e-4e3d-a3b9-bee589b19262
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6c834d9-4f73-4274-801c-137aa14d1035
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9a73545-4e17-4a83-a41f-7d8dd6e28dec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91b42808-eef7-4740-a3ad-560353763a13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e5aa83b-99e4-4371-b0bf-c96fa9e0225f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 836abc4c-f558-475f-8659-04d384b08b5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f3621ea-3602-4b0d-9081-fd8e5a2af448
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa0fc826-66c6-42ac-8b5a-271627047b2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21487861-5b26-493d-9fa0-4493a5369c62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2991d454-ac7c-4eda-b96d-e6050196b36c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2a851be-ea46-48d3-900c-5a435182e82a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd51fa5e-760d-4340-aaca-92ac7d2f9b80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7299fa75-e865-48a5-8b2f-26fb105a9ef7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44d823dd-6445-4d0f-98eb-13afea1bc399
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf69a3bf-e9cf-4a72-bc7f-b5417059b993
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4cb25a9b-97a1-45f2-b514-78afc2169290
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8497e185-e9eb-453e-9e3f-81c3035ea0cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8bd13dca-4887-4a8e-a96f-787ca2da25e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71608dd4-4451-43fa-8294-adb8639a934a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f9ab23b-82c5-4729-a976-e33f0043217a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ffb80f48-99df-41ec-bf58-c9e654bcca6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85ff5946-5d03-4b1e-93a0-a852f344d39b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4baf4406-d24e-4c5b-8264-b7115c9574b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c502dc74-5c8c-42a6-92dc-c01727994675
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb687d09-d6a5-46a4-ac7e-c94e0fdbd2df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 986f0559-6466-487e-a286-e661d412ecd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2c9156d-d224-4738-b9b9-70b365110459
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b954e360-0b0e-4ddf-a778-4149148f02d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba7c8c0a-2146-4583-a507-32c5b57b7888
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c37fc6fa-376e-4051-b05d-75a211b5d376
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61262196-0f01-4555-a8dc-564c0f790ce3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a47fb26a-9600-48a9-ab58-bb507aabc7e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd7f66eb-80e8-404b-b031-a86ca56ec61f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b4049b2-e635-4298-9e7c-a9bd13807068
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 319fff86-5b28-41ff-8c94-07d9bcaa24a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7e3b4bc-a29d-4265-8fce-11835514ed29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ae07a3d-7e1a-4896-b14f-9f45c1123ec5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 509d4392-20af-4e39-b1df-e37fde6e7516
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb47c9e0-8aea-4a53-b8d0-08c836dfa528
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a533780-f96f-46d4-8b73-3d9bb6ef632a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d74926d-5950-4254-90ce-4a2098b8ba91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19f14be2-72c5-46e4-8948-e56c0c53f573
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96cd8914-2ef6-42b5-a9c2-05aac3f34e32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 986dff5a-6c14-46bd-ba53-e0bcbcd1d6c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28127dbc-4f47-4b20-baaa-8e842181ac66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0ab15bf-2b07-465b-8358-0de5b909e6fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7369babc-2e4b-4663-8403-bfc3bb24bd2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9740390-c268-4300-8026-9fc38e383135
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e854e345-ad80-42ca-bc4a-4555ac02263a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 440d7ebf-a800-4f1e-bee8-eabb376bfa9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 787d1afc-a899-4b97-8519-2c9a02122627
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3599dc2-a116-4aad-857c-31f2d6e7c0bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bee2e52b-78ff-416f-b965-90e3d6cfbd91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c43de808-0732-49aa-bd8e-8aaa822cf5e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d733b3d-04b7-4a9c-a1c8-e5ff3d1ab747
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3391f36b-c9c6-4df6-ae42-dffbeb87335f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49e9b4c2-fbf6-4e44-bb41-e9ed1f2bb975
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6825834a-edd4-4972-98ad-684a06554238
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a0c56ff-10ac-4eb6-a783-b31f6c5d00a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7dcfe796-77e7-4967-a47d-654420ba393d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd8d3ef8-8066-4fce-9657-34c2ec1df73f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e1ad3ba-0329-4d74-b354-bdda443ac52d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05008233-00ca-4408-823a-5cecc0f720bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28e1a6f6-ddf4-4bf0-aa65-f1af4c327ce4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5ded5c9-367e-44e4-b68d-4e02ab405272
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30d853a1-a29f-43d1-bb5a-b837aa22efd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0757a41c-6f55-4ba3-b448-27d0e4f21f1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d8f8d57-373d-46bf-be5e-8bdcb204be42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 366f8d7b-b8ae-475c-aab6-617077072dd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0d167d8-3407-48d0-b79a-61fc7272b330
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea5336ec-c609-4f73-b3df-a491d3ee56a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0e57fed-dd96-4caa-849c-dc68911adf77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce68b769-fb6c-4296-929a-3f0797114d01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 796cea11-78e2-43dc-9ef9-6acf52ade9fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f26dc59-a6ca-4037-b702-8431c4db9053
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac36947d-aab9-4b45-a927-727bf145d45d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6fc2f369-64fd-49b7-8153-aae558d5d08b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5adc3ddc-dfc0-48aa-b028-e968fc32b5a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48e7f9a6-8980-4557-8d50-a2a71ec5139a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15b1eb90-1969-482c-a228-1063f0b27457
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1118a225-3d4b-4309-8761-a9279c258702
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9abcab85-d4f6-4647-a290-86e94b94b614
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 933f8209-5faf-441e-803f-345b7afca99e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 899cc717-e61c-4511-99a5-942c5ef313a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca31b766-479d-4f13-9fb2-fb7b91a1a4cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a446c9c-a1a6-460e-b1d9-0ee20d78e754
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92466532-cfb5-4833-9a7a-25b2e4909236
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d84b6de-ed85-4e55-bd92-459766c36bbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c34beac3-a6a0-4d76-939a-219941ceb101
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a12fa062-5ab0-41df-bd51-8d749a6a1eca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96d381c9-7f29-41dd-9f0f-d83b6e3fdaf5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f00fef82-4703-4211-a8d1-8034a22ae81a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5039c44-1332-4a6b-9b33-a91e9ec6b89b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1018b3eb-8298-4a15-a5f7-d5b7657a7254
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2eaa517-ade3-45ee-a639-11b10c1bf314
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24703e8b-7f35-49ef-9266-b3caff943f27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d95f28ef-a168-47cc-ae3f-b636c29f2eea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d566c749-d8ec-4ce4-8759-0f0237351c4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad7525c0-15b6-45e4-bb3e-6291425b4fa5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7d98801-ff70-4ede-b655-ed461d530c66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 173fc91c-00af-4d48-b070-c7f77fa36e50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5095516b-9dd2-4c3a-9587-871bc6c9d626
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 816f2b75-f7f2-43fd-b143-eaff1bc8a0c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58d84c16-b90c-4c78-9773-df1b7ad496e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16a034c9-9887-4045-8ff8-1d0e3221dfe7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e07531c-3b77-43e4-bc4b-2a5e30f0756a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d30d857-30d2-4cfb-9060-818e1b7ee12e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42affb51-6442-4b4f-8b44-6cafb230034c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bcef4a44-bdfd-4d5a-8936-32b0d536a880
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c41b2326-04ef-4176-8bfd-f3322b08dda9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 602655e1-c5e6-4dd8-a3fb-b41756f8ac71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fec62bde-3584-4275-9525-6b72bd9b1e44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b319ce48-d8f9-469f-a490-7e6c92e7ee54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eea8307f-0bde-4ede-ae79-8b7ba4795670
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a31f829b-5d57-4373-a523-926014b434b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ee16bd5-0af8-45e7-a817-8d15e3ce3745
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 024f4837-6125-420f-86b3-af12569df0c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0246223-1134-4896-b096-088b6f1ace84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c827fcb-a049-4df0-8d0f-d20d197d0590
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 320cee4f-4757-4007-bd90-c5ede5526fbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7307be31-183b-4ced-9bfd-dbc397afd27e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49a0513b-5f39-4d75-8df6-d475a9a601f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4fc6c26-5213-42e6-8bff-ffce0b83fc8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e07b296a-efa9-4421-903d-0f519ba82caa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06bb30cf-7ea2-4c23-969b-0a8d220f7d55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f21ad20f-c498-4d9f-bf3d-8d894771772f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ba4f186-1148-4e88-8a39-bba9e890b507
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message faabc622-016d-417f-bad4-fe63ea3a8d07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f790443d-72b6-443b-b0da-c72d22fe3804
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69a5f46c-37a8-44d0-93e4-8e0dd6df62f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d89a02ef-222b-4a42-bc97-d61342a75ae0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2e646e6-79a2-4e4c-b003-a53aaa1226e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5385b257-7bf3-44d3-beb6-a27a124d9063
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 482db2fd-867a-405f-9e29-7a618a0f1c64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15621542-7a7b-445a-b21f-bd5bd50f19ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 964ec91f-5a94-4910-8384-2242abf9c2dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d73c0f4-32b4-4854-902d-0bf49e474fb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e4fa427-d03d-46ae-b084-58cfd2b678cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ddd5449-396a-4f2d-8994-3e8b47d8c909
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad44f6bf-66c3-44c4-b165-ec34ad8a24b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef5838b0-360a-4f39-a772-eb3b6c1c658e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4f054ca-f982-4721-a654-4f72a5a2b918
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 889df7dd-6f83-41c7-b4f3-9aecff2d7841
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 823b0b3b-3f26-4b8d-b573-af32d31e105d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53c17892-89c8-46c6-8867-9ba80628d849
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2c2f1ea-3732-4a15-8a7d-1fb499d69a7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 218eadf9-21bd-433c-8537-998c72211892
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb956349-2e8c-47f2-812b-7f799eb506cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2d6372c-e79a-426f-838e-3178ab15813d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a65400a2-147f-4393-affc-8ea52f0d10b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58f50d6d-6e12-46d5-9a45-b5a429232383
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5ed3a12-0884-4dbb-be93-c06ad6e00472
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51d95135-acad-485e-b6b1-cf5dd3c260af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 845f9082-c32e-4d6a-a5e5-df1499154abb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf91e19d-ca8b-46d9-b891-eab35f32aafa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61967b9e-1705-4fae-a654-a35d49662c65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16fe6441-0bca-44a4-8b6d-0e97d315debd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd673867-fec7-4558-a819-41434ccca7c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0506db93-d089-4280-9ae6-a07ee7532763
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef715c30-5bf6-4e53-9744-7f81480241e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21a16b87-0529-4cc4-a656-ba858842f64e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 897c010b-00d1-4a1f-9a7d-65a6959ad9ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff04710d-33ec-4298-9e8a-0d879cb9adbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b1cd3fd-9b26-4784-9c58-ddc6f1a3dc8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59618c8f-5c3f-4806-811e-b032e09273cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c14889e-73b6-4ae4-bb7c-8d596969b0b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c48dd71-dc80-42c9-b6f3-2d66454b78ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42142d96-f5de-4203-b003-73726c6ebadd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75183021-5dbe-457a-a1e1-73b89d88996f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37406974-e96f-4999-b43f-4c09ffbc4887
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df0dc86f-feaa-4401-bf17-e48d1a43eb6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4008822-fa8b-4324-9ef4-b74ba61c1f41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc1ce450-c023-4717-94e7-53b822ff5052
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e27048c2-e2db-4477-badc-ab244e3c17b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f34faa91-1860-4733-ac8f-93aabd550cef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9cf82bc-cbba-4561-a06c-6d239e338845
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3567f554-e1a6-4906-a1fe-2877cbcc105f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7fd43680-ff41-4a17-bdec-889fdd5e6c93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 252a2c93-9d9f-4f54-a1b7-66b30bd6ebf9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 085b55b4-cf3e-4d52-8149-7acd04ca1e66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 704055ee-bd96-44c8-8aae-a56ce0e47585
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff08dba6-5204-4e10-bddc-174ae9c212d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c85dbde-0a52-43d2-9377-c0883d45bd1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92b677eb-32cf-4092-99cd-48eae9549f13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e78c03e-2b2b-4720-8031-079c1446a822
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e68a0a1-8bd3-46ad-8e67-398d8090c08d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e8f9932-134e-450e-9e72-ba7380c5dd46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 322ef638-907c-4fa9-9e62-9efcf4fdb493
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1c10c47-a038-40b4-979c-223312b4683d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17eb7776-9215-4de3-ad3c-269e773e44bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07fa8785-e614-42df-b0d2-5bb5bdb72484
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ea936ed-44e8-4b58-bf86-2d57a9d5512d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7240c4a8-f651-404a-962c-d66a07a53e54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64d17ab9-fc8f-4379-831d-d35bcc398809
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86813618-1448-4541-9de1-6726c454b8aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1923594-0023-4519-8f42-c7c44bdff851
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e968b9b-9a6b-43a1-9ac2-6735f6390a9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7237fb3e-5b9d-4bab-99b7-1df330db7264
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04e5803d-8daf-4339-83a6-84e6ca33d439
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59cdc9a9-5b68-4e6c-937c-4be7c41dc6c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1acd6a0f-8e82-4e6d-a758-cf07d63db9e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43b331fc-189c-40f0-b246-170810cdf055
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 895281ce-7e52-46e2-8c42-ee617a589bca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 257c4020-38f4-4c12-9f68-c618206680a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 924ff801-8651-4768-bc94-02739fa1eeee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a4a3b6d-a8e3-45c7-bdf3-96447dfc2c4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb485245-8ae4-43b9-b3cf-1f32bce75f58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b586b0a-fe2c-49fc-a4cc-1b5dc3f4b1be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f0364b4-492f-4c14-9f7f-ab25368394ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6aa7bc46-f2ec-4008-a513-ec8762dab7c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be9618f1-65d3-484e-8cde-2c133f1c628f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9dcfcca0-6690-4bf8-adf3-8ac44b06a7df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09b27520-6f5f-43a5-9b39-7b3f64fa8802
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd2e2b86-daaf-46ce-acd0-ab2653168c5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ddf67a4b-b05c-4264-84ab-4dad66ce9fac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66acccd7-073b-4a75-b484-75761c0657c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56a5137e-3dc2-4952-bad8-c5e2fb3a63b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94f5f82d-ad61-4018-ae88-d39d8c810ec8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97d4914a-7e95-4e50-938a-a8e5a5845b70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 492d9da8-c935-4d7a-a144-754f1ce2ef74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cbc3761b-a3aa-4a4d-854c-5d76150ba444
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a9702ef-0170-481a-84ce-5749c5d95a75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ab6a326-e052-42e0-9935-41aac28b006b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88ae38b6-fa04-4715-9831-9600fae2b3ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f552410-f082-4b58-b85e-9c74a931e2d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab727f42-3189-430c-b1bb-3d49d49dba04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7045a7d6-bff2-411a-963e-7596066d1619
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0301b63-9e7f-4fdc-a4ea-aa9f5ae8d79c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5cb335da-da12-4eaa-a884-1ef8396ba573
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2bf69ad2-8e05-4977-9040-a152dfd312d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7d32938-465a-44cc-97c7-fc25797ed4c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 922587f0-a94b-4e4e-a58d-a3f4274f9082
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50296fcf-39cd-4f00-8af1-f94f3496171d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ac9b7bb-0976-4fca-8025-20994606bff6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b70d94b-4b13-4d7e-8be7-76065925d7a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7b3a5cf-cc28-4c9d-b7ad-053e601c36a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d22cb154-a622-4f2d-a1fe-1949d2a42b4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e4472e0-0be5-4a3c-bcb6-2a322027c02c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a338e381-0721-47a0-b7b9-7025148c1d86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90fbf692-81c6-4df2-899f-c635c7c9ccb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d2010eb-2135-40a4-9898-c6befd7f2879
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60d61480-0fd5-4d9c-98d8-b95ed2b2686a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37b48122-5981-4b7a-8f21-99338b1917dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27f97db5-7152-4b31-aadd-7d967abf5e04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4a9c64a-800e-44c2-a802-6752e5cf1ca5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c38c8e1-d250-438e-84ca-c95de33dbebd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a559d3c0-4a14-40e6-b012-f4920fa6adf8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1043d46a-34f3-44b7-823d-5b51215400e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5c3b67a-5d03-4e67-bd7c-9eb367e09597
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 100a7d1d-2f76-4b9c-99f8-bc0a600e1d74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf17f536-9d8e-4a48-984b-0b11f7652f19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd8addf4-ad2c-4ee1-9c38-daf0dbc3c0a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6948a56e-ebff-4fec-9c8c-515ce2af34bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82561351-3cc5-4d23-8c1e-99e452a89a8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90ef9cfd-d277-4ade-9bbd-58632ba3c432
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 510832d9-5548-400a-9683-49652c6f5608
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63006fcc-bd9e-4bf3-9972-23164286ec23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19f72fc3-ba54-4164-9692-01d6b41610e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d68be81-3a30-45c5-aad6-e531560c1f1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc8bddba-0140-43e6-ae4f-653060cc35b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf91126a-5955-4c04-a5e3-be379cca558f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b311f924-1bd4-4e37-86a6-f4c9e5f40b32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c6e7ec1-26e1-4100-adb3-18173450da58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31eb3aa5-b2b4-4081-9721-27afff84f95b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5ea8b32-0ad4-47a0-a245-04406ab79596
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cbc34c41-0bad-4bd3-a657-6eb6c4989c12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d055cbf9-ec8a-4959-9d13-d747e5696eb0
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8692 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_22
Server: localhost:8692
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_22
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_22/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_22/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_22/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_22/test_labels.txt

📊 Raw data loaded:
   Train: X=(3694, 24), y=(3694,)
   Test:  X=(924, 24), y=(924,)

⚠️  Limiting training data: 3694 → 800 samples
⚠️  Limiting test data: 924 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_22 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.5078, RMSE: 0.7126, MAE: 0.6539, R²: -5.3416

============================================================
🔄 Round 4 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.3336, val=0.1156 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0930, val=0.0869 (↓), lr=0.001000
   ✓ Epoch   3/100: train=0.0850, val=0.0782 (↓), lr=0.001000
   • Epoch   4/100: train=0.0816, val=0.0779, patience=1/15, lr=0.001000
   • Epoch   5/100: train=0.0815, val=0.0780, patience=2/15, lr=0.001000
   • Epoch  11/100: train=0.0812, val=0.0781, patience=8/15, lr=0.001000
   📉 Epoch 12: LR reduced 0.001000 → 0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 4 Summary - Client client_22
   Epochs: 18/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0025
   Val:   Loss=0.0782, RMSE=0.2796, R²=-0.0057
============================================================


============================================================
🔄 Round 8 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.3811, val=0.2738 (↓), lr=0.000500
   📉 Epoch 2: LR reduced 0.000500 → 0.000250
   ✓ Epoch   2/100: train=0.1579, val=0.0909 (↓), lr=0.000250
   ✓ Epoch   3/100: train=0.0856, val=0.0830 (↓), lr=0.000250
   • Epoch   4/100: train=0.0809, val=0.0832, patience=1/15, lr=0.000250
   • Epoch   5/100: train=0.0810, val=0.0832, patience=2/15, lr=0.000250
   📉 Epoch 10: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0804, val=0.0835, patience=8/15, lr=0.000125
   📉 Epoch 18: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 8 Summary - Client client_22
   Epochs: 18/100 (early stopped)
   LR: 0.000500 → 0.000063 (3 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0019
   Val:   Loss=0.0830, RMSE=0.2882, R²=0.0032
============================================================


============================================================
🔄 Round 9 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.4473, val=0.3675 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.4018, val=0.3279 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.3620, val=0.2938 (↓), lr=0.000063
   ✓ Epoch   4/100: train=0.3248, val=0.2591 (↓), lr=0.000063
   ✓ Epoch   5/100: train=0.2828, val=0.2169 (↓), lr=0.000063
   📉 Epoch 8: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0837, val=0.0769, patience=1/15, lr=0.000031
   📉 Epoch 16: LR reduced 0.000031 → 0.000016
   • Epoch  21/100: train=0.0819, val=0.0786, patience=11/15, lr=0.000016
   📉 Epoch 24: LR reduced 0.000016 → 0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 9 Summary - Client client_22
   Epochs: 25/100 (early stopped)
   LR: 0.000063 → 0.000008 (3 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0304
   Val:   Loss=0.0768, RMSE=0.2771, R²=-0.0101
============================================================


📊 Round 9 Test Metrics:
   Loss: 0.4673, RMSE: 0.6836, MAE: 0.6222, R²: -4.8355

============================================================
🔄 Round 10 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.4365, val=0.4589 (↓), lr=0.000008
   ✓ Epoch   2/100: train=0.4306, val=0.4526 (↓), lr=0.000008
   ✓ Epoch   3/100: train=0.4248, val=0.4470 (↓), lr=0.000008
   ✓ Epoch   4/100: train=0.4195, val=0.4419 (↓), lr=0.000008
   ✓ Epoch   5/100: train=0.4147, val=0.4371 (↓), lr=0.000008
   📉 Epoch 7: LR reduced 0.000008 → 0.000004
   ✓ Epoch  11/100: train=0.3972, val=0.4206 (↓), lr=0.000004
   📉 Epoch 15: LR reduced 0.000004 → 0.000002
   ✓ Epoch  21/100: train=0.3847, val=0.4084 (↓), lr=0.000002
   📉 Epoch 23: LR reduced 0.000002 → 0.000001
   ✓ Epoch  31/100: train=0.3798, val=0.4035 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.3761, val=0.3997 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.3725, val=0.3960 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.3690, val=0.3924 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.3655, val=0.3888 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.3621, val=0.3853 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.3586, val=0.3817 (↓), lr=0.000001

============================================================
📊 Round 10 Summary - Client client_22
   Epochs: 100/100
   LR: 0.000008 → 0.000001 (3 reductions)
   Train: Loss=0.3554, RMSE=0.5961, R²=-3.4777
   Val:   Loss=0.3786, RMSE=0.6153, R²=-3.2957
============================================================


📊 Round 10 Test Metrics:
   Loss: 0.4564, RMSE: 0.6756, MAE: 0.6134, R²: -4.7002

============================================================
🔄 Round 11 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.4264, val=0.4588 (↓), lr=0.000001
   ✓ Epoch   2/100: train=0.4260, val=0.4583 (↓), lr=0.000001
   • Epoch   3/100: train=0.4255, val=0.4578, patience=1/15, lr=0.000001
   ✓ Epoch   4/100: train=0.4250, val=0.4573 (↓), lr=0.000001
   • Epoch   5/100: train=0.4246, val=0.4568, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.4221, val=0.4542, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.4183, val=0.4503, patience=1/15, lr=0.000001
   • Epoch  31/100: train=0.4147, val=0.4465, patience=1/15, lr=0.000001
   • Epoch  41/100: train=0.4113, val=0.4429, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.4079, val=0.4393, patience=1/15, lr=0.000001
   • Epoch  61/100: train=0.4045, val=0.4358, patience=1/15, lr=0.000001
   • Epoch  71/100: train=0.4011, val=0.4322, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.3977, val=0.4286, patience=1/15, lr=0.000001
   • Epoch  91/100: train=0.3943, val=0.4250, patience=1/15, lr=0.000001

============================================================
📊 Round 11 Summary - Client client_22
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.3907, RMSE=0.6251, R²=-3.8236
   Val:   Loss=0.4217, RMSE=0.6494, R²=-4.2011
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.4476, RMSE: 0.6690, MAE: 0.6062, R²: -4.5897

============================================================
🔄 Round 12 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.4245, val=0.4252 (↓), lr=0.000001
   • Epoch   2/100: train=0.4241, val=0.4248, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.4237, val=0.4244 (↓), lr=0.000001
   • Epoch   4/100: train=0.4233, val=0.4240, patience=1/15, lr=0.000001
   ✓ Epoch   5/100: train=0.4229, val=0.4236 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.4206, val=0.4214 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.4169, val=0.4177 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.4133, val=0.4141 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.4097, val=0.4105 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.4060, val=0.4068 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.4024, val=0.4032 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.3987, val=0.3995 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.3949, val=0.3958 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.3912, val=0.3920 (↓), lr=0.000001

============================================================
📊 Round 12 Summary - Client client_22
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.3870, RMSE=0.6221, R²=-3.7706
   Val:   Loss=0.3886, RMSE=0.6234, R²=-3.7860
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.4118, RMSE: 0.6417, MAE: 0.5759, R²: -4.1421

============================================================
🔄 Round 14 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.3864, val=0.4070 (↓), lr=0.000001
   • Epoch   2/100: train=0.3860, val=0.4066, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.3856, val=0.4062 (↓), lr=0.000001
   • Epoch   4/100: train=0.3852, val=0.4058, patience=1/15, lr=0.000001
   ✓ Epoch   5/100: train=0.3848, val=0.4054 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.3823, val=0.4029 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.3783, val=0.3988 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.3742, val=0.3946 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.3701, val=0.3903 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.3659, val=0.3861 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.3617, val=0.3817 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.3574, val=0.3773 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.3531, val=0.3729 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.3488, val=0.3684 (↓), lr=0.000001

============================================================
📊 Round 14 Summary - Client client_22
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.3439, RMSE=0.5864, R²=-3.2890
   Val:   Loss=0.3644, RMSE=0.6036, R²=-3.2986
============================================================


============================================================
🔄 Round 16 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.3390, val=0.3318 (↓), lr=0.000001
   • Epoch   2/100: train=0.3386, val=0.3313, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.3381, val=0.3309 (↓), lr=0.000001
   • Epoch   4/100: train=0.3376, val=0.3304, patience=1/15, lr=0.000001
   ✓ Epoch   5/100: train=0.3372, val=0.3300 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.3344, val=0.3272 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.3297, val=0.3225 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.3250, val=0.3178 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.3202, val=0.3130 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.3154, val=0.3082 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.3105, val=0.3034 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.3055, val=0.2984 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.3005, val=0.2934 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.2954, val=0.2883 (↓), lr=0.000001

============================================================
📊 Round 16 Summary - Client client_22
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.2909, RMSE=0.5393, R²=-2.5191
   Val:   Loss=0.2836, RMSE=0.5326, R²=-2.7782
============================================================


============================================================
🔄 Round 17 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.3097, val=0.3121 (↓), lr=0.000001
   • Epoch   2/100: train=0.3093, val=0.3117, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.3088, val=0.3112 (↓), lr=0.000001
   • Epoch   4/100: train=0.3083, val=0.3108, patience=1/15, lr=0.000001
   ✓ Epoch   5/100: train=0.3079, val=0.3103 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.3051, val=0.3076 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.3004, val=0.3030 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.2956, val=0.2982 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.2906, val=0.2934 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.2856, val=0.2884 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.2804, val=0.2833 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.2751, val=0.2780 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.2696, val=0.2726 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.2641, val=0.2671 (↓), lr=0.000001

============================================================
📊 Round 17 Summary - Client client_22
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.2588, RMSE=0.5088, R²=-2.2450
   Val:   Loss=0.2620, RMSE=0.5119, R²=-2.0250
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.3085, RMSE: 0.5554, MAE: 0.4785, R²: -2.8526

============================================================
🔄 Round 18 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.2916, val=0.2864 (↓), lr=0.000001
   • Epoch   2/100: train=0.2911, val=0.2859, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.2906, val=0.2854 (↓), lr=0.000001
   • Epoch   4/100: train=0.2902, val=0.2849, patience=1/15, lr=0.000001
   ✓ Epoch   5/100: train=0.2897, val=0.2845 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.2868, val=0.2816 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.2819, val=0.2767 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.2769, val=0.2716 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.2718, val=0.2664 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.2665, val=0.2611 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.2610, val=0.2556 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.2554, val=0.2500 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.2497, val=0.2442 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.2438, val=0.2383 (↓), lr=0.000001

============================================================
📊 Round 18 Summary - Client client_22
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.2384, RMSE=0.4883, R²=-1.8838
   Val:   Loss=0.2329, RMSE=0.4826, R²=-2.1053
============================================================


============================================================
🔄 Round 19 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.2624, val=0.2733 (↓), lr=0.000001
   ✓ Epoch   2/100: train=0.2618, val=0.2728 (↓), lr=0.000001
   ✓ Epoch   3/100: train=0.2613, val=0.2722 (↓), lr=0.000001
   ✓ Epoch   4/100: train=0.2608, val=0.2717 (↓), lr=0.000001
   ✓ Epoch   5/100: train=0.2603, val=0.2712 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.2571, val=0.2679 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.2517, val=0.2622 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.2461, val=0.2565 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.2404, val=0.2505 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.2346, val=0.2445 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.2286, val=0.2383 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.2226, val=0.2319 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.2164, val=0.2255 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.2102, val=0.2190 (↓), lr=0.000001

============================================================
📊 Round 19 Summary - Client client_22
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.2039, RMSE=0.4516, R²=-1.5126
   Val:   Loss=0.2131, RMSE=0.4616, R²=-1.6340
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.2082, RMSE: 0.4562, MAE: 0.3781, R²: -1.5995

============================================================
🔄 Round 21 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1966, val=0.1910 (↓), lr=0.000001
   ✓ Epoch   2/100: train=0.1959, val=0.1904 (↓), lr=0.000001
   ✓ Epoch   3/100: train=0.1952, val=0.1897 (↓), lr=0.000001
   ✓ Epoch   4/100: train=0.1946, val=0.1890 (↓), lr=0.000001
   ✓ Epoch   5/100: train=0.1939, val=0.1883 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.1899, val=0.1843 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.1832, val=0.1776 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.1767, val=0.1710 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.1702, val=0.1645 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.1639, val=0.1582 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.1577, val=0.1519 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.1516, val=0.1459 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.1458, val=0.1400 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.1401, val=0.1343 (↓), lr=0.000001

============================================================
📊 Round 21 Summary - Client client_22
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1350, RMSE=0.3674, R²=-0.6408
   Val:   Loss=0.1294, RMSE=0.3597, R²=-0.6871
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.1461, RMSE: 0.3823, MAE: 0.3140, R²: -0.8250

📊 Round 21 Test Metrics:
   Loss: 0.0959, RMSE: 0.3097, MAE: 0.2595, R²: -0.1981

============================================================
🔄 Round 26 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0929 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0929, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0929, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0929, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0929, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0929, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0929)

============================================================
📊 Round 26 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0374
   Val:   Loss=0.0929, RMSE=0.3047, R²=-0.0087
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2458, R²: -0.0374

============================================================
🔄 Round 27 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 27 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0246
   Val:   Loss=0.0796, RMSE=0.2820, R²=0.0028
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2449, R²: -0.0277

============================================================
🔄 Round 29 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0924 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0924, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0924, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0923, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 29 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=-0.0167
   Val:   Loss=0.0924, RMSE=0.3039, R²=0.0004
============================================================


============================================================
🔄 Round 32 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 32 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0100
   Val:   Loss=0.0734, RMSE=0.2709, R²=-0.0009
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2439, R²: -0.0178

============================================================
🔄 Round 33 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 33 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0066
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0156
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2439, R²: -0.0175

============================================================
🔄 Round 36 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 36 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0104
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0114
============================================================


============================================================
🔄 Round 38 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 38 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=-0.0093
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0003
============================================================


============================================================
🔄 Round 39 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 39 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0065
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0222
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2438, R²: -0.0162

============================================================
🔄 Round 40 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 40 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=-0.0068
   Val:   Loss=0.0903, RMSE=0.3005, R²=-0.0151
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0814, RMSE: 0.2852, MAE: 0.2438, R²: -0.0160

============================================================
🔄 Round 41 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 41 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0083
   Val:   Loss=0.0882, RMSE=0.2970, R²=-0.0032
============================================================


============================================================
🔄 Round 42 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 42 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=-0.0056
   Val:   Loss=0.0796, RMSE=0.2822, R²=-0.0240
============================================================


============================================================
🔄 Round 43 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 43 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0054
   Val:   Loss=0.0778, RMSE=0.2790, R²=-0.0306
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2437, R²: -0.0146

============================================================
🔄 Round 45 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 45 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0091
   Val:   Loss=0.0829, RMSE=0.2880, R²=-0.0080
============================================================


============================================================
🔄 Round 46 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 46 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0083
   Val:   Loss=0.0870, RMSE=0.2949, R²=-0.0118
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2436, R²: -0.0137

============================================================
🔄 Round 47 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 47 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0069
   Val:   Loss=0.0787, RMSE=0.2805, R²=-0.0076
============================================================


📊 Round 47 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2436, R²: -0.0136

============================================================
🔄 Round 48 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0964 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0964, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0964, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0964, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0964, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0963, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0964)

============================================================
📊 Round 48 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2792, R²=-0.0030
   Val:   Loss=0.0964, RMSE=0.3104, R²=-0.0174
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2435, R²: -0.0127

============================================================
🔄 Round 53 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 53 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0063
   Val:   Loss=0.0757, RMSE=0.2751, R²=-0.0066
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2434, R²: -0.0114

============================================================
🔄 Round 57 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 57 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=-0.0007
   Val:   Loss=0.0903, RMSE=0.3004, R²=-0.0294
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2434, R²: -0.0106

📊 Round 57 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2433, R²: -0.0098

============================================================
🔄 Round 62 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 62 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0059
   Val:   Loss=0.0763, RMSE=0.2761, R²=-0.0217
============================================================


============================================================
🔄 Round 63 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0931 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0931, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0931, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0931, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0931, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0931, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0931)

============================================================
📊 Round 63 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=-0.0068
   Val:   Loss=0.0931, RMSE=0.3052, R²=-0.0015
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2433, R²: -0.0098

📊 Round 63 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2433, R²: -0.0093

📊 Round 63 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2433, R²: -0.0093

============================================================
🔄 Round 66 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 66 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0101
   Val:   Loss=0.0791, RMSE=0.2812, R²=-0.0010
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2433, R²: -0.0093

📊 Round 66 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2433, R²: -0.0093

📊 Round 66 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2433, R²: -0.0092

📊 Round 66 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2432, R²: -0.0092

============================================================
🔄 Round 76 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 76 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0060
   Val:   Loss=0.0777, RMSE=0.2788, R²=-0.0117
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2433, R²: -0.0095

📊 Round 76 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2433, R²: -0.0095

============================================================
🔄 Round 83 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 83 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0019
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0348
============================================================


============================================================
🔄 Round 85 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 85 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0066
   Val:   Loss=0.0844, RMSE=0.2906, R²=-0.0033
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2432, R²: -0.0091

📊 Round 85 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2432, R²: -0.0090

============================================================
🔄 Round 87 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 87 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0070
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0105
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2433, R²: -0.0094

============================================================
🔄 Round 90 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 90 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0054
   Val:   Loss=0.0786, RMSE=0.2803, R²=-0.0069
============================================================


============================================================
🔄 Round 92 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 92 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0078
   Val:   Loss=0.0772, RMSE=0.2779, R²=0.0013
============================================================


============================================================
🔄 Round 96 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 96 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0056
   Val:   Loss=0.0775, RMSE=0.2783, R²=-0.0216
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2433, R²: -0.0094

============================================================
🔄 Round 99 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 99 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0041
   Val:   Loss=0.0775, RMSE=0.2783, R²=-0.0309
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2433, R²: -0.0098

============================================================
🔄 Round 100 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 100 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0080
   Val:   Loss=0.0825, RMSE=0.2873, R²=-0.0193
============================================================


============================================================
🔄 Round 101 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 101 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=-0.0032
   Val:   Loss=0.0904, RMSE=0.3006, R²=-0.0136
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2433, R²: -0.0101

============================================================
🔄 Round 102 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 102 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=-0.0058
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0189
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2434, R²: -0.0109

============================================================
🔄 Round 105 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 105 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0053
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0085
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2434, R²: -0.0108

============================================================
🔄 Round 111 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 111 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0075
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0332
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0809, RMSE: 0.2843, MAE: 0.2433, R²: -0.0097

============================================================
🔄 Round 112 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 112 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0084
   Val:   Loss=0.0867, RMSE=0.2944, R²=0.0011
============================================================


============================================================
🔄 Round 115 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 115 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=-0.0054
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0100
============================================================


============================================================
🔄 Round 116 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 116 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=-0.0041
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0124
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2433, R²: -0.0095

📊 Round 116 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2432, R²: -0.0091

📊 Round 116 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2432, R²: -0.0091

============================================================
🔄 Round 121 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 121 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=-0.0086
   Val:   Loss=0.0756, RMSE=0.2749, R²=0.0010
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2432, R²: -0.0086

============================================================
🔄 Round 122 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 122 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0040
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0147
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2432, R²: -0.0090

============================================================
🔄 Round 124 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0680 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0680, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0680, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0681, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0681, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0682, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0680)

============================================================
📊 Round 124 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0062
   Val:   Loss=0.0680, RMSE=0.2608, R²=-0.0285
============================================================


============================================================
🔄 Round 125 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 125 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0043
   Val:   Loss=0.0786, RMSE=0.2803, R²=-0.0141
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2432, R²: -0.0085

📊 Round 125 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2431, R²: -0.0083

============================================================
🔄 Round 131 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 131 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0064
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0080
============================================================


============================================================
🔄 Round 134 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 134 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0092
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0242
============================================================


============================================================
🔄 Round 135 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 135 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2822, R²=-0.0031
   Val:   Loss=0.0891, RMSE=0.2985, R²=-0.0121
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2432, R²: -0.0085

============================================================
🔄 Round 136 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 136 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0039
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0111
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2432, R²: -0.0085

📊 Round 136 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2432, R²: -0.0085

============================================================
🔄 Round 142 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 142 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0051
   Val:   Loss=0.0743, RMSE=0.2727, R²=-0.0047
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2431, R²: -0.0080

============================================================
🔄 Round 145 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 145 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0051
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0111
============================================================


============================================================
🔄 Round 148 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 148 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=-0.0067
   Val:   Loss=0.0907, RMSE=0.3012, R²=-0.0017
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2432, R²: -0.0084

============================================================
🔄 Round 151 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 151 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=-0.0060
   Val:   Loss=0.0871, RMSE=0.2952, R²=-0.0028
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0807, RMSE: 0.2842, MAE: 0.2431, R²: -0.0084

📊 Round 151 Test Metrics:
   Loss: 0.0807, RMSE: 0.2842, MAE: 0.2431, R²: -0.0084

============================================================
🔄 Round 153 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 153 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0061
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0004
============================================================


============================================================
🔄 Round 154 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0709 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0709, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0709, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0709, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0709, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0709, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0709)

============================================================
📊 Round 154 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0037
   Val:   Loss=0.0709, RMSE=0.2663, R²=-0.0121
============================================================


============================================================
🔄 Round 156 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 156 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0058
   Val:   Loss=0.0732, RMSE=0.2706, R²=-0.0054
============================================================


============================================================
🔄 Round 158 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 158 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0078
   Val:   Loss=0.0729, RMSE=0.2700, R²=0.0053
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2432, R²: -0.0089

============================================================
🔄 Round 159 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 159 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0069
   Val:   Loss=0.0854, RMSE=0.2922, R²=0.0018
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2432, R²: -0.0088

📊 Round 159 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2432, R²: -0.0088

============================================================
🔄 Round 161 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 161 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=-0.0055
   Val:   Loss=0.0818, RMSE=0.2859, R²=-0.0034
============================================================


============================================================
🔄 Round 165 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 165 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2878, R²=-0.0042
   Val:   Loss=0.0762, RMSE=0.2761, R²=-0.0090
============================================================


============================================================
🔄 Round 170 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 170 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0027
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0258
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0807, RMSE: 0.2842, MAE: 0.2431, R²: -0.0084

📊 Round 170 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2432, R²: -0.0087

============================================================
🔄 Round 174 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 174 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=-0.0013
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0211
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2432, R²: -0.0086

📊 Round 174 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2432, R²: -0.0086

============================================================
🔄 Round 177 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 177 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0047
   Val:   Loss=0.0838, RMSE=0.2896, R²=-0.0073
============================================================


============================================================
🔄 Round 178 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 178 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0038
   Val:   Loss=0.0844, RMSE=0.2904, R²=-0.0082
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2431, R²: -0.0085

============================================================
🔄 Round 182 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 182 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0035
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0095
============================================================


============================================================
🔄 Round 184 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 184 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0022
   Val:   Loss=0.0775, RMSE=0.2785, R²=-0.0166
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2431, R²: -0.0082

📊 Round 184 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2431, R²: -0.0081

============================================================
🔄 Round 186 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 186 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0074
   Val:   Loss=0.0822, RMSE=0.2868, R²=0.0042
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2431, R²: -0.0083

============================================================
🔄 Round 187 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 187 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0047
   Val:   Loss=0.0768, RMSE=0.2771, R²=-0.0048
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2431, R²: -0.0083

📊 Round 187 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2431, R²: -0.0080

============================================================
🔄 Round 191 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 191 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=-0.0048
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0037
============================================================


============================================================
🔄 Round 192 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 192 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0051
   Val:   Loss=0.0771, RMSE=0.2776, R²=-0.0150
============================================================


📊 Round 192 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2431, R²: -0.0080

📊 Round 192 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2431, R²: -0.0080

📊 Round 192 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2431, R²: -0.0083

📊 Round 192 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2431, R²: -0.0082

============================================================
🔄 Round 200 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 200 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0045
   Val:   Loss=0.0797, RMSE=0.2824, R²=-0.0049
============================================================


============================================================
🔄 Round 201 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 201 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=-0.0035
   Val:   Loss=0.0770, RMSE=0.2774, R²=-0.0239
============================================================


============================================================
🔄 Round 202 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 202 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0062
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0195
============================================================


📊 Round 202 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2431, R²: -0.0082

============================================================
🔄 Round 203 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 203 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0063
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0023
============================================================


📊 Round 203 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2431, R²: -0.0085

============================================================
🔄 Round 204 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 204 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=-0.0055
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0005
============================================================


============================================================
🔄 Round 205 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 205 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0062
   Val:   Loss=0.0756, RMSE=0.2749, R²=0.0013
============================================================


📊 Round 205 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2432, R²: -0.0088

============================================================
🔄 Round 206 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 206 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=-0.0053
   Val:   Loss=0.0737, RMSE=0.2716, R²=-0.0336
============================================================


📊 Round 206 Test Metrics:
   Loss: 0.0807, RMSE: 0.2842, MAE: 0.2431, R²: -0.0084

📊 Round 206 Test Metrics:
   Loss: 0.0807, RMSE: 0.2842, MAE: 0.2431, R²: -0.0084

============================================================
🔄 Round 208 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 208 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0039
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0091
============================================================


============================================================
🔄 Round 210 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 210 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0069
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0007
============================================================


📊 Round 210 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2432, R²: -0.0087

📊 Round 210 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2432, R²: -0.0087

============================================================
🔄 Round 213 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 213 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0037
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0075
============================================================


📊 Round 213 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2432, R²: -0.0088

📊 Round 213 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2431, R²: -0.0086

============================================================
🔄 Round 217 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0715 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0715, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0715, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0715, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0715, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0715, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0715)

============================================================
📊 Round 217 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0067
   Val:   Loss=0.0715, RMSE=0.2674, R²=0.0060
============================================================


📊 Round 217 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2432, R²: -0.0089

📊 Round 217 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2432, R²: -0.0089

📊 Round 217 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2431, R²: -0.0085

📊 Round 217 Test Metrics:
   Loss: 0.0807, RMSE: 0.2842, MAE: 0.2431, R²: -0.0084

📊 Round 217 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2431, R²: -0.0086

📊 Round 217 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2431, R²: -0.0086

============================================================
🔄 Round 231 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 231 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0069
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0068
============================================================


============================================================
🔄 Round 232 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 232 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0067
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0188
============================================================


============================================================
🔄 Round 233 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 233 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0065
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0488
============================================================


============================================================
🔄 Round 234 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 234 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0058
   Val:   Loss=0.0771, RMSE=0.2776, R²=-0.0097
============================================================


📊 Round 234 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2431, R²: -0.0080

============================================================
🔄 Round 235 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 235 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0037
   Val:   Loss=0.0822, RMSE=0.2866, R²=-0.0105
============================================================


📊 Round 235 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2431, R²: -0.0079

============================================================
🔄 Round 238 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 238 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0077
   Val:   Loss=0.0759, RMSE=0.2755, R²=0.0101
============================================================


📊 Round 238 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2430, R²: -0.0076

============================================================
🔄 Round 239 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0940 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0940, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0940, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0940, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0940, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0940, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0940)

============================================================
📊 Round 239 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=-0.0043
   Val:   Loss=0.0940, RMSE=0.3065, R²=-0.0061
============================================================


============================================================
🔄 Round 240 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 240 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0055
   Val:   Loss=0.0809, RMSE=0.2844, R²=-0.0057
============================================================


📊 Round 240 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2431, R²: -0.0080

============================================================
🔄 Round 243 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 243 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0044
   Val:   Loss=0.0751, RMSE=0.2741, R²=-0.0091
============================================================


📊 Round 243 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2430, R²: -0.0076

============================================================
🔄 Round 246 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 246 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0050
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0016
============================================================


📊 Round 246 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2430, R²: -0.0076

============================================================
🔄 Round 248 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 248 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0031
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0109
============================================================


============================================================
🔄 Round 250 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0702 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0702, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0702, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0702, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0702, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0702, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0702)

============================================================
📊 Round 250 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0054
   Val:   Loss=0.0702, RMSE=0.2650, R²=0.0010
============================================================


📊 Round 250 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2431, R²: -0.0080

============================================================
🔄 Round 253 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 253 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=-0.0042
   Val:   Loss=0.0903, RMSE=0.3006, R²=-0.0047
============================================================


============================================================
🔄 Round 254 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 254 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0036
   Val:   Loss=0.0839, RMSE=0.2896, R²=-0.0141
============================================================


📊 Round 254 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2431, R²: -0.0080

============================================================
🔄 Round 255 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 255 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0009
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0254
============================================================


📊 Round 255 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2431, R²: -0.0080

📊 Round 255 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2431, R²: -0.0084

============================================================
🔄 Round 258 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 258 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=-0.0025
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0109
============================================================


📊 Round 258 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2431, R²: -0.0081

============================================================
🔄 Round 261 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 261 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=-0.0055
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0210
============================================================


📊 Round 261 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2431, R²: -0.0082

============================================================
🔄 Round 268 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 268 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=-0.0054
   Val:   Loss=0.0752, RMSE=0.2742, R²=-0.0004
============================================================


============================================================
🔄 Round 270 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 270 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0015
   Val:   Loss=0.0755, RMSE=0.2747, R²=-0.0231
============================================================


============================================================
🔄 Round 271 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 271 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0044
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0092
============================================================


📊 Round 271 Test Metrics:
   Loss: 0.0807, RMSE: 0.2842, MAE: 0.2431, R²: -0.0083

📊 Round 271 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2431, R²: -0.0083

📊 Round 271 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2431, R²: -0.0082

============================================================
🔄 Round 277 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 277 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2856, R²=-0.0017
   Val:   Loss=0.0812, RMSE=0.2849, R²=-0.0140
============================================================


📊 Round 277 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2431, R²: -0.0082

📊 Round 277 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2431, R²: -0.0081

============================================================
🔄 Round 279 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 279 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=-0.0037
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0075
============================================================


📊 Round 279 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2430, R²: -0.0077

============================================================
🔄 Round 281 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 281 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0042
   Val:   Loss=0.0726, RMSE=0.2695, R²=-0.0058
============================================================


============================================================
🔄 Round 283 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 283 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0053
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0011
============================================================


📊 Round 283 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2430, R²: -0.0077

============================================================
🔄 Round 285 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 285 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=-0.0031
   Val:   Loss=0.0903, RMSE=0.3005, R²=-0.0093
============================================================


📊 Round 285 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2430, R²: -0.0077

📊 Round 285 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2430, R²: -0.0077

============================================================
🔄 Round 288 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 288 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0041
   Val:   Loss=0.0741, RMSE=0.2722, R²=-0.0073
============================================================


📊 Round 288 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2430, R²: -0.0073

============================================================
🔄 Round 290 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 290 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0019
   Val:   Loss=0.0844, RMSE=0.2906, R²=-0.0346
============================================================


📊 Round 290 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2430, R²: -0.0073

============================================================
🔄 Round 291 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 291 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0024
   Val:   Loss=0.0820, RMSE=0.2863, R²=-0.0112
============================================================


📊 Round 291 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2430, R²: -0.0070

============================================================
🔄 Round 292 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 292 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=-0.0033
   Val:   Loss=0.0800, RMSE=0.2829, R²=-0.0208
============================================================


📊 Round 292 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2430, R²: -0.0069

============================================================
🔄 Round 294 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 294 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0031
   Val:   Loss=0.0858, RMSE=0.2930, R²=-0.0132
============================================================


📊 Round 294 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2429, R²: -0.0067

============================================================
🔄 Round 296 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0935 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0935, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0935, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0935, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0935, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0935, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0935)

============================================================
📊 Round 296 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=-0.0030
   Val:   Loss=0.0935, RMSE=0.3058, R²=-0.0109
============================================================


📊 Round 296 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2430, R²: -0.0071

============================================================
🔄 Round 298 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 298 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=-0.0013
   Val:   Loss=0.0883, RMSE=0.2971, R²=-0.0158
============================================================


📊 Round 298 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2430, R²: -0.0076

📊 Round 298 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2430, R²: -0.0076

============================================================
🔄 Round 306 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 306 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0046
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0066
============================================================


📊 Round 306 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2430, R²: -0.0076

============================================================
🔄 Round 307 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 307 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=-0.0035
   Val:   Loss=0.0814, RMSE=0.2854, R²=-0.0300
============================================================


📊 Round 307 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2430, R²: -0.0076

============================================================
🔄 Round 309 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 309 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0052
   Val:   Loss=0.0768, RMSE=0.2772, R²=0.0011
============================================================


============================================================
🔄 Round 310 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 310 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0069
   Val:   Loss=0.0834, RMSE=0.2887, R²=-0.0197
============================================================


============================================================
🔄 Round 311 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 311 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=-0.0047
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0021
============================================================


📊 Round 311 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2430, R²: -0.0075

============================================================
🔄 Round 314 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 314 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0025
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0098
============================================================


📊 Round 314 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2430, R²: -0.0075

============================================================
🔄 Round 315 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 315 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=-0.0041
   Val:   Loss=0.0847, RMSE=0.2911, R²=-0.0103
============================================================


📊 Round 315 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2430, R²: -0.0075

============================================================
🔄 Round 316 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 316 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0019
   Val:   Loss=0.0849, RMSE=0.2913, R²=-0.0149
============================================================


📊 Round 316 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2430, R²: -0.0075

📊 Round 316 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2430, R²: -0.0074

📊 Round 316 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2430, R²: -0.0074

📊 Round 316 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2430, R²: -0.0076

============================================================
🔄 Round 324 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 324 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0057
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0028
============================================================


📊 Round 324 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2430, R²: -0.0077

============================================================
🔄 Round 325 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 325 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0045
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0062
============================================================


============================================================
🔄 Round 326 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 326 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0026
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0145
============================================================


📊 Round 326 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2430, R²: -0.0076

============================================================
🔄 Round 327 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 327 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0027
   Val:   Loss=0.0736, RMSE=0.2712, R²=-0.0114
============================================================


📊 Round 327 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2430, R²: -0.0072

============================================================
🔄 Round 328 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 328 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0016
   Val:   Loss=0.0785, RMSE=0.2801, R²=-0.0140
============================================================


📊 Round 328 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2430, R²: -0.0073

📊 Round 328 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2430, R²: -0.0072

============================================================
🔄 Round 332 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 332 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0044
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0038
============================================================


============================================================
🔄 Round 333 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 333 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0040
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0041
============================================================


📊 Round 333 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2430, R²: -0.0072

📊 Round 333 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2429, R²: -0.0068

📊 Round 333 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2429, R²: -0.0068

📊 Round 333 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2429, R²: -0.0068

============================================================
🔄 Round 341 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 341 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0050
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0003
============================================================


📊 Round 341 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2430, R²: -0.0073

📊 Round 341 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2430, R²: -0.0073

============================================================
🔄 Round 347 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 347 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0055
   Val:   Loss=0.0756, RMSE=0.2749, R²=-0.0094
============================================================


============================================================
🔄 Round 348 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 348 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0043
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0162
============================================================


============================================================
🔄 Round 349 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 349 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0037
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0228
============================================================


📊 Round 349 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2430, R²: -0.0073

============================================================
🔄 Round 354 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0706 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0706, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0706, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0706, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0706, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0706, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0706)

============================================================
📊 Round 354 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0033
   Val:   Loss=0.0706, RMSE=0.2656, R²=-0.0085
============================================================


📊 Round 354 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2430, R²: -0.0073

============================================================
🔄 Round 357 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 357 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0069
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0211
============================================================


============================================================
🔄 Round 359 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 359 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0044
   Val:   Loss=0.0771, RMSE=0.2777, R²=-0.0038
============================================================


📊 Round 359 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2430, R²: -0.0073

📊 Round 359 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2430, R²: -0.0076

============================================================
🔄 Round 364 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 364 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=-0.0032
   Val:   Loss=0.0886, RMSE=0.2977, R²=-0.0075
============================================================


============================================================
🔄 Round 365 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 365 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0048
   Val:   Loss=0.0782, RMSE=0.2796, R²=-0.0420
============================================================


📊 Round 365 Test Metrics:
   Loss: 0.0807, RMSE: 0.2842, MAE: 0.2431, R²: -0.0083

============================================================
🔄 Round 366 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 366 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=-0.0051
   Val:   Loss=0.0891, RMSE=0.2984, R²=-0.0006
============================================================


============================================================
🔄 Round 367 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 367 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0049
   Val:   Loss=0.0775, RMSE=0.2783, R²=-0.0024
============================================================


============================================================
🔄 Round 368 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 368 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=-0.0044
   Val:   Loss=0.0831, RMSE=0.2882, R²=-0.0067
============================================================


📊 Round 368 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2431, R²: -0.0082

============================================================
🔄 Round 369 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 369 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2808, R²=-0.0013
   Val:   Loss=0.0918, RMSE=0.3029, R²=-0.0122
============================================================


📊 Round 369 Test Metrics:
   Loss: 0.0807, RMSE: 0.2842, MAE: 0.2431, R²: -0.0083

📊 Round 369 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2431, R²: -0.0085

============================================================
🔄 Round 375 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 375 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0037
   Val:   Loss=0.0753, RMSE=0.2743, R²=-0.0097
============================================================


============================================================
🔄 Round 376 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 376 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2856, R²=-0.0042
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0016
============================================================


============================================================
🔄 Round 377 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 377 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0041
   Val:   Loss=0.0768, RMSE=0.2771, R²=-0.0132
============================================================


📊 Round 377 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2431, R²: -0.0087

============================================================
🔄 Round 379 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 379 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0025
   Val:   Loss=0.0771, RMSE=0.2776, R²=-0.0109
============================================================


📊 Round 379 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2431, R²: -0.0085

📊 Round 379 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2431, R²: -0.0083

============================================================
🔄 Round 381 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 381 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0060
   Val:   Loss=0.0764, RMSE=0.2765, R²=-0.0179
============================================================


📊 Round 381 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2431, R²: -0.0083

============================================================
🔄 Round 384 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 384 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0025
   Val:   Loss=0.0742, RMSE=0.2724, R²=-0.0135
============================================================


============================================================
🔄 Round 385 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0725, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 385 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2892, R²=-0.0043
   Val:   Loss=0.0725, RMSE=0.2693, R²=-0.0072
============================================================


📊 Round 385 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2431, R²: -0.0085

📊 Round 385 Test Metrics:
   Loss: 0.0807, RMSE: 0.2842, MAE: 0.2431, R²: -0.0084

============================================================
🔄 Round 387 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 387 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0017
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0116
============================================================


📊 Round 387 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2431, R²: -0.0088

============================================================
🔄 Round 388 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 388 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0019
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0111
============================================================


📊 Round 388 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2431, R²: -0.0082

============================================================
🔄 Round 392 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 392 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0041
   Val:   Loss=0.0819, RMSE=0.2863, R²=-0.0105
============================================================


============================================================
🔄 Round 394 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 394 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0017
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0144
============================================================


============================================================
🔄 Round 395 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 395 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0007
   Val:   Loss=0.0831, RMSE=0.2882, R²=-0.0160
============================================================


📊 Round 395 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2430, R²: -0.0081

============================================================
🔄 Round 397 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 397 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0044
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0031
============================================================


📊 Round 397 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2430, R²: -0.0081

============================================================
🔄 Round 402 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 402 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0049
   Val:   Loss=0.0802, RMSE=0.2831, R²=-0.0021
============================================================


📊 Round 402 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2430, R²: -0.0077

============================================================
🔄 Round 404 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 404 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0047
   Val:   Loss=0.0757, RMSE=0.2752, R²=-0.0036
============================================================


📊 Round 404 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2430, R²: -0.0077

============================================================
🔄 Round 405 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 405 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0055
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0011
============================================================


📊 Round 405 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2430, R²: -0.0074

============================================================
🔄 Round 409 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 409 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0048
   Val:   Loss=0.0818, RMSE=0.2861, R²=0.0011
============================================================


📊 Round 409 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2430, R²: -0.0074

============================================================
🔄 Round 410 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 410 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0017
   Val:   Loss=0.0766, RMSE=0.2767, R²=-0.0113
============================================================


============================================================
🔄 Round 411 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 411 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=-0.0038
   Val:   Loss=0.0923, RMSE=0.3038, R²=-0.0199
============================================================


📊 Round 411 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2430, R²: -0.0074

============================================================
🔄 Round 413 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 413 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0048
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0019
============================================================


📊 Round 413 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2430, R²: -0.0074

📊 Round 413 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2430, R²: -0.0077

============================================================
🔄 Round 417 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 417 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0008
   Val:   Loss=0.0860, RMSE=0.2932, R²=-0.0189
============================================================


============================================================
🔄 Round 419 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 419 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0045
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0023
============================================================


📊 Round 419 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2430, R²: -0.0079

📊 Round 419 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2430, R²: -0.0078

📊 Round 419 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2430, R²: -0.0077

📊 Round 419 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2430, R²: -0.0077

============================================================
🔄 Round 425 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 425 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0018
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0102
============================================================


📊 Round 425 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2430, R²: -0.0077

📊 Round 425 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2430, R²: -0.0076

============================================================
🔄 Round 428 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 428 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=-0.0049
   Val:   Loss=0.0902, RMSE=0.3003, R²=-0.0065
============================================================


📊 Round 428 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2430, R²: -0.0076

============================================================
🔄 Round 430 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 430 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2856, R²=-0.0054
   Val:   Loss=0.0809, RMSE=0.2844, R²=-0.0182
============================================================


============================================================
🔄 Round 431 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 431 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0040
   Val:   Loss=0.0782, RMSE=0.2797, R²=-0.0059
============================================================


============================================================
🔄 Round 432 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 432 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0008
   Val:   Loss=0.0869, RMSE=0.2948, R²=-0.0215
============================================================


============================================================
🔄 Round 433 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 433 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2856, R²=-0.0037
   Val:   Loss=0.0809, RMSE=0.2844, R²=-0.0314
============================================================


📊 Round 433 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2430, R²: -0.0075

📊 Round 433 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2430, R²: -0.0073

============================================================
🔄 Round 439 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 439 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0035
   Val:   Loss=0.0738, RMSE=0.2716, R²=-0.0045
============================================================


============================================================
🔄 Round 440 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 440 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0029
   Val:   Loss=0.0817, RMSE=0.2857, R²=-0.0057
============================================================


📊 Round 440 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2430, R²: -0.0076

============================================================
🔄 Round 442 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 442 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=-0.0041
   Val:   Loss=0.0909, RMSE=0.3015, R²=-0.0030
============================================================


📊 Round 442 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2430, R²: -0.0076

============================================================
🔄 Round 444 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 444 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0030
   Val:   Loss=0.0801, RMSE=0.2829, R²=-0.0052
============================================================


============================================================
🔄 Round 445 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 445 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0048
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0314
============================================================


📊 Round 445 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2430, R²: -0.0078

============================================================
🔄 Round 446 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 446 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0036
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0149
============================================================


📊 Round 446 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2430, R²: -0.0078

📊 Round 446 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2430, R²: -0.0077

============================================================
🔄 Round 453 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 453 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2863, R²=-0.0028
   Val:   Loss=0.0793, RMSE=0.2815, R²=-0.0393
============================================================


📊 Round 453 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2430, R²: -0.0077

📊 Round 453 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2430, R²: -0.0075

============================================================
🔄 Round 457 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 457 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=-0.0053
   Val:   Loss=0.0849, RMSE=0.2914, R²=0.0041
============================================================


📊 Round 457 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2430, R²: -0.0076

📊 Round 457 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2430, R²: -0.0076

============================================================
🔄 Round 460 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 460 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0036
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0103
============================================================


============================================================
🔄 Round 462 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 462 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0024
   Val:   Loss=0.0736, RMSE=0.2712, R²=-0.0272
============================================================


📊 Round 462 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2430, R²: -0.0074

============================================================
🔄 Round 463 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 463 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0028
   Val:   Loss=0.0842, RMSE=0.2901, R²=-0.0060
============================================================


============================================================
🔄 Round 464 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 464 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0026
   Val:   Loss=0.0809, RMSE=0.2845, R²=-0.0084
============================================================


📊 Round 464 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2430, R²: -0.0074

📊 Round 464 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2429, R²: -0.0073

📊 Round 464 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2430, R²: -0.0073

📊 Round 464 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2429, R²: -0.0071

📊 Round 464 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2429, R²: -0.0072

📊 Round 464 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2429, R²: -0.0073

📊 Round 464 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2429, R²: -0.0073

📊 Round 464 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2429, R²: -0.0073

============================================================
🔄 Round 473 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 473 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0058
   Val:   Loss=0.0758, RMSE=0.2753, R²=0.0034
============================================================


============================================================
🔄 Round 474 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0716 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0716, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0716, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0716, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0717, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0717, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0716)

============================================================
📊 Round 474 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2896, R²=-0.0043
   Val:   Loss=0.0716, RMSE=0.2676, R²=-0.0155
============================================================


============================================================
🔄 Round 475 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 475 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0020
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0154
============================================================


📊 Round 475 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2430, R²: -0.0077

============================================================
🔄 Round 477 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 477 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0031
   Val:   Loss=0.0754, RMSE=0.2745, R²=-0.0044
============================================================


📊 Round 477 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2430, R²: -0.0077

📊 Round 477 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2430, R²: -0.0077

============================================================
🔄 Round 479 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 479 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0051
   Val:   Loss=0.0763, RMSE=0.2762, R²=0.0048
============================================================


============================================================
🔄 Round 480 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 480 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0057
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0012
============================================================


============================================================
🔄 Round 481 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0670 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0670, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0670, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0670, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0670, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0670, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0670)

============================================================
📊 Round 481 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0033
   Val:   Loss=0.0670, RMSE=0.2588, R²=-0.0059
============================================================


📊 Round 481 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2429, R²: -0.0073

📊 Round 481 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2429, R²: -0.0073

📊 Round 481 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2429, R²: -0.0073

============================================================
🔄 Round 486 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0922 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0922, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0922, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0922, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0922, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0922, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0922)

============================================================
📊 Round 486 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=-0.0039
   Val:   Loss=0.0922, RMSE=0.3036, R²=-0.0007
============================================================


📊 Round 486 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2429, R²: -0.0073

============================================================
🔄 Round 488 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 488 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0032
   Val:   Loss=0.0775, RMSE=0.2784, R²=-0.0031
============================================================


📊 Round 488 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2429, R²: -0.0071

📊 Round 488 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2429, R²: -0.0072

============================================================
🔄 Round 492 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 492 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0040
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0006
============================================================


📊 Round 492 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2429, R²: -0.0072

============================================================
🔄 Round 494 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 494 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0036
   Val:   Loss=0.0742, RMSE=0.2724, R²=-0.0068
============================================================


📊 Round 494 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2429, R²: -0.0071

============================================================
🔄 Round 496 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 496 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0046
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0113
============================================================


============================================================
🔄 Round 497 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 497 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0041
   Val:   Loss=0.0759, RMSE=0.2755, R²=0.0007
============================================================


📊 Round 497 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2429, R²: -0.0073

============================================================
🔄 Round 499 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 499 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0021
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0073
============================================================


============================================================
🔄 Round 500 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 500 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=-0.0042
   Val:   Loss=0.0907, RMSE=0.3012, R²=-0.0034
============================================================


📊 Round 500 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2429, R²: -0.0073

============================================================
🔄 Round 501 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 501 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0038
   Val:   Loss=0.0759, RMSE=0.2754, R²=-0.0147
============================================================


📊 Round 501 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2429, R²: -0.0072

============================================================
🔄 Round 503 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 503 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0014
   Val:   Loss=0.0758, RMSE=0.2753, R²=-0.0109
============================================================


📊 Round 503 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2429, R²: -0.0073

============================================================
🔄 Round 506 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 506 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0045
   Val:   Loss=0.0833, RMSE=0.2887, R²=0.0008
============================================================


📊 Round 506 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2429, R²: -0.0072

============================================================
🔄 Round 508 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 508 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0037
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0013
============================================================


📊 Round 508 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2429, R²: -0.0072

📊 Round 508 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2429, R²: -0.0070

📊 Round 508 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2429, R²: -0.0070

📊 Round 508 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2429, R²: -0.0070

============================================================
🔄 Round 518 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0721, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0721, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 518 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0006
   Val:   Loss=0.0721, RMSE=0.2684, R²=-0.0234
============================================================


📊 Round 518 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2429, R²: -0.0069

📊 Round 518 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2429, R²: -0.0070

============================================================
🔄 Round 521 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 521 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0061
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0082
============================================================


============================================================
🔄 Round 522 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 522 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0027
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0071
============================================================


============================================================
🔄 Round 523 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 523 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0054
   Val:   Loss=0.0814, RMSE=0.2853, R²=-0.0015
============================================================


📊 Round 523 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2429, R²: -0.0069

============================================================
🔄 Round 524 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 524 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=-0.0014
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0107
============================================================


============================================================
🔄 Round 525 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 525 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2835, R²=-0.0038
   Val:   Loss=0.0855, RMSE=0.2925, R²=-0.0117
============================================================


📊 Round 525 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2429, R²: -0.0066

============================================================
🔄 Round 526 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 526 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0041
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0054
============================================================


📊 Round 526 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2429, R²: -0.0066

============================================================
🔄 Round 527 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 527 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2877, R²=-0.0027
   Val:   Loss=0.0759, RMSE=0.2755, R²=-0.0046
============================================================


📊 Round 527 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2429, R²: -0.0067

📊 Round 527 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2429, R²: -0.0073

============================================================
🔄 Round 533 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 533 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0042
   Val:   Loss=0.0786, RMSE=0.2803, R²=-0.0210
============================================================


📊 Round 533 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2429, R²: -0.0072

📊 Round 533 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2430, R²: -0.0076

============================================================
🔄 Round 536 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 536 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0038
   Val:   Loss=0.0755, RMSE=0.2747, R²=-0.0076
============================================================


📊 Round 536 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2430, R²: -0.0077

============================================================
🔄 Round 538 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 538 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0017
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0352
============================================================


📊 Round 538 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2429, R²: -0.0072

============================================================
🔄 Round 541 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 541 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2878, R²=-0.0032
   Val:   Loss=0.0755, RMSE=0.2747, R²=-0.0020
============================================================


📊 Round 541 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2429, R²: -0.0068

============================================================
🔄 Round 542 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 542 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0012
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0095
============================================================


📊 Round 542 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2429, R²: -0.0069

============================================================
🔄 Round 546 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 546 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0055
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0064
============================================================


============================================================
🔄 Round 547 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 547 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0034
   Val:   Loss=0.0807, RMSE=0.2840, R²=-0.0023
============================================================


============================================================
🔄 Round 548 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 548 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=-0.0035
   Val:   Loss=0.0894, RMSE=0.2989, R²=-0.0096
============================================================


📊 Round 548 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2429, R²: -0.0071

============================================================
🔄 Round 550 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 550 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=-0.0043
   Val:   Loss=0.0827, RMSE=0.2875, R²=0.0024
============================================================


📊 Round 550 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2429, R²: -0.0071

📊 Round 550 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2429, R²: -0.0068

============================================================
🔄 Round 555 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 555 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0045
   Val:   Loss=0.0778, RMSE=0.2790, R²=0.0010
============================================================


📊 Round 555 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2429, R²: -0.0071

📊 Round 555 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2429, R²: -0.0071

============================================================
🔄 Round 561 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0661 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0661, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0661, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0661, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0661, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0661, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0661)

============================================================
📊 Round 561 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0003
   Val:   Loss=0.0661, RMSE=0.2572, R²=-0.0170
============================================================


📊 Round 561 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2429, R²: -0.0068

============================================================
🔄 Round 564 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 564 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0024
   Val:   Loss=0.0789, RMSE=0.2808, R²=-0.0050
============================================================


📊 Round 564 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2429, R²: -0.0072

============================================================
🔄 Round 565 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 565 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2863, R²=-0.0030
   Val:   Loss=0.0791, RMSE=0.2812, R²=-0.0241
============================================================


============================================================
🔄 Round 566 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 566 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0034
   Val:   Loss=0.0837, RMSE=0.2894, R²=-0.0117
============================================================


📊 Round 566 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2429, R²: -0.0071

============================================================
🔄 Round 567 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 567 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0020
   Val:   Loss=0.0820, RMSE=0.2863, R²=-0.0135
============================================================


============================================================
🔄 Round 568 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 568 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0039
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0032
============================================================


📊 Round 568 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2429, R²: -0.0067

============================================================
🔄 Round 570 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 570 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=-0.0040
   Val:   Loss=0.0902, RMSE=0.3004, R²=-0.0038
============================================================


📊 Round 570 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2429, R²: -0.0070

============================================================
🔄 Round 571 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 571 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0028
   Val:   Loss=0.0737, RMSE=0.2716, R²=-0.0153
============================================================


📊 Round 571 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2429, R²: -0.0069

============================================================
🔄 Round 573 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 573 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0037
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0000
============================================================


============================================================
🔄 Round 574 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 574 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0000
   Val:   Loss=0.0846, RMSE=0.2908, R²=-0.0142
============================================================


📊 Round 574 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2429, R²: -0.0069

📊 Round 574 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2429, R²: -0.0072

============================================================
🔄 Round 576 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 576 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0051
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0102
============================================================


============================================================
🔄 Round 577 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 577 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=-0.0014
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0096
============================================================


============================================================
🔄 Round 578 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 578 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0048
   Val:   Loss=0.0791, RMSE=0.2813, R²=0.0051
============================================================


📊 Round 578 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2429, R²: -0.0069

============================================================
🔄 Round 579 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 579 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2870, R²=-0.0012
   Val:   Loss=0.0775, RMSE=0.2783, R²=-0.0133
============================================================


============================================================
🔄 Round 580 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 580 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0041
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0224
============================================================


============================================================
🔄 Round 581 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 581 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0022
   Val:   Loss=0.0768, RMSE=0.2771, R²=-0.0075
============================================================


============================================================
🔄 Round 582 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 582 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0019
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0071
============================================================


============================================================
🔄 Round 584 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 584 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0037
   Val:   Loss=0.0795, RMSE=0.2819, R²=-0.0077
============================================================


============================================================
🔄 Round 585 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 585 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0028
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0066
============================================================


📊 Round 585 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2428, R²: -0.0065

============================================================
🔄 Round 586 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 586 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2842, R²=-0.0037
   Val:   Loss=0.0839, RMSE=0.2896, R²=-0.0008
============================================================


📊 Round 586 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2428, R²: -0.0065

============================================================
🔄 Round 591 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 591 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0047
   Val:   Loss=0.0831, RMSE=0.2883, R²=0.0040
============================================================


📊 Round 591 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2428, R²: -0.0064

📊 Round 591 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2428, R²: -0.0064

============================================================
🔄 Round 599 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 599 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0016
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0093
============================================================


============================================================
🔄 Round 600 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 600 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=-0.0010
   Val:   Loss=0.0847, RMSE=0.2911, R²=-0.0100
============================================================


📊 Round 600 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2429, R²: -0.0066

============================================================
🔄 Round 601 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 601 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=-0.0019
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0097
============================================================


============================================================
🔄 Round 602 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0725, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 602 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0025
   Val:   Loss=0.0725, RMSE=0.2693, R²=-0.0065
============================================================


============================================================
🔄 Round 603 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 603 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0032
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0272
============================================================


📊 Round 603 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2428, R²: -0.0065

============================================================
🔄 Round 605 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0690 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0690, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0690, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0690, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0690, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0690, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0690)

============================================================
📊 Round 605 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0002
   Val:   Loss=0.0690, RMSE=0.2627, R²=-0.0159
============================================================


============================================================
🔄 Round 608 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 608 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0047
   Val:   Loss=0.0776, RMSE=0.2785, R²=-0.0081
============================================================


📊 Round 608 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2428, R²: -0.0064

============================================================
🔄 Round 612 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0703 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0703, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0703, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0703, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0703, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0703, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0703)

============================================================
📊 Round 612 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0041
   Val:   Loss=0.0703, RMSE=0.2652, R²=0.0014
============================================================


📊 Round 612 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2429, R²: -0.0067

============================================================
🔄 Round 615 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 615 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2849, R²=-0.0046
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0202
============================================================


📊 Round 615 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2429, R²: -0.0072

============================================================
🔄 Round 618 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 618 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0044
   Val:   Loss=0.0817, RMSE=0.2859, R²=-0.0060
============================================================


📊 Round 618 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2429, R²: -0.0069

============================================================
🔄 Round 619 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 619 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=-0.0038
   Val:   Loss=0.0863, RMSE=0.2937, R²=-0.0054
============================================================


📊 Round 619 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2428, R²: -0.0066

============================================================
🔄 Round 621 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 621 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0030
   Val:   Loss=0.0786, RMSE=0.2804, R²=-0.0017
============================================================


📊 Round 621 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2428, R²: -0.0066

============================================================
🔄 Round 622 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 622 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0048
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0025
============================================================


============================================================
🔄 Round 624 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 624 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0038
   Val:   Loss=0.0814, RMSE=0.2853, R²=-0.0153
============================================================


📊 Round 624 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2428, R²: -0.0066

============================================================
🔄 Round 625 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 625 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=-0.0035
   Val:   Loss=0.0897, RMSE=0.2995, R²=-0.0004
============================================================


============================================================
🔄 Round 629 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 629 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0032
   Val:   Loss=0.0829, RMSE=0.2880, R²=-0.0051
============================================================


📊 Round 629 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2428, R²: -0.0066

📊 Round 629 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2428, R²: -0.0065

============================================================
🔄 Round 631 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 631 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0044
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0159
============================================================


📊 Round 631 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2429, R²: -0.0067

📊 Round 631 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2429, R²: -0.0068

📊 Round 631 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2429, R²: -0.0067

============================================================
🔄 Round 634 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 634 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0047
   Val:   Loss=0.0857, RMSE=0.2927, R²=0.0048
============================================================


📊 Round 634 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2429, R²: -0.0068

📊 Round 634 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2429, R²: -0.0067

============================================================
🔄 Round 636 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 636 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0013
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0082
============================================================


📊 Round 636 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2429, R²: -0.0067

============================================================
🔄 Round 638 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 638 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=-0.0047
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0033
============================================================


📊 Round 638 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2428, R²: -0.0065

📊 Round 638 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2428, R²: -0.0065

============================================================
🔄 Round 641 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 641 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=-0.0023
   Val:   Loss=0.0906, RMSE=0.3009, R²=-0.0055
============================================================


============================================================
🔄 Round 642 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 642 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0026
   Val:   Loss=0.0782, RMSE=0.2796, R²=-0.0159
============================================================


============================================================
🔄 Round 643 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 643 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=-0.0014
   Val:   Loss=0.0896, RMSE=0.2993, R²=-0.0117
============================================================


📊 Round 643 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2428, R²: -0.0065

============================================================
🔄 Round 645 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 645 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0030
   Val:   Loss=0.0726, RMSE=0.2695, R²=-0.0015
============================================================


📊 Round 645 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2428, R²: -0.0065

📊 Round 645 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2428, R²: -0.0065

============================================================
🔄 Round 648 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 648 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0019
   Val:   Loss=0.0823, RMSE=0.2868, R²=-0.0058
============================================================


📊 Round 648 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2428, R²: -0.0065

============================================================
🔄 Round 649 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 649 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0033
   Val:   Loss=0.0821, RMSE=0.2866, R²=-0.0048
============================================================


📊 Round 649 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2428, R²: -0.0066

============================================================
🔄 Round 651 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 651 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0001
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0126
============================================================


📊 Round 651 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2428, R²: -0.0066

============================================================
🔄 Round 652 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0709 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0709, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0709, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0709, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0709, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0709, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0709)

============================================================
📊 Round 652 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0051
   Val:   Loss=0.0709, RMSE=0.2663, R²=0.0084
============================================================


📊 Round 652 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2428, R²: -0.0062

📊 Round 652 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2428, R²: -0.0064

============================================================
🔄 Round 657 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 657 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0037
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0013
============================================================


📊 Round 657 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2428, R²: -0.0066

📊 Round 657 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2428, R²: -0.0065

============================================================
🔄 Round 663 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 663 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0026
   Val:   Loss=0.0754, RMSE=0.2746, R²=-0.0057
============================================================


============================================================
🔄 Round 667 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 667 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=-0.0054
   Val:   Loss=0.0765, RMSE=0.2766, R²=0.0011
============================================================


📊 Round 667 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2429, R²: -0.0069

📊 Round 667 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2429, R²: -0.0068

============================================================
🔄 Round 670 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 670 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0007
   Val:   Loss=0.0742, RMSE=0.2725, R²=-0.0183
============================================================


📊 Round 670 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2429, R²: -0.0068

============================================================
🔄 Round 671 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 671 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0033
   Val:   Loss=0.0741, RMSE=0.2722, R²=-0.0071
============================================================


============================================================
🔄 Round 672 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 672 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0034
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0796
============================================================


============================================================
🔄 Round 674 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 674 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0027
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0081
============================================================


============================================================
🔄 Round 675 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 675 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0019
   Val:   Loss=0.0880, RMSE=0.2967, R²=-0.0057
============================================================


============================================================
🔄 Round 676 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 676 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0039
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0052
============================================================


============================================================
🔄 Round 677 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 677 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0041
   Val:   Loss=0.0799, RMSE=0.2826, R²=-0.0060
============================================================


📊 Round 677 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2428, R²: -0.0065

============================================================
🔄 Round 678 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 678 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0036
   Val:   Loss=0.0800, RMSE=0.2828, R²=-0.0172
============================================================


📊 Round 678 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2428, R²: -0.0064

📊 Round 678 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2428, R²: -0.0064

============================================================
🔄 Round 683 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 683 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0038
   Val:   Loss=0.0775, RMSE=0.2783, R²=-0.0086
============================================================


📊 Round 683 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2428, R²: -0.0064

📊 Round 683 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2428, R²: -0.0064

============================================================
🔄 Round 685 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 685 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0029
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0057
============================================================


📊 Round 685 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2428, R²: -0.0065

📊 Round 685 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2428, R²: -0.0064

============================================================
🔄 Round 689 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 689 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=-0.0045
   Val:   Loss=0.0781, RMSE=0.2795, R²=-0.0137
============================================================


📊 Round 689 Test Metrics:
   Loss: 0.0806, RMSE: 0.2838, MAE: 0.2428, R²: -0.0061

📊 Round 689 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2428, R²: -0.0065

📊 Round 689 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2428, R²: -0.0065

============================================================
🔄 Round 695 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0700 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0700, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0700, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0700, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0700, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0701, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0700)

============================================================
📊 Round 695 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0028
   Val:   Loss=0.0700, RMSE=0.2646, R²=-0.0085
============================================================


📊 Round 695 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2429, R²: -0.0069

============================================================
🔄 Round 696 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 696 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=-0.0009
   Val:   Loss=0.0781, RMSE=0.2794, R²=-0.0126
============================================================


📊 Round 696 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2428, R²: -0.0068

📊 Round 696 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2428, R²: -0.0068

📊 Round 696 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2428, R²: -0.0069

📊 Round 696 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2428, R²: -0.0068

============================================================
🔄 Round 702 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 702 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0006
   Val:   Loss=0.0812, RMSE=0.2849, R²=-0.0104
============================================================


============================================================
🔄 Round 703 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 703 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=-0.0028
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0047
============================================================


📊 Round 703 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2428, R²: -0.0069

============================================================
🔄 Round 705 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 705 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0022
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0150
============================================================


============================================================
🔄 Round 706 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 706 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0039
   Val:   Loss=0.0853, RMSE=0.2920, R²=-0.0015
============================================================


📊 Round 706 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2428, R²: -0.0068

📊 Round 706 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2428, R²: -0.0069

📊 Round 706 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2428, R²: -0.0069

📊 Round 706 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2428, R²: -0.0068

============================================================
🔄 Round 711 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 711 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=-0.0008
   Val:   Loss=0.0809, RMSE=0.2844, R²=-0.0113
============================================================


📊 Round 711 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2429, R²: -0.0069

📊 Round 711 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2428, R²: -0.0068

============================================================
🔄 Round 714 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 714 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0005
   Val:   Loss=0.0747, RMSE=0.2733, R²=-0.0116
============================================================


📊 Round 714 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2429, R²: -0.0071

============================================================
🔄 Round 716 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 716 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0029
   Val:   Loss=0.0798, RMSE=0.2826, R²=-0.0012
============================================================


============================================================
🔄 Round 717 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 717 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0044
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0014
============================================================


============================================================
🔄 Round 718 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 718 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=0.0001
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0189
============================================================


📊 Round 718 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2429, R²: -0.0070

============================================================
🔄 Round 720 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 720 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0023
   Val:   Loss=0.0839, RMSE=0.2896, R²=-0.0040
============================================================


📊 Round 720 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2429, R²: -0.0070

📊 Round 720 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2429, R²: -0.0070

📊 Round 720 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2428, R²: -0.0068

📊 Round 720 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2428, R²: -0.0068

============================================================
🔄 Round 726 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 726 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0005
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0197
============================================================


📊 Round 726 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2428, R²: -0.0067

📊 Round 726 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2428, R²: -0.0067

============================================================
🔄 Round 731 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 731 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0024
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0024
============================================================


📊 Round 731 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2428, R²: -0.0063

============================================================
🔄 Round 734 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 734 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0014
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0075
============================================================


============================================================
🔄 Round 735 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 735 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0021
   Val:   Loss=0.0847, RMSE=0.2911, R²=-0.0039
============================================================


📊 Round 735 Test Metrics:
   Loss: 0.0806, RMSE: 0.2838, MAE: 0.2428, R²: -0.0060

📊 Round 735 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2428, R²: -0.0067

📊 Round 735 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2428, R²: -0.0064

============================================================
🔄 Round 741 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 741 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0036
   Val:   Loss=0.0774, RMSE=0.2781, R²=-0.0104
============================================================


📊 Round 741 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2428, R²: -0.0063

============================================================
🔄 Round 742 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 742 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=-0.0015
   Val:   Loss=0.0885, RMSE=0.2975, R²=-0.0059
============================================================


============================================================
🔄 Round 743 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 743 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=-0.0035
   Val:   Loss=0.0745, RMSE=0.2729, R²=-0.0198
============================================================


📊 Round 743 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2428, R²: -0.0063

============================================================
🔄 Round 744 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 744 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0050
   Val:   Loss=0.0737, RMSE=0.2715, R²=0.0078
============================================================


📊 Round 744 Test Metrics:
   Loss: 0.0806, RMSE: 0.2838, MAE: 0.2428, R²: -0.0060

📊 Round 744 Test Metrics:
   Loss: 0.0806, RMSE: 0.2838, MAE: 0.2428, R²: -0.0060

============================================================
🔄 Round 748 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 748 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0025
   Val:   Loss=0.0791, RMSE=0.2812, R²=-0.0068
============================================================


📊 Round 748 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2427, R²: -0.0058

============================================================
🔄 Round 749 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 749 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0040
   Val:   Loss=0.0784, RMSE=0.2801, R²=0.0037
============================================================


📊 Round 749 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2427, R²: -0.0058

📊 Round 749 Test Metrics:
   Loss: 0.0806, RMSE: 0.2838, MAE: 0.2428, R²: -0.0061

📊 Round 749 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2428, R²: -0.0062

📊 Round 749 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2428, R²: -0.0066

============================================================
🔄 Round 758 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 758 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0041
   Val:   Loss=0.0814, RMSE=0.2852, R²=0.0042
============================================================


📊 Round 758 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2428, R²: -0.0069

============================================================
🔄 Round 760 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0698 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0698, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0698, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0699, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0699, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0699, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0698)

============================================================
📊 Round 760 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0030
   Val:   Loss=0.0698, RMSE=0.2642, R²=-0.0135
============================================================


============================================================
🔄 Round 762 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 762 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0016
   Val:   Loss=0.0777, RMSE=0.2788, R²=-0.0190
============================================================


============================================================
🔄 Round 763 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 763 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0020
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0039
============================================================


📊 Round 763 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2429, R²: -0.0072

📊 Round 763 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2429, R²: -0.0071

============================================================
🔄 Round 767 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 767 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0014
   Val:   Loss=0.0831, RMSE=0.2884, R²=-0.0103
============================================================


📊 Round 767 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2428, R²: -0.0070

============================================================
🔄 Round 768 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 768 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=-0.0027
   Val:   Loss=0.0893, RMSE=0.2988, R²=-0.0033
============================================================


============================================================
🔄 Round 769 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0929 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0929, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0930, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0930, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0930, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0933, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0929)

============================================================
📊 Round 769 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2801, R²=-0.0037
   Val:   Loss=0.0929, RMSE=0.3048, R²=-0.0455
============================================================


📊 Round 769 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2429, R²: -0.0072

============================================================
🔄 Round 770 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 770 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0022
   Val:   Loss=0.0869, RMSE=0.2948, R²=-0.0131
============================================================


============================================================
🔄 Round 772 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 772 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0032
   Val:   Loss=0.0765, RMSE=0.2766, R²=-0.0142
============================================================


📊 Round 772 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2428, R²: -0.0068

============================================================
🔄 Round 774 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 774 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0037
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0034
============================================================


📊 Round 774 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2428, R²: -0.0065

============================================================
🔄 Round 777 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 777 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0018
   Val:   Loss=0.0802, RMSE=0.2833, R²=-0.0045
============================================================


📊 Round 777 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2428, R²: -0.0064

============================================================
🔄 Round 778 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 778 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0030
   Val:   Loss=0.0759, RMSE=0.2756, R²=0.0004
============================================================


📊 Round 778 Test Metrics:
   Loss: 0.0806, RMSE: 0.2838, MAE: 0.2428, R²: -0.0062

============================================================
🔄 Round 779 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 779 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0048
   Val:   Loss=0.0798, RMSE=0.2824, R²=-0.0193
============================================================


============================================================
🔄 Round 781 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 781 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=-0.0024
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0022
============================================================


📊 Round 781 Test Metrics:
   Loss: 0.0806, RMSE: 0.2838, MAE: 0.2428, R²: -0.0061

📊 Round 781 Test Metrics:
   Loss: 0.0806, RMSE: 0.2838, MAE: 0.2428, R²: -0.0061

❌ Client client_22 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8692 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8692 {grpc_status:14, grpc_message:"Socket closed"}"
>
