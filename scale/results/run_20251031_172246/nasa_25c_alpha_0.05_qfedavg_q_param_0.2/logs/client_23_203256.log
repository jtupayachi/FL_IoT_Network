[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e95c2306-16cf-47a5-b49f-db7674fa9d80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e32176e-2551-4fc7-b6c9-74274497bd09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5de2233f-681b-4538-9d3f-645580929929
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6611165-28ff-42ed-95c0-a7fdc8669d60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b7387a8-36ba-493a-8efb-5508205a9da7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bcdc15f0-ca46-412f-9cb4-1d4e10c2ee25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6242edc2-5556-47a1-b43f-d693a27991bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e63bf1b-9376-46a6-8e5f-709fa3dff692
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d3519be-84bb-4329-af62-3049a58b4541
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12eb9be6-13bb-4f61-aee9-509eb4554742
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5fa203c6-6b5b-4a9f-bd58-2097ef5a3364
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a57abf2c-0581-4ead-bcea-4bc8709a7959
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78581a34-ab9e-41a3-b8b0-f6694e718886
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f75a87d6-8ac4-440b-ad35-7b88557fb1bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f76cb78-aba8-43e6-a45b-cb1a76218bde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 037109d9-ae23-4251-8774-f3778510d8df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cbf5b165-c970-4d4a-9b2a-3a3ac18ef80b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38f536a1-79ea-4d6b-96bb-4c39e10ede00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28110580-31c2-45ac-8a7e-cef390bacf94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5678452-c6fe-42b2-9b50-1ab9d92a7bb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3a0aa4e-975f-4d8f-ab03-d87da00c385e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45995d1d-3cb1-4d19-b239-f07b035d968d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 858e37c7-e72a-42b6-8475-f1402e84f04b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7da6f790-34c3-46cb-8044-748096e494cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63a8aa2e-ce16-4cb5-94fe-b73c66ed101e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b7a052b-797f-4d6a-a6a0-83bf0db3a117
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50820209-8c19-40ec-8a68-f749ed8decc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9ff1eb0-d54e-492d-946a-b86fcda7bbea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ed5628d-966d-49c7-86c0-dccd7bce6ec2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97b1fe2d-4709-4e17-a4a5-89026e37c569
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91a379eb-97f7-4d7e-902e-800c5887bcaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84af1d5c-1aad-4398-b3c9-9124f09c716d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e14f1544-f916-4d82-9941-21aa96d9d62a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94ea8011-d798-453d-ab1f-c6ff6307121f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c5a21e7-3447-4080-a82b-3dea5a296119
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e287580-e598-40e1-a6ae-f14ad3659568
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94daec58-d107-403a-a7c8-77ae200c6f49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6515ab62-c840-4a7a-afa9-de40de8e59a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb059573-7b78-4244-b707-0fc32eeb6837
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0a0e88f-704d-4ab3-acf1-060979837229
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7524003-ba24-42d0-837f-ad5958dd352e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf553c90-79b8-407e-9831-f5f9ccaab29f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14fe6870-6276-446a-8bef-9f1e5d8f71af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 403512b3-d180-4564-a20a-a37003a19adb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cff30d32-38d4-43c1-bbdb-6c1beae7540e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38fee132-584d-405b-9d83-9c77d1faf0f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39c581a3-5aeb-4d0b-8b45-b5b172681eb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39051487-9cae-4a8c-af78-de17fba633c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 282117b7-4a7e-46d1-98f8-652f29798fca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cff09bb3-8aea-41b4-a2a0-53bc77eb14ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0611492-1ed7-4add-9091-e1d4e285a99f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32dfdb7b-c79b-499b-8bfe-e7b17c3a293a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 891f1a9b-2a72-4eb8-8284-ee2a1ff23e0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36d9509c-aba1-4fee-b5d8-169fafe8cb83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc95f7be-6c44-4489-8855-5999056d4769
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa205339-1914-4771-ad8d-1058971444d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3d203f8-bad4-45bb-acd6-5e76a3dcb328
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 720a71b0-6e12-4d6b-8457-ca7467888d8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf644a7f-e0d9-49de-93e4-e6c0ee06640d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be625e5f-1ae6-4eb8-ac2b-e16d1d436f0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d95a14f-394a-4f5e-bae5-796790819829
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message edbcdc5c-447f-48a3-b313-51e2a1b5ff00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ac639a7-5f20-43fa-a4a9-9519722cf079
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3c3fe90-b945-4c32-9652-fab23eb710a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92fa60cc-bc14-49d9-96e5-ccb5f6e3466c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0b5dc86-a6ed-4324-bcd7-79ab7da7cf0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 812c0c5f-282b-463c-874b-7603a4cb7330
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4371c86-8e18-4c59-a736-22e99744e895
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1894cef6-95a0-46eb-bcce-63fe7ec6b5b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ae9b259-cc4c-4e43-b08e-10f8fa19f191
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c43c7956-022c-4bb7-9142-c0d7e6056c8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53033378-a46b-4056-800d-23744cb40c2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b34462c-4f52-4021-b946-de44e79b2c2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc81e1ad-51fc-485a-a9f3-b2da37b0901a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a40409f4-c8f1-48da-89ac-3f880feb8eb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fcc3a6d8-2446-4555-8d81-52640c43fc28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba423296-98ff-450c-8ada-0ef92dc64f97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa67fd0e-40fa-4eaf-8007-43c592d69292
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17982963-ffcc-49f3-9e3b-2607ef63422a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb065480-3be5-47a3-8d2f-1e524022ced8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6070cf1-b04c-49b3-91a4-2a01d47d6a58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da76da6a-edc8-413f-bb08-b30751bfac5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32778c8f-675c-4809-87df-cd7f24e1a290
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ae8e818-a4d0-405c-a56e-af4875c05053
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2409005c-305b-45eb-8d05-c820746ca5d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39c27aa3-c88a-4be6-b88e-5cf022b485db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 163ceda5-15d7-4f24-a2cc-18c24805e87f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67821720-e1b9-413b-897c-5bcac41ec7ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9ad7de7-6b05-4e11-ad1c-30db73c5186e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6818219-d0de-4454-a314-dbbf12531f22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad665c2f-e51a-4b0c-9500-a80b489f4d1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f02619c-a80c-4648-a43e-8b4b9ee09aad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 164727d4-68fa-4b94-b448-1d0a43e4167c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 724bfbcf-8aed-4b79-9b3c-5b75f3561653
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4c5c926-a256-48d3-831c-985cdd3cc5a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8a5536b-19fa-4e97-bc4f-506cb5631a46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a489d51c-7903-4361-9bc2-cf0820e456a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d06ff2c9-151b-48de-8686-56ae795e5847
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9611c38b-9f25-4151-a6b5-f9ad0d800f2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a30aa8e-ce00-4898-ac7c-a42d33f8c854
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 121303a8-4ba8-46a1-9400-1c7294a8d322
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f55e29d-4e20-4b2e-8fad-5e2e09e01fe6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6127491-e491-4fbf-9d7c-903ac89ed471
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68eddd05-5c2e-4b27-9211-5b987233d6a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72e76790-efc1-42e5-81c4-9c9643e074a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f0e4546-fc25-41a9-87ca-e994a01e7056
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d58005d-b3ef-4db3-941c-e3d05793e74c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 011dd5a0-b114-48f6-9b38-e3d9fb1c572c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16588163-78ab-433c-a693-91b57b1d64c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d0a5ace-e245-4aa1-b3da-a50f7bee1bf8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3123fe30-660a-41d9-85dc-e868fa8b5363
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8895d29-16bf-4c22-94a9-09efca9d3c47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e76e2ba2-1f48-4fdd-aff4-53d2c7b8885c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c76f085-8251-4192-9b6e-fcfae346b887
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9cd6832-68b7-4c04-af26-ac184e78684e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c2657f9-3c09-4d76-beb7-50a1df6f0e4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13954604-253e-4269-974c-dfae44cb926c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9fe5154d-cda8-4386-8732-f4179d173957
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12847ffe-b548-401a-90c5-d4ca7bc5e1f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8dbdb7ca-a36d-43d4-b85d-0aaca3d9ec36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8d77532-a0a7-4c1d-b3a3-77dcedeb9fe2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7d32ad9-3dca-4f82-a93c-61620bb3aab8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bda35a0b-af9f-4b4c-85c7-2956bc71b315
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3cc6cd99-3ee4-42a1-b5c1-e0ec6ab7179c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 090bd882-2c05-449c-9956-38c4dc4b3712
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e207abea-9be0-446b-a15a-85410fffb042
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b45f095f-911e-4292-98fc-12dc892f99ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f641daf1-f594-4923-81ce-4be2d1579e9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92db6006-0c34-4ba6-a093-e1cf1f9a7379
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 395d59b4-5da5-44b8-89a7-ca386f72a944
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3b76ad2-8443-43cf-a60d-cea3fad30722
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2018467-c12d-4a24-a3e5-b0e8825f766c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4e75e99-ba86-43fe-97f7-85c8011fcda1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11fc962d-5a87-4b4d-8bc5-497e8b30ed7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b47e817e-e5aa-4a89-93c2-e2f6f3c12796
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 522f2204-8a52-473b-a4a7-0f30d81fded3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a691bcf-a156-4477-a8a3-8bbb4fb2fc64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c54e5bdd-e0c8-47c3-8e28-f2ccb3696852
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c3af2ea-f4dc-4288-bd39-71a29408d7a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0939ec4b-266c-448b-92d4-522c1cb60f66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae6099f5-6b6f-42fd-a8e3-38002aedde41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1c676e9-24dc-46d1-929a-81b680c5e08b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6716bc33-cc3a-4034-882e-d397ba605989
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8e1c4ef-3537-483c-8e36-2e6c84ef9491
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 698559a9-e166-4738-9380-c82317391f0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff362a54-7ad5-4448-9079-e197ae603ff4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 601d8e2f-6bd8-477c-b0d8-e742a76493df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 693ef649-02c2-482b-9e88-aca3f501c364
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05568abd-6a1d-44fd-bcda-f7c031514c31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97093b5d-db2b-4d02-b72e-cabf6cbd7d09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9bd9a1ec-6acc-4cb8-b083-62cabcab43ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 872ba735-d514-4531-9e5d-6f3830a3933c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ed7c52f-f46e-49d6-89f2-0a06304615c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a354730-d039-4a41-a5c6-d6a3399a2b65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b593ff7-910b-415a-a567-950b736a6739
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ffe9e53-7567-4463-9452-15c37f4156df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1fe9ffac-b0c4-4eac-9e25-3b9de29c39e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51ac92f1-d3b7-4372-8198-2bd6bb5997b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac240b7d-c14d-40a2-b850-1f73dac21f7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c084a14-cf42-4ca2-a0dc-fb2ebb1065bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed39e896-8398-4b0b-a280-96874299be7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76de7bf9-df16-4f85-bf0d-9de0ed922114
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0e7f155-ba81-4038-bcea-c74e876a34be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c813b04f-f880-435c-a08b-6453510677da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1df02c83-5da0-4ed7-9084-630d9024af8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16e03abf-daae-430e-845e-3822fc78105e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34bd04d9-c2d2-4cec-95b7-cc7bd024955d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 941f7cba-1779-45ed-b3ed-dcc76e042e68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 953e213f-a639-4094-8d9c-4de374ac4695
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6302edc4-f8f3-49bf-9431-25e4f84ab092
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c430556-7090-472c-8ef1-ee1adfb74b91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d788c720-ae50-4576-8f42-150f7e99cd5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8692885c-c71e-4960-bb60-8cec5b264bfa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d13b68e8-e3c0-420c-a93f-dc6e1d2570d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5cd6650f-49ce-496c-9d60-1cc0ef31db8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 306d986e-f13c-48cd-9771-9b72d85e1b8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3749491-ddbd-4541-af40-fe50ceea8e73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f61faed7-de12-41c7-97de-bb34196e7d46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2434df81-4755-431e-a8b0-ed43315a094d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 045db4dc-362d-4903-bd4e-b8cb949b0772
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d0cfd50-7381-4a58-ac3b-2090cd37f989
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92db7d75-db2e-4f6e-8d7b-5cf409de8574
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c84dd127-ffa5-4100-ab07-d38a812b8a82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9abcaa9f-7302-4aba-87d8-705bd25a7983
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63ed4024-e4d2-4888-b5bf-aeda74df171a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2952eaa7-cd9b-4c90-b63f-249d44e6a80a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29cbfdf8-87b9-453c-af02-82995e469e9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 594cba60-a916-42d5-8842-548686cbad6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aeb73ef0-8d5e-4d96-bb62-079efe62f37c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f89a172-eb10-419d-a638-96242670af54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6998ca8-33d5-4499-8ae9-54827296cd76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06353e01-1cd8-426c-a04c-8533700febf6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e8eb680-034c-4256-b18a-cecadc045351
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 736512d3-779f-4fe8-8391-e583b46896e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62fa10f8-ac7e-48e8-81d1-b9f93eb515d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 200a41b3-fc8b-44d0-b8aa-146bf818d926
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83a52401-7dd6-416e-a597-9fd8828192dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f958518-e8a4-4076-8aae-0729d4b27d0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f773344e-6b97-4d19-8fa5-47f987b0add5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d67633e-401c-4be3-8bf0-5ab75731e4b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7155b997-3aec-4b00-b2f5-05dd2d486303
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39d5030e-77b1-4087-ad43-997246c0fb20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c90ff5f5-380d-4dca-bdac-ba20d01f134d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 913d2b38-e684-438b-bf5d-375dbe44f21d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7255361c-3b51-4877-812f-11e98e634f7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 330eb31d-ed40-401d-a692-061e8be73568
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b193e278-d62f-47f2-ac75-70207f941b85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af7847be-363e-42ae-bad7-cd30dfa78fbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message efee557b-e4d3-4664-bf67-a1847b630697
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 941ece1e-13de-406b-8603-183416350907
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f536e16d-cf88-4421-b8a8-34efbbb98c81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d6cbefe-1a6a-461e-a9c7-d3d05db73ce2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 927c327d-5e43-4238-99dd-ee485d6250ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d84334bc-55bf-4718-a436-32aebd918038
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc2de1be-f734-4a97-bcd4-52b3d2f575ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66f0c07f-3731-4cf2-86b8-d119762acc7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38e6c65e-28a8-4af7-9d99-8411d4dd63ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d0c5a2e-2322-4394-b71c-df1d0ca95b96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1adebe60-5902-445c-b4f5-c346569562b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b4038d4-750e-4af4-b603-9fc4e4ed2337
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2627b53-0715-4f7f-badb-800bda407a51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6c51bc3-1f72-4319-9222-8c1cdab70beb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72f11a5e-5bd8-48b5-b74d-5ea9d78743c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5245c666-a7ed-4b96-b721-f57fe4398c07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b1e7f66-4f6c-410c-8b05-942e57890973
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb2c0ef8-20c5-4d06-b232-3f5fa516dc65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c994c5c-dfca-455a-a833-463f83cbd41b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 931f04f1-ac75-44f7-8918-852e231a9c19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d08f01e7-7535-4fca-805a-432b7a047079
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95572dea-e8ce-4648-b5f8-564e89d114ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f2f7e64-8e50-4124-81a9-fa97d78ecde4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c959a17-caf5-42a9-8bff-c9fc7fd7c8da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1197880f-8fd8-4437-9390-2ca044f836ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b80c0dd-f717-4a2c-98ac-aa10b181d781
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 685343bf-fdb7-4f21-8279-e3ad58b5dab1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b2d029e-1ca7-4144-bd7b-ab5993146bec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be3420f8-602d-401c-8e06-4a44b41c688e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2f918bc-30f3-47cf-b964-da7b4f2b68e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message acc19651-96b8-4807-ab0a-f4611da66da4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83998b86-d395-4290-bbe6-175cf58604fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90c3c976-2ebd-47ac-82a8-6799bd6a5a6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ecf5a61a-a40b-48d8-83bc-fa794d4b40aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8fe30a85-dd46-4cfb-91b5-e12b8b89175a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10ff6542-cf9b-4509-b30f-560ec6ed4331
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80eac83a-9e27-47ec-8c78-5b19084a20aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4593b87d-04e7-4045-9c9a-04a3675f47a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c20aa297-4e68-4420-8806-3f99700ecab0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6cf57f74-d308-49b9-ad85-f0d9ca47a8ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35bc90d4-683b-474d-841a-4ef52cee9fe1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 493b335c-54c6-4b68-8301-f69f2dddd606
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 116ebb05-168d-4558-9fe6-088a8cf6193a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7cf0ec71-5def-42cb-b456-766fe77c2ff4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f81a6b48-c0b7-46ad-ab3f-c415da7b2395
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0c70f5c-c3c9-424a-9e48-01b930eb5a05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ca2508c-dd7a-4851-8f09-6dde2dde2820
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa76785c-f21a-4dee-a4ba-6e79a2ca592b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a51066e8-394a-4088-8777-623dcc27ccc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45d0d717-ebd0-45df-99a9-9b15c222882d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67a5c26f-5aba-469f-99c8-97146fb6cb32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71dd4a8f-359e-42f2-a175-5f4eea47c019
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25086974-46d0-4915-b3db-8e285dee9332
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd42441b-e13f-483c-ac87-251b9a466aaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a57c8b31-72c1-4b79-8169-f199090df303
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd6058e7-5419-4eab-ba32-293758bffbc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e96f7f8-3a79-4b2f-9938-3fba56c9c6e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e016e6b8-0f17-4c43-89ca-8165c650cf88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 613492b6-35b3-49f9-9039-01e684f31cb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65f545d9-e707-4c02-b5ec-f5e7926887cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3bfd4f1b-1bcb-4952-b5fa-df65ab6afc74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 601070af-5e26-4c50-84cf-7f4bcf3313d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0a96b0d-4156-44fa-bbb5-45795e933e6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0475cf7-47f1-4d56-9196-455f89ed8cf4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1443ed70-e5ad-4aaa-a0fe-3a7ddee3404c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60157dac-5287-467c-bc6e-47a31a81c843
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb6d48ab-c4b0-432b-80ba-a5a4cd3a8f5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49419d6e-ada9-4791-a0f1-1a3e8ba7fb14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6aa01cb9-e989-4295-bc04-0489a0361218
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b998acd-aced-4c29-b6b5-5060a366e844
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ffbd29d0-50ac-477e-8b31-bd7a18df9667
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6084fa4-ea30-49cd-b82e-85936dcf112a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6889eebd-0b17-4c60-be92-29c3841efd51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1a6aac5-07ce-4cca-9b58-f5fe3a3aca3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4938963-c314-4305-b80e-714bc09a821e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be48541d-0bd5-4110-bdf4-2ee5c95d5db4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63c75f2d-3277-4aa0-adfa-d20f9bd90317
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a1191bb-c114-4800-9eaa-3ca18f854cb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c01349ce-58ba-4b93-85bd-596c5a7bbae0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2d81f39-1bf2-40fe-b6ed-4e3a9b254d87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b8e18db-44aa-4a1c-8287-88013e5e46fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4cc9a06-1380-482e-a052-9061dfc19931
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bcb16a94-92b8-4972-998e-324cfb8499af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 413e8dbb-3dcf-4b13-bf82-d9702b3e7352
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e33cca8f-d7dd-4fba-8f32-9e33617ed3af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71580279-da78-43c4-a243-d8eb2da36107
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc3d78fa-0080-4f91-af8e-683e38937849
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a48a3d01-e958-424e-a3ea-1c4c8925803b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59f9ceec-87e5-4dfe-9606-c399b0387ae1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 330f077f-30dd-43a3-9e75-c4b18afa878a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae14537c-4308-47f0-aeb3-776a74cfe383
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14e28be6-6783-4716-8ede-4eee597cf5de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 814ba6f3-272b-4ee1-b15f-0d536c74ccff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27fcaf25-aec8-4bbf-ba34-42a806c489d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7beebdcc-f227-4f93-87c0-cb90520f6160
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 098c7e0a-59c6-44a9-a751-22921648580b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47b4e08b-d193-4b29-bb37-0d8bafa8565d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d84713d3-2cbc-4830-9fbb-e67c59ab6a21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3892cea2-87ca-4a8e-9dcb-e99d948e52e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53e0a148-16c0-4068-af07-b60f967fdd25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d643a26c-3c81-4942-ac2e-e44e924d89e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 908b4f75-ed15-4ee8-9b25-c01771f6ce1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9b8bf25-0a61-4abc-996b-f46172a06e65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00988a35-be64-4720-8d7a-c08c7533ab4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05fb8d31-0545-45d4-85bd-429d27f59a9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8825e113-4159-424c-a4f2-4d7602b5e271
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2a91042-d4c4-4dd3-96b0-27b083e31be9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82e0bb52-6066-46c2-b09f-9857204c891f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b208a3d-85f3-4f9b-9827-50873ebe062d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c085b837-6515-432a-8075-15bc485c13a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e273adc-b504-41d1-b1d8-f6c3d323c0fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 911926db-8c20-4719-a4a5-a4b780a440eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf74be4b-5fdd-4e23-af84-d63c29487632
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09889017-1bf2-4805-ace2-8b8f80010f7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 861046fb-bb85-486a-99d7-1ded0bff04bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d842fef0-c6ce-4a7b-a6a9-828efb8db93b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a661a342-f9ba-4e64-bded-edf5e0514e21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a52db9bf-4d29-4a3e-a0bf-7489e0703ce6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aecf1873-c6d3-4633-adcd-58f47f2e236b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74e46abe-b175-44d6-9d09-ba58ad80d5c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 233fe38e-4f5d-4b4d-b32c-07d8cd986227
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 557f8bc6-a8d6-4cbf-a04c-8927603b30b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0154cde-2b8b-4484-b533-b87a9e7c101a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0444ae35-ee62-4969-8f1c-4163b44584f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e9ceaa1-e224-4b76-bf9c-cbaab3c3ee4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7292ccb3-f894-4773-962c-cb7e49254a0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0bd49d8-6bf1-4c4e-9df9-d88356455eea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b3be461-6667-42ca-81e6-78d4181ac9c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0a9f8e8-d950-45d6-aaf6-0b76aabd8aba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2eb12a96-d783-4add-a223-a4e8e018e7d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6cefc3e5-548e-419c-8d10-ed31680065e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5d4c4f4-0c29-4bee-b235-b88b5052077b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a296ca0-ded6-4365-b9d2-fa438bb09307
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8f693e9-72bf-4355-865b-cb60b3eb6467
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d20c1e11-b52e-4ead-9939-c9fcb7695db8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c212840-2d75-43f7-a73e-ba71d0cd3fa8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95f6cb7b-97a9-4a56-9566-dd7e56dc64f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8c2d586-7855-470d-a6ec-ac343c854a2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92df3273-d545-45c6-a3b4-90a790dfdad2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d82800a-f31b-4774-b127-54f9196b6b62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f20c153-184b-44d6-924e-9fe04dd0c0b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c895d96-e3fc-4b26-beb6-fa82f11614a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47c0de28-52c2-480a-ada8-c6eee49b3239
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 616969c0-ec38-4218-850c-692f79cd0b89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f10923e2-ad58-4052-a47b-c1cc4ca18641
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 612efb3a-653c-4fef-80ff-a4837089cd12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ffc61716-9ce7-4dba-8c44-fa0b03c0fb64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b9cbf27-d8e1-4807-a554-e0bc532d5b6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24e048a7-13b6-41ea-a45b-6a9ec54abb2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 129a300c-bc5a-4f70-96d3-58d217315bd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b1f2064-e88a-47e6-9a0a-0aff3f2895a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44f19453-6227-4899-8d58-00aef81cb0f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91872cea-de3c-46fc-8404-4c3e02fff20c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b6cbb84-d5b9-4587-a9c5-a621f5ef0ae0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa68d9b0-5cb5-42d8-868c-7bd347b5cb3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77db1b1d-7627-4d35-868b-ddb33f17e19f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dcef7b01-de6d-4260-9336-a7e5867cd61b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6da13250-ed15-4821-8f8c-841951933d39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a422dcf-c679-4fbb-b419-6e426a946702
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79246c49-411d-4df2-9835-fce1487ed750
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 586dc54a-b67a-4230-b42b-85e4289407a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 661a9a7c-0d1f-4ab7-b64d-467d29ddc341
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9a3f83a-ae8e-41bf-8482-84095f61d336
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef3aabf0-c39e-4735-a2cd-ae9387ab047b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b9ae38c-968d-4cbb-9d88-995c1eeaf606
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bcbb2028-1390-49be-b17b-796e52b29ae3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 397c9755-7dcb-437b-a60d-3efc67f1c190
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 561e073f-438a-4eca-819a-0546c38d390c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 873c42b2-c5e7-4fa1-8918-55946c9ad96d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c40fe21e-352e-424b-8360-d2f0da9cdd6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49cf417d-4c76-4ca4-b003-2c64046a2e04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bae5b58d-3b27-4991-baee-e9e4738ed708
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2698c10b-2ff9-4f71-a4d6-8cd2e538da0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec1f0e4b-08fc-4647-be7a-69d0bacb2090
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06622d68-d3c8-40c6-a742-9781e804f04b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b11df36e-34b3-42aa-9baf-7b37b0439012
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef3f3955-da7b-472f-8a71-abef1926e793
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4647dcde-f440-4eba-a7cd-fc8e705c6db0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca0184e9-4263-45c2-8765-cf23beb678f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4dfe9c4b-3942-43e9-bc47-6e113e0f7b69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d1c6999-75a7-4392-a97c-6c339c3c8687
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3818bac5-dd77-4c70-a36e-4dd9bc4f439c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83c73a0f-99d3-4e11-9a46-367248136190
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 296ddb24-4520-4da5-869d-d7cdceedca21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d6d1ab2-41f4-4b00-af4b-b59df5e4828a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ceecdde-bb11-4d45-bcb5-0be26084e109
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4dc8c82b-2429-4bdf-bda9-452de10aac70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aec5a40c-3135-4555-9706-5f2a006bf3d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a8696c6-1e5b-477c-b5f2-cc4271003f58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60f48c83-1608-4a19-8319-7e08a92687cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24703db1-f91e-4bc7-84d5-672a407463e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f889ae89-0129-4c9c-a63f-ee0f04a92ab4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61810293-249a-4663-a021-5018256132bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49ad8af5-de06-457c-aa3f-fdcf078eca2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 247b4265-b665-411a-9ef5-190cc1324bb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4d7c9f3-2775-4023-b242-cdc26a861f4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba8f1c01-fd72-41ad-a34c-8763b6259e03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7cca93d-2d8e-4a3e-b8b9-39fc7b09bc4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d64aa93e-2737-4a10-ae59-2ef6efbbbe81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13f80684-2ffa-4679-93da-7546395475c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 785196ac-47d4-45a9-9e9c-abeb334dcb11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2bccb78-808a-4a37-a1c8-5f0e3ce03c3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2048fa1-d9db-4504-8733-76be7d0672e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f87c9891-fe28-4ab6-bd85-d8480c4d9219
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b895adf4-394a-4dc7-9645-68ec6a67ce42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81295150-8e92-4afb-a159-d8832e6028cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42b13629-8c43-443a-9da9-a238ce2a5b03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac055642-af4b-45d3-9625-d8e2335dd257
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4821a0eb-8883-49a0-9dc1-993058afe18f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 198ecd74-4011-455d-b873-6f9412f2a865
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6649e6c7-ae0c-407b-9930-a26d2e18f6aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a2b8754-d8da-412c-9b6a-29abdc9523db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5ccd3a1-1e90-40eb-abc7-7e646f781f13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5d2c2a1-8b39-46b6-9b87-a11f459bef40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bcbd3e59-11ea-4091-a264-cbd6cdbd636a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bed8ffb4-5577-42c0-a48a-7cfaaa387901
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22679454-1128-48c4-8e2c-f98215048778
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9195d4cf-0b4c-44fe-b9f3-9002abfc933f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c79e5021-39ba-44ed-91c5-10841455872c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7ad9fc4-6a9d-4524-b3f6-97360b8a0184
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e27f3fed-8cf5-487d-9b8a-841cb198d6b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e8736f5-fb3d-4971-877e-3fcf6a81dd3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d8b1bc1-2233-4f2d-ae2a-5e82fc37f54f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00b7198e-b83b-4cbc-80fd-a33b91f9e2b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message add1532a-f3b6-4c69-9fd1-7d362ba61931
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0745637-6db0-4555-8b70-e88bdd50c932
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30f2db2a-8a0b-4a42-bc0a-158ad9a792d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26279fdc-8378-4fac-a46c-d701623e81f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 965eba18-772b-47fe-bf7e-4ea81508892d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b83a204e-032b-42b5-aea1-0701db9b0546
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4aa0add-fd56-4b30-a206-e74b422db15e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b62d27a6-5b1a-4258-9880-e01c0c42352b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d79393db-5269-4c95-b945-b56a6fa65619
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c802a4c5-3fa1-4f94-b13a-88d901e25aba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0cfd212d-2706-4dd3-b584-3a2e4288879d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74a07993-9d9b-449b-a625-4e02a653a8aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d07ff44-ab82-4cec-b503-402544f7a0a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad8179e5-09e6-47b6-920a-bb069431f232
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 790aa15f-fed5-4069-860b-d7a08f7527ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ff9a70e-a864-4485-867c-6acb50675bfd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60e492bd-ad09-46dc-badf-2ab22acbc2df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6f7ff42-30a2-4815-9133-d6aa987ac280
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21706074-d362-4065-af7d-93a7d84f7602
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad2ad81d-e96b-42c3-b6bc-1bb13369f4ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4475815f-585f-41a8-907c-8c4b86837a30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b53d1e58-97c8-4273-8175-5f7ea0164f64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52a5bb6a-da21-423e-96b0-c5b3f8834055
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad3411cc-3602-437e-a4d4-0803e1d48c1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f7f43b9-9b9f-4288-b55b-de3e1dbac93e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c3335f6-0d42-4af3-bfac-4e5965e9f5be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0497113-80aa-43a3-be81-9ca9bb3452b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50bdd3d6-9c90-4158-a052-e62a789e2bc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dcefd723-87ab-4617-9cfc-e2add83a04d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b645db53-bda3-489c-a62e-11f7282a08d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c652ee52-ce08-4e1e-af80-1a3f77f13ba0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b69ddef6-5cd7-4764-bd10-1ad04f1ac2b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a42b8e21-9dbd-4899-83b6-8a2b3a5b1956
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df1d3b1f-7f7c-4e11-99a3-01d20011a657
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb22abf8-0aa0-47f5-bc1f-882c2f6b13fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ec7692a-0a64-4803-aa9d-a72e97a174d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28839926-1c87-4dc0-bb2b-d5fc0a72d7c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e61afe0-7b9d-4cdb-9254-e7c860d5e39e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d7723c5-6395-47d5-8b31-b83625041002
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6e9255d-a234-4a34-a3d8-f09ec250e376
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3199d957-f330-4226-ac88-41271b32f94d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9648bda-ea66-4fe7-95dc-e7d2ad835370
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d7cf1ec-5171-4b9c-aea0-bb7bda240161
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb975491-3ff8-407d-9f22-61f404ff5bf9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 455a7748-52b2-480c-a275-59e586460e7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e692dd43-3690-423a-a488-23d62be054ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd6f89a3-e43b-4849-9577-83c14e0190a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45e47e0d-7ad5-4472-9b34-0390ce49962b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3ac93dd-49b4-400e-a0a7-46a7714961fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67ac6b94-209d-4f33-acbb-42d77d7c7633
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aba7a7a9-63cb-4787-9338-934ce87c5778
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 340205aa-511b-494d-bb77-e93e88293c2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4fa4dc4e-604b-494d-952c-6b38593923a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a633d80-b913-4e34-9a4f-0a2ee562ae11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e143b6c7-0c83-461e-960b-a065020b663a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66b4c255-38e9-40a7-905d-9230d4874c73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52636f3e-fb94-442d-aa84-e8b4a0059c0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53bda7db-310c-4210-b317-d42189d0840e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9e8373d-97f7-4c54-8ffd-8770397b483b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c9e05da-6af3-49a9-a1bc-a0667a024806
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f76d422-a093-48c5-b727-021d376c8df4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0627b8da-04fd-4748-9c22-4801284075ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f453bfd-8a7d-4dbc-9bff-8dac7d7aa945
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd8ebbe1-918d-45fe-af9e-3729e59c2413
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 107845e3-9895-4881-afa3-25b6e855a2d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28541e7f-83cb-4d6d-8cd6-d4567103c327
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 904eb4f0-db80-4dbe-8e9c-eb5605fb7c61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c4cfd27-f48c-41fe-99c5-0fb95e59c02f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0221e260-9389-4551-805a-b14c09759450
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4cf634ad-91c6-4e79-927e-22855f0d0244
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30e24047-7d1f-4df4-bc51-5989aa097191
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 627839eb-56ae-4f8e-b226-707e4697f8af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c152c1d-6ac1-49a7-92a4-54649cda26b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8a1fc4b-df4e-4d8e-985d-2e5a00c0e3a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d73ea70b-bb71-4725-803a-3ac113f84adb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2614983a-c38f-4eaa-97a2-c5c6c0dd0af4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a6903dc-e813-4681-925c-d8e0cd6a145e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3cf9de9b-beee-4aa9-9edb-637de139e288
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8622c6d-8c27-4f6a-be3e-3a442141d86b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4b89c9e-b9c5-40c7-970c-8cc0e06482a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9026343b-4937-4068-8ad2-65510bc9f013
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e28e98c7-f985-4057-8d7c-0c86eb9b93d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8707adb3-9e6c-4e5c-bf69-838cd7d4667d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 911e2d26-a942-419b-843b-65afcd61b1ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f61500b-c3ae-4224-ba63-5194d4799a4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de8db8b5-b2fb-44c0-8059-c99947999993
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a4fc705-489c-4405-88d8-bd78faa9b6b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6f1b421-5316-49c1-a7c4-009d019cc95f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 002734d0-3468-495c-96db-3d6f0ac7d2e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 891664c4-c0b1-4c4c-b873-a9b8d4656687
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 939df6f6-ad8e-40a7-bd7a-38bee7ff57a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e6e93fe-9fa3-45ca-a6b6-4e197bd05b92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ca1b5d2-2b1d-4929-b95c-aed2b18f6a34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07d00924-bf0f-4412-8745-ca2fba924a24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 985b1b7f-385a-48b6-9702-c06d719d94fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c017bf92-8f07-4770-a5af-912acc941c42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0d56421-ffcf-4c9c-8e54-146540708c64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70f31257-1a6d-43b6-b891-68d0bd902c60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60cb4f5f-2b08-4626-97cb-7877973980fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1fd3c407-39fa-4c9c-b6fc-a3f286bd2e9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fce3ec4d-90fb-44df-bc7a-02c22d7bd7de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b0652f0-ea19-42d2-a230-5a5aedce44a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8f0adf7-2e66-41fe-a769-3b19609d08b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62b5f919-babe-4884-b804-053495f7e174
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16aa66a5-0208-4f7d-9b10-2cb12c7658b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64c26f4a-355c-4cbc-9998-6d455cbf01fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50f1ac51-1b5f-4785-8e93-8ccb4ae5dbff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65606ab2-026f-4183-9f61-3da13c310690
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5205e6a2-200c-4856-8633-644e1d253140
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3912ebe1-d351-4a7e-a1d3-85cded92ff50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04428560-d574-459d-86ae-782a9ec2ebc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b795bd84-3fbe-4a5a-8fff-a6006547c49a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb6e07f2-f079-469e-aa74-0feff6dc6fea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3454313e-3e7d-4aa2-be9d-a0ddd1ab5d22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f217ca05-3e84-4b7e-bf8c-b312f72d0def
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3a06e53-65f9-460f-9caf-7dfea3f3cf43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e81c3a6e-b961-49ab-8cf8-1a72ccc649d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7d91cc0-52a0-40e5-9797-6ce06f3217b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7aebc33b-7429-4498-82b0-21912a39a34a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e144117-41bd-4c6f-943e-f3f849eb80bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eaaf165a-365b-4924-8844-482c86d12484
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ccb6f80b-2e91-43cc-b11e-1b909a981b10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dcd85201-ce80-4102-aece-74748db8b0c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f253c246-699b-404b-8493-93f4bf809eca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05b3801b-fb08-49d1-8806-32edf2540e1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb7c88c0-a60d-40ae-bf62-9333b0a1a04c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ecf2bf4a-1def-49ec-99ec-68e3770daa33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51807766-62bd-49e4-a2bd-ebb6d87580ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2ea7c85-7c4f-4fa9-a439-0e6c66baeb2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90a5b269-7a84-41a0-b270-e3a46447fed2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2dda4ebb-4d33-4024-b8c0-47e7f9187f6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e83c94e-1a88-4a76-8efe-b43de76444ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f901a90-3390-46d1-ab22-3bcdbcd78753
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d197b58b-8a49-4ddf-aae1-1b665c1c81f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1beca76-f619-4862-b8fd-69728f4eb114
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 464ee53b-c60b-40c1-8d7d-62168b734f15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46f68e0f-21f7-48c7-9d2c-60567c603d17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a1118eb-424f-4ca6-a7e7-66ad4e0afc81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b488b2b-3754-48a7-b744-6fa38612b3b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8caa6949-983c-4c63-b55d-a2b938256566
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9b923d5-39b8-4d1e-a263-4b6df6bb633e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d61fe1c-9479-4551-9adc-c0639682c535
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62b1cbee-8c12-4457-b99f-b451d63758f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf64180b-9a17-4c75-b86e-98d224b43816
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32dbdf9a-a6b5-4e3a-94c3-8d873804c1a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1ebc8cd-e3ef-43dc-a7d9-5fe149b44604
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f38fa92-ac27-4f5d-946c-b13a1ffece46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00b9c4a8-e0af-4710-97bc-adbe0a2ccfc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7d471ac-4ec6-41dc-8a39-4bb20698e2e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7bbd6cfc-4c92-41cc-b0ca-3586194c3338
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cffaff12-b546-4cd2-b8b0-3366ea705e8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07630f41-01e2-4b6b-a006-8de1f3a92bf1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cbe5ecff-fc21-4e90-99bb-f83f9a08bd8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 484d68d3-2bf3-4be7-bfe9-8f4dee730812
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26e40681-1319-40fe-8b8a-ddbbef6a9152
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 911e489d-f70c-4dab-98ba-b7aa22737bd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c46e8e15-7e0d-42b0-85f2-22f5db7245c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87be4f78-4857-4ca1-9394-629dc6d41503
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 732fc93a-3530-430e-ac04-2f2e037c65d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f98ae010-4dd6-4063-8ea4-326ac525bb31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25e2e5fd-ff3e-43ba-b681-3330f6a92c71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 695bc608-efad-44e3-b73a-ba4b7fb65783
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e06c0afa-9ae0-4e69-95fe-5d24ce29a4b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8df96604-96a2-4038-a05a-e9b77fdc9c30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc381f08-b60c-4806-8af2-17dab469e130
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5051a451-95fc-49c7-bf50-56e6fbfd0826
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7fc6f635-26bf-4d2f-b0ea-dee014cf4844
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61eabdc4-92a5-4775-9d4e-03c628b114db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e8e4e3c-a6cb-4df0-b1af-9a1d8b11303e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c60450db-1192-45ae-bc91-863dacb4dddf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6218f34c-fd19-43a4-a474-5f9044320abb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06ed87c3-7987-4408-b0b5-98ee9a147e74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8134cccc-1623-48b4-b677-be5d3085be8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c074b043-29ba-433f-ad42-4ef14f483962
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5be10eb8-5713-4f3a-a915-5c413b59df06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0cbd83a-250f-4a83-a777-a497bb801a8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31a199f4-d55f-4f84-8a89-c5e07be34ba9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bfef2c75-a824-4eb5-b631-8f2cd29d1d01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de04737c-a8d9-4000-9f73-eb32a4fc48ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa2220b5-47e4-4636-9981-0fa91e611d9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd5d8d8b-110f-4371-b570-ae18f22db430
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8fac773-e069-47db-837a-0cf2ad348fd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06f14771-35c9-4a7e-92ff-f47c92c1e317
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2863f76e-e36e-4d12-9f7d-125f864b0fb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29dca508-a860-4632-9636-f7a3b59571df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f644ca8-dad9-4459-8210-40c3b668b865
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a809e281-ed27-483f-afd4-df3c8d7bc897
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c142f14a-1079-457f-8c0b-604c9c19ae51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 187ff159-7ef1-4e90-be09-0be32116458d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aacb5cbb-efaf-4d1e-8913-7aed79042a51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a63796d6-d9da-4c79-969e-3105353cca7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f9b39c2-5704-4c6c-946a-f6dc863346d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de6c3ffc-c17b-4f16-a187-7cc3570456c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 859acd86-689e-4589-bac2-2c90ba4295d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ea6afd3-d8e4-4ccf-bd7d-13ea1b3226a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6271bb82-1765-4823-93f7-adc0312f22f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 879ada2d-8dfd-49d8-a19a-e6430c5c863e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4ffc9ca-8bf3-4de9-aefc-06dafc466c38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a1a296c-d331-40c8-b0b6-8f06f3b7d4d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10174cd5-6b7d-477f-a107-0b1b6eb57f85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca2dd943-f1f1-4478-9bf9-0468a90a557f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3be4ece-cc30-49e3-a58e-9319e6ccbf39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c8642c0-a95e-4a5c-a7b1-406fac9134db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9fcac248-3682-40c0-9af7-33ce51d32b0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62376796-bfe2-432d-bcaf-5ca6c615400f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0ca8661-764f-4a67-9d61-81d350eef959
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f91dcf8-eb18-493a-a2ab-d29e89f31dd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 737236c7-9763-4f52-a3c7-e17e168087a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01626208-8fc4-4791-80dd-a18e5a500e6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb71495f-1bf6-42da-9cd4-87817c948127
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80e65b8d-7989-4098-9450-c35dc98cf4d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dbe1ab69-38d9-4848-8420-628a74a48172
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d64a4fe9-6506-4b17-be16-f9a4d0735d13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7749094f-db77-449f-93bf-9f3c1d608188
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 562c0c11-0b82-4bf2-b9af-caba39cb97ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1dcde14b-43ce-4173-a57c-9e1a081d4a1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ebc268e1-eaac-472c-b96b-4839dc936a8a
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8692 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_23
Server: localhost:8692
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_23
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_23/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_23/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_23/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_23/test_labels.txt

📊 Raw data loaded:
   Train: X=(7224, 24), y=(7224,)
   Test:  X=(1806, 24), y=(1806,)

⚠️  Limiting training data: 7224 → 800 samples
⚠️  Limiting test data: 1806 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_23 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.4967, RMSE: 0.7048, MAE: 0.6442, R²: -5.0846

📊 Round 0 Test Metrics:
   Loss: 0.4950, RMSE: 0.7036, MAE: 0.6429, R²: -5.0637

============================================================
🔄 Round 3 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.3574, val=0.1537 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.1003, val=0.0905 (↓), lr=0.001000
   ✓ Epoch   3/100: train=0.0849, val=0.0872 (↓), lr=0.001000
   • Epoch   4/100: train=0.0830, val=0.0869, patience=1/15, lr=0.001000
   • Epoch   5/100: train=0.0826, val=0.0871, patience=2/15, lr=0.001000
   📉 Epoch 10: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0815, val=0.0882, patience=8/15, lr=0.000500
   📉 Epoch 18: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 3 Summary - Client client_23
   Epochs: 18/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0023
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0172
============================================================


📊 Round 3 Test Metrics:
   Loss: 0.4883, RMSE: 0.6988, MAE: 0.6377, R²: -4.9817

============================================================
🔄 Round 4 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.4349, val=0.4318 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.3336, val=0.3219 (↓), lr=0.000250
   ✓ Epoch   3/100: train=0.2079, val=0.1377 (↓), lr=0.000250
   ✓ Epoch   4/100: train=0.0942, val=0.0800 (↓), lr=0.000250
   • Epoch   5/100: train=0.0845, val=0.0844, patience=1/15, lr=0.000250
   📉 Epoch 10: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0837, val=0.0830, patience=7/15, lr=0.000125
   📉 Epoch 18: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 4 Summary - Client client_23
   Epochs: 19/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0875, RMSE=0.2959, R²=-0.0406
   Val:   Loss=0.0800, RMSE=0.2828, R²=-0.0009
============================================================


📊 Round 4 Test Metrics:
   Loss: 0.4849, RMSE: 0.6963, MAE: 0.6349, R²: -4.9395

📊 Round 4 Test Metrics:
   Loss: 0.4780, RMSE: 0.6914, MAE: 0.6295, R²: -4.8555

============================================================
🔄 Round 7 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.4745, val=0.4004 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.4325, val=0.3634 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.3965, val=0.3321 (↓), lr=0.000063
   ✓ Epoch   4/100: train=0.3641, val=0.3023 (↓), lr=0.000063
   ✓ Epoch   5/100: train=0.3312, val=0.2697 (↓), lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   ✓ Epoch  11/100: train=0.1216, val=0.0916 (↓), lr=0.000031
   📉 Epoch 21: LR reduced 0.000031 → 0.000016
   • Epoch  21/100: train=0.0858, val=0.0753, patience=7/15, lr=0.000016
   📉 Epoch 29: LR reduced 0.000016 → 0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 7 Summary - Client client_23
   Epochs: 29/100 (early stopped)
   LR: 0.000063 → 0.000008 (3 reductions)
   Train: Loss=0.0887, RMSE=0.2979, R²=-0.0323
   Val:   Loss=0.0749, RMSE=0.2736, R²=-0.0148
============================================================


============================================================
🔄 Round 8 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.4685, val=0.4815 (↓), lr=0.000008
   ✓ Epoch   2/100: train=0.4627, val=0.4754 (↓), lr=0.000008
   ✓ Epoch   3/100: train=0.4570, val=0.4698 (↓), lr=0.000008
   ✓ Epoch   4/100: train=0.4519, val=0.4649 (↓), lr=0.000008
   ✓ Epoch   5/100: train=0.4472, val=0.4603 (↓), lr=0.000008
   📉 Epoch 8: LR reduced 0.000008 → 0.000004
   ✓ Epoch  11/100: train=0.4287, val=0.4430 (↓), lr=0.000004
   📉 Epoch 16: LR reduced 0.000004 → 0.000002
   ✓ Epoch  21/100: train=0.4164, val=0.4309 (↓), lr=0.000002
   📉 Epoch 24: LR reduced 0.000002 → 0.000001
   • Epoch  31/100: train=0.4115, val=0.4261, patience=1/15, lr=0.000001
   • Epoch  41/100: train=0.4080, val=0.4226, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.4046, val=0.4192, patience=1/15, lr=0.000001
   • Epoch  61/100: train=0.4014, val=0.4158, patience=1/15, lr=0.000001
   • Epoch  71/100: train=0.3981, val=0.4125, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.3949, val=0.4093, patience=1/15, lr=0.000001
   • Epoch  91/100: train=0.3917, val=0.4060, patience=1/15, lr=0.000001

============================================================
📊 Round 8 Summary - Client client_23
   Epochs: 100/100
   LR: 0.000008 → 0.000001 (3 reductions)
   Train: Loss=0.3884, RMSE=0.6232, R²=-3.6811
   Val:   Loss=0.4031, RMSE=0.6349, R²=-3.6555
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.4375, RMSE: 0.6615, MAE: 0.5965, R²: -4.3598

📊 Round 8 Test Metrics:
   Loss: 0.4289, RMSE: 0.6549, MAE: 0.5893, R²: -4.2539

📊 Round 8 Test Metrics:
   Loss: 0.4102, RMSE: 0.6405, MAE: 0.5732, R²: -4.0247

============================================================
🔄 Round 13 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.4113, val=0.4416 (↓), lr=0.000001
   • Epoch   2/100: train=0.4108, val=0.4411, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.4103, val=0.4406 (↓), lr=0.000001
   • Epoch   4/100: train=0.4099, val=0.4401, patience=1/15, lr=0.000001
   ✓ Epoch   5/100: train=0.4094, val=0.4396 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.4068, val=0.4368 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.4025, val=0.4322 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.3984, val=0.4278 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.3943, val=0.4235 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.3903, val=0.4192 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.3862, val=0.4148 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.3821, val=0.4105 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.3780, val=0.4061 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.3739, val=0.4017 (↓), lr=0.000001

============================================================
📊 Round 13 Summary - Client client_23
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.3698, RMSE=0.6081, R²=-3.2737
   Val:   Loss=0.3976, RMSE=0.6306, R²=-4.5897
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.3665, RMSE: 0.6054, MAE: 0.5337, R²: -3.4894

📊 Round 13 Test Metrics:
   Loss: 0.2923, RMSE: 0.5407, MAE: 0.4599, R²: -2.5810

============================================================
🔄 Round 18 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.2911, val=0.3307 (↓), lr=0.000001
   ✓ Epoch   2/100: train=0.2903, val=0.3299 (↓), lr=0.000001
   ✓ Epoch   3/100: train=0.2896, val=0.3290 (↓), lr=0.000001
   ✓ Epoch   4/100: train=0.2888, val=0.3282 (↓), lr=0.000001
   ✓ Epoch   5/100: train=0.2880, val=0.3274 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.2837, val=0.3226 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.2769, val=0.3150 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.2703, val=0.3077 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.2638, val=0.3005 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.2574, val=0.2932 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.2509, val=0.2860 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.2444, val=0.2787 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.2379, val=0.2713 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.2314, val=0.2640 (↓), lr=0.000001

============================================================
📊 Round 18 Summary - Client client_23
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.2247, RMSE=0.4740, R²=-1.6445
   Val:   Loss=0.2573, RMSE=0.5072, R²=-2.3582
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.2654, RMSE: 0.5152, MAE: 0.4321, R²: -2.2514

📊 Round 18 Test Metrics:
   Loss: 0.1114, RMSE: 0.3338, MAE: 0.2739, R²: -0.3646

📊 Round 18 Test Metrics:
   Loss: 0.0923, RMSE: 0.3038, MAE: 0.2536, R²: -0.1309

📊 Round 18 Test Metrics:
   Loss: 0.0833, RMSE: 0.2886, MAE: 0.2448, R²: -0.0204

============================================================
🔄 Round 27 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 27 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0151
   Val:   Loss=0.0917, RMSE=0.3028, R²=-0.0105
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2443, R²: -0.0049

============================================================
🔄 Round 31 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 31 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0050
   Val:   Loss=0.0872, RMSE=0.2952, R²=-0.0047
============================================================


============================================================
🔄 Round 32 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 32 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0074
   Val:   Loss=0.0851, RMSE=0.2917, R²=0.0046
============================================================


============================================================
🔄 Round 33 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 33 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0028
   Val:   Loss=0.0766, RMSE=0.2767, R²=-0.0088
============================================================


============================================================
🔄 Round 34 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 34 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0059
   Val:   Loss=0.0875, RMSE=0.2959, R²=0.0026
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2444, R²: -0.0039

============================================================
🔄 Round 37 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 37 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=-0.0066
   Val:   Loss=0.0849, RMSE=0.2915, R²=-0.0088
============================================================


============================================================
🔄 Round 38 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 38 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0011
   Val:   Loss=0.0839, RMSE=0.2896, R²=-0.0132
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2444, R²: -0.0036

📊 Round 38 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2444, R²: -0.0035

============================================================
🔄 Round 42 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 42 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0052
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.0089
============================================================


============================================================
🔄 Round 46 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 46 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0025
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0031
============================================================


============================================================
🔄 Round 50 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 50 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2908, R²=-0.0052
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.0068
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2446, R²: -0.0029

📊 Round 50 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2446, R²: -0.0029

📊 Round 50 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2446, R²: -0.0029

============================================================
🔄 Round 54 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 54 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0031
   Val:   Loss=0.0823, RMSE=0.2868, R²=0.0005
============================================================


============================================================
🔄 Round 55 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 55 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0046
   Val:   Loss=0.0912, RMSE=0.3020, R²=0.0064
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2446, R²: -0.0028

============================================================
🔄 Round 58 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 58 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0024
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.0035
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2447, R²: -0.0028

📊 Round 58 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2448, R²: -0.0029

============================================================
🔄 Round 60 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 60 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0036
   Val:   Loss=0.0828, RMSE=0.2877, R²=0.0040
============================================================


============================================================
🔄 Round 64 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 64 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0002
   Val:   Loss=0.0775, RMSE=0.2785, R²=-0.0098
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2448, R²: -0.0029

============================================================
🔄 Round 65 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0930 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0930, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0930, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0930, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0930, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0930, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0930)

============================================================
📊 Round 65 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0019
   Val:   Loss=0.0930, RMSE=0.3050, R²=-0.0008
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2448, R²: -0.0029

============================================================
🔄 Round 66 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 66 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0001
   Val:   Loss=0.0891, RMSE=0.2985, R²=-0.0071
============================================================


============================================================
🔄 Round 67 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0720, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 67 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0027
   Val:   Loss=0.0720, RMSE=0.2683, R²=0.0035
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2448, R²: -0.0029

============================================================
🔄 Round 69 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 69 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0015
   Val:   Loss=0.0744, RMSE=0.2727, R²=-0.0039
============================================================


============================================================
🔄 Round 70 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 70 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0018
   Val:   Loss=0.0894, RMSE=0.2990, R²=-0.0023
============================================================


============================================================
🔄 Round 72 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 72 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0004
   Val:   Loss=0.0897, RMSE=0.2995, R²=-0.0222
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2448, R²: -0.0029

============================================================
🔄 Round 73 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 73 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=-0.0028
   Val:   Loss=0.0758, RMSE=0.2753, R²=-0.0216
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2448, R²: -0.0029

============================================================
🔄 Round 75 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 75 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0007
   Val:   Loss=0.0899, RMSE=0.2999, R²=-0.0059
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2448, R²: -0.0029

📊 Round 75 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2448, R²: -0.0029

============================================================
🔄 Round 77 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 77 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0008
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0049
============================================================


============================================================
🔄 Round 79 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 79 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0016
   Val:   Loss=0.0896, RMSE=0.2994, R²=-0.0135
============================================================


============================================================
🔄 Round 80 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 80 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0002
   Val:   Loss=0.0866, RMSE=0.2942, R²=-0.0110
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2448, R²: -0.0028

============================================================
🔄 Round 81 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 81 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0013
   Val:   Loss=0.0821, RMSE=0.2866, R²=-0.0203
============================================================


============================================================
🔄 Round 82 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 82 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2911, R²=-0.0025
   Val:   Loss=0.0801, RMSE=0.2831, R²=0.0016
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2448, R²: -0.0028

============================================================
🔄 Round 83 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 83 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0030
   Val:   Loss=0.0912, RMSE=0.3019, R²=-0.0042
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2448, R²: -0.0028

============================================================
🔄 Round 84 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 84 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0014
   Val:   Loss=0.0815, RMSE=0.2854, R²=-0.0032
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2448, R²: -0.0028

============================================================
🔄 Round 86 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 86 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0013
   Val:   Loss=0.0820, RMSE=0.2863, R²=-0.0112
============================================================


============================================================
🔄 Round 87 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0940 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0940, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0940, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0940, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0940, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0941, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0940)

============================================================
📊 Round 87 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0012
   Val:   Loss=0.0940, RMSE=0.3066, R²=-0.0269
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2448, R²: -0.0028

📊 Round 87 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2448, R²: -0.0028

============================================================
🔄 Round 92 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 92 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2930, R²=-0.0045
   Val:   Loss=0.0757, RMSE=0.2752, R²=0.0112
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2448, R²: -0.0028

============================================================
🔄 Round 93 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 93 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0023
   Val:   Loss=0.0850, RMSE=0.2915, R²=0.0006
============================================================


============================================================
🔄 Round 94 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 94 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0028
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0030
============================================================


============================================================
🔄 Round 95 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 95 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0011
   Val:   Loss=0.0844, RMSE=0.2906, R²=-0.0038
============================================================


============================================================
🔄 Round 98 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 98 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0026
   Val:   Loss=0.0732, RMSE=0.2706, R²=-0.0065
============================================================


============================================================
🔄 Round 99 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 99 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0042
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0513
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2447, R²: -0.0027

============================================================
🔄 Round 100 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 100 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0002
   Val:   Loss=0.0748, RMSE=0.2735, R²=-0.0128
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2447, R²: -0.0027

============================================================
🔄 Round 102 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 102 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0026
   Val:   Loss=0.0868, RMSE=0.2947, R²=0.0005
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2446, R²: -0.0026

📊 Round 102 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2446, R²: -0.0026

============================================================
🔄 Round 105 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 105 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0018
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0032
============================================================


============================================================
🔄 Round 106 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 106 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2923, R²=-0.0011
   Val:   Loss=0.0774, RMSE=0.2782, R²=-0.0426
============================================================


============================================================
🔄 Round 107 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 107 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0022
   Val:   Loss=0.0894, RMSE=0.2989, R²=0.0002
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2447, R²: -0.0026

📊 Round 107 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2447, R²: -0.0026

📊 Round 107 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2447, R²: -0.0026

============================================================
🔄 Round 112 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0708 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0708, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0708, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0708, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0708, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0708, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0708)

============================================================
📊 Round 112 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=-0.0007
   Val:   Loss=0.0708, RMSE=0.2661, R²=-0.0084
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2447, R²: -0.0026

📊 Round 112 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2447, R²: -0.0026

============================================================
🔄 Round 119 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 119 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0033
   Val:   Loss=0.0862, RMSE=0.2937, R²=-0.0104
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2447, R²: -0.0027

📊 Round 119 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2447, R²: -0.0026

============================================================
🔄 Round 122 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 122 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0011
   Val:   Loss=0.0884, RMSE=0.2974, R²=-0.0068
============================================================


============================================================
🔄 Round 123 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0930 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0930, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0930, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0930, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0930, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0930, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0930)

============================================================
📊 Round 123 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0014
   Val:   Loss=0.0930, RMSE=0.3050, R²=-0.0042
============================================================


============================================================
🔄 Round 124 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0924 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0924, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0924, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 124 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0014
   Val:   Loss=0.0924, RMSE=0.3040, R²=-0.0129
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2447, R²: -0.0026

============================================================
🔄 Round 127 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 127 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0007
   Val:   Loss=0.0880, RMSE=0.2967, R²=-0.0128
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2448, R²: -0.0027

============================================================
🔄 Round 131 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 131 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0007
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0074
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2448, R²: -0.0028

============================================================
🔄 Round 133 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 133 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0001
   Val:   Loss=0.0809, RMSE=0.2845, R²=-0.0144
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2448, R²: -0.0027

📊 Round 133 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2448, R²: -0.0027

============================================================
🔄 Round 135 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 135 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2897, R²=-0.0025
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0015
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2448, R²: -0.0026

📊 Round 135 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2448, R²: -0.0027

============================================================
🔄 Round 140 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 140 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0033
   Val:   Loss=0.0920, RMSE=0.3034, R²=-0.0083
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2448, R²: -0.0027

📊 Round 140 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2448, R²: -0.0027

============================================================
🔄 Round 142 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 142 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=-0.0016
   Val:   Loss=0.0918, RMSE=0.3030, R²=-0.0105
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2448, R²: -0.0027

============================================================
🔄 Round 149 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 149 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0002
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0104
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2448, R²: -0.0026

============================================================
🔄 Round 151 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 151 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0032
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0075
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2448, R²: -0.0026

📊 Round 151 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2448, R²: -0.0026

============================================================
🔄 Round 154 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 154 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0016
   Val:   Loss=0.0857, RMSE=0.2928, R²=-0.0009
============================================================


============================================================
🔄 Round 155 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 155 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0021
   Val:   Loss=0.0866, RMSE=0.2943, R²=-0.0074
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2447, R²: -0.0025

📊 Round 155 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2447, R²: -0.0024

============================================================
🔄 Round 160 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 160 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0026
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0072
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2447, R²: -0.0024

============================================================
🔄 Round 161 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 161 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0028
   Val:   Loss=0.0768, RMSE=0.2770, R²=0.0010
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2447, R²: -0.0025

============================================================
🔄 Round 162 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0721, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0721, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 162 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0022
   Val:   Loss=0.0720, RMSE=0.2684, R²=-0.0321
============================================================


============================================================
🔄 Round 164 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 164 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0050
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0010
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2447, R²: -0.0024

📊 Round 164 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2447, R²: -0.0024

📊 Round 164 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2448, R²: -0.0025

============================================================
🔄 Round 170 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 170 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2892, R²=-0.0018
   Val:   Loss=0.0844, RMSE=0.2906, R²=-0.0225
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2448, R²: -0.0025

============================================================
🔄 Round 172 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 172 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0018
   Val:   Loss=0.0774, RMSE=0.2783, R²=-0.0069
============================================================


============================================================
🔄 Round 173 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 173 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=-0.0027
   Val:   Loss=0.0757, RMSE=0.2752, R²=0.0029
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2447, R²: -0.0024

============================================================
🔄 Round 175 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0929 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0929, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0929, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0929, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0929, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0929, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0929)

============================================================
📊 Round 175 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0007
   Val:   Loss=0.0929, RMSE=0.3048, R²=-0.0053
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2447, R²: -0.0024

============================================================
🔄 Round 176 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 176 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=-0.0043
   Val:   Loss=0.0746, RMSE=0.2732, R²=0.0061
============================================================


============================================================
🔄 Round 180 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 180 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0014
   Val:   Loss=0.0823, RMSE=0.2868, R²=-0.0072
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2447, R²: -0.0024

============================================================
🔄 Round 181 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 181 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0024
   Val:   Loss=0.0853, RMSE=0.2920, R²=0.0018
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2447, R²: -0.0024

📊 Round 181 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2447, R²: -0.0024

============================================================
🔄 Round 184 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 184 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0010
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.0067
============================================================


============================================================
🔄 Round 185 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 185 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0011
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0074
============================================================


============================================================
🔄 Round 187 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0992 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0992, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0992, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0992, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0992, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0992, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0992)

============================================================
📊 Round 187 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0014
   Val:   Loss=0.0992, RMSE=0.3150, R²=-0.0013
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2447, R²: -0.0024

============================================================
🔄 Round 188 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 188 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=-0.0025
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0076
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2447, R²: -0.0024

============================================================
🔄 Round 195 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 195 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0032
   Val:   Loss=0.0867, RMSE=0.2945, R²=0.0052
============================================================


📊 Round 195 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2447, R²: -0.0023

============================================================
🔄 Round 199 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 199 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0018
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0072
============================================================


📊 Round 199 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2447, R²: -0.0023

📊 Round 199 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2447, R²: -0.0023

📊 Round 199 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2446, R²: -0.0022

📊 Round 199 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2447, R²: -0.0023

📊 Round 199 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2447, R²: -0.0023

============================================================
🔄 Round 208 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 208 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0019
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0014
============================================================


📊 Round 208 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2447, R²: -0.0023

============================================================
🔄 Round 209 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 209 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=-0.0006
   Val:   Loss=0.0758, RMSE=0.2752, R²=-0.0129
============================================================


📊 Round 209 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2447, R²: -0.0023

📊 Round 209 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2447, R²: -0.0023

============================================================
🔄 Round 211 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 211 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0017
   Val:   Loss=0.0749, RMSE=0.2736, R²=-0.0008
============================================================


============================================================
🔄 Round 212 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 212 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0002
   Val:   Loss=0.0863, RMSE=0.2937, R²=-0.0061
============================================================


📊 Round 212 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2446, R²: -0.0022

============================================================
🔄 Round 213 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0934 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0934, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0934, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0934, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0934, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0935, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0934)

============================================================
📊 Round 213 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=-0.0014
   Val:   Loss=0.0934, RMSE=0.3055, R²=-0.0169
============================================================


============================================================
🔄 Round 214 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 214 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0019
   Val:   Loss=0.0775, RMSE=0.2783, R²=-0.0094
============================================================


📊 Round 214 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2446, R²: -0.0022

📊 Round 214 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2446, R²: -0.0022

============================================================
🔄 Round 221 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 221 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0042
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0078
============================================================


📊 Round 221 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2446, R²: -0.0022

============================================================
🔄 Round 222 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 222 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0025
   Val:   Loss=0.0778, RMSE=0.2790, R²=-0.0013
============================================================


============================================================
🔄 Round 223 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 223 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0010
   Val:   Loss=0.0863, RMSE=0.2937, R²=-0.0032
============================================================


============================================================
🔄 Round 224 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 224 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0005
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0074
============================================================


📊 Round 224 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2446, R²: -0.0022

============================================================
🔄 Round 226 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 226 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2923, R²=-0.0020
   Val:   Loss=0.0773, RMSE=0.2779, R²=-0.0086
============================================================


📊 Round 226 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2446, R²: -0.0022

============================================================
🔄 Round 228 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 228 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2863, R²=-0.0023
   Val:   Loss=0.0914, RMSE=0.3023, R²=-0.0083
============================================================


📊 Round 228 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2446, R²: -0.0022

============================================================
🔄 Round 229 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0929 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0929, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0929, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0929, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0929, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0929, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0929)

============================================================
📊 Round 229 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0024
   Val:   Loss=0.0929, RMSE=0.3048, R²=0.0020
============================================================


📊 Round 229 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2446, R²: -0.0022

📊 Round 229 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2447, R²: -0.0022

📊 Round 229 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2447, R²: -0.0022

============================================================
🔄 Round 232 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 232 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=-0.0028
   Val:   Loss=0.0853, RMSE=0.2921, R²=0.0012
============================================================


📊 Round 232 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2447, R²: -0.0022

============================================================
🔄 Round 233 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 233 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0002
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0066
============================================================


============================================================
🔄 Round 234 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 234 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0037
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0116
============================================================


============================================================
🔄 Round 236 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 236 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=0.0009
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0149
============================================================


============================================================
🔄 Round 237 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 237 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0024
   Val:   Loss=0.0755, RMSE=0.2748, R²=-0.0410
============================================================


📊 Round 237 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2447, R²: -0.0022

📊 Round 237 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2447, R²: -0.0023

============================================================
🔄 Round 239 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 239 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0007
   Val:   Loss=0.0772, RMSE=0.2778, R²=-0.0052
============================================================


============================================================
🔄 Round 240 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 240 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0022
   Val:   Loss=0.0880, RMSE=0.2967, R²=-0.0045
============================================================


📊 Round 240 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2447, R²: -0.0022

============================================================
🔄 Round 241 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0922, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0922, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0922, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0922, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0922, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 241 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0007
   Val:   Loss=0.0921, RMSE=0.3036, R²=-0.0083
============================================================


============================================================
🔄 Round 242 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 242 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0031
   Val:   Loss=0.0866, RMSE=0.2942, R²=0.0034
============================================================


============================================================
🔄 Round 243 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 243 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0015
   Val:   Loss=0.0821, RMSE=0.2866, R²=-0.0011
============================================================


============================================================
🔄 Round 247 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 247 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0019
   Val:   Loss=0.0854, RMSE=0.2923, R²=-0.0049
============================================================


============================================================
🔄 Round 248 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 248 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0003
   Val:   Loss=0.0900, RMSE=0.3000, R²=-0.0055
============================================================


📊 Round 248 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2447, R²: -0.0022

📊 Round 248 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2447, R²: -0.0022

📊 Round 248 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2447, R²: -0.0022

============================================================
🔄 Round 251 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 251 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0014
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0019
============================================================


============================================================
🔄 Round 252 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.1004 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.1004, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.1004, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.1004, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.1004, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.1005, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1004)

============================================================
📊 Round 252 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0019
   Val:   Loss=0.1004, RMSE=0.3168, R²=-0.0048
============================================================


📊 Round 252 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2447, R²: -0.0022

============================================================
🔄 Round 257 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 257 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0015
   Val:   Loss=0.0877, RMSE=0.2962, R²=-0.0168
============================================================


📊 Round 257 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2446, R²: -0.0021

============================================================
🔄 Round 259 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 259 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0030
   Val:   Loss=0.0907, RMSE=0.3012, R²=0.0024
============================================================


📊 Round 259 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2446, R²: -0.0021

============================================================
🔄 Round 262 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 262 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0010
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0032
============================================================


📊 Round 262 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2446, R²: -0.0021

📊 Round 262 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2447, R²: -0.0022

📊 Round 262 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2446, R²: -0.0021

============================================================
🔄 Round 265 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 265 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0019
   Val:   Loss=0.0802, RMSE=0.2833, R²=-0.0046
============================================================


📊 Round 265 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2446, R²: -0.0021

📊 Round 265 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2446, R²: -0.0021

============================================================
🔄 Round 267 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 267 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0022
   Val:   Loss=0.0808, RMSE=0.2843, R²=0.0018
============================================================


============================================================
🔄 Round 268 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 268 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0003
   Val:   Loss=0.0815, RMSE=0.2854, R²=-0.0092
============================================================


📊 Round 268 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2446, R²: -0.0021

============================================================
🔄 Round 269 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 269 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0002
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0064
============================================================


📊 Round 269 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2446, R²: -0.0020

📊 Round 269 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2446, R²: -0.0020

============================================================
🔄 Round 275 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 275 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=-0.0016
   Val:   Loss=0.0886, RMSE=0.2976, R²=-0.0029
============================================================


============================================================
🔄 Round 276 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 276 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0019
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.0029
============================================================


📊 Round 276 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2447, R²: -0.0021

============================================================
🔄 Round 280 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 280 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0020
   Val:   Loss=0.0884, RMSE=0.2972, R²=-0.0016
============================================================


============================================================
🔄 Round 283 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 283 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0012
   Val:   Loss=0.0853, RMSE=0.2920, R²=-0.0022
============================================================


📊 Round 283 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2446, R²: -0.0021

📊 Round 283 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2446, R²: -0.0021

============================================================
🔄 Round 288 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 288 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0018
   Val:   Loss=0.0889, RMSE=0.2982, R²=-0.0063
============================================================


📊 Round 288 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2447, R²: -0.0021

📊 Round 288 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2447, R²: -0.0021

============================================================
🔄 Round 290 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 290 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0031
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0016
============================================================


============================================================
🔄 Round 292 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 292 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0015
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0189
============================================================


📊 Round 292 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2447, R²: -0.0022

============================================================
🔄 Round 295 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 295 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0024
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0016
============================================================


📊 Round 295 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2448, R²: -0.0023

📊 Round 295 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2448, R²: -0.0023

============================================================
🔄 Round 297 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 297 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=-0.0009
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0059
============================================================


📊 Round 297 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2447, R²: -0.0022

============================================================
🔄 Round 300 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 300 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=-0.0004
   Val:   Loss=0.0768, RMSE=0.2772, R²=-0.0298
============================================================


📊 Round 300 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2447, R²: -0.0021

📊 Round 300 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2446, R²: -0.0020

============================================================
🔄 Round 303 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 303 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0024
   Val:   Loss=0.0796, RMSE=0.2822, R²=0.0017
============================================================


📊 Round 303 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2446, R²: -0.0020

📊 Round 303 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2446, R²: -0.0020

📊 Round 303 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2446, R²: -0.0020

============================================================
🔄 Round 307 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 307 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0015
   Val:   Loss=0.0911, RMSE=0.3019, R²=-0.0160
============================================================


📊 Round 307 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2446, R²: -0.0020

============================================================
🔄 Round 308 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 308 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0012
   Val:   Loss=0.0896, RMSE=0.2993, R²=-0.0082
============================================================


📊 Round 308 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2446, R²: -0.0020

📊 Round 308 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2446, R²: -0.0020

============================================================
🔄 Round 312 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 312 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0023
   Val:   Loss=0.0884, RMSE=0.2973, R²=0.0002
============================================================


📊 Round 312 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2446, R²: -0.0020

📊 Round 312 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2446, R²: -0.0020

📊 Round 312 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2446, R²: -0.0020

============================================================
🔄 Round 315 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 315 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0007
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0061
============================================================


📊 Round 315 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2446, R²: -0.0020

============================================================
🔄 Round 316 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 316 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=-0.0032
   Val:   Loss=0.0842, RMSE=0.2901, R²=0.0009
============================================================


============================================================
🔄 Round 317 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 317 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2903, R²=-0.0001
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0066
============================================================


📊 Round 317 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2446, R²: -0.0020

============================================================
🔄 Round 318 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 318 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=-0.0030
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0229
============================================================


📊 Round 318 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2446, R²: -0.0020

📊 Round 318 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2446, R²: -0.0020

📊 Round 318 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2447, R²: -0.0021

============================================================
🔄 Round 323 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 323 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0016
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0069
============================================================


============================================================
🔄 Round 324 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 324 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0016
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0230
============================================================


📊 Round 324 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2446, R²: -0.0019

============================================================
🔄 Round 326 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 326 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2920, R²=-0.0012
   Val:   Loss=0.0781, RMSE=0.2795, R²=-0.0050
============================================================


============================================================
🔄 Round 327 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 327 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0015
   Val:   Loss=0.0803, RMSE=0.2833, R²=-0.0171
============================================================


============================================================
🔄 Round 328 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 328 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0016
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0068
============================================================


📊 Round 328 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2447, R²: -0.0020

============================================================
🔄 Round 329 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 329 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0033
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0060
============================================================


📊 Round 329 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2447, R²: -0.0020

============================================================
🔄 Round 331 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 331 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0037
   Val:   Loss=0.0884, RMSE=0.2974, R²=0.0051
============================================================


📊 Round 331 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2447, R²: -0.0020

============================================================
🔄 Round 333 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 333 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0018
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0033
============================================================


============================================================
🔄 Round 335 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 335 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0003
   Val:   Loss=0.0765, RMSE=0.2765, R²=-0.0123
============================================================


📊 Round 335 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2447, R²: -0.0021

📊 Round 335 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2447, R²: -0.0021

============================================================
🔄 Round 337 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 337 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0022
   Val:   Loss=0.0910, RMSE=0.3016, R²=-0.0177
============================================================


📊 Round 337 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2447, R²: -0.0021

============================================================
🔄 Round 340 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 340 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0016
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0032
============================================================


📊 Round 340 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2447, R²: -0.0021

📊 Round 340 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2447, R²: -0.0021

📊 Round 340 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2446, R²: -0.0020

📊 Round 340 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2446, R²: -0.0019

📊 Round 340 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2446, R²: -0.0020

📊 Round 340 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2446, R²: -0.0020

📊 Round 340 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2446, R²: -0.0020

============================================================
🔄 Round 349 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 349 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0030
   Val:   Loss=0.0884, RMSE=0.2973, R²=0.0002
============================================================


📊 Round 349 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2446, R²: -0.0020

📊 Round 349 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2446, R²: -0.0020

============================================================
🔄 Round 354 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 354 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0025
   Val:   Loss=0.0916, RMSE=0.3026, R²=0.0023
============================================================


📊 Round 354 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2446, R²: -0.0020

============================================================
🔄 Round 355 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 355 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0026
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0090
============================================================


============================================================
🔄 Round 356 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 356 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0014
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0074
============================================================


📊 Round 356 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2446, R²: -0.0020

📊 Round 356 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2446, R²: -0.0019

============================================================
🔄 Round 358 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 358 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0002
   Val:   Loss=0.0896, RMSE=0.2993, R²=-0.0069
============================================================


============================================================
🔄 Round 359 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 359 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0013
   Val:   Loss=0.0813, RMSE=0.2852, R²=-0.0021
============================================================


📊 Round 359 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2446, R²: -0.0019

📊 Round 359 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2446, R²: -0.0019

============================================================
🔄 Round 361 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 361 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0029
   Val:   Loss=0.0819, RMSE=0.2863, R²=0.0033
============================================================


📊 Round 361 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2446, R²: -0.0019

📊 Round 361 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2445, R²: -0.0018

============================================================
🔄 Round 363 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0927 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0927, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0927, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0927, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0927, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0927, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0927)

============================================================
📊 Round 363 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0024
   Val:   Loss=0.0927, RMSE=0.3045, R²=0.0018
============================================================


📊 Round 363 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2445, R²: -0.0018

============================================================
🔄 Round 368 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 368 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0023
   Val:   Loss=0.0856, RMSE=0.2925, R²=-0.0168
============================================================


📊 Round 368 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2445, R²: -0.0018

============================================================
🔄 Round 370 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 370 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0048
   Val:   Loss=0.0887, RMSE=0.2978, R²=0.0034
============================================================


============================================================
🔄 Round 372 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 372 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0004
   Val:   Loss=0.0826, RMSE=0.2875, R²=-0.0104
============================================================


📊 Round 372 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2445, R²: -0.0017

============================================================
🔄 Round 374 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 374 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0023
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0006
============================================================


📊 Round 374 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2444, R²: -0.0017

============================================================
🔄 Round 375 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 375 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0046
   Val:   Loss=0.0820, RMSE=0.2863, R²=0.0076
============================================================


============================================================
🔄 Round 376 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 376 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0017
   Val:   Loss=0.0857, RMSE=0.2928, R²=-0.0057
============================================================


📊 Round 376 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2444, R²: -0.0017

============================================================
🔄 Round 380 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 380 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0024
   Val:   Loss=0.0783, RMSE=0.2798, R²=0.0018
============================================================


📊 Round 380 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2445, R²: -0.0017

============================================================
🔄 Round 381 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0682 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0682, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0682, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0682, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0682, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0683, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0682)

============================================================
📊 Round 381 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2962, R²=-0.0004
   Val:   Loss=0.0682, RMSE=0.2611, R²=-0.0245
============================================================


📊 Round 381 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2445, R²: -0.0017

📊 Round 381 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2445, R²: -0.0017

============================================================
🔄 Round 386 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 386 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=-0.0039
   Val:   Loss=0.0785, RMSE=0.2802, R²=-0.0067
============================================================


============================================================
🔄 Round 387 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 387 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=-0.0029
   Val:   Loss=0.0825, RMSE=0.2873, R²=0.0035
============================================================


============================================================
🔄 Round 388 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 388 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0029
   Val:   Loss=0.0893, RMSE=0.2988, R²=0.0032
============================================================


📊 Round 388 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2445, R²: -0.0017

============================================================
🔄 Round 389 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 389 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0023
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0002
============================================================


📊 Round 389 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2445, R²: -0.0017

============================================================
🔄 Round 390 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 390 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0009
   Val:   Loss=0.0838, RMSE=0.2894, R²=-0.0057
============================================================


============================================================
🔄 Round 391 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 391 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0020
   Val:   Loss=0.0899, RMSE=0.2999, R²=-0.0078
============================================================


📊 Round 391 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2445, R²: -0.0016

============================================================
🔄 Round 392 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 392 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0011
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0039
============================================================


📊 Round 392 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2445, R²: -0.0016

============================================================
🔄 Round 394 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 394 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0001
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0069
============================================================


============================================================
🔄 Round 399 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 399 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0007
   Val:   Loss=0.0915, RMSE=0.3024, R²=-0.0048
============================================================


============================================================
🔄 Round 400 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 400 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0025
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0477
============================================================


📊 Round 400 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2445, R²: -0.0016

============================================================
🔄 Round 403 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 403 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2915, R²=-0.0041
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.0043
============================================================


📊 Round 403 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2445, R²: -0.0016

📊 Round 403 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2445, R²: -0.0016

📊 Round 403 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2445, R²: -0.0017

============================================================
🔄 Round 407 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 407 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=-0.0009
   Val:   Loss=0.0768, RMSE=0.2772, R²=-0.0046
============================================================


📊 Round 407 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2445, R²: -0.0017

============================================================
🔄 Round 408 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 408 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=-0.0023
   Val:   Loss=0.0905, RMSE=0.3008, R²=-0.0054
============================================================


📊 Round 408 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2445, R²: -0.0017

============================================================
🔄 Round 412 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0940 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0940, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0940, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0940, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0940, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0940, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0940)

============================================================
📊 Round 412 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0029
   Val:   Loss=0.0940, RMSE=0.3065, R²=0.0030
============================================================


📊 Round 412 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2445, R²: -0.0017

📊 Round 412 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2445, R²: -0.0017

============================================================
🔄 Round 416 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 416 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0016
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0008
============================================================


📊 Round 416 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2445, R²: -0.0016

📊 Round 416 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2445, R²: -0.0016

📊 Round 416 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2445, R²: -0.0016

============================================================
🔄 Round 422 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 422 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=-0.0026
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0061
============================================================


============================================================
🔄 Round 425 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 425 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0028
   Val:   Loss=0.0838, RMSE=0.2895, R²=0.0030
============================================================


============================================================
🔄 Round 426 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 426 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0025
   Val:   Loss=0.0766, RMSE=0.2768, R²=-0.0050
============================================================


============================================================
🔄 Round 431 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 431 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0002
   Val:   Loss=0.0818, RMSE=0.2859, R²=-0.0092
============================================================


============================================================
🔄 Round 433 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 433 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0018
   Val:   Loss=0.0789, RMSE=0.2809, R²=-0.0032
============================================================


📊 Round 433 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2445, R²: -0.0016

============================================================
🔄 Round 436 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 436 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0017
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0027
============================================================


📊 Round 436 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2445, R²: -0.0016

📊 Round 436 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2445, R²: -0.0016

📊 Round 436 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2445, R²: -0.0016

📊 Round 436 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2445, R²: -0.0016

============================================================
🔄 Round 441 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 441 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2916, R²=-0.0026
   Val:   Loss=0.0789, RMSE=0.2808, R²=-0.0020
============================================================


📊 Round 441 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2445, R²: -0.0015

============================================================
🔄 Round 443 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 443 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2928, R²=-0.0020
   Val:   Loss=0.0761, RMSE=0.2758, R²=-0.0025
============================================================


📊 Round 443 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2445, R²: -0.0015

============================================================
🔄 Round 446 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 446 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0009
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0038
============================================================


============================================================
🔄 Round 447 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 447 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0005
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0068
============================================================


============================================================
🔄 Round 449 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 449 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0025
   Val:   Loss=0.0825, RMSE=0.2871, R²=-0.0002
============================================================


============================================================
🔄 Round 450 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 450 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0020
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0049
============================================================


📊 Round 450 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2445, R²: -0.0015

📊 Round 450 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2445, R²: -0.0015

📊 Round 450 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2445, R²: -0.0015

============================================================
🔄 Round 453 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 453 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0004
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0127
============================================================


============================================================
🔄 Round 455 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 455 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0018
   Val:   Loss=0.0890, RMSE=0.2983, R²=-0.0001
============================================================


📊 Round 455 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2445, R²: -0.0015

📊 Round 455 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2445, R²: -0.0015

============================================================
🔄 Round 459 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 459 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0012
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0096
============================================================


📊 Round 459 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2445, R²: -0.0015

📊 Round 459 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2445, R²: -0.0015

📊 Round 459 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2445, R²: -0.0015

📊 Round 459 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2445, R²: -0.0015

============================================================
🔄 Round 467 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 467 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0023
   Val:   Loss=0.0842, RMSE=0.2903, R²=-0.0002
============================================================


============================================================
🔄 Round 471 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 471 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0002
   Val:   Loss=0.0918, RMSE=0.3030, R²=-0.0114
============================================================


📊 Round 471 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2445, R²: -0.0015

📊 Round 471 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2444, R²: -0.0015

============================================================
🔄 Round 476 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 476 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0002
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0066
============================================================


📊 Round 476 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2444, R²: -0.0015

📊 Round 476 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2445, R²: -0.0015

📊 Round 476 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2445, R²: -0.0015

============================================================
🔄 Round 482 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 482 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0013
   Val:   Loss=0.0894, RMSE=0.2990, R²=-0.0138
============================================================


============================================================
🔄 Round 485 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 485 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0027
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0030
============================================================


============================================================
🔄 Round 487 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 487 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0031
   Val:   Loss=0.0812, RMSE=0.2850, R²=0.0036
============================================================


📊 Round 487 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2445, R²: -0.0015

============================================================
🔄 Round 489 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 489 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0014
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0014
============================================================


============================================================
🔄 Round 490 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 490 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0013
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0031
============================================================


============================================================
🔄 Round 491 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 491 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0023
   Val:   Loss=0.0884, RMSE=0.2974, R²=-0.0013
============================================================


============================================================
🔄 Round 492 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 492 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0009
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0106
============================================================


📊 Round 492 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2445, R²: -0.0015

============================================================
🔄 Round 493 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 493 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0013
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0192
============================================================


📊 Round 493 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2445, R²: -0.0015

============================================================
🔄 Round 495 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 495 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0019
   Val:   Loss=0.0906, RMSE=0.3010, R²=0.0005
============================================================


📊 Round 495 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2444, R²: -0.0014

📊 Round 495 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2444, R²: -0.0014

============================================================
🔄 Round 498 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 498 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0005
   Val:   Loss=0.0888, RMSE=0.2979, R²=-0.0056
============================================================


📊 Round 498 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2445, R²: -0.0015

📊 Round 498 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2444, R²: -0.0014

============================================================
🔄 Round 501 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 501 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0031
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0193
============================================================


📊 Round 501 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2444, R²: -0.0014

📊 Round 501 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2444, R²: -0.0014

📊 Round 501 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2444, R²: -0.0014

============================================================
🔄 Round 505 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 505 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=-0.0023
   Val:   Loss=0.0770, RMSE=0.2774, R²=0.0016
============================================================


============================================================
🔄 Round 507 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 507 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0013
   Val:   Loss=0.0909, RMSE=0.3015, R²=-0.0022
============================================================


============================================================
🔄 Round 509 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 509 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0020
   Val:   Loss=0.0882, RMSE=0.2970, R²=-0.0119
============================================================


============================================================
🔄 Round 511 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 511 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0017
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0001
============================================================


📊 Round 511 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2445, R²: -0.0015

📊 Round 511 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2445, R²: -0.0014

============================================================
🔄 Round 516 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 516 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2878, R²=-0.0010
   Val:   Loss=0.0877, RMSE=0.2961, R²=-0.0028
============================================================


📊 Round 516 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2445, R²: -0.0014

============================================================
🔄 Round 518 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 518 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0001
   Val:   Loss=0.0776, RMSE=0.2785, R²=-0.0096
============================================================


============================================================
🔄 Round 519 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 519 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2930, R²=-0.0030
   Val:   Loss=0.0757, RMSE=0.2751, R²=-0.0024
============================================================


============================================================
🔄 Round 520 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 520 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0004
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0122
============================================================


📊 Round 520 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2445, R²: -0.0015

============================================================
🔄 Round 521 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 521 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=-0.0026
   Val:   Loss=0.0918, RMSE=0.3030, R²=-0.0181
============================================================


📊 Round 521 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2445, R²: -0.0015

============================================================
🔄 Round 523 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 523 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0013
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0144
============================================================


📊 Round 523 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2445, R²: -0.0015

============================================================
🔄 Round 527 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 527 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0017
   Val:   Loss=0.0776, RMSE=0.2786, R²=-0.0006
============================================================


============================================================
🔄 Round 529 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 529 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0036
   Val:   Loss=0.0852, RMSE=0.2919, R²=0.0034
============================================================


📊 Round 529 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2445, R²: -0.0015

============================================================
🔄 Round 531 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 531 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0024
   Val:   Loss=0.0863, RMSE=0.2937, R²=0.0021
============================================================


📊 Round 531 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2444, R²: -0.0014

============================================================
🔄 Round 533 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 533 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0021
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0111
============================================================


============================================================
🔄 Round 535 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 535 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0003
   Val:   Loss=0.0859, RMSE=0.2930, R²=-0.0061
============================================================


📊 Round 535 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2444, R²: -0.0013

============================================================
🔄 Round 537 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 537 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=-0.0026
   Val:   Loss=0.0758, RMSE=0.2753, R²=0.0002
============================================================


📊 Round 537 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2444, R²: -0.0013

📊 Round 537 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2444, R²: -0.0014

============================================================
🔄 Round 541 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 541 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0014
   Val:   Loss=0.0733, RMSE=0.2708, R²=-0.0077
============================================================


📊 Round 541 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2445, R²: -0.0014

============================================================
🔄 Round 544 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0936 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0936, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0936, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0936, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0936, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0937, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0936)

============================================================
📊 Round 544 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0027
   Val:   Loss=0.0936, RMSE=0.3059, R²=-0.0036
============================================================


📊 Round 544 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2444, R²: -0.0013

📊 Round 544 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2444, R²: -0.0013

📊 Round 544 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2444, R²: -0.0013

============================================================
🔄 Round 553 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 553 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0015
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0309
============================================================


📊 Round 553 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2444, R²: -0.0014

============================================================
🔄 Round 554 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 554 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0010
   Val:   Loss=0.0779, RMSE=0.2791, R²=-0.0032
============================================================


============================================================
🔄 Round 555 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 555 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=-0.0031
   Val:   Loss=0.0901, RMSE=0.3002, R²=0.0049
============================================================


============================================================
🔄 Round 556 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 556 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0003
   Val:   Loss=0.0872, RMSE=0.2954, R²=-0.0057
============================================================


============================================================
🔄 Round 557 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 557 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0007
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0040
============================================================


📊 Round 557 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2444, R²: -0.0014

📊 Round 557 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2444, R²: -0.0013

============================================================
🔄 Round 561 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 561 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0023
   Val:   Loss=0.0778, RMSE=0.2790, R²=0.0020
============================================================


============================================================
🔄 Round 562 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 562 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0018
   Val:   Loss=0.0867, RMSE=0.2945, R²=-0.0025
============================================================


============================================================
🔄 Round 564 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 564 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0010
   Val:   Loss=0.0883, RMSE=0.2971, R²=-0.0053
============================================================


============================================================
🔄 Round 565 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 565 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0032
   Val:   Loss=0.0907, RMSE=0.3012, R²=-0.0192
============================================================


============================================================
🔄 Round 566 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 566 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0025
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0007
============================================================


============================================================
🔄 Round 567 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0923, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 567 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0026
   Val:   Loss=0.0923, RMSE=0.3037, R²=0.0017
============================================================


📊 Round 567 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2444, R²: -0.0013

============================================================
🔄 Round 568 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 568 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=-0.0026
   Val:   Loss=0.0739, RMSE=0.2719, R²=-0.0123
============================================================


============================================================
🔄 Round 569 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 569 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0035
   Val:   Loss=0.0852, RMSE=0.2918, R²=0.0069
============================================================


============================================================
🔄 Round 570 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 570 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0003
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0061
============================================================


📊 Round 570 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2444, R²: -0.0013

============================================================
🔄 Round 571 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 571 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0013
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0019
============================================================


📊 Round 571 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2444, R²: -0.0013

============================================================
🔄 Round 572 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0715 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0715, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0715, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0715, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0715, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0716, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0715)

============================================================
📊 Round 572 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0026
   Val:   Loss=0.0715, RMSE=0.2674, R²=-0.0093
============================================================


📊 Round 572 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2444, R²: -0.0013

============================================================
🔄 Round 574 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 574 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0041
   Val:   Loss=0.0910, RMSE=0.3017, R²=-0.0022
============================================================


📊 Round 574 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2444, R²: -0.0013

============================================================
🔄 Round 577 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 577 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0021
   Val:   Loss=0.0767, RMSE=0.2770, R²=-0.0002
============================================================


📊 Round 577 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2444, R²: -0.0013

📊 Round 577 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2444, R²: -0.0013

============================================================
🔄 Round 580 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 580 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0016
   Val:   Loss=0.0767, RMSE=0.2770, R²=-0.0072
============================================================


📊 Round 580 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2444, R²: -0.0013

============================================================
🔄 Round 583 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 583 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0038
   Val:   Loss=0.0882, RMSE=0.2970, R²=-0.0266
============================================================


============================================================
🔄 Round 585 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 585 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0019
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0121
============================================================


============================================================
🔄 Round 586 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 586 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0009
   Val:   Loss=0.0857, RMSE=0.2928, R²=-0.0076
============================================================


📊 Round 586 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2445, R²: -0.0014

============================================================
🔄 Round 587 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 587 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2877, R²=-0.0029
   Val:   Loss=0.0881, RMSE=0.2968, R²=0.0044
============================================================


============================================================
🔄 Round 589 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 589 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0020
   Val:   Loss=0.0915, RMSE=0.3025, R²=0.0007
============================================================


📊 Round 589 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2445, R²: -0.0014

============================================================
🔄 Round 591 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 591 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=-0.0017
   Val:   Loss=0.0825, RMSE=0.2873, R²=-0.0021
============================================================


============================================================
🔄 Round 593 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 593 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0039
   Val:   Loss=0.0847, RMSE=0.2910, R²=0.0073
============================================================


📊 Round 593 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2445, R²: -0.0014

📊 Round 593 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2445, R²: -0.0014

============================================================
🔄 Round 596 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 596 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=-0.0019
   Val:   Loss=0.0728, RMSE=0.2697, R²=0.0008
============================================================


📊 Round 596 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2445, R²: -0.0014

📊 Round 596 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2444, R²: -0.0013

============================================================
🔄 Round 601 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 601 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0020
   Val:   Loss=0.0809, RMSE=0.2844, R²=-0.0086
============================================================


============================================================
🔄 Round 602 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 602 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0013
   Val:   Loss=0.0903, RMSE=0.3005, R²=-0.0022
============================================================


📊 Round 602 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2444, R²: -0.0013

📊 Round 602 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2444, R²: -0.0013

============================================================
🔄 Round 604 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 604 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0019
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0018
============================================================


============================================================
🔄 Round 605 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 605 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0021
   Val:   Loss=0.0799, RMSE=0.2826, R²=-0.0005
============================================================


📊 Round 605 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2444, R²: -0.0013

📊 Round 605 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2444, R²: -0.0013

📊 Round 605 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2445, R²: -0.0013

📊 Round 605 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2444, R²: -0.0013

📊 Round 605 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2444, R²: -0.0013

============================================================
🔄 Round 611 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 611 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0017
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0003
============================================================


📊 Round 611 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2444, R²: -0.0013

============================================================
🔄 Round 612 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 612 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0008
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0044
============================================================


📊 Round 612 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2444, R²: -0.0013

📊 Round 612 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2444, R²: -0.0012

============================================================
🔄 Round 616 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 616 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0015
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0139
============================================================


============================================================
🔄 Round 617 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0953 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0953, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0953, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0953, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0953, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0953, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0953)

============================================================
📊 Round 617 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=-0.0007
   Val:   Loss=0.0953, RMSE=0.3087, R²=-0.0053
============================================================


📊 Round 617 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2444, R²: -0.0012

📊 Round 617 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2444, R²: -0.0012

============================================================
🔄 Round 620 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 620 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0022
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0031
============================================================


📊 Round 620 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2444, R²: -0.0013

📊 Round 620 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2444, R²: -0.0013

============================================================
🔄 Round 627 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 627 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0015
   Val:   Loss=0.0868, RMSE=0.2947, R²=-0.0015
============================================================


📊 Round 627 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2444, R²: -0.0013

============================================================
🔄 Round 630 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 630 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0013
   Val:   Loss=0.0793, RMSE=0.2815, R²=-0.0037
============================================================


============================================================
🔄 Round 631 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 631 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0014
   Val:   Loss=0.0890, RMSE=0.2983, R²=-0.0022
============================================================


============================================================
🔄 Round 632 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 632 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2870, R²=-0.0022
   Val:   Loss=0.0897, RMSE=0.2996, R²=-0.0036
============================================================


📊 Round 632 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2444, R²: -0.0012

📊 Round 632 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2444, R²: -0.0012

============================================================
🔄 Round 636 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 636 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0002
   Val:   Loss=0.0885, RMSE=0.2975, R²=-0.0129
============================================================


============================================================
🔄 Round 637 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 637 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0010
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0151
============================================================


📊 Round 637 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2444, R²: -0.0012

============================================================
🔄 Round 638 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 638 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0034
   Val:   Loss=0.0766, RMSE=0.2767, R²=-0.0040
============================================================


============================================================
🔄 Round 639 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 639 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0015
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0076
============================================================


📊 Round 639 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2444, R²: -0.0013

📊 Round 639 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2444, R²: -0.0013

📊 Round 639 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2444, R²: -0.0012

============================================================
🔄 Round 643 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 643 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0049
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0498
============================================================


📊 Round 643 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2444, R²: -0.0013

============================================================
🔄 Round 647 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 647 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0018
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0001
============================================================


📊 Round 647 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2444, R²: -0.0013

📊 Round 647 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2444, R²: -0.0012

============================================================
🔄 Round 650 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 650 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0025
   Val:   Loss=0.0810, RMSE=0.2847, R²=0.0027
============================================================


============================================================
🔄 Round 651 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 651 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0018
   Val:   Loss=0.0827, RMSE=0.2875, R²=0.0001
============================================================


📊 Round 651 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2444, R²: -0.0012

📊 Round 651 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2445, R²: -0.0013

📊 Round 651 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2445, R²: -0.0013

📊 Round 651 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2444, R²: -0.0013

📊 Round 651 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2444, R²: -0.0012

============================================================
🔄 Round 658 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 658 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0030
   Val:   Loss=0.0911, RMSE=0.3019, R²=-0.0073
============================================================


📊 Round 658 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2444, R²: -0.0012

📊 Round 658 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2444, R²: -0.0012

============================================================
🔄 Round 660 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 660 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0039
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0284
============================================================


📊 Round 660 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2444, R²: -0.0012

============================================================
🔄 Round 661 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 661 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0014
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0021
============================================================


📊 Round 661 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2444, R²: -0.0012

📊 Round 661 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2443, R²: -0.0011

📊 Round 661 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2443, R²: -0.0011

📊 Round 661 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2444, R²: -0.0012

============================================================
🔄 Round 670 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 670 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0015
   Val:   Loss=0.0855, RMSE=0.2925, R²=-0.0034
============================================================


============================================================
🔄 Round 671 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 671 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0011
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0028
============================================================


📊 Round 671 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2444, R²: -0.0012

📊 Round 671 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2444, R²: -0.0012

============================================================
🔄 Round 675 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 675 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0026
   Val:   Loss=0.0771, RMSE=0.2777, R²=0.0035
============================================================


📊 Round 675 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2444, R²: -0.0012

============================================================
🔄 Round 676 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 676 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0009
   Val:   Loss=0.0869, RMSE=0.2948, R²=-0.0087
============================================================


📊 Round 676 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2444, R²: -0.0012

============================================================
🔄 Round 678 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 678 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0035
   Val:   Loss=0.0789, RMSE=0.2810, R²=-0.0074
============================================================


📊 Round 678 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2444, R²: -0.0012

📊 Round 678 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2444, R²: -0.0012

============================================================
🔄 Round 680 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 680 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0033
   Val:   Loss=0.0812, RMSE=0.2850, R²=0.0057
============================================================


📊 Round 680 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2444, R²: -0.0012

📊 Round 680 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2444, R²: -0.0012

============================================================
🔄 Round 684 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0986 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0986, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0986, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0987, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0987, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0988, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0986)

============================================================
📊 Round 684 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=-0.0026
   Val:   Loss=0.0986, RMSE=0.3140, R²=-0.0099
============================================================


============================================================
🔄 Round 686 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 686 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0006
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.0117
============================================================


📊 Round 686 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2444, R²: -0.0012

📊 Round 686 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2444, R²: -0.0012

============================================================
🔄 Round 688 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 688 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0013
   Val:   Loss=0.0856, RMSE=0.2927, R²=-0.0045
============================================================


📊 Round 688 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2444, R²: -0.0012

============================================================
🔄 Round 689 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 689 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0006
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0086
============================================================


📊 Round 689 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2444, R²: -0.0012

📊 Round 689 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2444, R²: -0.0011

📊 Round 689 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2444, R²: -0.0011

============================================================
🔄 Round 695 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 695 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0030
   Val:   Loss=0.0756, RMSE=0.2749, R²=-0.0072
============================================================


============================================================
🔄 Round 699 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 699 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0002
   Val:   Loss=0.0908, RMSE=0.3013, R²=-0.0063
============================================================


📊 Round 699 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2443, R²: -0.0011

============================================================
🔄 Round 702 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 702 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0016
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0082
============================================================


============================================================
🔄 Round 704 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 704 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0021
   Val:   Loss=0.0772, RMSE=0.2779, R²=-0.0013
============================================================


📊 Round 704 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2443, R²: -0.0011

============================================================
🔄 Round 706 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 706 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0030
   Val:   Loss=0.0821, RMSE=0.2866, R²=0.0049
============================================================


============================================================
🔄 Round 708 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 708 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0001
   Val:   Loss=0.0811, RMSE=0.2847, R²=-0.0088
============================================================


📊 Round 708 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2443, R²: -0.0011

============================================================
🔄 Round 710 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 710 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0027
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0002
============================================================


============================================================
🔄 Round 711 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 711 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0019
   Val:   Loss=0.0873, RMSE=0.2954, R²=-0.0021
============================================================


============================================================
🔄 Round 713 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 713 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0012
   Val:   Loss=0.0891, RMSE=0.2986, R²=-0.0070
============================================================


📊 Round 713 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2443, R²: -0.0011

📊 Round 713 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2443, R²: -0.0011

============================================================
🔄 Round 717 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 717 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2863, R²=-0.0016
   Val:   Loss=0.0914, RMSE=0.3023, R²=-0.0062
============================================================


============================================================
🔄 Round 718 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 718 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0016
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0017
============================================================


============================================================
🔄 Round 719 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 719 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0023
   Val:   Loss=0.0820, RMSE=0.2863, R²=-0.0018
============================================================


📊 Round 719 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2443, R²: -0.0011

📊 Round 719 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2443, R²: -0.0011

📊 Round 719 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2443, R²: -0.0011

📊 Round 719 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2443, R²: -0.0011

============================================================
🔄 Round 725 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 725 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0015
   Val:   Loss=0.0827, RMSE=0.2875, R²=-0.0066
============================================================


============================================================
🔄 Round 726 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 726 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0013
   Val:   Loss=0.0844, RMSE=0.2904, R²=-0.0224
============================================================


📊 Round 726 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2443, R²: -0.0011

============================================================
🔄 Round 731 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 731 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0006
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0055
============================================================


📊 Round 731 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2444, R²: -0.0011

📊 Round 731 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2444, R²: -0.0012

============================================================
🔄 Round 737 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 737 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0031
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0259
============================================================


📊 Round 737 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2444, R²: -0.0011

============================================================
🔄 Round 740 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0708 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0708, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0708, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0708, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0708, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0709, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0708)

============================================================
📊 Round 740 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=-0.0025
   Val:   Loss=0.0708, RMSE=0.2662, R²=0.0006
============================================================


📊 Round 740 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2444, R²: -0.0011

============================================================
🔄 Round 743 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 743 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=-0.0029
   Val:   Loss=0.0921, RMSE=0.3035, R²=0.0022
============================================================


============================================================
🔄 Round 744 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 744 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0011
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0045
============================================================


📊 Round 744 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2444, R²: -0.0011

📊 Round 744 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2444, R²: -0.0011

📊 Round 744 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2444, R²: -0.0011

📊 Round 744 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2444, R²: -0.0012

📊 Round 744 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2444, R²: -0.0012

============================================================
🔄 Round 750 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 750 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2923, R²=-0.0020
   Val:   Loss=0.0773, RMSE=0.2780, R²=0.0007
============================================================


📊 Round 750 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2444, R²: -0.0012

============================================================
🔄 Round 751 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 751 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0022
   Val:   Loss=0.0909, RMSE=0.3015, R²=-0.0010
============================================================


============================================================
🔄 Round 753 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 753 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=-0.0026
   Val:   Loss=0.0854, RMSE=0.2922, R²=0.0020
============================================================


📊 Round 753 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2443, R²: -0.0010

📊 Round 753 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2443, R²: -0.0010

============================================================
🔄 Round 757 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 757 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2877, R²=-0.0035
   Val:   Loss=0.0882, RMSE=0.2969, R²=-0.0057
============================================================


============================================================
🔄 Round 762 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 762 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0001
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0090
============================================================


============================================================
🔄 Round 763 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 763 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0011
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0048
============================================================


📊 Round 763 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2442, R²: -0.0010

📊 Round 763 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2442, R²: -0.0010

📊 Round 763 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2442, R²: -0.0010

============================================================
🔄 Round 767 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0940 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0940, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0940, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0940, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0940, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0941, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0940)

============================================================
📊 Round 767 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0020
   Val:   Loss=0.0940, RMSE=0.3067, R²=-0.0001
============================================================


============================================================
🔄 Round 768 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 768 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=-0.0024
   Val:   Loss=0.0785, RMSE=0.2803, R²=0.0015
============================================================


📊 Round 768 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2443, R²: -0.0010

============================================================
🔄 Round 772 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 772 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0025
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0374
============================================================


============================================================
🔄 Round 774 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 774 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0001
   Val:   Loss=0.0856, RMSE=0.2925, R²=-0.0070
============================================================


📊 Round 774 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2443, R²: -0.0010

============================================================
🔄 Round 776 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 776 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0020
   Val:   Loss=0.0877, RMSE=0.2961, R²=-0.0086
============================================================


📊 Round 776 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2443, R²: -0.0010

============================================================
🔄 Round 777 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 777 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=-0.0027
   Val:   Loss=0.0842, RMSE=0.2902, R²=0.0031
============================================================


📊 Round 777 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2443, R²: -0.0010

📊 Round 777 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2443, R²: -0.0010

📊 Round 777 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2444, R²: -0.0010

📊 Round 777 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2443, R²: -0.0010

============================================================
🔄 Round 781 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 781 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0027
   Val:   Loss=0.0801, RMSE=0.2831, R²=0.0033
============================================================


📊 Round 781 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2444, R²: -0.0010

============================================================
🔄 Round 783 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 783 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0032
   Val:   Loss=0.0827, RMSE=0.2875, R²=0.0050
============================================================


============================================================
🔄 Round 784 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 784 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0004
   Val:   Loss=0.0866, RMSE=0.2943, R²=-0.0213
============================================================


============================================================
🔄 Round 785 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 785 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0025
   Val:   Loss=0.0835, RMSE=0.2890, R²=0.0017
============================================================


❌ Client client_23 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8692 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8692 {grpc_message:"Socket closed", grpc_status:14}"
>
