[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d699e79e-6f62-4492-b6a1-25dc55ba6ea3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3bd0e12c-f4fa-4962-af34-abb6d0a8dccf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1adcb1eb-cb92-436d-9c1c-79020c8e4798
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8cd27cf8-1a31-45d9-969b-963ecfdd5e3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39babb77-c801-43fc-9589-39f98124788f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 039d49a1-7de4-4a6c-80e8-a33321c76c4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61d977d6-d994-4f67-be4e-bc39dadda0d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0464befd-bc97-4278-ba82-983135c074ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98025bfa-8270-4522-b363-7957a734e5c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 728aa8ef-b59b-4931-98ef-9d414d479ba8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c13feb2-a79c-4154-b2d6-8d169355288e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7a319e4-3f14-4f2f-ab33-47fdb2c1a0df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d3de20b-b7a4-47b5-abe6-56aa5b21ae6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d04419c-975d-49ba-9943-06c41070a679
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69384605-69ce-4a59-a706-f79cf699bc4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03794935-cef1-4012-8673-a69e948eaf17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 873168e1-eef1-4e39-a9dd-58f4a7a1966c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e57f800-bae8-48ec-9c97-4649f8051703
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 029494b5-c44a-4ef2-a012-98eb8314762f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47999cc5-e88b-4797-81cb-ee0020c196b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c44ae8f-e6f7-4233-a138-75fec9ef4733
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f4071b4-bc80-4d7b-8080-2f571a9c11d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71a76508-375c-4322-9994-d2324b91c980
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21325c11-7d92-4a93-82b0-2b4d92da3fd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d48569b-2d61-4458-b9d4-d77abccd846a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3624a2c-b0b2-4557-9814-88ceedc27409
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11b14a78-d6c9-4e01-a72b-e56f4da24727
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf092b8d-f41b-49bd-a768-1611b212219b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38418972-5cf4-4ac5-8369-dfb75dad1661
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e466329c-4ee3-4722-8c58-5740a84f3104
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ccce5b51-3ee0-4707-b801-845a859d3cd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52702cee-a847-46e3-8bc5-a91f70114c5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02060d70-c9c3-45c4-a477-5cc41576a0eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d674d2be-3527-4627-bfeb-0cc04a4eb31e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76f1b18f-3fe5-4905-a08b-ef611376f333
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 018b6e7d-9698-4fa0-ac6f-af1beb70150a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df858e45-5b6f-42f4-932b-74185ee9c3e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ee4df6c-2cec-4dfa-9f83-35f9c8b647dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79d1a22b-7236-4cca-9693-874b10665338
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4780f3c2-510a-4072-886e-b7fb1fda5d78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52a345e7-a941-4bca-88d9-2ab94c71a2cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 997b2e70-1763-45e5-96ee-f4e3798b44ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2752e932-737c-4734-a273-4c88fdcba93a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ea5a3a0-7563-4c9c-ba9f-cf5868d2e675
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6bcc88f9-468b-4e59-b96c-d65e903b443e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e8c309c-4318-4dce-9673-2e527bb793ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4eaceb08-a2b1-4fc0-9fa3-036970bef548
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db49186f-5061-47db-82ac-255752076b12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d4c4c73-9b3e-462f-924d-cc03e192f98e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7272f5dd-6919-46b7-aec5-ba0076765f5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 610a8487-e592-443b-873e-2a18c562695c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df4552bc-3666-4443-ab67-c600d3b4a2ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d28bd0bc-2f4c-47de-9752-e00418eb1d2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93c80b81-94c1-4315-b9ed-b46c53a7eef4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54104dd0-1885-4dee-a8e4-8f036e5414a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b32be415-605b-47d4-ac41-eec80eeae438
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bbbb9cd8-5589-41d8-803c-74a878087170
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16ac691b-d5f4-4555-b559-3dfd3e6a721d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f97e06ee-0b0e-44db-9dfb-6ad53d35854e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a75ce2a3-7e37-4046-b350-0aeeca4ac119
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7a409ac-7df1-4a84-bf2b-8e7c629aad57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef3c8054-d25d-4d4f-a9c3-dfa36bc108b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14fb2228-773d-4ea6-9220-bc9a69a0f09e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0fbafa06-9ee0-4277-9200-32d75ba75814
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51401334-274e-4a10-a789-b9da672b028b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a202837f-9010-48a4-bfb9-71fa1e32e09b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d36110f-60ea-4e1f-a727-0b6b611f1c41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8764c57f-556f-40fd-8e2d-7d651223777d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab44a5e7-ce86-4835-8678-93b7cceddd3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31600f40-2818-4b11-8746-beceb21b6643
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 331ccae3-5703-4e8e-9463-7e6df3740eea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89a45a73-d598-43df-8a3f-b4263c399866
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4610668f-7b25-4ac8-982e-cf783beb06f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4544a791-be80-4e7b-b01c-eff4567f6afb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe3002b7-9cbe-44f4-bea1-ccf5256b6826
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e450ec75-bb15-4c8d-a98c-0a73d242ab87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6a1fa33-338b-4513-b35d-58f7821f29bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2996a6fc-21e5-41ea-8c66-01112a00cacc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d6bb1ca-5cd3-49a9-809c-1fd971d12234
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4160fdf7-629a-45ee-ba4a-8554e5264c8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab600b62-a77f-4627-baa3-a756ec8adf10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 712ac5d2-ad6d-44a3-80ca-70d11c851e02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2632e4ae-4e89-4600-8d7d-b353e6e1eb7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37752ea7-9232-4134-a932-e1adebaa784e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6e644de-6fd0-4b99-b20a-57ce9a68a31b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7de2ca22-50b2-4b70-84b9-48bd6bb8d1a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72d42f09-379f-4acc-96a8-c5c8598fe49b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0958a579-deb5-47ed-a866-e8dd59572bcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f03783cf-b6b6-46b8-be6e-05ba554ddc8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89152773-6d14-4a86-b0ec-2cbf7b916c83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c443946a-300d-43d5-a489-515012af7b7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc18e45b-e7b2-44ba-b82d-5e2619a3f5db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c04774b2-06c1-4666-bcae-b48dd719e208
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10264837-aad9-43c9-8ffa-5f3853bd2ebe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 788d734b-c803-4515-b75f-c7d8cba8286c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2cb85189-be1f-4281-86c4-630b89f767d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22c61c3e-b9ce-42ce-9532-bcdd8c4a4a04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d03d496d-cf57-4cd2-bb22-ceec8963e927
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c31b944-6a39-49cc-b776-a76583275f07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ae86bf2-30e7-4dea-9723-fe1a0e2691d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27ba253d-c3cc-495c-abb9-11ffd3842784
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6e40b1a-e4f7-4c1c-84c5-6d804ac39589
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8897715-cbc4-4f0e-a223-075641dd4d61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message afc18a8f-13e2-4608-a4fb-fb7c2cd60be3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 815622ca-5ea5-48d4-a8cd-1896ad168633
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee42eb37-84b1-4e05-a3dd-0439d81d8db8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6338b6d1-b5c2-41f6-9793-934d9104dd09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 366d9900-32cd-497c-9311-3b4026387b97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4bf16c44-cf8d-445a-a902-1ca0408e6a0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fdaf13f1-439e-4057-ae75-382c14786a67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 836b35d5-c40b-4b93-810d-292b179471d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fde672d8-f292-40a0-b13b-d4909d43dbdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62e4f6dc-5c04-4430-9510-a02f158b44ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60cc7423-f607-419f-ab56-6fb86f751235
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cdcdbe68-4c6f-47ef-9d6c-3389c308ade6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cbd26a53-c392-4911-8b8e-369d4e88283d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99b0150d-b810-45cf-b3f1-a6ad36c068b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6d5deee-884c-4f22-919d-83580af16ea2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfda8616-17b2-46ce-824f-1dbbdb6ca6a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3421673-9416-4e0b-ba3b-25f9287567bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49e0a491-7b13-4aac-a57e-a37cd1eda0f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57cb9352-c7d4-4b13-aa31-d9962e9d69eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94c0ba98-7107-43db-984f-a9a287c1ed0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6fbfb08-93b0-4968-a105-f529a3f817f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 486aa58e-24a8-4922-a0d6-cbee8fbed159
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e76d1376-6a29-454e-a0ea-55dcec0bd303
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37f2c0f9-038e-4d7b-8dbf-b4de4fcb9425
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0b7243c-b874-4ea9-acb7-41d44867d7af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f03e1477-d00a-4f7a-9ba2-c6c47edc36a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ebdf472-8991-4448-bc0c-5ca43f1478ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73fb3155-1944-4c4c-940b-a914c8863be7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1992b07-2fbe-46c8-96b7-f29dc864760f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a03b1e4b-3255-4e07-8d2e-f22da6ff6fbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 460c20b5-9c29-4e93-a016-f757e4145bec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c9720fe-5ef5-4e8b-bd52-15ea5cf49dc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ad3144d-d396-453c-8812-15c3a7cd4fe5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7fd6f649-c763-4908-bb49-8d08df1335ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4299f189-f142-4f6a-89d1-9a42e9357f3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e04ee73f-ae3c-4cde-bbf0-e1282bc6d6c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 014444c1-a716-4a63-8740-c42618344e33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c9d7e88-3c15-40d3-b2a6-3004956c248e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98b699a6-81cc-48f7-b430-41449bd477db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf558773-c30a-4296-9a00-48ccb58d3050
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a79fbd91-86a9-4a46-b95a-8bfcb3d1102b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e89e6707-6a97-4877-91b8-2c1466bf8b04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c90d330a-53a5-4ae1-bed6-dd190d0523e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d97324f-dafa-4ad0-9ff9-c68686238ac1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87dce982-9050-47cd-b696-34a2dd18bb37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c343b41-b2e5-45c1-98d9-759b418d335b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73bf6177-4340-4712-b344-87fa3bb6bb3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 432f45ba-b827-4c53-815a-f0b9cf949c66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b629297d-5c08-4976-9a4a-7590c26107b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86fb9146-12f1-4a01-8e76-ce58876507a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13bdaa55-1680-4ee5-a5fe-3b9102f8364e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e110eca6-e8e8-4594-9469-10d7408b9579
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a6de4a6-c8b8-481f-82ad-a8e48b92f9fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1acf7ff6-80c6-46d0-adc7-d5e161543a83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf34ce11-88e4-4ad3-89cb-4e22acd75828
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91280682-645f-4ca0-8290-f90c59d6d1e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47a93631-1f5b-4af3-a79d-1fb155c6a7f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18bb1a12-5f9a-4e15-8d9a-e31c21000912
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e6a1ca1-5fc7-458e-9e2a-34d47bfc7295
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fdf66181-17c9-46ec-a4a5-ecb55b079118
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d02739ca-d2b1-4293-87b6-2b152ba00046
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb35100c-f19b-468d-a5ef-a0ab1e7a1f90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa666f61-9264-4fba-9917-543cc5570ad8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67421087-5281-43ae-aaae-921cd24675a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0397ce1c-8948-4b2c-a92f-aae3960f7c79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 005fca4c-5dde-4174-affe-fee555ec63a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 890eb6e2-ecd1-4c7d-abc0-c80cb4049bd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf2436a6-fa35-4761-8a8b-df103acea67b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a95f9ec-e35e-490a-aac3-ddf1c70c6878
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8acf05e9-abf7-4607-b688-60102820b195
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4c05f6e-a664-4ebf-acaf-46c8e82894c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d343eba7-6dbf-44e0-bee3-f81f8f716612
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e4b2212-7313-4e08-abed-9eefd125e760
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message faf079a7-0068-4b86-bb96-fb057e9b0573
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c413472-c064-4b27-bc73-c629c4281e3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75e27889-2822-43f3-946a-95da65031a8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a59f96a-6a86-444c-9be9-2137607c15e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb9235d3-cb00-4ddb-8a02-4e1b978ba52c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7da0cc26-9c37-436e-a385-147ad697a26a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 932fa9b9-814c-4798-8cbf-c6f25652c8b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72fede7c-4c7c-4dd4-9d84-af218128294d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0bd00d7d-f6f0-402f-8a18-3347a9951e17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a380e016-50f4-49b4-b536-92f1844a31fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b89a370-3129-4e4e-99c3-55288a3db369
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8350f8f-d7c3-4140-90a8-d3df3c356748
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c10e9e10-12fc-4c47-a146-92b12c54ff4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a996501-2604-48a2-8d5c-f8fabd5b64d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2cb2c86a-ce0b-4e4c-bfb5-3eded1a52873
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce07e589-41bb-4d0b-938d-f3c5ba4f1a70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c0abec2-cbae-4e33-a7fa-be7a2fd581ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c4b75d8-8f4e-442d-8aeb-f1c4cf069bc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e6f3876-200d-4801-a2e3-c87c2aed2a4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf91d8d5-c7fa-4232-9dd8-9cc9701c9d59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8512a733-dc7d-40e0-bc05-61bcc6a60e00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 283493aa-ad2a-485b-8647-43fd72a6a7a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2bf64d7-8e7b-46ae-8b35-9176e75967dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3dbdef6-5115-4f8d-ba6f-b58829b55dbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ce5910d-d10f-401f-83a3-96d8a10ab589
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a7ec15b-3968-4f7b-9ca9-222308aa9496
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35325265-9107-4fda-9da3-7beb541e2d3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47934448-a061-4d30-975f-6cbe7034ab81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30c15cff-b279-48ac-9895-e77e82d4be8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aeec1fab-a9c7-4c4e-a184-6392f321b297
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1f27126-7b75-4923-ac75-2f05a87342a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11a6e78c-4d2c-4847-8156-70026a802c1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a995660-b169-4a37-8c4b-432c9507b773
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 808a2104-ef7c-4b9c-bd3b-fabedb795100
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8473fda-67b1-45bd-91c0-cadfa8db713b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec1a9faa-ed75-460b-b10d-90d9ccf17f0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78a58a00-2940-4d65-a8c1-bfc737d75529
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b16a5c04-f152-44d8-a38f-f95a0cef0639
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 571283e5-1ffd-46bf-9814-bbe954723ef5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11666828-16f4-4f7d-aa9b-4591f602f57c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d346f994-7ac7-46b4-8abb-94f9cfa25f43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd9007f7-7f56-4321-8c8e-fd7f03112928
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37c04b19-a80d-49ae-8406-6b0154f3277f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dac7b5c6-93eb-4f52-9adb-56cf23ca3159
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef262d5e-e24c-44f2-9e72-0ccf3161e088
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84c25fdd-768d-4a6b-926e-0ae2b3309445
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a7fc129-8cbe-4059-8e47-abc61f98e4cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04098b04-1bd5-4933-b807-fa296b77fdb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80772e3a-7c90-46df-8999-057b28ec65fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2646dfb7-2faf-4e2e-86e3-465554ff9d1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f059ae38-bb84-41b6-8882-8ba8bc537ce7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55bd066d-3349-418e-a577-54f39cbcb04c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de5740e4-f5d8-419f-a169-496e8de0a887
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f41f66d-09a5-433b-8362-ae6ea5b8b553
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f332948f-be75-44e3-bce7-ef68af2f8dc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c756e64e-fd82-4e8c-88ba-8d3274d4597e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3c19489-30f4-4520-a98c-cdad114f22ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3fa91b5a-9010-45a8-a3f1-6710c5df284a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e250dc9c-1496-4a9c-9194-ed8a23966f83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b62b106d-ba9e-4a42-b552-94ae82530569
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f7e47b6-28ae-49eb-aa19-0ba7e0513074
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13100534-70c4-4c30-be77-31f9f30991c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce3450a5-a71e-4343-810b-c7e5f4d1f20a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2f9fdc8-081a-4a76-9b9b-14179dac8fd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9b5d71b-b2ea-43c4-b46a-d37936104779
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 763d95d5-7ea8-4518-89bd-3409fd76f49e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1761ac29-056c-4157-91c5-ac85e06fd314
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b894cd9d-0c95-4204-b65e-443dd1481a5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3e661ca-4058-453e-aa5b-58debb93e650
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 310fe8a8-afa6-47ca-a942-299ae9713f1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5fa8fbf0-8844-41a0-8913-52e84ecd41ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0661c8e4-1923-49cb-bf04-b271945a7ced
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9188c1ca-415d-4de6-b8be-78ef1e435393
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 003162f4-6327-40d0-87e1-26eb1b820de3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45d34415-5271-487c-8619-f17d571c7ec6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc88fb09-b58a-48fb-a96f-ae9d127d327b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f0e1d7e-b4f5-46aa-aef9-e1f52164a21f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e801d4e4-0114-4b0e-8a26-fcbb8cad5409
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9dacf606-1828-4c95-8b6e-ad4fe29ac4cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1298d94e-37d6-4f9f-8333-3a44281dc2ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2b392b7-cc53-4fee-ac23-93f7f24c3f40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f79740b9-ecf9-44df-b913-3fe5472f5f32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42b96419-219e-447f-8d45-196d9ceb0c04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 465279b7-a7ee-4410-95e7-2ea1fdbd5f77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 762c2bda-b626-4887-bd54-a8b0696ad8db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0381f06-c864-4a5e-ba37-0ffe6b29e849
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69d8f9bb-7255-4d38-b782-1e1bc6b8050c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6312252e-c91d-4d7d-851a-ec9f8f1494c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 065f4100-31da-4f42-9ba9-90b053ad97fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d70bde0c-da1f-4d83-8b96-46dc11c638d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message adbfd72b-06f4-4abf-aec7-6ba2bf9ce953
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8ef2d02-5bd3-4e1a-99a1-6f2d4d18f53c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80761a0d-fe3c-48c9-a174-c82db784c6ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66eb3949-3c80-49f7-a8ed-2ec6a1cac349
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21f573d8-14f0-48e6-99c2-1c38466eb10b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb926073-2d90-4245-94c5-ee20db9e1d61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9eba4fc-8559-49f9-949e-6f004fc7ec28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f55b35fd-d80b-4bc8-b72e-d9f5f6ea9bce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aaca6f57-34d8-4e85-a38e-7ead0402bcf5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20f066ab-663e-4593-a87f-8826eff45f79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60435e0a-9dc2-48d6-a3c7-3668ec79d264
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ccd5da6d-cbc2-4279-906d-6add2127bc08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40de9fad-3bf7-447a-9f8e-b8539d0e1a29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c14a4af7-cee1-4b8f-841c-70820dec859a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29ccae03-1c85-4dc3-bfd0-8084770acb55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ba077e4-4cff-4fd4-9534-bde20e262cc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1443785a-b872-4a60-ae95-dda9f291d619
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5bfe0842-6e4f-4662-b112-7f71a8ed87d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6277532-af34-40aa-bdd3-131fff7e908e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cfe76d9f-3f75-43ac-a030-e86066c9f886
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f77e7af1-fb6a-48c1-8dae-dcecb4843249
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35c0e3df-8b6a-42fa-a68d-3a521dedc19a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b1a8b5c-1961-4d07-9f0c-c0d99aa54a6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f873e28b-e57a-4299-a5b4-02fce287f322
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 325376ff-bab5-4992-ae21-279097a0fc00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf0086b4-7af0-4df0-b29e-8224b8d3400d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df0e37c2-8109-4454-9d51-d952be4d7312
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 255212c3-aabc-4090-b773-b5381122d4b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 331bb032-f54d-492b-bacc-31f3d32ddccc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de5ca9d5-d420-4d2b-872b-779a9bee095b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9453b3dd-113a-42c3-932b-f4c1cfcca5c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f22f9cbb-ce4f-4e98-adf4-34855f79c593
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e34da80c-8341-4242-996b-bd42d187599f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f788c2b8-9560-4889-9bd5-ae1abc265685
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7603adfa-9417-4620-a4cc-f08cc20f6d95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df60b58a-e06d-4e63-8d26-47e8accfeef3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a4819da-5c57-42bf-8f5e-ab2c3208a26d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13b0785e-0554-46c5-b063-20940d02f281
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 800436b6-d2e6-4387-bca2-181f583dc6c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bbb21bb8-2aad-4741-9162-dc241f1b445d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32d7a60d-b7d4-42f9-8bef-1746ca4a5029
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 065a7984-2ba7-43af-9074-097a47534caa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 128fa7e9-5024-4be9-8a3c-df370d103601
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1686bb04-0665-42bb-90d4-6fc1c0e823c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bba9eed7-7743-40a7-922a-7c07b095952d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7677c49b-4a5c-4046-bf9b-eb2601cff50d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b56ea68-d077-476e-a987-65c6179345d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1effaea9-6ed0-4af9-a704-b773c14b6d20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac5f27fb-a417-4b4f-aace-3d18de0c2e63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06877656-dee5-41e3-bd59-3d1a362ff09f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6554c34-4b39-4405-9fd4-65ae0a2ff957
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb248ae2-a3e5-4016-b207-80f0935fd7c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2abbdf16-df50-41c0-89ef-da6e00def97b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f7146e4-f958-44a4-9d6d-60975fb65c5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 357c31ab-878a-4ea0-8f8c-e6e0d9141043
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f6d3e18-a47e-43d7-943a-b2dfb072b673
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ce263ab-d06a-44cc-b8f3-a34e6272bd6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f244ed9a-0941-4002-93da-6ccdb04446a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52511fd4-1779-42bc-8046-95f755a76684
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d65a687a-ebf7-460f-aa6c-c5056e408dae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1fe52c8a-581e-43e3-aa19-49f43241a54b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a791b9c9-d7ab-4e73-af1e-55af49a9875b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01cacae1-fc22-45f4-8f61-ec18b28862cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff81b3b3-5c67-48b3-82d5-b60b0eaa76d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4e31741-13f0-420b-9613-4b52c4d40510
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0af18a6f-dac4-4432-87d7-8fae6d5aa7ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e69bf86-53ca-4120-95af-970da73e081e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 861e823d-dc72-4f5d-996f-436442267ebb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f968438d-c4a9-425a-83b1-8a726cfd16ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8baf992-6856-4248-b84f-a6c6ca5d5027
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d2f05fa-5a02-4e67-bd95-6ecd9f58a029
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42d92260-6a5e-4131-a4be-1dd8604215df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b18db4b9-808e-4c6f-9849-d28c0b2657f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message afae351d-fd09-43b9-a020-02d960287782
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98e25b1d-102c-4738-9d3e-71f0ea6dc7ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da0d463a-ae99-4fd3-ba2e-6ba14a03b457
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 198413ec-40a9-44b9-a2ed-038e5cfdbc4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message beefcf97-4687-4775-9c43-97aaaab1a48c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f28b4c4-2b9c-4cb6-b87c-2c0e3070536a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f2de7ea-c6ea-4abb-9c8e-0ad7f74efadd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b9f5459-7f43-46d4-a422-35cd2320538e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c49a2ad8-b33c-456f-8fe5-7ebee0b78067
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8be057a9-4b62-4174-8f49-19ff8d9f3821
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9f7493a-74b6-41fb-b2d7-4bbf12ca85de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 059a2d15-01c0-4472-95b7-580016ef8948
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe78f758-70aa-4fb2-b68f-a6478a69e65d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc1a8214-d072-4b33-8177-82bab2bdedf3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8484bca8-53c8-48dd-9a97-951e70a3a26c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bbcd574b-4e5d-4192-8ea7-30e1da980849
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eff0fd32-3b86-47d8-bc88-bc2c252bd3e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a459b10-ef22-4d4b-9f6e-48df42084c3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f24aa1d-efbc-46cf-b006-a48343b73cb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf55a36b-9d79-4baa-8750-910f31dda0d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77df2b78-2a68-4c1e-9486-2a87ee740191
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d727a426-fafc-4f65-8353-d1623c09cc4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9c3b95d-c68c-457e-ba74-a90e0cd46b54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00d2e372-6a6a-4430-96d1-043a47d2b76c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57ebbe00-a42e-4ede-b3ed-5f5545defb2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a730f9d1-dbf1-4580-91b3-c36e60e0a64d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b677fda1-26af-4162-a9a5-7895beddd181
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e39eda93-acb9-4c23-af69-b8a26bf7911f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1cec70c4-0bf9-4db3-8187-ac043c3cb64a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da207cad-1615-4678-bf2a-7578a63e840e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72773805-d7b4-4553-85fd-5d60a3f0ee08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29a24a1e-e725-4656-85e9-fbe4f027b31b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dbcdec40-66f4-4d97-8240-61a57474efe0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 150ea841-e45c-4ce9-bf90-1907fdc4cbb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 566446d6-cb65-4f03-986d-c7799ba1419b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50300167-d873-421e-9856-e9a1b0383873
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67e63478-ff7e-4085-a224-78848072a572
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e84226d6-e118-4adb-850c-331b119fbb48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59129bc7-3022-482b-b7fa-effb13508556
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6202f5e7-c161-4336-a7c8-1b89a4fafb7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f5d7806-8772-4173-8172-f2c7af642a3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d2cfebe-ce11-4602-a9f8-67deda42160a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3fa6a12-f8d4-41d2-8969-40d8f06d4d9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 801aeaaf-63f7-4151-82c7-d873a8ec4a6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03dfc788-d8de-4902-9130-30debb0f0f94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b973a63e-b8c1-4ebd-9d5a-d6d62f4ffcb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f68b567-f040-4aa3-b997-1f5fed7b5958
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1918c533-6b22-42fc-ace9-d53e5b177f87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8169b20a-fe9a-4f22-986a-338b1ee8d867
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b8b837f-d075-46fb-ae6d-b43b31c4bb74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ca0cb5f-fbdb-4a54-a08c-33a09f500982
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 915ae82a-23ff-420e-9abb-45df9c267956
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c776c752-cc34-48f4-a41b-6bcaa2607d05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8a6cc26-330a-46de-841a-628e3c8e044f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f83e4093-5f65-4734-a442-73b1908ece69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e72ef9c-008b-4e9d-992c-7eaf3a1e560c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 819e01f2-7d70-4e85-b8d8-fff5ca61881c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7dc564b7-889c-4963-aa74-72009fd9c320
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d500728b-1348-48f8-9bc5-c209945d3d35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e526f9cb-cefb-41d2-8a44-c7fd019ce073
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4ddf499-0438-4fe4-98d8-d2452ddf2a65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d1add95-6f86-4118-a44c-d77387fc9165
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2af7f862-7e76-4edd-8563-5a3d530d5ce8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e45c093-5dc0-4c5b-bff6-06459381a279
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c651290-5009-4a26-b43c-e159f6742ac8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6de773ad-d5a5-4035-8188-abcb9989414e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5fe83ca4-ec9b-4ce8-a000-9a0c6f67b942
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aedf12a9-8842-4198-b0d6-5e24551fe1be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35bd0186-a7af-4e94-b70e-8f84215ec80a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18d463b7-a9b2-4874-902e-6e6efca3db6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60cb9787-231f-4b4d-afb6-06f73813123c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message abfd8de4-901a-4d75-bd56-56e65b2e86ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 137bef43-916d-4cdd-92e0-48295efb3402
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1bbb019-1e4c-4e14-8593-f34f31b4c6bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 044545aa-0920-4a95-a700-b2eb582bb53a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a750b04-6318-4430-a427-f04585307f22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 376eff0d-67f1-4cd4-b109-b8f313cf8819
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e2c3698-67b0-4a6f-ae3f-31ebf0df3519
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01baf5a8-15eb-48eb-8e16-4a46812abe37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message baa47a7e-8bb5-42c4-8c15-c5bbfa5045dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5b1b87a-d9c6-4479-849a-d1d06928d5f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e729535b-e00c-47f7-a53c-48e97461658b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0d40a9e-7847-489f-9f08-807deacdeeba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e228d0dd-94f0-45e5-b030-494087abf6aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17bc6196-094e-414e-9526-e027396cd4a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98652ac3-ce0d-4bdc-b0a4-32e262b330a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae7d01f6-c2f3-47ea-9e28-6248089ca903
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60d0d24e-ce76-4a63-a0c4-6ed665f41f5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00ce1798-a9b0-4985-b54a-6f37b73886b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d52ca51a-9111-4ae2-a189-778873b29088
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed3bf5fa-5fc2-4eba-94ba-54c6637a3d3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d2308d2-22c1-4d6b-930e-7d5a828225bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ccef4412-5c17-4468-9e7a-03d92d0e57fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3efc6375-53cb-43f3-8d81-755cbc468d56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32f7fda7-d8e7-440f-b835-9135be7ec783
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91ee2309-e511-49e7-9741-af43aa4098db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f330c4d8-e8ed-440f-bf5e-40ffaa5e8d48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9268f13c-5c03-40c0-a112-7cd5249bf58b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 144549ba-df61-4bce-9160-e095c95647a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5410a0a-50d2-49af-b5a4-e24fc1411c54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 524d8a4c-3b6b-4bb2-b148-8558e6a276cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message abcef0a7-6ace-4821-8084-59a53bb8e88f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9754ae33-c4b2-49e7-bc88-2cfb6e47e85e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6253621-982f-4576-9419-27de19e6a794
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25a404aa-0bfe-41cb-aa63-e053e78e2e7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15bc9935-32e3-4255-9d73-976c8b698360
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ebd258e4-f471-4524-a8f6-1c187f4a3581
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb482691-1460-4aac-a136-2574439ac375
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ae0aafb-6a38-424c-952e-65ccb5bb566c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aad9310f-2acd-4aac-8c85-cc20f9766b45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dff9f491-be3d-4839-a86e-39820ce74304
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c093aea-de57-409d-8b03-162550b96da3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2dc20cd-1f33-40e3-9e85-6833203a20ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2ba7292-e967-4d9b-8a1d-2f3cb8b6c700
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f34c0d6-53f0-4bff-86d8-c13cc022cf18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4595634b-0d0b-47eb-b98e-7b8886660264
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72b8083f-e8a6-4fd8-bddc-88192fc7f9fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb2b0259-7e19-4764-bafe-65b199a5755c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6d1ea4b-1802-400f-bb99-7b1ac653bf84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d3cf0c7-cf71-4a2c-b9ee-545eeb487644
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15966f8f-d17b-4965-87b2-2764274b3dde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b29e817-6916-45ee-b7a7-9ed31786c2bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f80fe299-5c1b-42f6-a86b-fe11accf92cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aadedceb-d40c-4f06-a221-dbb7fa07ab27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 591b1f1c-1cd5-4082-8777-a426b39d1cd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 557862b8-3a7a-416d-bff6-47ab54814024
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a80b6f8-f7a4-453a-b259-41600690c92e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1a4dea2-df21-436e-bedd-e369a81e9808
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a7a01ed-a20f-4a1d-97c9-8c64c13a7ee4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60d8682a-3148-4e96-b6ac-ebe76d034c49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b20e2944-9ab8-44bc-b6bb-4c8909003d0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cdd380dc-e93e-4657-bc4d-73a3972a3b9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 797bda19-ff5d-4d72-8552-e8101b9fb627
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5821458-767b-4d4b-934d-58f035de0b4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6199da0d-283b-468a-b35e-cccac629cee8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae753b81-0d3c-4165-a102-1a1cffd1b4c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60d039ea-453e-4932-bc71-b514cd45019f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9488c3b0-0477-4d0b-9b0a-26013a493450
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14bc2e1c-b343-49f7-9390-51b043c9d3ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1fc96f5b-4991-4bc4-ab18-0747faf8651b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d84ef9b4-5167-4eed-9e1c-04fff0dff7a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1fa0aa0-0401-4c50-a13a-f5a864b9f5da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8430f2f6-143a-4e4d-8bbd-9d4fa180c422
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1973dfc0-87d7-47ee-9525-ddb504388115
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5191b364-9f46-4c07-b8b0-ba9d3fb1d969
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 824ae5ba-1215-488f-b250-5cbf9bdb7fe6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be63e86a-dfce-4b3d-80c3-25f6e04578e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d8c87eb-3bce-4a8a-9092-86b86fb8cd12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dca897f2-a08b-4c51-ab4e-5ede66908a6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2edeea28-1d48-44e3-a2f7-dc8a535cff19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c33183c-82ee-44ab-b13f-074e6e304aed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 651aefc8-e2f4-4322-b6e0-9b6b0c401c82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65421f79-00dc-4686-9d7c-c933bc795174
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df475dac-5c29-45e4-a05b-4138f17ff6f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a768139c-86cd-4c77-913e-de7253f4b47f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1cd96752-773f-4c79-9c9a-5a4ac9ecc678
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6fee67e3-31fb-4d17-9d2d-f60ec9521bbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac6dfb69-93c8-459f-a54e-6abd0b8ff688
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5417192f-dd04-40ec-aff3-748d484800c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27b46223-eb58-4850-a38b-89438145d9da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90935e19-141b-473c-b81a-0c15df411e4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4996dc69-164b-4131-9ec9-d16b4d25d7b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fddfa62d-3da6-456d-803b-07ec0b550d9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3cf60c4a-2f57-4aab-a975-f7127ba649fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1cf4f199-5771-498b-8c99-750069c03735
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bcad4539-6526-4121-b761-329e203afc15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f866554-71ec-4641-ad11-df1d340402aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb2aaaaf-32c8-4c11-9970-713b7859befc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab68997d-2a32-4a59-8e7e-40558c1e23df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e83b4434-40c6-41af-b537-1e11059e6309
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9c3b13b-cf17-4ccd-af76-0ce9bfa8d485
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9d5f0cf-ae63-4074-9311-888ab50ec461
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f10d4df-9c94-44d8-8ad9-a49d66ab079f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e384cfc-a227-4aba-8a44-f61b2fc2d15f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4888507-1160-430e-804d-08d9b6d1e0e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0b724a6-fab5-4df6-a708-e1c8c867ffbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3907b342-1877-4a34-b6f3-10eca8ebbebf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c93f4cb8-32be-405a-9fff-3258228e44c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4581ec6-fe70-463c-a7de-8a06a6dbe1c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e04f0464-8e25-45b8-b264-6d2508c81f7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd459d23-726d-42a7-aa30-cd394c8775d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b47a0a36-91a8-45be-b74f-c195ae3d706d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2211ed0-006a-4982-8d1f-a0720e7b09e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message baa35164-c367-4fd2-94b1-e7a1917e2e46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52f14383-86ae-4558-8404-42d5115e7216
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c31992b-594d-4e02-92d3-d96466156984
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d78cb88-1726-450a-9ef2-ff1683960943
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc541125-9e82-4266-b7a3-b0fce131c0fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c37e6a1c-94f8-43bf-9aff-5546de4d242c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16c4e77d-e17e-44e9-a08e-cd0a99bb7b2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da8e840b-b744-4ff6-a442-56e78f43087f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d70304e-bed2-4f68-ad44-68070f2dd02f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4a9488e-d097-4235-b63f-3602b89d65b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7aba0d7-e895-4822-af21-acc12de97033
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ffdb2f39-8926-4142-b0c0-f5c1ca8bc40b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b298c19-d038-4541-8f24-4cc609418216
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c65b6c2-d073-46f0-a6d9-070838e83cee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 099bafd6-e4db-4329-8781-78bdc659aad0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76d2e0d8-8e67-4abf-a615-4ea61479de98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c97ef26-a01c-46e1-9923-d53d3d712aad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 176f012e-557d-48aa-bb72-71578c1ee8e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79b8bb29-edae-4dfd-952b-8908768e5edd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b522a8d-8864-4ea3-9828-681cc943524b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6e45a9d-a7b0-4536-a802-4a04d56a39a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4596a54b-a472-4182-8932-e2063c652ea5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a1d8c7a-0e0d-49b3-a4af-def7154f1653
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83ad3516-1613-41db-8f1e-eacce0a8845a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19774dbe-5fae-4920-b57b-546a8709330a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea7f5d46-5dcc-4ac3-a9f5-0b4ac354d14f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75347294-6df7-4b10-8d59-ae5b10f82c84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b52b1d2-04f4-4eaa-a228-5650f29463aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message accac20b-719f-4b56-8271-f3c54867fb69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93129275-a211-4459-b1c0-c6519403834c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 287d82df-9005-4d6d-bb53-1ebf7b1df7aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8576193a-ddbd-4e4d-8cb8-59b2e0be27dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5fe8f0d-e7d2-4c1b-ade0-fe3578f11a18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7864d0fb-c952-43b5-9350-4b457062da2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61e770a2-027b-4816-83f2-866fd13e39a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54c13c48-0acb-4c78-96c0-d9a2bd2b4a0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae2815be-a758-478f-ae61-971da4eb8373
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f30b4d8a-1177-4e12-8d8c-e45e661e4b65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d1f06de-84cd-4452-8df1-aad702a7d7fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca3ebe76-7970-4fa5-bfaf-dd45c27b5068
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18a30805-2456-4dd9-aeb4-1c6263a0a89c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82016992-51bf-4854-9de9-2e20f6cd0feb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2328ff2c-d67f-4182-86e4-f4927d8d3f46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ac3f592-86dd-4f43-9fad-b7247369b45d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b21b8f7d-0660-42a5-8c06-616a4180ac13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98677ec0-7414-4b64-b7d7-118644c6e876
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36282d2e-8b3f-451f-b912-699aad5967c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c5d5bd8-ab31-4bd3-a293-9f4808541025
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1bcb06f-5622-477b-8daa-72846dca2a95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f87de661-01c6-41da-9077-db09b2226a2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2bf27f5b-0609-4c34-86ee-508601caae2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e63a3056-98e0-4331-ad0e-cb0f44b050af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7532c143-3cf1-43fd-847f-64936528818d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e92ba494-d091-4d2e-8fc5-6c3c0ac3ff2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b786df9-34fe-4af8-a29b-1caf87ca809a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce484bad-1824-458d-953a-61fcb88dd13d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa6f1c57-8f06-4ae6-b99a-b5202d6a7b83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2e7c02a-d7c6-4376-a4f1-10c98ff3eac1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 505da819-c0ce-494b-8c1c-1992a3299972
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68449a65-df62-43a7-9fd7-3844f75d0096
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7cdc1b3b-c82a-4d54-936a-d0871c23c027
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 109cb504-2eb9-4f07-93fd-c33cd97b558f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f63f862b-e982-4eda-8b68-16b5131ad4ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4a264b9-6f32-478d-894b-e76fa2dd9bc1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2110e84e-b342-4197-bfdf-fa699c090fe9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2b61c1f-55b6-40f0-ac0f-901e673dd301
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6d5affd-2391-47b3-8b04-27003bc178d1
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8692 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_24
Server: localhost:8692
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_24
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_24/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_24/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_24/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_24/test_labels.txt

📊 Raw data loaded:
   Train: X=(3897, 24), y=(3897,)
   Test:  X=(975, 24), y=(975,)

⚠️  Limiting training data: 3897 → 800 samples
⚠️  Limiting test data: 975 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_24 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.5146, RMSE: 0.7173, MAE: 0.6579, R²: -5.2966

============================================================
🔄 Round 3 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.3660, val=0.1457 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.1093, val=0.0930 (↓), lr=0.001000
   ✓ Epoch   3/100: train=0.0938, val=0.0883 (↓), lr=0.001000
   • Epoch   4/100: train=0.0902, val=0.0882, patience=1/15, lr=0.001000
   ✓ Epoch   5/100: train=0.0907, val=0.0878 (↓), lr=0.001000
   • Epoch  11/100: train=0.0897, val=0.0875, patience=6/15, lr=0.001000
   • Epoch  21/100: train=0.0856, val=0.0873, patience=7/15, lr=0.001000
   📉 Epoch 23: LR reduced 0.001000 → 0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 3 Summary - Client client_24
   Epochs: 29/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0883, RMSE=0.2971, R²=0.0229
   Val:   Loss=0.0872, RMSE=0.2954, R²=0.0163
============================================================


📊 Round 3 Test Metrics:
   Loss: 0.5025, RMSE: 0.7089, MAE: 0.6486, R²: -5.1483

============================================================
🔄 Round 5 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.4064, val=0.3142 (↓), lr=0.000500
   📉 Epoch 2: LR reduced 0.000500 → 0.000250
   ✓ Epoch   2/100: train=0.1783, val=0.0986 (↓), lr=0.000250
   ✓ Epoch   3/100: train=0.0909, val=0.0981 (↓), lr=0.000250
   • Epoch   4/100: train=0.0884, val=0.0979, patience=1/15, lr=0.000250
   • Epoch   5/100: train=0.0880, val=0.0977, patience=2/15, lr=0.000250
   📉 Epoch 10: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0877, val=0.0976, patience=8/15, lr=0.000125
   📉 Epoch 18: LR reduced 0.000125 → 0.000063
   • Epoch  21/100: train=0.0875, val=0.0975, patience=9/15, lr=0.000063
   📉 Epoch 26: LR reduced 0.000063 → 0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0975)

============================================================
📊 Round 5 Summary - Client client_24
   Epochs: 27/100 (early stopped)
   LR: 0.000500 → 0.000031 (4 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=0.0055
   Val:   Loss=0.0975, RMSE=0.3123, R²=0.0030
============================================================


📊 Round 5 Test Metrics:
   Loss: 0.4892, RMSE: 0.6994, MAE: 0.6383, R²: -4.9858

============================================================
🔄 Round 8 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.4694, val=0.4550 (↓), lr=0.000031
   ✓ Epoch   2/100: train=0.4406, val=0.4273 (↓), lr=0.000031
   ✓ Epoch   3/100: train=0.4155, val=0.4041 (↓), lr=0.000031
   ✓ Epoch   4/100: train=0.3941, val=0.3836 (↓), lr=0.000031
   ✓ Epoch   5/100: train=0.3744, val=0.3640 (↓), lr=0.000031
   📉 Epoch 7: LR reduced 0.000031 → 0.000016
   ✓ Epoch  11/100: train=0.2899, val=0.2821 (↓), lr=0.000016
   📉 Epoch 15: LR reduced 0.000016 → 0.000008
   ✓ Epoch  21/100: train=0.2005, val=0.1938 (↓), lr=0.000008
   📉 Epoch 23: LR reduced 0.000008 → 0.000004
   📉 Epoch 31: LR reduced 0.000004 → 0.000002
   ✓ Epoch  31/100: train=0.1659, val=0.1604 (↓), lr=0.000002
   📉 Epoch 39: LR reduced 0.000002 → 0.000001
   ✓ Epoch  41/100: train=0.1549, val=0.1501 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.1499, val=0.1450 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.1453, val=0.1402 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.1410, val=0.1358 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.1369, val=0.1316 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.1331, val=0.1277 (↓), lr=0.000001

============================================================
📊 Round 8 Summary - Client client_24
   Epochs: 100/100
   LR: 0.000031 → 0.000001 (5 reductions)
   Train: Loss=0.1295, RMSE=0.3599, R²=-0.4129
   Val:   Loss=0.1244, RMSE=0.3527, R²=-0.4901
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.4739, RMSE: 0.6884, MAE: 0.6262, R²: -4.7985

============================================================
🔄 Round 10 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.4725, val=0.4258 (↓), lr=0.000001
   ✓ Epoch   2/100: train=0.4717, val=0.4250 (↓), lr=0.000001
   ✓ Epoch   3/100: train=0.4708, val=0.4243 (↓), lr=0.000001
   ✓ Epoch   4/100: train=0.4701, val=0.4236 (↓), lr=0.000001
   ✓ Epoch   5/100: train=0.4694, val=0.4230 (↓), lr=0.000001
   • Epoch  11/100: train=0.4659, val=0.4197, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.4611, val=0.4153, patience=1/15, lr=0.000001
   • Epoch  31/100: train=0.4571, val=0.4115, patience=1/15, lr=0.000001
   • Epoch  41/100: train=0.4533, val=0.4080, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.4497, val=0.4046, patience=1/15, lr=0.000001
   • Epoch  61/100: train=0.4463, val=0.4014, patience=1/15, lr=0.000001
   • Epoch  71/100: train=0.4429, val=0.3983, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.4396, val=0.3951, patience=1/15, lr=0.000001
   • Epoch  91/100: train=0.4363, val=0.3920, patience=1/15, lr=0.000001

============================================================
📊 Round 10 Summary - Client client_24
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.4317, RMSE=0.6570, R²=-3.8174
   Val:   Loss=0.3892, RMSE=0.6239, R²=-3.2974
============================================================


📊 Round 10 Test Metrics:
   Loss: 0.3814, RMSE: 0.6176, MAE: 0.5473, R²: -3.6670

============================================================
🔄 Round 15 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.3843, val=0.3601 (↓), lr=0.000001
   • Epoch   2/100: train=0.3838, val=0.3597, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.3833, val=0.3592 (↓), lr=0.000001
   • Epoch   4/100: train=0.3828, val=0.3588, patience=1/15, lr=0.000001
   ✓ Epoch   5/100: train=0.3823, val=0.3583 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.3794, val=0.3556 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.3746, val=0.3511 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.3699, val=0.3467 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.3652, val=0.3423 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.3605, val=0.3379 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.3559, val=0.3335 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.3512, val=0.3291 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.3465, val=0.3247 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.3417, val=0.3202 (↓), lr=0.000001

============================================================
📊 Round 15 Summary - Client client_24
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.3379, RMSE=0.5813, R²=-2.8412
   Val:   Loss=0.3162, RMSE=0.5623, R²=-2.2447
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.3257, RMSE: 0.5707, MAE: 0.4939, R²: -2.9857

============================================================
🔄 Round 17 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.3201, val=0.3514 (↓), lr=0.000001
   ✓ Epoch   2/100: train=0.3196, val=0.3509 (↓), lr=0.000001
   ✓ Epoch   3/100: train=0.3191, val=0.3503 (↓), lr=0.000001
   ✓ Epoch   4/100: train=0.3186, val=0.3498 (↓), lr=0.000001
   ✓ Epoch   5/100: train=0.3181, val=0.3493 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.3151, val=0.3460 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.3100, val=0.3405 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.3049, val=0.3350 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.2997, val=0.3294 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.2943, val=0.3236 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.2889, val=0.3178 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.2834, val=0.3118 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.2777, val=0.3056 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.2719, val=0.2993 (↓), lr=0.000001

============================================================
📊 Round 17 Summary - Client client_24
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.2656, RMSE=0.5153, R²=-1.9290
   Val:   Loss=0.2935, RMSE=0.5418, R²=-2.3961
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.3052, RMSE: 0.5524, MAE: 0.4733, R²: -2.7344

============================================================
🔄 Round 18 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.3009, val=0.3258 (↓), lr=0.000001
   • Epoch   2/100: train=0.3004, val=0.3253, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.3000, val=0.3248 (↓), lr=0.000001
   • Epoch   4/100: train=0.2995, val=0.3243, patience=1/15, lr=0.000001
   ✓ Epoch   5/100: train=0.2990, val=0.3238 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.2961, val=0.3208 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.2912, val=0.3157 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.2861, val=0.3104 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.2809, val=0.3050 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.2755, val=0.2994 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.2699, val=0.2936 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.2641, val=0.2876 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.2582, val=0.2815 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.2522, val=0.2753 (↓), lr=0.000001

============================================================
📊 Round 18 Summary - Client client_24
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.2461, RMSE=0.4960, R²=-1.8211
   Val:   Loss=0.2696, RMSE=0.5192, R²=-1.6640
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.2048, RMSE: 0.4526, MAE: 0.3719, R²: -1.5064

📊 Round 18 Test Metrics:
   Loss: 0.1748, RMSE: 0.4181, MAE: 0.3411, R²: -1.1385

============================================================
🔄 Round 23 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1476, val=0.1476 (↓), lr=0.000001
   ✓ Epoch   2/100: train=0.1469, val=0.1468 (↓), lr=0.000001
   ✓ Epoch   3/100: train=0.1462, val=0.1461 (↓), lr=0.000001
   ✓ Epoch   4/100: train=0.1454, val=0.1453 (↓), lr=0.000001
   ✓ Epoch   5/100: train=0.1447, val=0.1446 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.1407, val=0.1405 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.1346, val=0.1342 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.1292, val=0.1285 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.1242, val=0.1234 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.1197, val=0.1187 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.1156, val=0.1145 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.1119, val=0.1106 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.1086, val=0.1072 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.1057, val=0.1041 (↓), lr=0.000001

============================================================
📊 Round 23 Summary - Client client_24
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1032, RMSE=0.3213, R²=-0.1369
   Val:   Loss=0.1016, RMSE=0.3187, R²=-0.1681
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.1165, RMSE: 0.3414, MAE: 0.2819, R²: -0.4258

📊 Round 23 Test Metrics:
   Loss: 0.0956, RMSE: 0.3092, MAE: 0.2629, R²: -0.1695

📊 Round 23 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2523, R²: -0.0376

============================================================
🔄 Round 26 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0911, val=0.0940 (↓), lr=0.000001
   • Epoch   2/100: train=0.0910, val=0.0939, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0909, val=0.0939, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0909, val=0.0939, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0908, val=0.0939, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0905, val=0.0938, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0940)

============================================================
📊 Round 26 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0911, RMSE=0.3019, R²=-0.0258
   Val:   Loss=0.0940, RMSE=0.3065, R²=-0.0007
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2515, R²: -0.0274

============================================================
🔄 Round 28 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0898, val=0.0946 (↓), lr=0.000001
   • Epoch   2/100: train=0.0898, val=0.0946, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0897, val=0.0945, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0897, val=0.0945, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0897, val=0.0945, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0896, val=0.0943, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0946)

============================================================
📊 Round 28 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0898, RMSE=0.2996, R²=-0.0066
   Val:   Loss=0.0946, RMSE=0.3076, R²=-0.0177
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2504, R²: -0.0163

============================================================
🔄 Round 31 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.1007 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.1007, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.1007, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.1006, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.1006, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.1006, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1007)

============================================================
📊 Round 31 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2959, R²=-0.0010
   Val:   Loss=0.1007, RMSE=0.3173, R²=-0.0040
============================================================


============================================================
🔄 Round 35 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0910, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0910, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0910, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0910, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0910, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0909, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 35 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0912, RMSE=0.3021, R²=-0.0003
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0002
============================================================


============================================================
🔄 Round 38 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0908, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0908, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0908, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0908, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0908, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0908, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 38 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0911, RMSE=0.3018, R²=0.0031
   Val:   Loss=0.0857, RMSE=0.2928, R²=-0.0123
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2499, R²: -0.0108

============================================================
🔄 Round 41 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0920, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0920, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0920, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0920, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0920, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0919, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 41 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0919, RMSE=0.3032, R²=-0.0016
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0001
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2499, R²: -0.0103

============================================================
🔄 Round 43 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0894, val=0.0932 (↓), lr=0.000001
   • Epoch   2/100: train=0.0894, val=0.0932, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0894, val=0.0932, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0894, val=0.0932, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0894, val=0.0932, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0894, val=0.0932, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0932)

============================================================
📊 Round 43 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2986, R²=0.0003
   Val:   Loss=0.0932, RMSE=0.3053, R²=0.0020
============================================================


============================================================
🔄 Round 44 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0914, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0914, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0914, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0914, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0914, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0913, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 44 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0916, RMSE=0.3026, R²=0.0019
   Val:   Loss=0.0834, RMSE=0.2889, R²=-0.0029
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2498, R²: -0.0092

📊 Round 44 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2498, R²: -0.0090

============================================================
🔄 Round 47 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0970 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0970, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0970, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0970, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0970, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0969, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0970)

============================================================
📊 Round 47 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2969, R²=0.0009
   Val:   Loss=0.0970, RMSE=0.3115, R²=0.0011
============================================================


============================================================
🔄 Round 50 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0908, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0908, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0908, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0908, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0908, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0908, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 50 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0907, RMSE=0.3012, R²=0.0022
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.0012
============================================================


============================================================
🔄 Round 53 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0913, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0913, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0913, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0913, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0913, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0913, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 53 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0913, RMSE=0.3022, R²=0.0019
   Val:   Loss=0.0840, RMSE=0.2899, R²=0.0008
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2497, R²: -0.0079

============================================================
🔄 Round 54 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0969 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0969, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0969, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0970, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0970, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0971, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0969)

============================================================
📊 Round 54 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2968, R²=0.0032
   Val:   Loss=0.0969, RMSE=0.3113, R²=-0.0143
============================================================


============================================================
🔄 Round 55 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0895, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0895, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0894, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0894, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0894, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0894, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 55 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0893, RMSE=0.2988, R²=0.0020
   Val:   Loss=0.0921, RMSE=0.3035, R²=0.0022
============================================================


============================================================
🔄 Round 56 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0925, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0925, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0925, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0925, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0925, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0925, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 56 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0930, RMSE=0.3049, R²=0.0000
   Val:   Loss=0.0773, RMSE=0.2781, R²=0.0032
============================================================


============================================================
🔄 Round 58 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0937, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0937, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0937, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0937, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0937, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0936, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 58 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0935, RMSE=0.3059, R²=0.0009
   Val:   Loss=0.0749, RMSE=0.2738, R²=-0.0141
============================================================


============================================================
🔄 Round 59 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0910, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0910, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0910, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0910, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0910, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0910, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 59 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0913, RMSE=0.3022, R²=0.0019
   Val:   Loss=0.0839, RMSE=0.2896, R²=0.0044
============================================================


============================================================
🔄 Round 61 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0905, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0905, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0905, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0905, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0905, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0904, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 61 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0904, RMSE=0.3007, R²=0.0025
   Val:   Loss=0.0874, RMSE=0.2956, R²=0.0019
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2495, R²: -0.0065

============================================================
🔄 Round 62 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0979 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0979, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0979, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0979, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0979, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0978, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0979)

============================================================
📊 Round 62 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=0.0024
   Val:   Loss=0.0979, RMSE=0.3128, R²=0.0027
============================================================


============================================================
🔄 Round 63 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0898, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0898, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0898, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0898, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0898, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0898, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 63 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0896, RMSE=0.2993, R²=0.0019
   Val:   Loss=0.0907, RMSE=0.3012, R²=0.0035
============================================================


============================================================
🔄 Round 64 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0903, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0903, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0903, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0903, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0903, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0902, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 64 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0905, RMSE=0.3008, R²=0.0006
   Val:   Loss=0.0872, RMSE=0.2954, R²=0.0095
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2495, R²: -0.0062

============================================================
🔄 Round 67 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0896, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0896, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0896, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0896, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0896, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0895, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 67 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0894, RMSE=0.2990, R²=0.0022
   Val:   Loss=0.0914, RMSE=0.3023, R²=-0.0001
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2495, R²: -0.0062

============================================================
🔄 Round 68 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0955 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0955, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0955, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0955, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0955, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0955, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0955)

============================================================
📊 Round 68 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2973, R²=0.0024
   Val:   Loss=0.0955, RMSE=0.3091, R²=0.0020
============================================================


============================================================
🔄 Round 69 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0900, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0900, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0900, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0900, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0900, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0899, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 69 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0899, RMSE=0.2999, R²=0.0031
   Val:   Loss=0.0893, RMSE=0.2988, R²=-0.0161
============================================================


============================================================
🔄 Round 70 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0904, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0904, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0904, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0904, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0904, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0903, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 70 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0903, RMSE=0.3005, R²=0.0027
   Val:   Loss=0.0879, RMSE=0.2965, R²=-0.0087
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2495, R²: -0.0062

============================================================
🔄 Round 74 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0894, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0894, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0894, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0894, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0894, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0894, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 74 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0897, RMSE=0.2995, R²=-0.0004
   Val:   Loss=0.0903, RMSE=0.3004, R²=0.0114
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2495, R²: -0.0061

📊 Round 74 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2495, R²: -0.0063

📊 Round 74 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2495, R²: -0.0063

============================================================
🔄 Round 80 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0894, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0894, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0894, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0894, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0894, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0894, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 80 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0898, RMSE=0.2996, R²=0.0039
   Val:   Loss=0.0900, RMSE=0.2999, R²=-0.0088
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2495, R²: -0.0062

============================================================
🔄 Round 84 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0895, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0895, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0895, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0895, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0895, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0895, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 84 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0896, RMSE=0.2993, R²=0.0024
   Val:   Loss=0.0909, RMSE=0.3014, R²=0.0012
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2495, R²: -0.0062

============================================================
🔄 Round 85 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0891, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0891, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0891, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0891, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0891, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0891, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 85 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0893, RMSE=0.2989, R²=0.0013
   Val:   Loss=0.0918, RMSE=0.3030, R²=0.0071
============================================================


============================================================
🔄 Round 86 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0925, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0925, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0925, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0925, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0925, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0924, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 86 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0923, RMSE=0.3039, R²=0.0012
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0096
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2495, R²: -0.0062

============================================================
🔄 Round 91 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0947 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0948, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0949, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0950, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0950, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0955, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0947)

============================================================
📊 Round 91 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2976, R²=0.0010
   Val:   Loss=0.0947, RMSE=0.3078, R²=-0.0898
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2495, R²: -0.0062

============================================================
🔄 Round 92 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0899, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0899, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0899, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0899, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0898, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0897, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 92 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0899, RMSE=0.2998, R²=-0.0017
   Val:   Loss=0.0896, RMSE=0.2993, R²=-0.0397
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2495, R²: -0.0062

============================================================
🔄 Round 94 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0920, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0920, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0920, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0919, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0919, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0919, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 94 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0921, RMSE=0.3034, R²=0.0012
   Val:   Loss=0.0808, RMSE=0.2843, R²=0.0007
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2495, R²: -0.0062

📊 Round 94 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2495, R²: -0.0062

============================================================
🔄 Round 97 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0891, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0891, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0891, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0891, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0891, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0891, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 97 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0891, RMSE=0.2985, R²=0.0022
   Val:   Loss=0.0926, RMSE=0.3043, R²=-0.0001
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2495, R²: -0.0062

============================================================
🔄 Round 99 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0918, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0918, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0918, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0918, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0918, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0918, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 99 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0916, RMSE=0.3027, R²=0.0024
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0019
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2495, R²: -0.0064

📊 Round 99 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2496, R²: -0.0068

📊 Round 99 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2496, R²: -0.0070

📊 Round 99 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2496, R²: -0.0070

📊 Round 99 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2495, R²: -0.0067

============================================================
🔄 Round 108 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0906, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0906, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0906, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0906, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0906, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0906, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 108 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0903, RMSE=0.3006, R²=0.0021
   Val:   Loss=0.0878, RMSE=0.2963, R²=0.0029
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2495, R²: -0.0066

============================================================
🔄 Round 110 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0897, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0897, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0897, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0897, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0897, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0897, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 110 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0895, RMSE=0.2991, R²=0.0043
   Val:   Loss=0.0914, RMSE=0.3023, R²=-0.0095
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2495, R²: -0.0066

============================================================
🔄 Round 111 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0897, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0897, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0897, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0897, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0897, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0896, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 111 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0895, RMSE=0.2991, R²=0.0031
   Val:   Loss=0.0912, RMSE=0.3020, R²=-0.0019
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2495, R²: -0.0063

📊 Round 111 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2495, R²: -0.0062

============================================================
🔄 Round 116 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0935 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0935, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0936, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0936, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0936, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0937, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0935)

============================================================
📊 Round 116 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0889, RMSE=0.2982, R²=0.0000
   Val:   Loss=0.0935, RMSE=0.3058, R²=0.0016
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2495, R²: -0.0062

============================================================
🔄 Round 119 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0927, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0927, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0927, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0927, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0927, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0927, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 119 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0926, RMSE=0.3043, R²=0.0017
   Val:   Loss=0.0787, RMSE=0.2806, R²=-0.0022
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2495, R²: -0.0059

📊 Round 119 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2495, R²: -0.0058

📊 Round 119 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2494, R²: -0.0053

📊 Round 119 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2494, R²: -0.0053

📊 Round 119 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2494, R²: -0.0055

============================================================
🔄 Round 135 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0919, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0919, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0919, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0919, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0919, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0919, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 135 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0920, RMSE=0.3033, R²=0.0027
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0018
============================================================


============================================================
🔄 Round 136 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0891, val=0.0929 (↓), lr=0.000001
   • Epoch   2/100: train=0.0891, val=0.0929, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0891, val=0.0929, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0891, val=0.0929, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0891, val=0.0929, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0891, val=0.0929, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0929)

============================================================
📊 Round 136 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0890, RMSE=0.2984, R²=0.0026
   Val:   Loss=0.0929, RMSE=0.3048, R²=0.0023
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2494, R²: -0.0056

============================================================
🔄 Round 139 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0896, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0896, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0896, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0896, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0896, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0896, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 139 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0896, RMSE=0.2993, R²=0.0040
   Val:   Loss=0.0906, RMSE=0.3010, R²=-0.0105
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2494, R²: -0.0054

============================================================
🔄 Round 140 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0899, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0899, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0899, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0899, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0899, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0899, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 140 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0897, RMSE=0.2995, R²=0.0026
   Val:   Loss=0.0903, RMSE=0.3005, R²=0.0022
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2494, R²: -0.0054

📊 Round 140 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2494, R²: -0.0053

📊 Round 140 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2494, R²: -0.0053

============================================================
🔄 Round 147 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0910, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0910, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0910, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0910, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0910, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0910, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 147 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0911, RMSE=0.3018, R²=0.0023
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0057
============================================================


============================================================
🔄 Round 148 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0917, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0917, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0917, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0917, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0917, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0917, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 148 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0915, RMSE=0.3025, R²=0.0019
   Val:   Loss=0.0831, RMSE=0.2882, R²=-0.0099
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2494, R²: -0.0053

============================================================
🔄 Round 150 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0891, val=0.0928 (↓), lr=0.000001
   • Epoch   2/100: train=0.0891, val=0.0928, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0891, val=0.0928, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0891, val=0.0928, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0891, val=0.0928, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0891, val=0.0928, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0928)

============================================================
📊 Round 150 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0891, RMSE=0.2984, R²=0.0003
   Val:   Loss=0.0928, RMSE=0.3046, R²=0.0085
============================================================


============================================================
🔄 Round 151 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0902, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0902, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0902, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0902, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0902, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0902, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 151 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0902, RMSE=0.3003, R²=0.0025
   Val:   Loss=0.0884, RMSE=0.2974, R²=-0.0022
============================================================


============================================================
🔄 Round 154 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0916, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0916, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0916, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0916, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0916, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0915, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 154 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0919, RMSE=0.3032, R²=0.0022
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0073
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2494, R²: -0.0055

📊 Round 154 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2494, R²: -0.0053

============================================================
🔄 Round 156 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0897, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0897, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0897, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0897, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0897, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0896, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 156 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0895, RMSE=0.2992, R²=0.0002
   Val:   Loss=0.0908, RMSE=0.3014, R²=-0.0248
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2494, R²: -0.0056

============================================================
🔄 Round 157 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0955 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0955, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0955, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0955, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0955, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0955, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0955)

============================================================
📊 Round 157 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2973, R²=0.0037
   Val:   Loss=0.0955, RMSE=0.3091, R²=-0.0022
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2494, R²: -0.0057

============================================================
🔄 Round 161 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0934 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0934, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0934, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0934, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0934, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0934, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0934)

============================================================
📊 Round 161 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0889, RMSE=0.2982, R²=0.0018
   Val:   Loss=0.0934, RMSE=0.3056, R²=-0.0029
============================================================


============================================================
🔄 Round 162 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0917, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0917, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0917, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0917, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0917, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0917, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 162 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0914, RMSE=0.3024, R²=0.0048
   Val:   Loss=0.0833, RMSE=0.2887, R²=-0.0086
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2494, R²: -0.0056

============================================================
🔄 Round 163 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0914, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0914, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0914, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0914, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0914, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0914, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 163 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0913, RMSE=0.3022, R²=0.0015
   Val:   Loss=0.0838, RMSE=0.2894, R²=0.0030
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2494, R²: -0.0058

📊 Round 163 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2494, R²: -0.0058

============================================================
🔄 Round 166 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0894, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0894, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0894, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0894, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0894, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0894, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 166 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2987, R²=0.0031
   Val:   Loss=0.0921, RMSE=0.3035, R²=-0.0003
============================================================


============================================================
🔄 Round 167 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0913, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0913, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0913, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0913, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0913, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0913, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 167 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0914, RMSE=0.3023, R²=-0.0001
   Val:   Loss=0.0835, RMSE=0.2889, R²=0.0122
============================================================


============================================================
🔄 Round 168 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0943 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0943, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0943, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0943, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0943, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0943, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0943)

============================================================
📊 Round 168 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2978, R²=0.0042
   Val:   Loss=0.0943, RMSE=0.3071, R²=-0.0090
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2494, R²: -0.0054

============================================================
🔄 Round 171 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0901, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0901, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0901, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0901, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0901, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0900, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 171 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0902, RMSE=0.3003, R²=-0.0008
   Val:   Loss=0.0883, RMSE=0.2972, R²=-0.0222
============================================================


============================================================
🔄 Round 172 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0899, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0899, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0899, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0899, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0899, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0899, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 172 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0896, RMSE=0.2994, R²=0.0035
   Val:   Loss=0.0905, RMSE=0.3008, R²=-0.0084
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2494, R²: -0.0054

📊 Round 172 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2494, R²: -0.0056

📊 Round 172 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2494, R²: -0.0055

📊 Round 172 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2494, R²: -0.0055

📊 Round 172 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2494, R²: -0.0055

📊 Round 172 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2494, R²: -0.0055

============================================================
🔄 Round 180 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0909, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0909, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0909, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0909, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0909, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0909, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 180 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0910, RMSE=0.3017, R²=0.0026
   Val:   Loss=0.0851, RMSE=0.2917, R²=0.0021
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2494, R²: -0.0052

============================================================
🔄 Round 182 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0925, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0925, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0925, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0925, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0925, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0925, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 182 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0925, RMSE=0.3041, R²=0.0017
   Val:   Loss=0.0790, RMSE=0.2811, R²=0.0042
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2494, R²: -0.0052

📊 Round 182 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2494, R²: -0.0052

============================================================
🔄 Round 184 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0951 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0951, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0952, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0952, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0952, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0954, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0951)

============================================================
📊 Round 184 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2975, R²=0.0009
   Val:   Loss=0.0951, RMSE=0.3083, R²=-0.0363
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2494, R²: -0.0052

📊 Round 184 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2494, R²: -0.0053

📊 Round 184 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2494, R²: -0.0053

============================================================
🔄 Round 188 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0923, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0923, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0923, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0923, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0923, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0923, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 188 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0919, RMSE=0.3032, R²=0.0042
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0066
============================================================


============================================================
🔄 Round 189 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0940 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0940, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0940, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0940, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0940, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0941, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0940)

============================================================
📊 Round 189 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2979, R²=0.0018
   Val:   Loss=0.0940, RMSE=0.3066, R²=-0.0044
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2494, R²: -0.0052

📊 Round 189 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2494, R²: -0.0052

============================================================
🔄 Round 191 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.1003 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.1003, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.1003, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.1003, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.1003, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.1003, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1003)

============================================================
📊 Round 191 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=0.0032
   Val:   Loss=0.1003, RMSE=0.3167, R²=-0.0049
============================================================


📊 Round 191 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2494, R²: -0.0051

============================================================
🔄 Round 195 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0920, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0920, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0920, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0920, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0920, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0920, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 195 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0917, RMSE=0.3028, R²=0.0011
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0081
============================================================


📊 Round 195 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2494, R²: -0.0051

============================================================
🔄 Round 197 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0908, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0908, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0908, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0908, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0908, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0907, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 197 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0909, RMSE=0.3015, R²=0.0023
   Val:   Loss=0.0855, RMSE=0.2924, R²=0.0029
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2494, R²: -0.0053

============================================================
🔄 Round 198 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0911, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0911, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0911, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0911, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0911, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0911, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 198 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0914, RMSE=0.3023, R²=0.0017
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0001
============================================================


============================================================
🔄 Round 200 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0897, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0897, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0897, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0897, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0897, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0897, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 200 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0897, RMSE=0.2995, R²=0.0030
   Val:   Loss=0.0902, RMSE=0.3003, R²=-0.0006
============================================================


📊 Round 200 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2494, R²: -0.0053

📊 Round 200 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2494, R²: -0.0052

============================================================
🔄 Round 204 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0947 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0948, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0948, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0948, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0948, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0948, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0947)

============================================================
📊 Round 204 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2976, R²=0.0027
   Val:   Loss=0.0947, RMSE=0.3078, R²=0.0009
============================================================


📊 Round 204 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2494, R²: -0.0056

============================================================
🔄 Round 205 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0895, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0895, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0895, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0895, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0895, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0895, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 205 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0893, RMSE=0.2988, R²=0.0024
   Val:   Loss=0.0919, RMSE=0.3032, R²=-0.0087
============================================================


📊 Round 205 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2494, R²: -0.0053

📊 Round 205 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2494, R²: -0.0053

📊 Round 205 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2494, R²: -0.0053

📊 Round 205 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2494, R²: -0.0056

============================================================
🔄 Round 217 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0892, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0891, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0891, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0891, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0891, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0891, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 217 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0893, RMSE=0.2988, R²=0.0004
   Val:   Loss=0.0919, RMSE=0.3032, R²=0.0053
============================================================


============================================================
🔄 Round 218 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0920, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0920, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0920, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0920, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0920, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0920, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 218 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0918, RMSE=0.3030, R²=0.0025
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0015
============================================================


============================================================
🔄 Round 219 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0952 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0952, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0952, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0952, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0952, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0952, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0952)

============================================================
📊 Round 219 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2975, R²=0.0028
   Val:   Loss=0.0952, RMSE=0.3085, R²=-0.0157
============================================================


============================================================
🔄 Round 220 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0912, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0912, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0912, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0912, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0912, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0911, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 220 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0913, RMSE=0.3022, R²=0.0026
   Val:   Loss=0.0837, RMSE=0.2894, R²=-0.0015
============================================================


============================================================
🔄 Round 222 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0914, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0914, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0914, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0914, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0914, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0913, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 222 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0914, RMSE=0.3023, R²=0.0020
   Val:   Loss=0.0837, RMSE=0.2893, R²=0.0031
============================================================


📊 Round 222 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2494, R²: -0.0056

============================================================
🔄 Round 223 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0905, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0904, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0904, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0904, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0904, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0904, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 223 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0902, RMSE=0.3004, R²=0.0013
   Val:   Loss=0.0882, RMSE=0.2970, R²=0.0057
============================================================


📊 Round 223 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2494, R²: -0.0056

============================================================
🔄 Round 224 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0892, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0892, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0892, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0892, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0892, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 224 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0895, RMSE=0.2991, R²=0.0020
   Val:   Loss=0.0913, RMSE=0.3021, R²=0.0035
============================================================


============================================================
🔄 Round 225 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0988 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0988, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0988, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0988, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0988, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0988, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0988)

============================================================
📊 Round 225 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2959, R²=0.0022
   Val:   Loss=0.0988, RMSE=0.3143, R²=0.0021
============================================================


📊 Round 225 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2494, R²: -0.0053

📊 Round 225 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2494, R²: -0.0053

============================================================
🔄 Round 227 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0904, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0903, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0903, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0903, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0903, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0903, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 227 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0903, RMSE=0.3005, R²=0.0045
   Val:   Loss=0.0878, RMSE=0.2964, R²=-0.0130
============================================================


============================================================
🔄 Round 228 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0911, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0911, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0911, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0911, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0911, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0911, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 228 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0909, RMSE=0.3016, R²=0.0016
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0043
============================================================


📊 Round 228 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2494, R²: -0.0054

============================================================
🔄 Round 229 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0900, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0900, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0900, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0900, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0900, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0900, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 229 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0901, RMSE=0.3002, R²=0.0013
   Val:   Loss=0.0887, RMSE=0.2978, R²=0.0057
============================================================


📊 Round 229 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2494, R²: -0.0054

============================================================
🔄 Round 231 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0892, val=0.0928 (↓), lr=0.000001
   • Epoch   2/100: train=0.0892, val=0.0928, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0892, val=0.0928, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0928, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0892, val=0.0928, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0892, val=0.0928, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0928)

============================================================
📊 Round 231 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0891, RMSE=0.2985, R²=0.0014
   Val:   Loss=0.0928, RMSE=0.3046, R²=-0.0042
============================================================


📊 Round 231 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2494, R²: -0.0051

============================================================
🔄 Round 233 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0984 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0984, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0984, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0984, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0984, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0985, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0984)

============================================================
📊 Round 233 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=0.0014
   Val:   Loss=0.0984, RMSE=0.3137, R²=-0.0073
============================================================


📊 Round 233 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2493, R²: -0.0051

============================================================
🔄 Round 235 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0928, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0928, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0928, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0928, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0928, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0928, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 235 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0926, RMSE=0.3044, R²=0.0016
   Val:   Loss=0.0785, RMSE=0.2801, R²=0.0068
============================================================


📊 Round 235 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2493, R²: -0.0050

============================================================
🔄 Round 239 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0909, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0909, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0909, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0909, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0909, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0909, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 239 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0906, RMSE=0.3010, R²=0.0040
   Val:   Loss=0.0867, RMSE=0.2945, R²=-0.0039
============================================================


📊 Round 239 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2493, R²: -0.0050

============================================================
🔄 Round 243 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0904, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0904, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0904, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0904, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0904, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0904, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 243 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0903, RMSE=0.3005, R²=0.0030
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0013
============================================================


📊 Round 243 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2493, R²: -0.0050

============================================================
🔄 Round 247 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0965 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0965, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0965, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0965, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0965, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0966, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0965)

============================================================
📊 Round 247 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2969, R²=0.0006
   Val:   Loss=0.0965, RMSE=0.3106, R²=0.0000
============================================================


📊 Round 247 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2493, R²: -0.0048

📊 Round 247 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2493, R²: -0.0051

📊 Round 247 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2493, R²: -0.0050

📊 Round 247 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2493, R²: -0.0050

📊 Round 247 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2493, R²: -0.0050

📊 Round 247 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2493, R²: -0.0050

============================================================
🔄 Round 254 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0902, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0902, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0902, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0902, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0902, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0901, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 254 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0900, RMSE=0.3001, R²=0.0026
   Val:   Loss=0.0889, RMSE=0.2981, R²=-0.0033
============================================================


📊 Round 254 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2493, R²: -0.0050

============================================================
🔄 Round 256 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0968 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0968, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0968, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0968, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0968, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0968, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0968)

============================================================
📊 Round 256 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2968, R²=0.0022
   Val:   Loss=0.0968, RMSE=0.3111, R²=-0.0004
============================================================


📊 Round 256 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2494, R²: -0.0053

============================================================
🔄 Round 259 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0903, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0903, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0903, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0903, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0902, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0902, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 259 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0902, RMSE=0.3004, R²=0.0025
   Val:   Loss=0.0881, RMSE=0.2969, R²=0.0014
============================================================


============================================================
🔄 Round 260 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0904, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0904, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0904, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0904, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0904, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0904, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 260 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0903, RMSE=0.3005, R²=0.0034
   Val:   Loss=0.0880, RMSE=0.2967, R²=-0.0057
============================================================


📊 Round 260 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2493, R²: -0.0050

📊 Round 260 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2493, R²: -0.0050

📊 Round 260 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2493, R²: -0.0049

📊 Round 260 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2493, R²: -0.0051

============================================================
🔄 Round 267 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0923, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0923, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0923, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0923, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0923, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0923, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 267 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0924, RMSE=0.3040, R²=0.0015
   Val:   Loss=0.0794, RMSE=0.2819, R²=-0.0010
============================================================


📊 Round 267 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2493, R²: -0.0051

============================================================
🔄 Round 269 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0955 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0955, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0955, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0955, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0955, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0955, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0955)

============================================================
📊 Round 269 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2973, R²=0.0022
   Val:   Loss=0.0955, RMSE=0.3090, R²=0.0031
============================================================


📊 Round 269 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2494, R²: -0.0052

============================================================
🔄 Round 272 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0903, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0903, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0903, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0903, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0903, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0902, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 272 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0904, RMSE=0.3007, R²=0.0036
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0029
============================================================


============================================================
🔄 Round 273 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0953 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0953, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0953, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0953, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0953, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0953, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0953)

============================================================
📊 Round 273 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2974, R²=0.0025
   Val:   Loss=0.0953, RMSE=0.3087, R²=0.0022
============================================================


📊 Round 273 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2493, R²: -0.0051

============================================================
🔄 Round 276 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0985 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0985, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0985, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0985, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0985, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0985, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0985)

============================================================
📊 Round 276 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=0.0033
   Val:   Loss=0.0985, RMSE=0.3138, R²=-0.0051
============================================================


📊 Round 276 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2493, R²: -0.0051

============================================================
🔄 Round 277 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0959 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0959, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0959, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0959, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0959, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0960, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0959)

============================================================
📊 Round 277 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2972, R²=0.0009
   Val:   Loss=0.0959, RMSE=0.3097, R²=0.0006
============================================================


📊 Round 277 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2493, R²: -0.0051

============================================================
🔄 Round 281 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0891, val=0.0932 (↓), lr=0.000001
   • Epoch   2/100: train=0.0891, val=0.0932, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0891, val=0.0932, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0891, val=0.0932, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0891, val=0.0932, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0891, val=0.0932, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0932)

============================================================
📊 Round 281 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0890, RMSE=0.2983, R²=0.0022
   Val:   Loss=0.0932, RMSE=0.3052, R²=0.0036
============================================================


📊 Round 281 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2493, R²: -0.0048

📊 Round 281 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2493, R²: -0.0048

============================================================
🔄 Round 284 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0951 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0951, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0951, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0951, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0951, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0952, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0951)

============================================================
📊 Round 284 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2975, R²=0.0028
   Val:   Loss=0.0951, RMSE=0.3084, R²=-0.0002
============================================================


============================================================
🔄 Round 286 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0897, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0897, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0897, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0897, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0897, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0897, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 286 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0894, RMSE=0.2990, R²=0.0031
   Val:   Loss=0.0914, RMSE=0.3023, R²=-0.0051
============================================================


📊 Round 286 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2493, R²: -0.0048

📊 Round 286 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2493, R²: -0.0046

============================================================
🔄 Round 292 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0989 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0989, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0990, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0990, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0990, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0992, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0989)

============================================================
📊 Round 292 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2959, R²=0.0017
   Val:   Loss=0.0989, RMSE=0.3145, R²=-0.0221
============================================================


📊 Round 292 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2493, R²: -0.0044

📊 Round 292 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2493, R²: -0.0043

============================================================
🔄 Round 297 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0899, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0899, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0899, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0899, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0899, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0899, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 297 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0899, RMSE=0.2998, R²=0.0020
   Val:   Loss=0.0896, RMSE=0.2994, R²=0.0041
============================================================


============================================================
🔄 Round 298 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0929 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0929, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0929, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0929, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0929, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0931, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0929)

============================================================
📊 Round 298 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0890, RMSE=0.2984, R²=0.0016
   Val:   Loss=0.0929, RMSE=0.3047, R²=-0.0165
============================================================


============================================================
🔄 Round 299 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0905, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0905, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0905, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0905, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0905, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0905, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 299 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0905, RMSE=0.3008, R²=-0.0001
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0000
============================================================


📊 Round 299 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2493, R²: -0.0045

============================================================
🔄 Round 301 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0924, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0924, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0924, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0924, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0924, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0924, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 301 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0926, RMSE=0.3042, R²=0.0023
   Val:   Loss=0.0788, RMSE=0.2808, R²=0.0017
============================================================


============================================================
🔄 Round 302 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0922, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0922, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0922, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0922, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0922, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0922, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 302 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0919, RMSE=0.3031, R²=0.0028
   Val:   Loss=0.0815, RMSE=0.2856, R²=-0.0072
============================================================


============================================================
🔄 Round 303 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0897, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0897, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0897, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0897, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0897, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0897, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 303 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0897, RMSE=0.2996, R²=0.0026
   Val:   Loss=0.0901, RMSE=0.3002, R²=0.0008
============================================================


📊 Round 303 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2493, R²: -0.0047

============================================================
🔄 Round 304 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0915, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0915, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0915, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0915, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0915, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0915, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 304 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0916, RMSE=0.3026, R²=0.0041
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0050
============================================================


📊 Round 304 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2493, R²: -0.0047

📊 Round 304 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2493, R²: -0.0047

📊 Round 304 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2493, R²: -0.0047

📊 Round 304 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2493, R²: -0.0047

📊 Round 304 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2493, R²: -0.0047

📊 Round 304 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2493, R²: -0.0046

============================================================
🔄 Round 312 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0908, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0908, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0908, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0908, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0907, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0907, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 312 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0907, RMSE=0.3012, R²=0.0018
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0052
============================================================


📊 Round 312 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2493, R²: -0.0046

============================================================
🔄 Round 315 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0948 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0948, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0948, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0948, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0948, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0948, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0948)

============================================================
📊 Round 315 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2976, R²=0.0021
   Val:   Loss=0.0948, RMSE=0.3080, R²=0.0027
============================================================


============================================================
🔄 Round 317 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0942 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0942, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0943, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0943, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0943, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0943, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0942)

============================================================
📊 Round 317 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2978, R²=0.0025
   Val:   Loss=0.0942, RMSE=0.3070, R²=-0.0012
============================================================


============================================================
🔄 Round 318 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0925, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0925, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0925, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0925, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0925, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0925, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 318 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0924, RMSE=0.3040, R²=0.0030
   Val:   Loss=0.0794, RMSE=0.2819, R²=-0.0018
============================================================


📊 Round 318 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2493, R²: -0.0045

============================================================
🔄 Round 320 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0895, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0895, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0895, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0895, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0895, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0895, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 320 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0893, RMSE=0.2989, R²=0.0034
   Val:   Loss=0.0917, RMSE=0.3028, R²=-0.0168
============================================================


============================================================
🔄 Round 323 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0928, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0928, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0928, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0928, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0928, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0928, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 323 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0925, RMSE=0.3042, R²=0.0037
   Val:   Loss=0.0789, RMSE=0.2809, R²=-0.0091
============================================================


📊 Round 323 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2493, R²: -0.0047

============================================================
🔄 Round 324 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0893, val=0.0922 (↓), lr=0.000001
   • Epoch   2/100: train=0.0893, val=0.0922, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0893, val=0.0922, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0893, val=0.0922, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0893, val=0.0922, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0893, val=0.0923, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0922)

============================================================
📊 Round 324 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2987, R²=0.0022
   Val:   Loss=0.0922, RMSE=0.3037, R²=0.0021
============================================================


📊 Round 324 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2493, R²: -0.0047

📊 Round 324 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2493, R²: -0.0049

============================================================
🔄 Round 326 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0899, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0899, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0899, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0899, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0899, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0899, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 326 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0900, RMSE=0.3000, R²=0.0026
   Val:   Loss=0.0892, RMSE=0.2987, R²=-0.0041
============================================================


============================================================
🔄 Round 328 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0897, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0897, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0897, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0897, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0897, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0897, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 328 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0897, RMSE=0.2995, R²=0.0027
   Val:   Loss=0.0902, RMSE=0.3003, R²=-0.0063
============================================================


📊 Round 328 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2493, R²: -0.0044

============================================================
🔄 Round 329 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0899, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0899, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0899, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0899, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0899, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0899, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 329 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0899, RMSE=0.2999, R²=0.0038
   Val:   Loss=0.0893, RMSE=0.2988, R²=-0.0029
============================================================


============================================================
🔄 Round 330 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0902, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0902, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0902, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0902, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0902, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0902, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 330 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0900, RMSE=0.3000, R²=0.0018
   Val:   Loss=0.0890, RMSE=0.2983, R²=0.0050
============================================================


📊 Round 330 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2493, R²: -0.0044

============================================================
🔄 Round 333 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0894, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0894, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0894, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0894, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0894, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0894, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 333 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0896, RMSE=0.2993, R²=0.0008
   Val:   Loss=0.0908, RMSE=0.3013, R²=0.0068
============================================================


📊 Round 333 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2493, R²: -0.0044

============================================================
🔄 Round 337 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0902, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0902, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0902, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0902, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0902, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0902, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 337 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0902, RMSE=0.3003, R²=0.0005
   Val:   Loss=0.0883, RMSE=0.2971, R²=0.0109
============================================================


📊 Round 337 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2492, R²: -0.0042

============================================================
🔄 Round 338 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0950 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0950, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0950, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0950, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0950, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0950, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0950)

============================================================
📊 Round 338 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2975, R²=0.0009
   Val:   Loss=0.0950, RMSE=0.3082, R²=0.0076
============================================================


============================================================
🔄 Round 339 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0947 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0947, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0947, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0947, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0947, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0948, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0947)

============================================================
📊 Round 339 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2976, R²=0.0024
   Val:   Loss=0.0947, RMSE=0.3078, R²=-0.0014
============================================================


📊 Round 339 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2492, R²: -0.0042

============================================================
🔄 Round 346 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0899, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0899, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0899, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0899, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0899, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0899, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 346 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0899, RMSE=0.2998, R²=0.0008
   Val:   Loss=0.0897, RMSE=0.2994, R²=-0.0024
============================================================


============================================================
🔄 Round 347 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0955 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0955, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0955, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0955, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0955, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0956, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0955)

============================================================
📊 Round 347 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2973, R²=0.0031
   Val:   Loss=0.0955, RMSE=0.3091, R²=-0.0042
============================================================


📊 Round 347 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2493, R²: -0.0044

📊 Round 347 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2493, R²: -0.0045

============================================================
🔄 Round 356 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0893, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0893, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0892, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0892, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0892, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 356 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0894, RMSE=0.2990, R²=0.0012
   Val:   Loss=0.0915, RMSE=0.3025, R²=-0.0090
============================================================


📊 Round 356 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2493, R²: -0.0045

============================================================
🔄 Round 358 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0908, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0908, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0908, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0908, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0908, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0908, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 358 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0908, RMSE=0.3014, R²=0.0027
   Val:   Loss=0.0857, RMSE=0.2928, R²=0.0009
============================================================


📊 Round 358 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2493, R²: -0.0045

============================================================
🔄 Round 360 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0950 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0950, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0950, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0950, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0950, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0950, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0950)

============================================================
📊 Round 360 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2975, R²=0.0026
   Val:   Loss=0.0950, RMSE=0.3082, R²=-0.0005
============================================================


📊 Round 360 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2493, R²: -0.0051

📊 Round 360 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2493, R²: -0.0050

============================================================
🔄 Round 369 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0918, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0918, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0918, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0918, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0918, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0918, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 369 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0919, RMSE=0.3031, R²=0.0003
   Val:   Loss=0.0816, RMSE=0.2857, R²=0.0072
============================================================


📊 Round 369 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2493, R²: -0.0050

📊 Round 369 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2493, R²: -0.0052

============================================================
🔄 Round 374 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.1047 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.1047, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.1047, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.1047, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.1047, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.1047, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1047)

============================================================
📊 Round 374 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=0.0012
   Val:   Loss=0.1047, RMSE=0.3235, R²=0.0030
============================================================


============================================================
🔄 Round 375 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0965 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0965, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0965, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0965, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0966, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0967, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0965)

============================================================
📊 Round 375 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2970, R²=-0.0003
   Val:   Loss=0.0965, RMSE=0.3106, R²=-0.0053
============================================================


📊 Round 375 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2493, R²: -0.0053

============================================================
🔄 Round 378 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0891, val=0.0945 (↓), lr=0.000001
   • Epoch   2/100: train=0.0890, val=0.0945, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0945, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0946, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0890, val=0.0946, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0948, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0945)

============================================================
📊 Round 378 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2978, R²=0.0012
   Val:   Loss=0.0945, RMSE=0.3074, R²=-0.0110
============================================================


============================================================
🔄 Round 379 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0907, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0907, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0907, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0907, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0907, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0907, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 379 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0907, RMSE=0.3012, R²=0.0035
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0097
============================================================


📊 Round 379 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2493, R²: -0.0050

📊 Round 379 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2493, R²: -0.0050

============================================================
🔄 Round 382 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0897, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0897, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0897, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0897, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0897, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0897, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 382 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0897, RMSE=0.2996, R²=0.0020
   Val:   Loss=0.0902, RMSE=0.3004, R²=-0.0061
============================================================


============================================================
🔄 Round 383 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0906, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0906, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0906, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0906, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0906, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0905, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 383 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0907, RMSE=0.3011, R²=0.0022
   Val:   Loss=0.0864, RMSE=0.2940, R²=0.0002
============================================================


📊 Round 383 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2493, R²: -0.0051

============================================================
🔄 Round 386 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0906, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0906, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0906, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0906, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0906, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0905, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 386 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0906, RMSE=0.3010, R²=0.0010
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0095
============================================================


============================================================
🔄 Round 391 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0992 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0992, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0992, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0992, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0992, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0992, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0992)

============================================================
📊 Round 391 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=0.0021
   Val:   Loss=0.0992, RMSE=0.3149, R²=-0.0019
============================================================


📊 Round 391 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2493, R²: -0.0050

============================================================
🔄 Round 394 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0892, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0892, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0892, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0892, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0891, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 394 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0891, RMSE=0.2986, R²=0.0012
   Val:   Loss=0.0926, RMSE=0.3043, R²=0.0050
============================================================


📊 Round 394 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2493, R²: -0.0051

📊 Round 394 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2493, R²: -0.0049

📊 Round 394 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2493, R²: -0.0048

📊 Round 394 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2493, R²: -0.0048

============================================================
🔄 Round 404 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0913, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0913, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0913, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0913, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0913, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0913, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 404 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0916, RMSE=0.3026, R²=0.0026
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0076
============================================================


📊 Round 404 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2493, R²: -0.0046

============================================================
🔄 Round 406 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0905, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0905, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0905, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0905, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0905, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0905, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 406 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0904, RMSE=0.3007, R²=0.0023
   Val:   Loss=0.0875, RMSE=0.2958, R²=0.0008
============================================================


============================================================
🔄 Round 407 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.1065 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.1065, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.1065, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.1065, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.1065, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.1065, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1065)

============================================================
📊 Round 407 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=0.0023
   Val:   Loss=0.1065, RMSE=0.3264, R²=0.0018
============================================================


📊 Round 407 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2492, R²: -0.0044

📊 Round 407 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2492, R²: -0.0043

============================================================
🔄 Round 411 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0947 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0947, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0948, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0948, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0948, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0949, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0947)

============================================================
📊 Round 411 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2977, R²=0.0015
   Val:   Loss=0.0947, RMSE=0.3077, R²=-0.0230
============================================================


📊 Round 411 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2492, R²: -0.0044

============================================================
🔄 Round 413 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0891, val=0.0934 (↓), lr=0.000001
   • Epoch   2/100: train=0.0891, val=0.0934, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0891, val=0.0934, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0934, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0890, val=0.0934, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0890, val=0.0935, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0934)

============================================================
📊 Round 413 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0889, RMSE=0.2982, R²=0.0017
   Val:   Loss=0.0934, RMSE=0.3056, R²=-0.0043
============================================================


📊 Round 413 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2492, R²: -0.0044

============================================================
🔄 Round 414 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0988 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0988, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0988, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0988, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0988, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0989, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0988)

============================================================
📊 Round 414 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=0.0028
   Val:   Loss=0.0988, RMSE=0.3142, R²=-0.0132
============================================================


📊 Round 414 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2492, R²: -0.0044

📊 Round 414 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2492, R²: -0.0045

📊 Round 414 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2493, R²: -0.0047

============================================================
🔄 Round 419 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0892, val=0.0932 (↓), lr=0.000001
   • Epoch   2/100: train=0.0892, val=0.0932, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0892, val=0.0932, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0932, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0892, val=0.0932, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0892, val=0.0933, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0932)

============================================================
📊 Round 419 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0890, RMSE=0.2983, R²=0.0032
   Val:   Loss=0.0932, RMSE=0.3053, R²=-0.0143
============================================================


============================================================
🔄 Round 420 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0902, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0901, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0901, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0901, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0901, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0901, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 420 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0903, RMSE=0.3004, R²=0.0028
   Val:   Loss=0.0882, RMSE=0.2969, R²=-0.0015
============================================================


📊 Round 420 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2493, R²: -0.0046

============================================================
🔄 Round 421 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0904, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0904, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0904, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0904, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0904, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0904, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 421 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0904, RMSE=0.3007, R²=0.0030
   Val:   Loss=0.0875, RMSE=0.2959, R²=-0.0020
============================================================


============================================================
🔄 Round 423 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0912, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0912, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0912, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0912, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0912, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0912, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 423 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0912, RMSE=0.3020, R²=0.0003
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0033
============================================================


📊 Round 423 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2492, R²: -0.0045

============================================================
🔄 Round 426 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0943 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0943, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0943, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0943, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0943, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0943, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0943)

============================================================
📊 Round 426 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2979, R²=0.0012
   Val:   Loss=0.0943, RMSE=0.3071, R²=0.0059
============================================================


============================================================
🔄 Round 427 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0910, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0910, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0909, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0909, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0909, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0909, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 427 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0908, RMSE=0.3014, R²=0.0010
   Val:   Loss=0.0858, RMSE=0.2930, R²=0.0076
============================================================


============================================================
🔄 Round 429 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0896, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0896, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0896, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0896, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0896, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0896, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 429 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0897, RMSE=0.2994, R²=0.0018
   Val:   Loss=0.0906, RMSE=0.3009, R²=0.0043
============================================================


============================================================
🔄 Round 430 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0982 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0982, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0982, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0982, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0981, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0981, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0982)

============================================================
📊 Round 430 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2962, R²=0.0021
   Val:   Loss=0.0982, RMSE=0.3133, R²=0.0010
============================================================


============================================================
🔄 Round 442 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0893, val=0.0932 (↓), lr=0.000001
   • Epoch   2/100: train=0.0893, val=0.0932, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0892, val=0.0932, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0932, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0892, val=0.0932, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0892, val=0.0933, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0932)

============================================================
📊 Round 442 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0890, RMSE=0.2983, R²=0.0024
   Val:   Loss=0.0932, RMSE=0.3053, R²=-0.0076
============================================================


📊 Round 442 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2492, R²: -0.0044

📊 Round 442 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2492, R²: -0.0045

📊 Round 442 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2492, R²: -0.0045

📊 Round 442 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2492, R²: -0.0045

============================================================
🔄 Round 450 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0947 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0947, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0947, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0947, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0947, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0947, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0947)

============================================================
📊 Round 450 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2977, R²=0.0032
   Val:   Loss=0.0947, RMSE=0.3078, R²=-0.0017
============================================================


============================================================
🔄 Round 451 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0914, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0914, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0913, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0913, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0913, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0913, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 451 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0912, RMSE=0.3019, R²=0.0015
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0106
============================================================


============================================================
🔄 Round 452 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0895, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0894, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0894, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0894, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0894, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0894, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 452 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0894, RMSE=0.2989, R²=0.0018
   Val:   Loss=0.0918, RMSE=0.3029, R²=-0.0021
============================================================


📊 Round 452 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2492, R²: -0.0045

============================================================
🔄 Round 454 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0894, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0894, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0894, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0894, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0894, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0894, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 454 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0895, RMSE=0.2992, R²=0.0027
   Val:   Loss=0.0911, RMSE=0.3018, R²=-0.0040
============================================================


📊 Round 454 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2492, R²: -0.0044

============================================================
🔄 Round 455 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0897, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0897, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0897, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0897, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0897, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0897, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 455 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0897, RMSE=0.2995, R²=0.0013
   Val:   Loss=0.0903, RMSE=0.3006, R²=0.0039
============================================================


📊 Round 455 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2492, R²: -0.0044

📊 Round 455 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2492, R²: -0.0044

📊 Round 455 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2492, R²: -0.0044

📊 Round 455 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2492, R²: -0.0044

============================================================
🔄 Round 460 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0893, val=0.0931 (↓), lr=0.000001
   • Epoch   2/100: train=0.0893, val=0.0931, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0893, val=0.0931, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0893, val=0.0931, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0893, val=0.0931, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0892, val=0.0931, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0931)

============================================================
📊 Round 460 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0890, RMSE=0.2984, R²=0.0004
   Val:   Loss=0.0931, RMSE=0.3051, R²=0.0084
============================================================


============================================================
🔄 Round 461 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0896, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0896, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0895, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0895, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0895, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0895, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 461 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0896, RMSE=0.2993, R²=0.0011
   Val:   Loss=0.0909, RMSE=0.3014, R²=-0.0187
============================================================


📊 Round 461 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2492, R²: -0.0043

============================================================
🔄 Round 464 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0891, val=0.0929 (↓), lr=0.000001
   • Epoch   2/100: train=0.0891, val=0.0930, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0891, val=0.0930, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0891, val=0.0930, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0891, val=0.0930, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0890, val=0.0931, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0929)

============================================================
📊 Round 464 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0891, RMSE=0.2984, R²=0.0010
   Val:   Loss=0.0929, RMSE=0.3048, R²=-0.0104
============================================================


============================================================
🔄 Round 466 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0909, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0909, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0909, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0909, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0909, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0908, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 466 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0908, RMSE=0.3014, R²=0.0017
   Val:   Loss=0.0858, RMSE=0.2930, R²=-0.0073
============================================================


============================================================
🔄 Round 467 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0901, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0901, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0901, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0901, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0901, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0901, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 467 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0896, RMSE=0.2993, R²=0.0021
   Val:   Loss=0.0909, RMSE=0.3015, R²=-0.0012
============================================================


============================================================
🔄 Round 468 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0913, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0913, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0913, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0913, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0913, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0913, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 468 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0913, RMSE=0.3022, R²=0.0013
   Val:   Loss=0.0838, RMSE=0.2894, R²=0.0063
============================================================


📊 Round 468 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2492, R²: -0.0042

============================================================
🔄 Round 472 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0949 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0949, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0949, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0949, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0949, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0949, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0949)

============================================================
📊 Round 472 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2976, R²=0.0025
   Val:   Loss=0.0949, RMSE=0.3080, R²=-0.0107
============================================================


📊 Round 472 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2492, R²: -0.0042

📊 Round 472 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2492, R²: -0.0045

📊 Round 472 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2492, R²: -0.0044

📊 Round 472 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2492, R²: -0.0044

📊 Round 472 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2492, R²: -0.0044

📊 Round 472 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2492, R²: -0.0044

📊 Round 472 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2492, R²: -0.0044

📊 Round 472 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2492, R²: -0.0042

============================================================
🔄 Round 485 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0939, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0939, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0939, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0939, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0939, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0938, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 485 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0937, RMSE=0.3061, R²=0.0011
   Val:   Loss=0.0744, RMSE=0.2728, R²=0.0034
============================================================


📊 Round 485 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2492, R²: -0.0042

============================================================
🔄 Round 487 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0891, val=0.0929 (↓), lr=0.000001
   • Epoch   2/100: train=0.0891, val=0.0929, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0891, val=0.0929, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0891, val=0.0929, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0891, val=0.0929, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0891, val=0.0929, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0929)

============================================================
📊 Round 487 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0891, RMSE=0.2984, R²=0.0020
   Val:   Loss=0.0929, RMSE=0.3049, R²=0.0019
============================================================


📊 Round 487 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2492, R²: -0.0041

📊 Round 487 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2492, R²: -0.0041

============================================================
🔄 Round 489 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0898, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0898, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0898, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0898, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0898, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0898, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 489 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0896, RMSE=0.2993, R²=0.0014
   Val:   Loss=0.0909, RMSE=0.3014, R²=-0.0024
============================================================


============================================================
🔄 Round 490 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0897, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0896, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0896, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0896, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0896, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0896, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 490 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0899, RMSE=0.2998, R²=0.0021
   Val:   Loss=0.0896, RMSE=0.2994, R²=0.0013
============================================================


============================================================
🔄 Round 491 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0892, val=0.0927 (↓), lr=0.000001
   • Epoch   2/100: train=0.0892, val=0.0927, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0892, val=0.0927, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0927, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0892, val=0.0927, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0892, val=0.0927, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0927)

============================================================
📊 Round 491 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0891, RMSE=0.2985, R²=0.0016
   Val:   Loss=0.0927, RMSE=0.3045, R²=0.0047
============================================================


============================================================
🔄 Round 493 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0993 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0993, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0993, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0993, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0994, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0994, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0993)

============================================================
📊 Round 493 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=0.0015
   Val:   Loss=0.0993, RMSE=0.3151, R²=0.0001
============================================================


📊 Round 493 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2492, R²: -0.0042

📊 Round 493 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2492, R²: -0.0042

📊 Round 493 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2492, R²: -0.0042

============================================================
🔄 Round 501 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0939 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0939, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0889, val=0.0939, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0889, val=0.0939, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0889, val=0.0939, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0940, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0939)

============================================================
📊 Round 501 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2980, R²=0.0018
   Val:   Loss=0.0939, RMSE=0.3065, R²=-0.0003
============================================================


📊 Round 501 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2492, R²: -0.0041

📊 Round 501 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2492, R²: -0.0041

============================================================
🔄 Round 507 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0955 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0956, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0956, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0956, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0956, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0956, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0955)

============================================================
📊 Round 507 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2974, R²=0.0024
   Val:   Loss=0.0955, RMSE=0.3091, R²=-0.0064
============================================================


📊 Round 507 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2492, R²: -0.0041

============================================================
🔄 Round 509 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0943 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0943, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0943, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0943, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0943, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0942, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0943)

============================================================
📊 Round 509 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2979, R²=0.0023
   Val:   Loss=0.0943, RMSE=0.3070, R²=0.0010
============================================================


📊 Round 509 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2492, R²: -0.0041

============================================================
🔄 Round 510 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0953 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0953, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0953, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0953, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0953, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0953, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0953)

============================================================
📊 Round 510 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2975, R²=0.0038
   Val:   Loss=0.0953, RMSE=0.3087, R²=-0.0044
============================================================


============================================================
🔄 Round 511 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0893, val=0.0928 (↓), lr=0.000001
   • Epoch   2/100: train=0.0893, val=0.0928, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0893, val=0.0928, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0893, val=0.0929, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0893, val=0.0929, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0892, val=0.0929, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0928)

============================================================
📊 Round 511 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0891, RMSE=0.2985, R²=0.0024
   Val:   Loss=0.0928, RMSE=0.3047, R²=-0.0024
============================================================


📊 Round 511 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2492, R²: -0.0040

📊 Round 511 Test Metrics:
   Loss: 0.0821, RMSE: 0.2864, MAE: 0.2492, R²: -0.0040

============================================================
🔄 Round 513 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0900, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0900, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0900, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0900, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0900, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0900, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 513 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0898, RMSE=0.2996, R²=0.0015
   Val:   Loss=0.0901, RMSE=0.3001, R²=-0.0055
============================================================


============================================================
🔄 Round 514 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0900, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0900, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0900, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0900, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0900, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0900, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 514 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0901, RMSE=0.3001, R²=0.0011
   Val:   Loss=0.0889, RMSE=0.2981, R²=0.0038
============================================================


📊 Round 514 Test Metrics:
   Loss: 0.0821, RMSE: 0.2864, MAE: 0.2492, R²: -0.0040

============================================================
🔄 Round 518 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0957 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0957, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0957, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0957, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0957, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0957, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0957)

============================================================
📊 Round 518 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2973, R²=0.0026
   Val:   Loss=0.0957, RMSE=0.3093, R²=0.0007
============================================================


============================================================
🔄 Round 519 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0891, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0891, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0891, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0891, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0891, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0891, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 519 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0894, RMSE=0.2991, R²=0.0016
   Val:   Loss=0.0915, RMSE=0.3024, R²=-0.0057
============================================================


📊 Round 519 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2492, R²: -0.0040

📊 Round 519 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2492, R²: -0.0039

📊 Round 519 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2492, R²: -0.0039

============================================================
🔄 Round 525 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0911, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0911, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0911, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0911, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0911, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0910, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 525 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0909, RMSE=0.3016, R²=0.0035
   Val:   Loss=0.0854, RMSE=0.2923, R²=-0.0033
============================================================


============================================================
🔄 Round 526 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.1006 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.1006, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.1006, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.1006, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.1006, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.1007, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1006)

============================================================
📊 Round 526 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2952, R²=0.0014
   Val:   Loss=0.1006, RMSE=0.3171, R²=-0.0045
============================================================


📊 Round 526 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2491, R²: -0.0037

============================================================
🔄 Round 529 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0964 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0964, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0963, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0963, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0963, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0963, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0964)

============================================================
📊 Round 529 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2970, R²=0.0026
   Val:   Loss=0.0964, RMSE=0.3104, R²=0.0002
============================================================


============================================================
🔄 Round 532 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0978 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0978, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0978, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0978, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0978, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0979, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0978)

============================================================
📊 Round 532 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2964, R²=0.0009
   Val:   Loss=0.0978, RMSE=0.3127, R²=0.0001
============================================================


============================================================
🔄 Round 533 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0949 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0949, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0949, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0949, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0949, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0949, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0949)

============================================================
📊 Round 533 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2976, R²=0.0029
   Val:   Loss=0.0949, RMSE=0.3081, R²=-0.0023
============================================================


============================================================
🔄 Round 535 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0934 (↓), lr=0.000001
   • Epoch   2/100: train=0.0890, val=0.0934, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0934, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0934, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0890, val=0.0934, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0890, val=0.0934, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0934)

============================================================
📊 Round 535 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0890, RMSE=0.2983, R²=0.0015
   Val:   Loss=0.0934, RMSE=0.3056, R²=0.0016
============================================================


📊 Round 535 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2492, R²: -0.0043

📊 Round 535 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2492, R²: -0.0043

📊 Round 535 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2492, R²: -0.0044

============================================================
🔄 Round 539 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0916, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0916, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0916, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0916, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0916, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0915, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 539 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0916, RMSE=0.3027, R²=0.0024
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0002
============================================================


📊 Round 539 Test Metrics:
   Loss: 0.0821, RMSE: 0.2864, MAE: 0.2492, R²: -0.0040

============================================================
🔄 Round 540 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0947 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0947, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0947, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0947, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0947, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0947, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0947)

============================================================
📊 Round 540 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2977, R²=0.0016
   Val:   Loss=0.0947, RMSE=0.3077, R²=0.0037
============================================================


📊 Round 540 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2491, R²: -0.0038

============================================================
🔄 Round 544 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0904, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0904, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0904, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0904, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0904, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0904, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 544 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0905, RMSE=0.3009, R²=0.0020
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0009
============================================================


============================================================
🔄 Round 547 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0997 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0997, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0997, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0997, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0997, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0997, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0997)

============================================================
📊 Round 547 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=0.0009
   Val:   Loss=0.0997, RMSE=0.3158, R²=0.0058
============================================================


📊 Round 547 Test Metrics:
   Loss: 0.0821, RMSE: 0.2864, MAE: 0.2492, R²: -0.0040

📊 Round 547 Test Metrics:
   Loss: 0.0821, RMSE: 0.2864, MAE: 0.2492, R²: -0.0040

📊 Round 547 Test Metrics:
   Loss: 0.0821, RMSE: 0.2864, MAE: 0.2492, R²: -0.0040

============================================================
🔄 Round 550 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0979 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0979, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0979, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0979, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0979, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0979, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0979)

============================================================
📊 Round 550 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2964, R²=0.0022
   Val:   Loss=0.0979, RMSE=0.3129, R²=0.0011
============================================================


============================================================
🔄 Round 552 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0896, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0896, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0896, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0896, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0896, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0896, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 552 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0897, RMSE=0.2995, R²=0.0018
   Val:   Loss=0.0904, RMSE=0.3007, R²=-0.0023
============================================================


============================================================
🔄 Round 553 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0978 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0978, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0978, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0978, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0978, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0979, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0978)

============================================================
📊 Round 553 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2964, R²=0.0012
   Val:   Loss=0.0978, RMSE=0.3127, R²=0.0019
============================================================


📊 Round 553 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2491, R²: -0.0038

============================================================
🔄 Round 558 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0974 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0974, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0974, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0974, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0974, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0974, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0974)

============================================================
📊 Round 558 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2966, R²=0.0021
   Val:   Loss=0.0974, RMSE=0.3121, R²=0.0020
============================================================


📊 Round 558 Test Metrics:
   Loss: 0.0821, RMSE: 0.2864, MAE: 0.2492, R²: -0.0040

============================================================
🔄 Round 559 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0929 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0929, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0889, val=0.0929, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0889, val=0.0929, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0889, val=0.0929, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0929, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0929)

============================================================
📊 Round 559 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0891, RMSE=0.2985, R²=0.0015
   Val:   Loss=0.0929, RMSE=0.3048, R²=0.0043
============================================================


============================================================
🔄 Round 560 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0906, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0906, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0906, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0906, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0906, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0906, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 560 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0907, RMSE=0.3012, R²=0.0029
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0033
============================================================


============================================================
🔄 Round 561 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0898, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0898, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0898, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0898, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0898, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0898, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 561 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0894, RMSE=0.2990, R²=0.0033
   Val:   Loss=0.0915, RMSE=0.3025, R²=-0.0149
============================================================


============================================================
🔄 Round 562 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0906, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0906, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0906, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0906, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0906, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0906, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 562 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0904, RMSE=0.3007, R²=0.0011
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0003
============================================================


============================================================
🔄 Round 563 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0934 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0934, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0934, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0934, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0934, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0934, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0934)

============================================================
📊 Round 563 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0890, RMSE=0.2983, R²=0.0018
   Val:   Loss=0.0934, RMSE=0.3056, R²=-0.0051
============================================================


📊 Round 563 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2492, R²: -0.0040

📊 Round 563 Test Metrics:
   Loss: 0.0821, RMSE: 0.2864, MAE: 0.2492, R²: -0.0040

============================================================
🔄 Round 566 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0900, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0900, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0900, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0900, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0900, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0900, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 566 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0901, RMSE=0.3001, R²=0.0015
   Val:   Loss=0.0890, RMSE=0.2984, R²=0.0039
============================================================


📊 Round 566 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2491, R²: -0.0039

============================================================
🔄 Round 568 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0910, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0910, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0910, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0910, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0910, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0910, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 568 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0908, RMSE=0.3014, R²=0.0015
   Val:   Loss=0.0859, RMSE=0.2930, R²=-0.0009
============================================================


📊 Round 568 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2491, R²: -0.0039

📊 Round 568 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2491, R²: -0.0038

============================================================
🔄 Round 573 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0899, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0899, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0899, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0899, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0899, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0899, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 573 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0897, RMSE=0.2996, R²=0.0007
   Val:   Loss=0.0903, RMSE=0.3004, R²=0.0060
============================================================


📊 Round 573 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2491, R²: -0.0038

📊 Round 573 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2492, R²: -0.0041

============================================================
🔄 Round 577 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0977 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0977, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0977, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0977, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0978, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0978, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0977)

============================================================
📊 Round 577 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=0.0021
   Val:   Loss=0.0977, RMSE=0.3126, R²=-0.0032
============================================================


📊 Round 577 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2491, R²: -0.0038

============================================================
🔄 Round 580 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.1031 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.1031, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.1031, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.1031, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.1031, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.1031, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1031)

============================================================
📊 Round 580 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=0.0025
   Val:   Loss=0.1031, RMSE=0.3210, R²=-0.0014
============================================================


📊 Round 580 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2491, R²: -0.0038

📊 Round 580 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2491, R²: -0.0036

📊 Round 580 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2491, R²: -0.0036

📊 Round 580 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2491, R²: -0.0036

============================================================
🔄 Round 588 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0903, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0903, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0903, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0903, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0903, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0903, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 588 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0902, RMSE=0.3003, R²=0.0033
   Val:   Loss=0.0885, RMSE=0.2975, R²=-0.0023
============================================================


============================================================
🔄 Round 589 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0906, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0906, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0906, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0906, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0906, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0906, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 589 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0906, RMSE=0.3011, R²=0.0017
   Val:   Loss=0.0866, RMSE=0.2944, R²=0.0039
============================================================


============================================================
🔄 Round 591 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0907, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0907, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0907, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0907, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0907, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0906, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 591 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0907, RMSE=0.3011, R²=0.0014
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0159
============================================================


============================================================
🔄 Round 594 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0952 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0952, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0952, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0952, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0952, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0952, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0952)

============================================================
📊 Round 594 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2975, R²=0.0022
   Val:   Loss=0.0952, RMSE=0.3085, R²=0.0021
============================================================


============================================================
🔄 Round 598 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0906, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0906, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0906, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0906, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0906, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0906, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 598 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0907, RMSE=0.3011, R²=0.0020
   Val:   Loss=0.0866, RMSE=0.2942, R²=0.0027
============================================================


📊 Round 598 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2491, R²: -0.0037

============================================================
🔄 Round 601 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0952 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0952, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0952, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0952, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0952, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0953, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0952)

============================================================
📊 Round 601 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2975, R²=0.0022
   Val:   Loss=0.0952, RMSE=0.3086, R²=0.0020
============================================================


📊 Round 601 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2491, R²: -0.0037

============================================================
🔄 Round 602 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0916, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0916, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0916, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0916, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0916, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0916, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 602 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0915, RMSE=0.3025, R²=0.0016
   Val:   Loss=0.0832, RMSE=0.2884, R²=0.0046
============================================================


============================================================
🔄 Round 604 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0906, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0906, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0906, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0906, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0906, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0905, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 604 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0903, RMSE=0.3005, R²=0.0013
   Val:   Loss=0.0879, RMSE=0.2965, R²=-0.0028
============================================================


============================================================
🔄 Round 606 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.1012 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.1012, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.1012, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.1012, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.1012, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.1012, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1012)

============================================================
📊 Round 606 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=0.0033
   Val:   Loss=0.1012, RMSE=0.3181, R²=-0.0033
============================================================


📊 Round 606 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2491, R²: -0.0036

============================================================
🔄 Round 607 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0893, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0893, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0893, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0893, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0893, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0893, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 607 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0894, RMSE=0.2990, R²=0.0003
   Val:   Loss=0.0916, RMSE=0.3026, R²=0.0080
============================================================


============================================================
🔄 Round 608 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0904, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0904, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0904, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0903, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0903, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0903, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 608 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0904, RMSE=0.3007, R²=0.0023
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0004
============================================================


📊 Round 608 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2491, R²: -0.0035

📊 Round 608 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2491, R²: -0.0037

📊 Round 608 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2491, R²: -0.0037

📊 Round 608 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2491, R²: -0.0040

============================================================
🔄 Round 617 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0902, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0902, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0902, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0902, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0902, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0902, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 617 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0902, RMSE=0.3003, R²=0.0030
   Val:   Loss=0.0885, RMSE=0.2975, R²=-0.0014
============================================================


============================================================
🔄 Round 619 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0952 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0952, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0953, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0953, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0953, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0953, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0952)

============================================================
📊 Round 619 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2975, R²=0.0022
   Val:   Loss=0.0952, RMSE=0.3086, R²=-0.0069
============================================================


============================================================
🔄 Round 620 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0903, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0903, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0903, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0903, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0903, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0903, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 620 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0905, RMSE=0.3009, R²=0.0027
   Val:   Loss=0.0872, RMSE=0.2952, R²=-0.0058
============================================================


============================================================
🔄 Round 621 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0913, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0913, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0913, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0913, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0913, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0913, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 621 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0914, RMSE=0.3023, R²=0.0019
   Val:   Loss=0.0837, RMSE=0.2894, R²=-0.0070
============================================================


📊 Round 621 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2491, R²: -0.0036

📊 Round 621 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2491, R²: -0.0036

============================================================
🔄 Round 623 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0900, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0900, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0900, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0900, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0900, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0900, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 623 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0900, RMSE=0.2999, R²=0.0028
   Val:   Loss=0.0894, RMSE=0.2989, R²=-0.0019
============================================================


📊 Round 623 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2491, R²: -0.0035

📊 Round 623 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2491, R²: -0.0036

📊 Round 623 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2491, R²: -0.0036

============================================================
🔄 Round 626 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0894, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0894, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0894, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0894, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0894, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0894, val=0.0923, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 626 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2987, R²=0.0027
   Val:   Loss=0.0923, RMSE=0.3038, R²=-0.0002
============================================================


📊 Round 626 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2491, R²: -0.0037

📊 Round 626 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2491, R²: -0.0036

============================================================
🔄 Round 630 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0919, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0919, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0919, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0919, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0919, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0919, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 630 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0917, RMSE=0.3028, R²=0.0017
   Val:   Loss=0.0825, RMSE=0.2873, R²=0.0030
============================================================


============================================================
🔄 Round 631 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0962 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0963, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0963, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0963, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0963, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0965, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0962)

============================================================
📊 Round 631 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2971, R²=0.0011
   Val:   Loss=0.0962, RMSE=0.3102, R²=-0.0140
============================================================


📊 Round 631 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2491, R²: -0.0037

============================================================
🔄 Round 632 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0914, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0914, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0913, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0913, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0913, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0913, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 632 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0914, RMSE=0.3023, R²=0.0012
   Val:   Loss=0.0837, RMSE=0.2894, R²=0.0024
============================================================


📊 Round 632 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2491, R²: -0.0037

============================================================
🔄 Round 633 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0958 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0959, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0959, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0959, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0960, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0962, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0958)

============================================================
📊 Round 633 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2972, R²=0.0006
   Val:   Loss=0.0958, RMSE=0.3096, R²=-0.0193
============================================================


📊 Round 633 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2491, R²: -0.0037

============================================================
🔄 Round 634 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0954 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0954, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0954, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0954, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0954, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0954, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0954)

============================================================
📊 Round 634 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2974, R²=0.0032
   Val:   Loss=0.0954, RMSE=0.3089, R²=-0.0047
============================================================


============================================================
🔄 Round 636 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0929, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0929, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0929, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0929, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0929, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0929, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 636 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0925, RMSE=0.3042, R²=0.0016
   Val:   Loss=0.0790, RMSE=0.2811, R²=0.0043
============================================================


📊 Round 636 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2491, R²: -0.0037

============================================================
🔄 Round 639 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0961 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0961, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0961, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0961, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0961, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0961, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0961)

============================================================
📊 Round 639 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2971, R²=0.0017
   Val:   Loss=0.0961, RMSE=0.3100, R²=-0.0055
============================================================


📊 Round 639 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2491, R²: -0.0035

📊 Round 639 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2491, R²: -0.0035

📊 Round 639 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2491, R²: -0.0036

📊 Round 639 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2491, R²: -0.0035

============================================================
🔄 Round 648 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.1008 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.1008, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.1008, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.1008, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.1008, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.1008, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1008)

============================================================
📊 Round 648 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2952, R²=0.0032
   Val:   Loss=0.1008, RMSE=0.3174, R²=-0.0038
============================================================


============================================================
🔄 Round 649 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0890, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0890, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0890, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 649 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0893, RMSE=0.2988, R²=0.0033
   Val:   Loss=0.0920, RMSE=0.3034, R²=-0.0028
============================================================


📊 Round 649 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2491, R²: -0.0036

============================================================
🔄 Round 651 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0903, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0902, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0902, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0902, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0902, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0902, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 651 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0901, RMSE=0.3002, R²=0.0027
   Val:   Loss=0.0887, RMSE=0.2979, R²=-0.0001
============================================================


📊 Round 651 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2491, R²: -0.0033

📊 Round 651 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2491, R²: -0.0033

============================================================
🔄 Round 655 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0930 (↓), lr=0.000001
   • Epoch   2/100: train=0.0890, val=0.0930, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0930, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0930, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0890, val=0.0930, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0931, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0930)

============================================================
📊 Round 655 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0890, RMSE=0.2984, R²=0.0024
   Val:   Loss=0.0930, RMSE=0.3050, R²=-0.0014
============================================================


📊 Round 655 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2491, R²: -0.0035

============================================================
🔄 Round 657 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0900, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0900, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0900, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0900, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0900, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0900, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 657 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0901, RMSE=0.3001, R²=0.0019
   Val:   Loss=0.0889, RMSE=0.2982, R²=0.0000
============================================================


📊 Round 657 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2491, R²: -0.0036

============================================================
🔄 Round 660 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0897, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0896, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0896, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0896, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0896, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0896, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 660 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0898, RMSE=0.2997, R²=0.0019
   Val:   Loss=0.0900, RMSE=0.2999, R²=-0.0044
============================================================


============================================================
🔄 Round 661 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0913, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0913, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0913, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0913, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0913, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0913, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 661 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0915, RMSE=0.3024, R²=0.0033
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0029
============================================================


📊 Round 661 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2491, R²: -0.0038

============================================================
🔄 Round 664 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0899, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0899, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0899, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0899, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0899, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0898, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 664 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0900, RMSE=0.3000, R²=0.0024
   Val:   Loss=0.0894, RMSE=0.2990, R²=0.0008
============================================================


📊 Round 664 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2491, R²: -0.0037

============================================================
🔄 Round 670 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0891, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0891, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0891, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0891, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0891, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0891, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 670 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0893, RMSE=0.2989, R²=0.0023
   Val:   Loss=0.0920, RMSE=0.3033, R²=-0.0002
============================================================


============================================================
🔄 Round 676 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0916, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0916, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0916, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0916, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0916, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0916, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 676 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0913, RMSE=0.3022, R²=0.0024
   Val:   Loss=0.0839, RMSE=0.2897, R²=0.0001
============================================================


============================================================
🔄 Round 677 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.1021 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.1021, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.1021, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.1021, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.1021, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.1021, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1021)

============================================================
📊 Round 677 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=0.0033
   Val:   Loss=0.1021, RMSE=0.3195, R²=-0.0035
============================================================


📊 Round 677 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2491, R²: -0.0034

============================================================
🔄 Round 684 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0906, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0906, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0906, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0906, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0906, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0906, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 684 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0907, RMSE=0.3012, R²=0.0019
   Val:   Loss=0.0864, RMSE=0.2939, R²=0.0023
============================================================


============================================================
🔄 Round 686 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0893, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0893, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0893, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0893, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0893, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0893, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 686 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0896, RMSE=0.2992, R²=0.0026
   Val:   Loss=0.0911, RMSE=0.3018, R²=-0.0023
============================================================


============================================================
🔄 Round 688 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0911, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0911, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0911, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0911, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0911, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0911, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 688 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0912, RMSE=0.3019, R²=0.0004
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0018
============================================================


📊 Round 688 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2491, R²: -0.0034

============================================================
🔄 Round 690 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0919, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0919, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0919, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0919, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0919, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0919, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 690 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0920, RMSE=0.3033, R²=0.0026
   Val:   Loss=0.0814, RMSE=0.2853, R²=-0.0044
============================================================


============================================================
🔄 Round 691 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0961 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0961, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0961, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0961, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0961, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0961, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0961)

============================================================
📊 Round 691 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2971, R²=0.0012
   Val:   Loss=0.0961, RMSE=0.3101, R²=0.0052
============================================================


============================================================
🔄 Round 692 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0891, val=0.0930 (↓), lr=0.000001
   • Epoch   2/100: train=0.0891, val=0.0930, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0891, val=0.0930, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0891, val=0.0930, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0891, val=0.0930, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0891, val=0.0930, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0930)

============================================================
📊 Round 692 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0891, RMSE=0.2984, R²=0.0034
   Val:   Loss=0.0930, RMSE=0.3049, R²=-0.0066
============================================================


📊 Round 692 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2491, R²: -0.0035

📊 Round 692 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2491, R²: -0.0035

📊 Round 692 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2491, R²: -0.0035

============================================================
🔄 Round 695 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0918, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0918, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0918, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0918, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0918, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0917, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 695 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0920, RMSE=0.3033, R²=0.0018
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0010
============================================================


📊 Round 695 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2491, R²: -0.0037

============================================================
🔄 Round 696 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0919, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0919, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0919, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0919, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0919, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0918, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 696 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0919, RMSE=0.3031, R²=0.0023
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0006
============================================================


📊 Round 696 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2491, R²: -0.0036

📊 Round 696 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2491, R²: -0.0036

============================================================
🔄 Round 699 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0911, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0911, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0911, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0911, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0911, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0911, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 699 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0913, RMSE=0.3022, R²=0.0017
   Val:   Loss=0.0840, RMSE=0.2898, R²=0.0023
============================================================


============================================================
🔄 Round 700 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0898, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0898, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0898, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0898, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0898, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0898, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 700 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0897, RMSE=0.2996, R²=0.0030
   Val:   Loss=0.0904, RMSE=0.3006, R²=-0.0095
============================================================


📊 Round 700 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2491, R²: -0.0037

============================================================
🔄 Round 701 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0911, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0911, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0911, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0911, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0911, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0911, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 701 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0912, RMSE=0.3020, R²=0.0031
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0042
============================================================


============================================================
🔄 Round 702 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0916, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0916, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0916, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0916, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0916, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0916, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 702 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0916, RMSE=0.3026, R²=0.0012
   Val:   Loss=0.0829, RMSE=0.2880, R²=-0.0134
============================================================


📊 Round 702 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2491, R²: -0.0037

📊 Round 702 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2491, R²: -0.0037

============================================================
🔄 Round 706 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0909, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0909, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0909, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0909, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0909, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0909, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 706 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0910, RMSE=0.3017, R²=0.0006
   Val:   Loss=0.0853, RMSE=0.2920, R²=0.0040
============================================================


📊 Round 706 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2491, R²: -0.0037

============================================================
🔄 Round 707 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0944 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0945, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0945, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0945, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0945, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0946, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0944)

============================================================
📊 Round 707 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2978, R²=0.0017
   Val:   Loss=0.0944, RMSE=0.3073, R²=-0.0053
============================================================


📊 Round 707 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2491, R²: -0.0037

============================================================
🔄 Round 709 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0900, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0900, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0900, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0900, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0900, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0900, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 709 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0901, RMSE=0.3001, R²=0.0028
   Val:   Loss=0.0891, RMSE=0.2985, R²=-0.0183
============================================================


📊 Round 709 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2491, R²: -0.0036

📊 Round 709 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2491, R²: -0.0039

============================================================
🔄 Round 711 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0905, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0905, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0905, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0905, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0905, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0905, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 711 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0906, RMSE=0.3009, R²=0.0011
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0010
============================================================


============================================================
🔄 Round 715 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0893, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0893, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0893, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0893, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0893, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0893, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 715 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0893, RMSE=0.2989, R²=0.0009
   Val:   Loss=0.0919, RMSE=0.3032, R²=0.0043
============================================================


📊 Round 715 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2491, R²: -0.0038

============================================================
🔄 Round 716 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0897, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0897, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0897, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0897, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0897, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0896, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 716 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0897, RMSE=0.2995, R²=0.0025
   Val:   Loss=0.0904, RMSE=0.3007, R²=-0.0002
============================================================


📊 Round 716 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2491, R²: -0.0038

============================================================
🔄 Round 719 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0902, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0902, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0902, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0902, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0902, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0901, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 719 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0900, RMSE=0.3000, R²=0.0007
   Val:   Loss=0.0893, RMSE=0.2988, R²=0.0018
============================================================


📊 Round 719 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2491, R²: -0.0038

============================================================
🔄 Round 722 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0910, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0910, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0910, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0910, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0910, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0910, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 722 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0912, RMSE=0.3020, R²=0.0021
   Val:   Loss=0.0846, RMSE=0.2908, R²=-0.0051
============================================================


============================================================
🔄 Round 723 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0911, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0911, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0911, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0911, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0911, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0911, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 723 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0911, RMSE=0.3018, R²=0.0025
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0013
============================================================


📊 Round 723 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2491, R²: -0.0036

============================================================
🔄 Round 725 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0899, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0899, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0899, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0899, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0899, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0899, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 725 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0899, RMSE=0.2998, R²=0.0010
   Val:   Loss=0.0898, RMSE=0.2996, R²=-0.0231
============================================================


📊 Round 725 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2491, R²: -0.0036

📊 Round 725 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2491, R²: -0.0036

📊 Round 725 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2491, R²: -0.0036

📊 Round 725 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2491, R²: -0.0036

📊 Round 725 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2491, R²: -0.0035

📊 Round 725 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2491, R²: -0.0033

📊 Round 725 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2491, R²: -0.0033

📊 Round 725 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2490, R²: -0.0032

📊 Round 725 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2490, R²: -0.0032

============================================================
🔄 Round 736 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0897, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0897, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0897, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0897, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0897, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0897, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 736 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0895, RMSE=0.2991, R²=0.0018
   Val:   Loss=0.0913, RMSE=0.3022, R²=0.0016
============================================================


📊 Round 736 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2490, R²: -0.0031

============================================================
🔄 Round 737 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0904, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0904, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0903, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0903, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0903, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0903, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 737 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0899, RMSE=0.2998, R²=0.0036
   Val:   Loss=0.0898, RMSE=0.2997, R²=-0.0182
============================================================


📊 Round 737 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2491, R²: -0.0033

📊 Round 737 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2491, R²: -0.0033

============================================================
🔄 Round 741 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0936, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0936, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0936, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0936, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0936, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0936, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 741 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0936, RMSE=0.3060, R²=0.0022
   Val:   Loss=0.0747, RMSE=0.2733, R²=0.0003
============================================================


============================================================
🔄 Round 744 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.1048 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.1048, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.1049, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.1049, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.1049, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.1050, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1048)

============================================================
📊 Round 744 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=0.0011
   Val:   Loss=0.1048, RMSE=0.3238, R²=-0.0037
============================================================


============================================================
🔄 Round 745 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0960 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0960, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0960, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0960, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0960, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0960, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0960)

============================================================
📊 Round 745 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2972, R²=0.0016
   Val:   Loss=0.0960, RMSE=0.3099, R²=0.0003
============================================================


============================================================
🔄 Round 746 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0972 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0972, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0972, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0972, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0972, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0972, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0972)

============================================================
📊 Round 746 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2967, R²=0.0017
   Val:   Loss=0.0972, RMSE=0.3117, R²=0.0015
============================================================


📊 Round 746 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2490, R²: -0.0031

============================================================
🔄 Round 747 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0933 (↓), lr=0.000001
   • Epoch   2/100: train=0.0890, val=0.0933, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0933, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0933, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0890, val=0.0933, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0890, val=0.0933, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0933)

============================================================
📊 Round 747 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0890, RMSE=0.2983, R²=0.0019
   Val:   Loss=0.0933, RMSE=0.3055, R²=-0.0038
============================================================


============================================================
🔄 Round 748 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0960 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0960, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0960, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0960, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0960, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0960, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0960)

============================================================
📊 Round 748 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2972, R²=0.0017
   Val:   Loss=0.0960, RMSE=0.3098, R²=0.0022
============================================================


============================================================
🔄 Round 749 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0913, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0913, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0913, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0913, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0913, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0913, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 749 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0915, RMSE=0.3024, R²=0.0024
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0005
============================================================


📊 Round 749 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2491, R²: -0.0034

============================================================
🔄 Round 756 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0899, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0899, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0899, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0899, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0899, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0899, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 756 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0899, RMSE=0.2998, R²=0.0020
   Val:   Loss=0.0897, RMSE=0.2995, R²=-0.0012
============================================================


📊 Round 756 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2491, R²: -0.0035

📊 Round 756 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2491, R²: -0.0037

============================================================
🔄 Round 760 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0985 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0985, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0985, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0985, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0985, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0985, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0985)

============================================================
📊 Round 760 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2962, R²=0.0013
   Val:   Loss=0.0985, RMSE=0.3139, R²=0.0039
============================================================


============================================================
🔄 Round 761 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0892, val=0.0935 (↓), lr=0.000001
   • Epoch   2/100: train=0.0892, val=0.0935, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0892, val=0.0935, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0934, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0892, val=0.0934, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0892, val=0.0934, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0935)

============================================================
📊 Round 761 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0890, RMSE=0.2983, R²=0.0017
   Val:   Loss=0.0935, RMSE=0.3057, R²=0.0023
============================================================


📊 Round 761 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2491, R²: -0.0039

============================================================
🔄 Round 763 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0902, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0902, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0902, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0902, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0902, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0902, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 763 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0903, RMSE=0.3005, R²=0.0015
   Val:   Loss=0.0881, RMSE=0.2968, R²=0.0027
============================================================


============================================================
🔄 Round 764 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0981 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0981, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0981, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0981, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0981, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0981, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0981)

============================================================
📊 Round 764 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2964, R²=0.0019
   Val:   Loss=0.0981, RMSE=0.3131, R²=0.0016
============================================================


============================================================
🔄 Round 765 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0948 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0948, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0948, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0948, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0948, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0949, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0948)

============================================================
📊 Round 765 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2977, R²=0.0024
   Val:   Loss=0.0948, RMSE=0.3079, R²=-0.0108
============================================================


============================================================
🔄 Round 766 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0903, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0903, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0903, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0903, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0903, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0903, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 766 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0901, RMSE=0.3002, R²=0.0015
   Val:   Loss=0.0890, RMSE=0.2983, R²=0.0019
============================================================


📊 Round 766 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2491, R²: -0.0038

============================================================
🔄 Round 767 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0890, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0925, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0890, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 767 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2987, R²=0.0020
   Val:   Loss=0.0925, RMSE=0.3042, R²=0.0002
============================================================


============================================================
🔄 Round 768 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0915, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0915, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0915, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0915, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0915, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0915, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 768 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0913, RMSE=0.3021, R²=0.0000
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0054
============================================================


📊 Round 768 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2491, R²: -0.0039

📊 Round 768 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2491, R²: -0.0038

📊 Round 768 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2491, R²: -0.0036

============================================================
🔄 Round 776 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0982 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0982, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0982, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0982, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0982, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0982, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0982)

============================================================
📊 Round 776 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=0.0022
   Val:   Loss=0.0982, RMSE=0.3133, R²=0.0005
============================================================


📊 Round 776 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2490, R²: -0.0033

============================================================
🔄 Round 777 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0915, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0915, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0915, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0915, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0914, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0914, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 777 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0913, RMSE=0.3022, R²=0.0027
   Val:   Loss=0.0841, RMSE=0.2899, R²=-0.0038
============================================================


📊 Round 777 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2490, R²: -0.0033

============================================================
🔄 Round 779 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0902, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0902, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0902, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0902, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0902, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0902, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 779 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0902, RMSE=0.3004, R²=0.0007
   Val:   Loss=0.0883, RMSE=0.2971, R²=0.0023
============================================================


============================================================
🔄 Round 780 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0917, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0917, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0917, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0917, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0917, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0917, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 780 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0916, RMSE=0.3026, R²=0.0008
   Val:   Loss=0.0829, RMSE=0.2880, R²=0.0013
============================================================


📊 Round 780 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2490, R²: -0.0031

📊 Round 780 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2490, R²: -0.0031

❌ Client client_24 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8692 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8692 {grpc_message:"Socket closed", grpc_status:14}"
>
