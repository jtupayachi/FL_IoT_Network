[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39d4a08b-5376-4db5-a9db-b0bdc0e418e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a11cc6f2-3fa7-4990-b5b4-80b6e7a1d36e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93182805-0950-40c6-8320-f1da10f1f5a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f6544f5-605c-457d-8599-79c8d40ee1b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd656933-03fc-4792-9e70-d0f6fd655720
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de953b71-9fba-467b-88ec-8931e7497b74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f7f0510-ceae-47ae-b57f-9dc6c1331547
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 478c8041-5922-41f9-b6b6-a176d36f231c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e7af6e0-e310-4f8e-a6bb-037c5ec86e06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa382f96-6639-49d7-a48a-31d7e0f1bb64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 355cef8d-5ecb-4302-bc24-fba49be283df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00b93c82-dc70-4a77-85ab-19ff0fc3e5ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6c816dd-fd54-4799-841e-7e4f20eb024c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7751a7f-f147-4b03-ba92-2bee1fc8c3e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32397f79-afff-4fdf-b1d5-0077b7102221
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c00de9ab-c66b-41d3-9877-49afb02644c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca198a73-d32c-4475-bd25-75d8eb726875
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac79663e-aa66-4cf2-9e63-bd123d50d204
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9af4b3b-f09e-4602-a9b2-ab9046039b9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0aea8f6d-5a47-45a7-8ad1-7f9ff73fee0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14c7df6b-844b-4d5d-9adb-a4580028fc57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 401e0398-f8f2-44dd-85e4-832d529b4d03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c008b3b1-0d67-4aa4-8038-950c4bb51b54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e8fb582-78c0-4728-b16c-b515e88cb7de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 789e7ab0-4032-4830-a61f-af5df681b8b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58ced094-34b0-4a70-83e7-235a6d6aacde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9ca16ec-38b8-4067-88d7-fbfa74e12536
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68ff02be-e94d-405e-8b0d-aa7ae61bd781
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4cb9cb8-7b68-4735-a3e2-f1e10701774d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6349f005-55fd-4909-8722-a727a93e603d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc283f77-03dd-4b7e-b0e3-fad6db6c48dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b2ddf1f-f324-4bc7-a3fb-541bf311316a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e42f74e-b884-4701-8849-9c63a20916e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1b7e406-04f9-422d-8aa7-45bc91894c12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d1d7649-d2a7-46d5-80d7-da3683d0d771
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfc02c03-e6b3-4d54-bad2-25a8568b3935
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72e4b32e-101a-49ea-9a96-e110ebe3a81d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35a8fbb6-e17e-45b2-b7df-6c2328adddd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ea802b0-dac3-42c5-99fd-f4bd32d35c7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eeb03508-b28e-4614-bb91-d458f785b8ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc835ce4-ac1d-4493-929c-49682ddcd62f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66af7cd2-6f5f-450b-ba87-4c0ca20d19b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5aff896-2644-47e0-a25c-245335b00d29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 498b13e8-23ef-4403-ba21-2999ce71a000
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b81fdf7b-b8b5-4797-96d5-d882a36e2f47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4eaca2e-1010-4a99-8e73-f2dceb8c818d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba5fadf3-dd79-4d51-8a4f-26a94ba75689
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 676309e6-006c-4fb4-8332-54dc1811ed7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c428f34-0464-4132-9c63-d28ebf0c6cb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8aa68ed4-348c-4d61-9ac0-d6d9aa0cc571
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8db40165-3f22-4fb5-bf32-89338ca0eec1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 216eaf0c-2c2e-4542-a940-14b62f6ba5e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0bec5ac5-19ac-47ef-9df0-50cfb16bff36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b211426-ed4e-4d79-af76-0b18564b9fa8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea61af5d-e85f-4cc5-b1d3-09936c0acf1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b24bd96-6d08-4d60-a848-a52399cd6122
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 861b13c6-4b3c-47bd-9029-1ed0eae331fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f897ef9-b448-4ade-a17b-96f25c19ca63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20a6d3a7-1b9e-48ee-92fd-9a4a6f690bc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 490b000c-76d3-46fc-8223-32eae23f40f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d79d0c71-057d-4206-bed5-579a79e20e9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a377ec55-1211-42d0-bed9-be27923bfde9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2463119-d54f-4233-be64-108cddd9b76f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 171f5d81-35f4-4f2a-b952-6e24c610c692
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1ad4f38-2af9-4f5f-aa40-aafe6c4aaa6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb950b59-0a9a-491e-ae39-afdc21c9fb33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 315105cf-2323-4096-800a-700b2c1de7db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40457163-f878-4944-94d6-b972cd59c587
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42694ab9-3ecd-4eb8-8ca5-4d52fd844ddf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29edc74b-3d34-4429-a0de-9a6d53cf8105
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 365a27f6-aba7-4719-a00a-837d1fb847db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91870056-4dac-4954-b0c7-09745f8b7a13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f68978f-540a-4aa7-a5dc-47d4a0534aee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b79b510-d7e3-4a70-b995-d2d279894255
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d4563b1-9759-447a-866e-7185a387861b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 877e3c36-79c5-4994-bbb2-ea51a4fba01d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0cd50dd7-bcd5-43ac-9a4e-88f17f76770f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5dd4964c-0ed2-4eee-ad6c-4aa4e7898690
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2a97f33-3132-4810-8653-d57153108a68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 314483bd-a77c-4b98-9d29-89cdc944eaf8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8455be82-1201-462e-ac02-adb0cb68555b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d66d6903-27c1-41b1-b3d0-a08d6aa6882b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 137dac70-4a2e-4054-8d81-5703157607ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 660c5bc2-518c-4c3f-a282-7eaa65e32953
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea47edd6-59ec-42d0-b1e6-a55639c67e66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1ce92c4-08b5-4ea8-b4af-52202adba7e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86863641-3017-4ec1-ab35-d63e4930b20f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7659774-de44-4a6e-9fa7-551d9466cb6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52ec49e7-a7df-4948-966c-02c5ffb8b4bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e456970f-67c2-456a-8eaf-a536483da6a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a778665-b8fa-438d-b100-33e4d44a4a2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf13155d-5396-4a81-b14b-47f3f6ea6656
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8584e00-4bac-485b-9236-851af4fe8cf5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb8114a9-ccc4-4c1a-80e1-7e1fd9067f18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc72e45f-2561-4a39-8921-56d2d1c8243d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d820773f-e9e1-41a2-82c3-8dc5397ed857
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 112345f6-8a1d-4698-8e83-9a09d3b3753e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message baa93c37-0309-465a-8c67-c4e6aa655f97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed5f736f-3a2c-4ba3-ace7-197ab70bdf03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c32ae71-9f51-4a98-93aa-1b684553b830
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ffacab2f-6dba-45ec-aa5c-e5d8a1fe2b65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30259e46-2359-4df6-ba48-54b28f57ff95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bdd6cb1d-62f5-4385-92fc-b3f5b0785e0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc5adbbe-45bd-47c4-8d3c-06d55bebcfd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ce22109-d36a-4767-828c-faf890e1b4d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 738ea897-7912-4a9a-bbf1-9a79e2db1100
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de21bcee-5658-4edd-bd5a-2455097a18b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff42a854-8505-489b-95c9-4994c55c68ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 707909a2-eada-437c-808b-b96ead949789
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e9cd636-535f-4b32-a229-b0c781d88b17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fef87524-339b-49a2-a0f1-2c987ffc7cfc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3eeb25a4-7530-48c3-b645-f3b88d8fc4e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84ee98f4-6cf9-4fab-9e0d-ad9c710a5650
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28d9867d-3ef4-4328-8b17-ab05dd802475
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b6a8679-a3c9-4a87-a005-a4b82804065a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ace96a7b-748f-4b70-a49a-2a567bdbe394
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0aeddda-7c73-47fb-9772-8a157d610d9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d3ef34b-0a7f-4e38-a972-0933ecd91296
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5187f617-4e8a-4dcb-88e7-0aeddf96f1b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61b20bea-a9f0-485c-a76b-7093d47dcaa2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85aa55e0-c983-48a0-9a08-6a6195ee5450
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f0d1d3e-f0f5-4071-b49d-a89e75beffde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cebf26f3-7633-4195-bac8-1a6b0b938427
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ccd5aa7-1674-43c9-a1e8-22e40f82e62d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2bd8474e-5988-4179-8590-b08384fb9539
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29582995-5c96-48fe-bc71-30ad61183f75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b12489dd-b038-4791-954f-f2926c1dfa28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88e14c09-9815-4c34-9b2c-cb743e390257
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f76a8f0-c51b-4ffd-9ff0-f9516c2f989e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31c04ee6-345e-4953-b50b-261478a6d92b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79a40396-88b0-4f36-91fb-f7bad57e26e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3f7aaa3-a176-4760-9af2-8dc697bdc280
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47b58abc-98a7-4b8b-b739-4a477c7ac298
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a0966d8-9e77-4a58-b22c-0407133f72a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aaf6066a-5b09-4c97-8b96-165b33ba312c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23d8068c-1bf7-4cdc-90f7-8f4a279c2da5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17b571b9-eda2-4ab9-a2ed-30a48e554172
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4988486b-ea84-48e4-9ca2-cdf8a17b9323
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a808d6a1-1176-4eaa-8bec-c69bd6e57de7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 982f0128-3cb5-46d1-9f41-5c0985b478d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80eb8e4b-44a0-4608-9d63-82b2ad719998
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47d6c8a9-ce02-4c84-83e9-e6068c730910
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5944b2b0-4ac9-4772-adb5-d7a56df08da6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed5171e2-c7c5-47d6-bf53-e62c3eed1234
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20255ced-f1db-42e9-9250-fa470dcef1a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ad9c022-e26a-4783-8ff3-b1ef2ccf81ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20288241-2e26-491d-8bdf-44b6442ffb48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 733dad30-d5fb-4e92-aa18-35e11ae41601
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96d82129-dd59-41bf-8553-f4a7961cf25f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e69172b8-4c87-4428-9d6c-aa0fb97ce093
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba58bb7e-4481-4198-bd8a-2360db0ce3c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba0888fb-dab6-4938-886a-35e58c9ad6c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63d2e61d-9b14-49f7-be2d-3d88911ddc76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7bd1c182-3f2d-4114-9d13-12f40b9b40d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f14ed6a4-af67-4df5-a664-413895fa80a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0ad3676-de43-4265-a22c-cd351144e335
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 588efc01-d38d-4d21-9515-3b95cdb5e446
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4705f339-3145-4978-901a-c89c0ccc1df3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eed346d4-8a6e-4c7c-ab2b-79a1d91bbc47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86fd6d31-90f0-40a8-8585-34a727376f03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c4c074c-79d2-49dc-8d5b-d1ccc0530193
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f93f8090-f051-42cc-9139-f1ead6d34d63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61b4f43d-3401-4252-a814-5ed57bb4f7ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97fcba64-efc3-4ec0-a5f2-5a8cef177e2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70a91f2d-0cd6-475e-b98b-a9b0dc86f38a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9e4f7d1-1cf5-41ad-bc44-fec324ee5b3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52fb0665-f4b1-4774-af19-af5e1259ceba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 595d5ef7-c847-4b89-8abc-8833ea77a07f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3e8ce9a-fbe9-484b-94e0-841efe402627
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a45852be-2e2e-4016-a871-dc142c2c80af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 676d647f-eef6-4ab1-aeb3-a277a21c2453
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01b80f52-77da-4b0c-a699-ca65b37a9f9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8757ede-3d42-4f77-be07-d6e2ce5bd593
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77313619-d8e4-4316-933c-fc27e812e67f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5b81a57-f19a-413f-8f3d-cf6ec8686d4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f38cd36-3cf4-4de5-a990-e63e69e37c3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9160b63-660c-45f7-af34-70bc454a576e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 032e36b9-0001-4277-af98-abaaaea8bafb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8458d727-bb9a-4968-ad03-ec9c68178c87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6e6e5f6-131a-4b56-bfae-0c45f6a008db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f02b02db-9407-458b-aefe-20562b7a4531
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09e7d4a4-b8b5-4877-b0d1-3aade2871e8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c0f3356-3517-4ef7-8378-169643068bac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02c55825-2ef5-4b2f-a961-7345a3e35365
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82b1e7f9-5ac8-4d8e-958a-e8bb70bdb76a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2fc64cc-09a7-4668-8496-ccd93d7260e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e02f5914-59f1-46e0-8c0f-095c4499d913
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e10ba078-2036-445d-9c8f-a494e2b203a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83051b60-d52b-4564-8559-041966ee464b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 249ecf79-3d5a-42a3-820c-1b9769211174
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 571863a3-4f56-481a-97a5-0219ff87d7bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c73792aa-a424-4546-9e79-7edee48aff05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2e047d4-791f-4a6c-a69d-8cd8a1ae23c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d18850f6-941e-412f-9bf2-d7d3e52d1d8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e2f3cfc-50c6-40ff-8913-3b9807ed8335
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f821b13-c2c7-41d5-8ef6-473cb186933c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00f16edc-0a10-456e-94c6-1417cbb3c664
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fbeaa74c-a54e-4f7b-b4da-ea72c491c637
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1136eaf-aaf2-442d-9473-e3c166840c67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3405be35-b093-48ad-b5e7-7b0c3a79c7cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64c09111-3f37-436f-8e68-5a2605f26440
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab57f43d-433d-4d1b-8b13-cb8b86419bf5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ccd2218b-1306-4971-b82c-bd330500e77b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73735820-463d-43e4-b554-2ab0dd07ec8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26ba790c-7f31-4c4c-ae04-1f5058617926
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4f5cba2-ecf5-451f-a107-34900bb6eac9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71ad15fe-19c9-4abb-86ae-7bd90bee7791
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06f4ab25-50f9-473f-9122-0293e0b651f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4468ec73-867f-432e-bc73-6c1e2d542248
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d7ed4cf-fbe4-4194-897d-adc2897e4e26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93a044b4-8ee5-467e-816c-0f2b3bdcc914
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03078ace-ba4a-4c01-ac1c-f3bf503ac433
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f72d2cfa-cfba-4238-987b-17a0b4d02033
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f0eefed-7af2-4307-980a-77d14c11802b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9fef7e91-6256-4edb-9415-8230d2856387
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 365a116f-7f39-46f7-8b53-592696063a61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29e8169c-193e-43ab-83f9-95bc1e155f1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4128f37f-3e45-468a-ae9d-66e1411d251f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d5511e4-8d7e-44b8-b07e-72996f71257e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd0836e3-9a42-4dfd-86e2-cc35e5487f6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9cfe933c-af04-44d3-ba9a-2c4098c43fe8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f185d433-5ad4-48d0-b086-d09246136081
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff6c4781-9f69-4995-8893-067367883de4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e8c0103-34e2-4a46-b26f-17f513c635f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6663f2f0-9363-4f48-93ea-2730c8ab38b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 803d5a28-c7d5-44d5-8ba9-234a06cc697c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0b35b43-0eb9-4131-9ef9-9047cf17a6d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38e034e8-a4cc-46cc-a7a5-3a6bc50e83af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3fbcf962-2985-4c07-aaae-8c1e2b3c91e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98096e21-ff12-4f05-bf63-d68d2e8392cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a1fcf3c-ea23-4d42-8b11-e9daa0604a30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1b99da4-8318-4e02-b644-04ce361ca921
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c69ec1e-e407-49c2-9b4e-97b58ccfe12f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 027cf106-7e00-4c71-8034-9e3ed0985308
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6bcc748c-a4de-40a5-b876-0e79d082c018
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c18653fc-1ce2-4e71-8858-368d851b4aea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ab431e9-1016-4928-966f-24d6bf22464e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aedb0a13-e211-4345-b431-0ac99533516f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e006e7a-a3d0-4b1e-8891-b1a42c126fe9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c283d23-0f3b-4011-a563-358aa37ea794
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c7d9664-84b1-4cd8-92cd-43be644eb96b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c483f877-7212-429e-a28f-7c065a9faa46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b24c0f93-57f7-4aaa-8229-1618d4cf369e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f60d2937-b5f2-4906-ac59-47d235facc25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fdd7858e-7178-47ea-9559-f56e93e6a0e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30850052-a195-4c95-954a-75ca5f1f4f25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cabbd6ad-d1af-4fe1-94d9-ed406a51a92d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f89ebca-3e4d-4144-bdea-2da1da53a3ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38a08498-fb10-47bb-bab1-c3888e819c89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4412b9d-4d4c-44d0-89a5-f8e6076c7f15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1d50ef1-ac9f-42e8-8916-d932fb96a8d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04d2666e-df6d-45b7-996e-3fa336d0ca33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 765d404f-b902-447f-9e74-dd71e0600fcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7dda9f68-fef1-484a-ace9-161c6828b863
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7236711-9371-4f32-9ad5-9b8f98e459bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cdbe203f-ce60-4397-8a75-88078e85cd07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7b02b32-f788-41a5-ab14-a63350c0519f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55a7ec27-64ec-40d0-89a9-b73827057325
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b33ecdd-917a-4adb-ba39-2e26bc575172
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e4ffde3-25ee-4481-815b-2b196fe1af91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73ef5f7b-3354-45db-99be-c919f49a31b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c149f5d-e4e5-488b-ac38-7e6e388f5229
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cee5f927-63fe-477e-b939-a141f177e25d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 748df7e2-1a8e-40bc-8c7d-bc0c8faee660
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b662848-eaf3-4d64-adb0-2cd55368299a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94374eb3-8a9e-4748-8376-63947a31df96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ec6d86d-71a0-4f99-864e-ddc9ce97be14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4906f06-38f1-4315-ae20-04970c0bfe5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0741b3ea-357d-4df6-b151-90c7f40a012f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57bc5728-cd2a-4d71-8afb-83ee0c8746f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c47ba99-6302-49a3-8d67-b9e4fad5c2a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d98cf65a-dcab-485d-8e46-bdd6c09b6a2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b09f6fc-f9ec-4bb8-a62a-54a952889857
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bad65464-c86c-4f5b-a9ee-9f49e72eafc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b663f19-5aec-42ba-99f6-597fe8bf979a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce5422c6-cb97-4281-993e-4a4ce3f69431
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1791869-0540-45cc-bff1-485ded8f73c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c61df55-d95c-4aad-a0d6-ae83080b5e6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 901a94f9-de88-47cd-a649-d90ed46a5faf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8cae08a-c5d4-4a79-b396-8485f8eeaf35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93b8e5c0-c5e2-4ae1-972f-654a089268ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b546856-2aaf-45cf-91b7-82e8ea3c6003
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03b52b5e-acb5-4593-933d-e05157b25ad4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32caba79-8a6c-4cf8-a7b0-2ca92813925d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11fc07fa-7f26-441c-9573-6caa85ccf9d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2433a452-a0ec-40f1-8aec-f1fd5f862d3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85a03b06-a5ec-4815-9a51-3252b77cd9ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c593e1f-dc2a-4f4e-af4a-67a753eaf658
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b036909e-4512-48b3-baee-e406e611b569
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8b0256a-d058-4227-91c0-9891c70e1d87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 498a9d07-c035-4f14-9963-defaf5b4c2aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64334fd9-a3bc-48bf-a602-714ae2e55215
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe8aaf46-08a5-46a0-a0f4-04768e2dce76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1672bf7c-db84-41dd-926f-5bf50b292f79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06642e02-3a53-4252-908f-cbdfee9d9a58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ac85ae0-f167-43e0-a8ad-a5bf30431780
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3840382-ccc2-4886-9164-d0e8af5a34aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9054091c-df8e-40d2-804e-0bf46c56fd8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c03eab1-9fd7-4046-b8d5-a8ce51cea30d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b1527bb-e563-40b4-8d3f-0e323fccde34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45c4d474-b7d0-45e4-a899-51456bdbb513
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b43a500-b3e0-4f83-92d9-bf53aa1f5abc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 617c99e1-c193-40f5-856c-1517a2dca3e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9518198-9786-4a83-80d8-5dad573096db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4a82643-9fbc-4e50-a661-1389a37c40c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35d33c1c-65a4-4ab3-81b3-e09764eef060
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message acc239f2-7841-4092-9c16-130e81c53c69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 364c7e67-23b9-48e6-bd19-80ea0b095805
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6dbe3e7b-5311-4cf1-a29f-cccdc2172c3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46122d95-a4ba-45e9-b08b-9305cd493381
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c813e237-e11d-4d43-b778-66273c37c06e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87c07ec4-c121-4009-89d2-4d25168ffd16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b23dd57f-65af-493e-93f8-3ccfa131a3b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3194666b-dd00-42b5-860f-6208010e0960
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1490e74-4fb7-47df-95d1-b2c1d46647ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4fd3f71b-a081-4dd3-88e7-4e4fc94e2fba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 992b016c-f0f1-4a92-9c2c-17ff9959eab2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0e072b3-2af9-4e94-bcbb-3c54bfa16e09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5364956a-55b4-421b-b1cd-affd752b1bab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0906a47-c5b9-4f3e-934e-0f56ef48a515
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 927e92ea-1bd7-4b95-a6eb-44f2ba08f0aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2181ece2-d794-41f4-b3e1-ae99529b8269
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86ba90b9-3188-4c4c-a318-1e13935a106f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d7548e5-377a-41ca-bfb5-85c6ab236d6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb589656-84d2-4061-8fb6-365093f6e79d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9bc00c1a-5bf0-41b6-b43e-828a9a2401be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cedbb534-ba03-4ab7-bbdf-a3797ca7635b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2bc94544-7f21-4bf0-9bdc-1952fcf3edb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e7bbb5b-0fd9-424e-bdd6-525614c64c35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5174da22-aebf-456a-b8ab-a49af41181d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28b6b67d-767b-43f8-ba43-bfe54014e2fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1081675-72e4-4ece-a4b0-b8e7a22c1834
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7cc4f696-cc31-4161-8443-f9aab27f52c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 891a1bd2-fa34-43b0-847a-327e569ea47d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ee426d8-b357-4e62-adfa-bc88f5dab2b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e2dd4ab-3d5c-4f65-9909-4aa58e7a9968
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae0c8a25-8538-4fdd-b281-c3a0b53b1df4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d57f78ef-6efc-4551-af4d-deab85dd2d53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9695076-1793-4192-a908-b7341ea4d97e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76dbb5d6-acda-44d0-88c0-ae76bb013c10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34e2f1f0-18ee-4592-be88-93aec14942df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message afb8564b-0e0c-4481-b636-70a64abc5f25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e2ab202-6eb0-457c-8e76-90250a99a6ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f889a2e-d4d0-45c1-b5af-f463ef42d635
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af1f70ae-13ae-4ea9-b40e-f06aa942a1dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60767501-057f-4316-b35c-e22832214613
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e50f3066-c5a6-41ef-8680-4ad9026beab9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3539c12a-e02b-4762-a8a3-ad20c5e06f0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8195785-262d-4845-bb06-a1a8c736595c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4dd44cb5-8506-42a1-b8b2-433b2805fe7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e6df731-798b-48ce-b8a2-6292f7c313f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message caaf13d7-a245-4a09-8532-58e6a1b9153b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f76945d3-c41d-431e-aad7-da5254aed706
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05fba81e-92a7-48bb-ac63-34aa563e0a79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 447f20f6-fda8-4fd1-90f2-57a49e1329a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37a06e6d-71a1-4ebb-a1ad-21606c45eba6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd85e7e0-7eca-4680-bf45-1a6c00b8fea1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02c43347-4102-4afa-bdb9-bd256922c4fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ade20f55-87ec-4ea3-91e5-4c397c470cf2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd9f9d57-594b-4357-9f40-f75ebb7005d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1545802-2694-4fde-8af5-90d5c0b1452f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f986afe-8a3b-4fd5-866d-4abb3017066b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 345bed51-727d-4736-af79-95f241094878
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6628b7fa-23eb-4703-9594-8bd3b12f2533
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78074e32-11d3-43d8-86dc-ea579b3d9309
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ef0123c-9674-4cb6-8250-54c4296f65ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 191e00af-8896-4310-87f3-1fa17f911fc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3bacbdf-3e5f-479b-8648-048c158bf8e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d14db849-b057-4dc1-b745-c7f96cc70928
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d578dd1-9b68-4d6c-8cf2-e7851f0dd365
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8a9e582-7629-45ec-ad40-5d5f1d96e87d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd4e021a-3a9f-4531-8a89-75766fdaf030
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 888503ee-d4c8-4b98-b434-1b6b87e043d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb683247-9baa-4889-86ec-20908af8db15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27061dc5-f5cc-464b-9c77-aee4f0d8fc83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ebb047b-afbc-4964-b125-aea9ae490969
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a97c456a-9d03-4dfd-9c4b-5f63d67f73d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58aa1b05-2407-4ac8-ba8c-b49b1d1de50f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98e9f0e9-2723-413e-93cf-080dc361f26e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d52e439-9acf-4319-9645-bfbfdde3140b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23cbd877-2a88-44dc-962b-630d33d106ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2959f00d-adb8-4b95-8546-dc5296b98bd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f51c5435-bd0f-4c9b-a2ed-00b67e50bde2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76a6b41d-9b84-40fe-b3f8-74b3ae0f4d38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a52f4779-5101-4e68-9f57-e52b6988fa8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10761138-7ce4-4bec-9ed8-85ca5c05921e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d53764d-2197-46be-9e16-2368fcb55f72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07923935-3209-4040-95bc-29ab5bddb142
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c3998b0-e3f0-49a6-90ec-9ca024c956b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43d809bf-2a4c-4646-88e5-477448de43f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef66eb08-35ae-4c07-a5e0-e50d17c7a89b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b60b399d-4663-4390-83d6-2aecd55dcef9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ade14e7-71be-4db5-ac35-b0a43933970f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 132201ba-73fc-44ad-9fd1-75f44fd833b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c035d46-60a6-4824-a18b-6ca71ff27a56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f55e2874-95c4-4c34-b232-af186f5fabab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23fb2f27-5155-4947-99bb-041fa0dda06d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9fe93704-efd1-417d-bb73-5c4773e2cea6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7407d68-d19e-45f7-9b02-73727ed61df8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ffb1e3d2-3311-405f-bd42-865d94ea4ec7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e77b570-ee8a-4ae3-a560-da7b8cb5f1d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef4684c6-1e7f-4440-a78e-f82395559e12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d292c477-8174-465d-b21c-84e3c1ac6bcb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 412008a7-c24f-47ec-8245-4ae38eb064bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16414880-5994-458b-8dc4-19dbe849c818
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 014bfffa-c7f4-4192-81e7-fba3f373c3f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 535aa27f-faff-48b1-92ff-ab020cff00bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09ff54ef-355c-402d-b7eb-48c7197e5400
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91d3665e-d935-440b-a407-053d8da8db8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2822b962-7233-47ab-b601-f27b71638592
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9e07777-ae6d-4bae-86ec-4198efa89ac1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e2d32c8-cc8a-4f8a-b207-14c1c103e688
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a07f3b0-1bb8-459d-886a-0f38b71d42cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61b8b3fd-203a-47e8-8223-44a41b4fc043
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce6d1644-11ce-4045-8d31-1986a4deec35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 583c2b0c-81a4-4012-95fe-c9a4e73e1ffe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a474e853-08e7-4712-b26b-5c523f8fe0b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 301385a4-06db-461c-b111-380e57f66004
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d531bed1-3b8b-4a0c-b3a9-03e4ae7c7f1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a87703f8-6f4c-4a95-8bd4-6b8a7cbcda12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75417a5d-75ac-4397-8365-0fc9d83d9266
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2e00a0b-fb69-40f8-9f11-4713caa5b3cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 603f5ccb-d544-4828-bb32-acbab57eea49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b553ef3-c703-4feb-a23e-17b27859bdc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c749523-d078-4cba-acb4-2653699ee22d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4d76121-d41d-4c1e-8a33-b84e66526e10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d56ffc9-9bbc-4acf-a457-46a02b938695
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f552251-2e2c-463c-8d2c-1da3a3cbbaa9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8fc8f7a-bbfa-4232-a902-7bf784bf9804
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85b3e192-1cfa-4e2b-b167-1b3759d43f49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 247be92a-4efe-4e38-afc9-326978d84287
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 926721de-32a0-4726-a458-8490c7275e91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a15941e2-e176-4b26-921b-7b1763fc81a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de102798-8d8b-494a-a595-e47bc4391be7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ebf61b70-6952-41a5-985f-9e7338751757
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97e1c9dc-8795-416e-b00d-734ea1e189db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f8cd861-baab-41f0-8d28-3fd89d4c0ac5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5af3d7aa-79e9-469a-a451-cc41760199ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36f66a61-daf3-46d7-bb10-7d3a7fe1c8a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa908050-248e-4331-b9a2-dd8958ff8884
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6af2c0fe-f57b-4a89-af9b-ada31a3b6829
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08442a54-09d9-4e36-b135-3b47ae7accc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96860890-8ff9-4daa-a65f-5b49231f0c50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99338700-df91-456c-b812-5fb5ec0ba52d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b74a0aa0-3642-4132-b243-29fa1c4ecdee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7084a37f-cf72-4507-b9f0-30cebec419d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bede33fc-f60a-4f61-9cf7-cd0e7ceb72ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a394ff50-cfbe-4466-8dde-896723d0ff11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30c84af6-50af-4356-80a4-0443bfa6eae8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f749ce72-7b73-4285-b2ae-5d453fb80f80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50fdad76-548d-42f4-b32e-e1d71d5a1bb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc6293f1-8081-411b-bf35-c769f85104dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf9e32b3-0133-41a0-8f91-b4886cde81a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38268062-bb26-4c84-8fcf-f373c7433f4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71e560f7-675b-4f3c-b5d9-8e0f63fcbd19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c76cc4d3-f1fd-4228-861a-5d58da2e01e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca080149-8315-4191-9af7-8122a89214df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15b697ef-f546-4760-bec3-98b1af0c5ea2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d85be8c0-ef06-4efd-a2e0-2feb0b789146
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f92d7ab-107e-4981-977f-85dfbedbf1f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc064de0-b2bf-42ce-81ed-1636337ff49d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e08acaf9-52d4-4d79-8951-18496faa2f9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d35a9b93-d95f-476b-8a0e-3012631a3c26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 657f2903-0aaf-4555-aa82-4bd6c31057e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5aaaddb0-0964-4ddf-bbe1-ca99c7c82dcd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5855c3e-e1ba-428e-945d-a0d345b78a83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27b42b01-ad7e-4503-96c5-7cdb0eeb72f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ddfc9dc4-65f6-403e-816d-456d88835fdf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5c7e2ac-cb3a-4971-bd43-1f70ea17742c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 822ce7e4-b33b-452d-8620-0a5daaa10e36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b6ed355-02e3-463b-b036-0d3a7caf1580
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b43b6f29-9092-422c-8ba2-9d9b53d7e041
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef2af75d-b0b9-4aa6-9b06-dd2b95899826
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0aad554-585d-491f-8571-703549daec9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a44bca5e-e83a-49bb-99dd-3953d370c5b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e99bd01-12c6-4126-bc7c-8d0bf218e133
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb2598e4-cf06-481c-93e9-1c38768f54fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef8630a2-5cc1-4d39-a8d7-c24034fc3932
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3866e612-967a-4818-8bf4-0714cabfb170
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7cb5f8a9-ac5c-4514-8b35-422db9a66d90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c069e99-aab5-40af-bca7-1ef9a9fa974a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20dfdd27-ef28-4814-a408-9dd88ae22401
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33badfca-d111-405b-9bc3-7011b7ed9170
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b14526ae-fa21-4b46-a8d6-2fcc3cbf3c76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 775ccda5-aa5d-4404-9bcc-7d831a28108d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f98af356-4d08-4309-a59f-0d1b3ed978bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b0c3932-8305-4ac2-9fdd-5f41ea60acd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a08d0829-fbae-4134-9e0c-e1225e9057b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c1ccb26-92d6-461c-a626-c6697f754fa6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 234fbbe0-ad01-40ba-a1c6-3b2f7182f128
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 989f52ab-babf-43e5-9eb7-63f629e2cb75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c0bf9be-c5c1-49a0-9b82-fbd224fa47be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d14fe95a-e3c0-458e-bf2f-0899f9b889e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c2763d2-dad1-448f-969e-4a93583a05c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7066682f-2842-42ba-8e73-824ba23285cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf00a5a3-c8b0-43bb-a753-94214c6f0adb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 973c894a-4e4b-4f17-9b1b-e6bddf5dd8c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9de100f2-1e21-4edf-be21-d02ccdd00705
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f9e0bc1-c0f5-4ac8-a069-c5c17d680f35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 857de431-8d0d-4b65-88a1-8091ba975aa8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2b4d7a8-f6b3-4670-adce-a2368dcea78a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a2ab498-57ae-494b-8919-7a802a52b2e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message abd82dc9-28bd-4087-a941-eadc938a3df4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message daadcb98-ba29-4aea-b245-71ccc0d1e112
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c8c83df-cac3-4622-b70b-04ef3a36b1e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3eb3e30f-e9e2-4c42-afc9-789c288fdc4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e4ad259-b592-4324-8f29-1afd04a734b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21c98326-6ce2-4ba4-87e8-f7ffa183c6d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c0f57c1-ac7f-472f-8110-093c8d0bc774
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e27815e1-5205-4b7f-9775-4a72b476c423
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 359c3c0e-e99a-4602-8f33-324f45438bc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8637c37-2294-4d9c-8a9c-995db13f8b09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 694d7146-1ba7-4a9d-bcc4-c4583574274b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ead17d67-3dc6-46ca-99eb-9e82fae9f3e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d49c73f3-74e9-42ab-8b67-f7b7a6e90759
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24996126-5d5e-4b81-af51-0cb703128728
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e43eef10-c0d4-453e-867a-a9a7e02cf62d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3a90eca-cadb-4b18-b342-86d804957999
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3bc3d27-55b7-4ae8-babe-9e7a5ba48929
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3a9b7c1-3d61-4620-bf2b-db36334f7f1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0351470-4017-4d81-913d-3d8dc49814f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7744330-06f8-47ab-9b2c-d375e18145bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6fb1f865-eb7d-406a-bbe5-8f7009a2df00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d511f7bb-9a80-4c7f-9e31-1c8f8fcb5f88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ebb5278-3c97-494b-a12d-2be52e671979
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41621cec-0ece-4999-9833-035c30018909
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02e31fe0-c6f1-4975-b109-4c1cf3707fc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 413a7535-0406-41ff-8787-0b18afb50c55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b01fe74-b991-4a91-9084-a8e0a8d1d9b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3983e2e0-065f-4d3b-8fa3-c67ff6468b2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7119aba-8aa7-4808-b8f3-fc8a2d489a1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff9a2d53-de29-4763-9bad-8f4f03bf04d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c3314f9-6815-4df0-950b-95ee13acb33a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3eab916f-7fd8-4de7-aed2-23fedd64a69e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38d33fa3-700b-40d0-93e5-3835b43a3bd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3450988a-e91c-4a01-aa0b-455edb508414
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4378ef30-cd71-4dfd-9778-a8bf3bee2d60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 630a57be-f40b-4c9d-b1e6-8ba7bfca2055
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f54f92b-d116-4966-9f1e-eeca7e4920a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 533b9af2-610b-4d02-af3c-cc2aee9e036c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3e59e1a-c069-4dc8-a452-bce3f50d36da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a413a9cf-a6d6-43f8-98d7-82355f909282
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30332811-bdbe-490d-b331-883e7eebe595
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b73e39ad-63b4-4ad0-b0c9-14c98c39a5f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 670da2f3-edf8-449c-8b75-f784c47802dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e15a2c8-e9a6-4510-a8f2-2ca84459753c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36ee8ceb-e3c4-46f0-8131-4c0a27de6ca4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03a4ee74-1916-4058-bbf9-a79393d69e3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb8577c6-6058-4f79-a458-99e3606a5197
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61fe9110-692b-44b8-bdfb-b1f0537c335b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72079b65-cf48-4a76-82a9-26c7c77d41b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d4e5fe3-7af8-43cb-a0a4-248d0691ee06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6522cbe8-6d46-426f-acd3-7a26eacb67e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8fb4d6ff-744a-46f6-bb96-f7a089db4dd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0fde4ccc-b293-48db-aa01-8698398ee59e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44c287fa-64b4-4c3f-869d-cb53273bb241
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7bd985da-dc5d-4f3a-b183-5a68abbd3c24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 391ba51d-c85d-4a33-a601-50644db6f51a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3ac145e-a220-4568-bd61-e328bb03d960
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02673bb1-a801-4642-b35a-b01732086450
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6560bc62-c700-41de-908d-bac7a2392aca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55232d89-dd75-4d6f-b08a-639c02f939df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21f8664a-0c79-4dee-b0b4-40c2bcb879b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a94dbb16-6d9d-4c1d-b1b2-3ed60d5ffdc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17542dfa-bebf-485e-b20a-4508c804803f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 688b5515-5ea3-4879-87fc-26839b0fdd67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e488a3fc-1de2-422c-8507-6b3a754b5d65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4afaee5b-81ce-4272-8d2d-8a1ec857479d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b64ef6db-4de5-4dee-8571-93eff55d2c45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c954db06-3687-4967-a3bf-27ddef8753b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8f04249-aa1c-4f64-8351-52d4efdb5fb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8de7246b-e672-4e6e-a426-09cce91ea34a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed13fa2c-fc8a-428d-99c4-5239729626e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 912b1426-2f28-4682-b838-305cbb393480
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6fb1183b-9d19-4fa2-835f-2a86c76e4edb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 040b6f64-e8ca-4d78-b39a-3db07ab1883f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3bdf70e6-b5bc-477e-9f22-fbe27c0c8531
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f64d3dc-1d46-4e10-9296-466c4c159bb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3127863a-b3bd-4269-a7cc-e100b63a628b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16b9469c-6689-4add-8117-a1b3f9bd2af4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0e8cd51-f119-4c22-85b5-e1256c990e54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eac550bf-b157-4475-9261-df45fd36baf6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78943208-a632-4404-a183-6fbb894dfb8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6c12604-9634-4a8b-ac7c-b2fb681c789a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3db4605-9fb8-4c6c-879e-b7baf249e42c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 716bb29e-b022-4d12-8e2f-b772e58e7100
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ace04d57-ff03-4aa3-9c5f-37823fb6f8f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89716d3e-e451-4133-874f-3611f6d5307d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd8e2861-b88f-47bd-8e5e-db331f56fa31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 980f097e-d1d9-4939-8fac-1221217e9064
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cadbf920-ea12-4cd3-a9d9-da850b23e72a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9953a204-19c2-40df-a631-d7de54a00533
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ac7c0c1-2f58-4b4b-83fe-252ef9e82ee2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1113f25-99fd-488b-9410-8da9e2f1182a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b738fe0c-f489-4dfc-93e0-2ea51a323f3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5c62e9d-aa38-416e-bd2b-0d5c88284049
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0b734d9-e516-4e78-9fd3-530a90b7cc31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b435b853-c454-4f3e-a3a9-18aae5e90505
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b2eff12-c72c-463d-820e-091f4efd556f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f1524a4-7c58-4122-8719-bd8ca4733752
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3efca305-1099-4807-9bca-45b4fd18d1d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c39422ae-aa84-4cdb-bd25-3d1772a5a5b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef564c87-9f05-4e5b-9ad3-536c25938da2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26700adc-f7fd-4695-9c64-b4802fe13f56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62041518-5c33-4e7b-9c08-bd56ae3496ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de546206-eb2d-411d-b28b-6989ba6a50d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa45cda8-02db-4ae3-a267-a31bd82287a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0144077-f271-4f30-8482-9205a6ca50ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e39da728-777b-4ea4-9e77-6963589bae22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb95a201-814b-482a-ba52-50a8ac69ecc1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62a72cb9-0d9b-449a-92fa-6f22b628fe58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bedb1224-eb07-4f77-8984-39b418df8c24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6136b287-b1f7-497f-828a-bdb105fa1951
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a31e2245-d689-42ae-ad4b-a53510faf93a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d60a96a3-a3ff-47bd-a34a-c65613a13472
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 315ac397-16b0-4c35-81e1-02c8d0921fef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd1a643c-652b-40bf-bd06-d3d5c8951d0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6e87de9-4560-46bb-88e9-d83f77e51a7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aef46084-97fc-4e82-9def-a611fdb3dd1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95d951bc-4311-41ff-9b64-174275212685
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56aa1242-dc52-46bc-8613-e1240be32c87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc4796ff-cdcd-4004-a7ff-e157a09f145b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 234215cc-3b3b-4087-a05e-edcefaf65f92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a07bd9f0-c28a-42d3-a39c-bdad4c2c6382
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5451aa40-6771-4614-a21f-ab16709992c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa008a08-02b9-4e6b-a787-7b76a1d71cb2
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8692 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_2
Server: localhost:8692
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_2
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_2/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_2/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_2/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_2/test_labels.txt

📊 Raw data loaded:
   Train: X=(5055, 24), y=(5055,)
   Test:  X=(1264, 24), y=(1264,)

⚠️  Limiting training data: 5055 → 800 samples
⚠️  Limiting test data: 1264 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_2 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 2 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.3344, val=0.1394 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0998, val=0.0847 (↓), lr=0.001000
   ✓ Epoch   3/100: train=0.0844, val=0.0763 (↓), lr=0.001000
   • Epoch   4/100: train=0.0796, val=0.0770, patience=1/15, lr=0.001000
   • Epoch   5/100: train=0.0804, val=0.0765, patience=2/15, lr=0.001000
   • Epoch  11/100: train=0.0796, val=0.0757, patience=1/15, lr=0.001000
   • Epoch  21/100: train=0.0780, val=0.0750, patience=7/15, lr=0.001000
   📉 Epoch 25: LR reduced 0.001000 → 0.000500
   • Epoch  31/100: train=0.0763, val=0.0748, patience=5/15, lr=0.000500
   📉 Epoch 33: LR reduced 0.000500 → 0.000250
   📉 Epoch 41: LR reduced 0.000250 → 0.000125
   • Epoch  41/100: train=0.0753, val=0.0751, patience=15/15, lr=0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 2 Summary - Client client_2
   Epochs: 41/100 (early stopped)
   LR: 0.001000 → 0.000125 (3 reductions)
   Train: Loss=0.0764, RMSE=0.2765, R²=0.0520
   Val:   Loss=0.0743, RMSE=0.2726, R²=0.0355
============================================================


============================================================
🔄 Round 3 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.4262, val=0.4111 (↓), lr=0.000125
   ✓ Epoch   2/100: train=0.3527, val=0.3467 (↓), lr=0.000125
   ✓ Epoch   3/100: train=0.2910, val=0.2758 (↓), lr=0.000125
   ✓ Epoch   4/100: train=0.2102, val=0.1716 (↓), lr=0.000125
   ✓ Epoch   5/100: train=0.1149, val=0.0873 (↓), lr=0.000125
   📉 Epoch 8: LR reduced 0.000125 → 0.000063
   • Epoch  11/100: train=0.0801, val=0.0804, patience=5/15, lr=0.000063
   📉 Epoch 16: LR reduced 0.000063 → 0.000031
   • Epoch  21/100: train=0.0799, val=0.0802, patience=15/15, lr=0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 3 Summary - Client client_2
   Epochs: 21/100 (early stopped)
   LR: 0.000125 → 0.000031 (2 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=-0.0087
   Val:   Loss=0.0798, RMSE=0.2824, R²=-0.0019
============================================================


============================================================
🔄 Round 4 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.4571, val=0.4145 (↓), lr=0.000031
   ✓ Epoch   2/100: train=0.4334, val=0.3923 (↓), lr=0.000031
   📉 Epoch 3: LR reduced 0.000031 → 0.000016
   ✓ Epoch   3/100: train=0.4131, val=0.3746 (↓), lr=0.000016
   ✓ Epoch   4/100: train=0.4001, val=0.3669 (↓), lr=0.000016
   ✓ Epoch   5/100: train=0.3926, val=0.3598 (↓), lr=0.000016
   📉 Epoch 11: LR reduced 0.000016 → 0.000008
   ✓ Epoch  11/100: train=0.3536, val=0.3220 (↓), lr=0.000008
   📉 Epoch 19: LR reduced 0.000008 → 0.000004
   ✓ Epoch  21/100: train=0.3237, val=0.2953 (↓), lr=0.000004
   📉 Epoch 27: LR reduced 0.000004 → 0.000002
   ✓ Epoch  31/100: train=0.3117, val=0.2840 (↓), lr=0.000002
   📉 Epoch 35: LR reduced 0.000002 → 0.000001
   ✓ Epoch  41/100: train=0.3065, val=0.2791 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.3029, val=0.2757 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.2995, val=0.2724 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.2961, val=0.2690 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.2926, val=0.2656 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.2891, val=0.2622 (↓), lr=0.000001

============================================================
📊 Round 4 Summary - Client client_2
   Epochs: 100/100
   LR: 0.000031 → 0.000001 (5 reductions)
   Train: Loss=0.2869, RMSE=0.5356, R²=-2.4334
   Val:   Loss=0.2592, RMSE=0.5091, R²=-2.9686
============================================================


📊 Round 4 Test Metrics:
   Loss: 0.5043, RMSE: 0.7102, MAE: 0.6483, R²: -5.0058

============================================================
🔄 Round 5 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.4518, val=0.4782 (↓), lr=0.000001
   ✓ Epoch   2/100: train=0.4510, val=0.4774 (↓), lr=0.000001
   ✓ Epoch   3/100: train=0.4503, val=0.4767 (↓), lr=0.000001
   ✓ Epoch   4/100: train=0.4497, val=0.4761 (↓), lr=0.000001
   ✓ Epoch   5/100: train=0.4491, val=0.4755 (↓), lr=0.000001
   • Epoch  11/100: train=0.4461, val=0.4724, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.4421, val=0.4683, patience=1/15, lr=0.000001
   • Epoch  31/100: train=0.4386, val=0.4647, patience=1/15, lr=0.000001
   • Epoch  41/100: train=0.4354, val=0.4614, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.4324, val=0.4582, patience=1/15, lr=0.000001
   • Epoch  61/100: train=0.4295, val=0.4552, patience=1/15, lr=0.000001
   • Epoch  71/100: train=0.4267, val=0.4523, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.4239, val=0.4494, patience=1/15, lr=0.000001
   • Epoch  91/100: train=0.4212, val=0.4466, patience=1/15, lr=0.000001

============================================================
📊 Round 5 Summary - Client client_2
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.4186, RMSE=0.6470, R²=-4.2058
   Val:   Loss=0.4441, RMSE=0.6664, R²=-4.7260
============================================================


📊 Round 5 Test Metrics:
   Loss: 0.4973, RMSE: 0.7052, MAE: 0.6429, R²: -4.9223

📊 Round 5 Test Metrics:
   Loss: 0.4847, RMSE: 0.6962, MAE: 0.6330, R²: -4.7713

============================================================
🔄 Round 8 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.4336, val=0.4638 (↓), lr=0.000001
   • Epoch   2/100: train=0.4333, val=0.4634, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.4329, val=0.4631 (↓), lr=0.000001
   • Epoch   4/100: train=0.4325, val=0.4627, patience=1/15, lr=0.000001
   ✓ Epoch   5/100: train=0.4322, val=0.4623 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.4300, val=0.4601 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.4266, val=0.4565 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.4233, val=0.4530 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.4200, val=0.4496 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.4168, val=0.4462 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.4136, val=0.4428 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.4104, val=0.4395 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.4072, val=0.4361 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.4040, val=0.4327 (↓), lr=0.000001

============================================================
📊 Round 8 Summary - Client client_2
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.3997, RMSE=0.6322, R²=-3.9312
   Val:   Loss=0.4297, RMSE=0.6555, R²=-4.7580
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.4758, RMSE: 0.6898, MAE: 0.6259, R²: -4.6655

📊 Round 8 Test Metrics:
   Loss: 0.4668, RMSE: 0.6832, MAE: 0.6187, R²: -4.5582

📊 Round 8 Test Metrics:
   Loss: 0.4560, RMSE: 0.6752, MAE: 0.6099, R²: -4.4296

============================================================
🔄 Round 11 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.4161, val=0.3961 (↓), lr=0.000001
   • Epoch   2/100: train=0.4157, val=0.3957, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.4154, val=0.3953 (↓), lr=0.000001
   • Epoch   4/100: train=0.4150, val=0.3949, patience=1/15, lr=0.000001
   ✓ Epoch   5/100: train=0.4146, val=0.3946 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.4123, val=0.3923 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.4085, val=0.3886 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.4048, val=0.3850 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.4011, val=0.3813 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.3973, val=0.3777 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.3936, val=0.3740 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.3899, val=0.3703 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.3861, val=0.3667 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.3823, val=0.3629 (↓), lr=0.000001

============================================================
📊 Round 11 Summary - Client client_2
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.3782, RMSE=0.6149, R²=-3.6573
   Val:   Loss=0.3596, RMSE=0.5996, R²=-3.8118
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.4108, RMSE: 0.6409, MAE: 0.5717, R²: -3.8920

============================================================
🔄 Round 16 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.3128, val=0.3389 (↓), lr=0.000001
   ✓ Epoch   2/100: train=0.3122, val=0.3383 (↓), lr=0.000001
   ✓ Epoch   3/100: train=0.3117, val=0.3377 (↓), lr=0.000001
   ✓ Epoch   4/100: train=0.3111, val=0.3371 (↓), lr=0.000001
   ✓ Epoch   5/100: train=0.3105, val=0.3365 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.3072, val=0.3331 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.3019, val=0.3277 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.2968, val=0.3224 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.2918, val=0.3173 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.2869, val=0.3122 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.2820, val=0.3071 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.2771, val=0.3020 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.2722, val=0.2969 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.2671, val=0.2917 (↓), lr=0.000001

============================================================
📊 Round 16 Summary - Client client_2
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.2621, RMSE=0.5120, R²=-2.3818
   Val:   Loss=0.2869, RMSE=0.5357, R²=-2.2092
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.2782, RMSE: 0.5274, MAE: 0.4448, R²: -2.3128

📊 Round 16 Test Metrics:
   Loss: 0.2051, RMSE: 0.4529, MAE: 0.3726, R²: -1.4426

============================================================
🔄 Round 22 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1568, val=0.1333 (↓), lr=0.000001
   ✓ Epoch   2/100: train=0.1558, val=0.1324 (↓), lr=0.000001
   ✓ Epoch   3/100: train=0.1548, val=0.1316 (↓), lr=0.000001
   ✓ Epoch   4/100: train=0.1539, val=0.1308 (↓), lr=0.000001
   ✓ Epoch   5/100: train=0.1530, val=0.1300 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.1480, val=0.1256 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.1405, val=0.1192 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.1339, val=0.1136 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.1280, val=0.1085 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.1225, val=0.1039 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.1175, val=0.0997 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.1129, val=0.0960 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.1087, val=0.0926 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.1049, val=0.0896 (↓), lr=0.000001

============================================================
📊 Round 22 Summary - Client client_2
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1019, RMSE=0.3192, R²=-0.2577
   Val:   Loss=0.0871, RMSE=0.2952, R²=-0.1662
============================================================


============================================================
🔄 Round 24 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1037, val=0.0962 (↓), lr=0.000001
   • Epoch   2/100: train=0.1034, val=0.0960, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.1030, val=0.0957 (↓), lr=0.000001
   • Epoch   4/100: train=0.1026, val=0.0954, patience=1/15, lr=0.000001
   ✓ Epoch   5/100: train=0.1023, val=0.0951 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.1003, val=0.0935 (↓), lr=0.000001
   • Epoch  21/100: train=0.0971, val=0.0912, patience=2/15, lr=0.000001
   ✓ Epoch  31/100: train=0.0944, val=0.0891 (↓), lr=0.000001
   • Epoch  41/100: train=0.0919, val=0.0873, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.0897, val=0.0858, patience=3/15, lr=0.000001
   ✓ Epoch  61/100: train=0.0878, val=0.0845 (↓), lr=0.000001
   • Epoch  71/100: train=0.0862, val=0.0835, patience=5/15, lr=0.000001
   • Epoch  81/100: train=0.0848, val=0.0827, patience=2/15, lr=0.000001
   • Epoch  91/100: train=0.0837, val=0.0821, patience=4/15, lr=0.000001

============================================================
📊 Round 24 Summary - Client client_2
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0438
   Val:   Loss=0.0817, RMSE=0.2859, R²=-0.0103
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0962, RMSE: 0.3101, MAE: 0.2633, R²: -0.1451

📊 Round 24 Test Metrics:
   Loss: 0.0859, RMSE: 0.2930, MAE: 0.2534, R²: -0.0225

============================================================
🔄 Round 26 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 26 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=-0.0038
   Val:   Loss=0.0872, RMSE=0.2952, R²=-0.0323
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0851, RMSE: 0.2917, MAE: 0.2526, R²: -0.0135

📊 Round 26 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2523, R²: -0.0096

📊 Round 26 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2518, R²: -0.0040

📊 Round 26 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2515, R²: -0.0018

📊 Round 26 Test Metrics:
   Loss: 0.0841, RMSE: 0.2899, MAE: 0.2515, R²: -0.0010

============================================================
🔄 Round 34 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 34 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=-0.0070
   Val:   Loss=0.0845, RMSE=0.2906, R²=-0.0076
============================================================


============================================================
🔄 Round 37 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 37 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=-0.0099
   Val:   Loss=0.0866, RMSE=0.2942, R²=-0.0055
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2513, R²: 0.0004

📊 Round 37 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2513, R²: 0.0006

============================================================
🔄 Round 41 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 41 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0119
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0151
============================================================


============================================================
🔄 Round 42 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 42 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0086
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0077
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2513, R²: 0.0008

============================================================
🔄 Round 43 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 43 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0047
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0408
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2513, R²: 0.0013

============================================================
🔄 Round 44 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0709 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0709, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0709, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0708, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0708, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0708, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0709)

============================================================
📊 Round 44 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0085
   Val:   Loss=0.0709, RMSE=0.2663, R²=-0.0088
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0838, RMSE: 0.2896, MAE: 0.2512, R²: 0.0016

============================================================
🔄 Round 45 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 45 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0046
   Val:   Loss=0.0791, RMSE=0.2812, R²=-0.0311
============================================================


📊 Round 45 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2512, R²: 0.0017

============================================================
🔄 Round 46 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 46 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0088
   Val:   Loss=0.0756, RMSE=0.2750, R²=-0.0239
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2512, R²: 0.0017

📊 Round 46 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2512, R²: 0.0018

============================================================
🔄 Round 48 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 48 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0081
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0133
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2512, R²: 0.0022

============================================================
🔄 Round 51 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 51 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0114
   Val:   Loss=0.0751, RMSE=0.2741, R²=-0.0076
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0838, RMSE: 0.2894, MAE: 0.2511, R²: 0.0024

============================================================
🔄 Round 52 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 52 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0092
   Val:   Loss=0.0748, RMSE=0.2736, R²=-0.0144
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0838, RMSE: 0.2894, MAE: 0.2511, R²: 0.0024

📊 Round 52 Test Metrics:
   Loss: 0.0837, RMSE: 0.2894, MAE: 0.2511, R²: 0.0027

============================================================
🔄 Round 59 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 59 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0157
   Val:   Loss=0.0791, RMSE=0.2813, R²=-0.0014
============================================================


============================================================
🔄 Round 60 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 60 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0187
   Val:   Loss=0.0738, RMSE=0.2717, R²=-0.0138
============================================================


============================================================
🔄 Round 62 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 62 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=-0.0149
   Val:   Loss=0.0877, RMSE=0.2961, R²=-0.0042
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2510, R²: 0.0033

📊 Round 62 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2510, R²: 0.0034

📊 Round 62 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2510, R²: 0.0034

📊 Round 62 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2510, R²: 0.0034

============================================================
🔄 Round 72 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 72 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=-0.0132
   Val:   Loss=0.0898, RMSE=0.2996, R²=-0.0130
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2510, R²: 0.0034

📊 Round 72 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2510, R²: 0.0034

📊 Round 72 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2510, R²: 0.0034

============================================================
🔄 Round 77 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0754, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0817, val=0.0751, patience=8/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 77 Summary - Client client_2
   Epochs: 28/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0085
   Val:   Loss=0.0754, RMSE=0.2746, R²=-0.0211
============================================================


============================================================
🔄 Round 78 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 78 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0178
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0107
============================================================


============================================================
🔄 Round 79 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 79 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=-0.0112
   Val:   Loss=0.0825, RMSE=0.2873, R²=-0.0186
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2510, R²: 0.0033

📊 Round 79 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2510, R²: 0.0033

📊 Round 79 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2510, R²: 0.0033

📊 Round 79 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2510, R²: 0.0033

📊 Round 79 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2510, R²: 0.0034

============================================================
🔄 Round 86 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 86 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0124
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0166
============================================================


============================================================
🔄 Round 87 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0743, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0818, val=0.0740, patience=7/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 87 Summary - Client client_2
   Epochs: 29/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0098
   Val:   Loss=0.0742, RMSE=0.2724, R²=-0.0029
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2510, R²: 0.0032

============================================================
🔄 Round 89 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0825, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0801, val=0.0822, patience=6/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 89 Summary - Client client_2
   Epochs: 30/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=-0.0070
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0137
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2510, R²: 0.0031

============================================================
🔄 Round 90 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0725, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 90 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0158
   Val:   Loss=0.0725, RMSE=0.2693, R²=-0.0056
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2510, R²: 0.0032

============================================================
🔄 Round 91 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 91 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0081
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0295
============================================================


============================================================
🔄 Round 94 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0717 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0717, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0716, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0716, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0716, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0714, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0717)

============================================================
📊 Round 94 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0123
   Val:   Loss=0.0717, RMSE=0.2677, R²=-0.0127
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2510, R²: 0.0032

============================================================
🔄 Round 95 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0723, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0721, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0720, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 95 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0133
   Val:   Loss=0.0723, RMSE=0.2689, R²=-0.0090
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2510, R²: 0.0032

============================================================
🔄 Round 98 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0749, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0820, val=0.0747, patience=6/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 98 Summary - Client client_2
   Epochs: 30/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0057
   Val:   Loss=0.0748, RMSE=0.2735, R²=-0.0188
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0837, RMSE: 0.2894, MAE: 0.2510, R²: 0.0030

============================================================
🔄 Round 99 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 99 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0112
   Val:   Loss=0.0789, RMSE=0.2809, R²=-0.0181
============================================================


============================================================
🔄 Round 100 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0799, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0806, val=0.0796, patience=7/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 100 Summary - Client client_2
   Epochs: 29/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0057
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0347
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0837, RMSE: 0.2894, MAE: 0.2511, R²: 0.0029

============================================================
🔄 Round 101 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 101 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=-0.0076
   Val:   Loss=0.0736, RMSE=0.2713, R²=-0.0316
============================================================


============================================================
🔄 Round 102 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0791, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0812, val=0.0788, patience=6/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 102 Summary - Client client_2
   Epochs: 30/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0048
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0225
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0838, RMSE: 0.2894, MAE: 0.2511, R²: 0.0027

============================================================
🔄 Round 104 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0827, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0796, val=0.0824, patience=5/15, lr=0.000001
   • Epoch  31/100: train=0.0795, val=0.0823, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 104 Summary - Client client_2
   Epochs: 31/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0064
   Val:   Loss=0.0825, RMSE=0.2873, R²=-0.0115
============================================================


============================================================
🔄 Round 107 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 107 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0141
   Val:   Loss=0.0785, RMSE=0.2803, R²=-0.0025
============================================================


============================================================
🔄 Round 109 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 109 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=-0.0115
   Val:   Loss=0.0876, RMSE=0.2959, R²=-0.0113
============================================================


============================================================
🔄 Round 110 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 110 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0120
   Val:   Loss=0.0825, RMSE=0.2873, R²=-0.0099
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0837, RMSE: 0.2894, MAE: 0.2511, R²: 0.0027

📊 Round 110 Test Metrics:
   Loss: 0.0837, RMSE: 0.2894, MAE: 0.2510, R²: 0.0029

============================================================
🔄 Round 114 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 114 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=-0.0113
   Val:   Loss=0.0862, RMSE=0.2935, R²=-0.0135
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0837, RMSE: 0.2894, MAE: 0.2510, R²: 0.0029

============================================================
🔄 Round 115 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 115 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0094
   Val:   Loss=0.0759, RMSE=0.2755, R²=-0.0221
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0837, RMSE: 0.2894, MAE: 0.2510, R²: 0.0029

📊 Round 115 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2510, R²: 0.0030

📊 Round 115 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2510, R²: 0.0030

============================================================
🔄 Round 120 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0830, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0801, val=0.0827, patience=8/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 120 Summary - Client client_2
   Epochs: 28/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0056
   Val:   Loss=0.0829, RMSE=0.2880, R²=-0.0300
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0837, RMSE: 0.2894, MAE: 0.2510, R²: 0.0030

============================================================
🔄 Round 122 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0849, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0796, val=0.0847, patience=5/15, lr=0.000001
   • Epoch  31/100: train=0.0795, val=0.0845, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 122 Summary - Client client_2
   Epochs: 31/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=-0.0096
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0029
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0837, RMSE: 0.2894, MAE: 0.2510, R²: 0.0030

📊 Round 122 Test Metrics:
   Loss: 0.0837, RMSE: 0.2894, MAE: 0.2510, R²: 0.0030

============================================================
🔄 Round 124 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 124 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=-0.0168
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0043
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2510, R²: 0.0031

============================================================
🔄 Round 127 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 127 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=-0.0150
   Val:   Loss=0.0879, RMSE=0.2964, R²=-0.0066
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2510, R²: 0.0031

============================================================
🔄 Round 128 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 128 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=-0.0101
   Val:   Loss=0.0896, RMSE=0.2993, R²=-0.0235
============================================================


============================================================
🔄 Round 129 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 129 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0143
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0102
============================================================


============================================================
🔄 Round 132 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0826, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0801, val=0.0823, patience=8/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 132 Summary - Client client_2
   Epochs: 28/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0084
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0180
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2510, R²: 0.0031

============================================================
🔄 Round 134 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 134 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=-0.0222
   Val:   Loss=0.0761, RMSE=0.2759, R²=-0.0018
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0837, RMSE: 0.2894, MAE: 0.2510, R²: 0.0030

============================================================
🔄 Round 137 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 137 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0123
   Val:   Loss=0.0774, RMSE=0.2783, R²=-0.0152
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0837, RMSE: 0.2894, MAE: 0.2510, R²: 0.0030

📊 Round 137 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2510, R²: 0.0030

============================================================
🔄 Round 139 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 139 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0143
   Val:   Loss=0.0785, RMSE=0.2802, R²=-0.0084
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2510, R²: 0.0030

📊 Round 139 Test Metrics:
   Loss: 0.0837, RMSE: 0.2894, MAE: 0.2510, R²: 0.0030

📊 Round 139 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2510, R²: 0.0030

============================================================
🔄 Round 143 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 143 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=-0.0145
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0079
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2510, R²: 0.0031

============================================================
🔄 Round 146 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 146 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=-0.0167
   Val:   Loss=0.0879, RMSE=0.2965, R²=-0.0049
============================================================


============================================================
🔄 Round 147 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 147 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0137
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0122
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2510, R²: 0.0030

📊 Round 147 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2510, R²: 0.0030

============================================================
🔄 Round 149 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0850, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0795, val=0.0847, patience=7/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 149 Summary - Client client_2
   Epochs: 29/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=-0.0068
   Val:   Loss=0.0849, RMSE=0.2913, R²=-0.0180
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0837, RMSE: 0.2894, MAE: 0.2510, R²: 0.0029

📊 Round 149 Test Metrics:
   Loss: 0.0837, RMSE: 0.2894, MAE: 0.2510, R²: 0.0029

📊 Round 149 Test Metrics:
   Loss: 0.0837, RMSE: 0.2894, MAE: 0.2510, R²: 0.0029

============================================================
🔄 Round 152 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 152 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=-0.0149
   Val:   Loss=0.0907, RMSE=0.3011, R²=-0.0069
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0837, RMSE: 0.2894, MAE: 0.2510, R²: 0.0029

📊 Round 152 Test Metrics:
   Loss: 0.0837, RMSE: 0.2894, MAE: 0.2510, R²: 0.0029

============================================================
🔄 Round 154 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 154 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0183
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0008
============================================================


============================================================
🔄 Round 155 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 155 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0166
   Val:   Loss=0.0784, RMSE=0.2800, R²=-0.0033
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0837, RMSE: 0.2894, MAE: 0.2510, R²: 0.0029

============================================================
🔄 Round 156 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0785, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0810, val=0.0783, patience=6/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 156 Summary - Client client_2
   Epochs: 30/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0094
   Val:   Loss=0.0784, RMSE=0.2800, R²=-0.0031
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0837, RMSE: 0.2894, MAE: 0.2510, R²: 0.0028

============================================================
🔄 Round 158 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0826, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0800, val=0.0823, patience=6/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 158 Summary - Client client_2
   Epochs: 30/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0060
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0165
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0838, RMSE: 0.2894, MAE: 0.2510, R²: 0.0027

============================================================
🔄 Round 160 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 160 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0119
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0122
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0837, RMSE: 0.2894, MAE: 0.2510, R²: 0.0028

============================================================
🔄 Round 162 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0864, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.0791, val=0.0860, patience=11/15, lr=0.000001
   • Epoch  31/100: train=0.0791, val=0.0857, patience=8/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 162 Summary - Client client_2
   Epochs: 38/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=-0.0049
   Val:   Loss=0.0859, RMSE=0.2932, R²=-0.0579
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0838, RMSE: 0.2894, MAE: 0.2510, R²: 0.0027

============================================================
🔄 Round 163 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0822, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0803, val=0.0819, patience=5/15, lr=0.000001
   • Epoch  31/100: train=0.0803, val=0.0818, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 163 Summary - Client client_2
   Epochs: 31/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0033
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0217
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0838, RMSE: 0.2894, MAE: 0.2511, R²: 0.0025

📊 Round 163 Test Metrics:
   Loss: 0.0838, RMSE: 0.2894, MAE: 0.2511, R²: 0.0025

📊 Round 163 Test Metrics:
   Loss: 0.0838, RMSE: 0.2894, MAE: 0.2510, R²: 0.0026

============================================================
🔄 Round 168 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 168 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0132
   Val:   Loss=0.0728, RMSE=0.2699, R²=-0.0070
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0838, RMSE: 0.2894, MAE: 0.2510, R²: 0.0027

📊 Round 168 Test Metrics:
   Loss: 0.0837, RMSE: 0.2894, MAE: 0.2510, R²: 0.0028

============================================================
🔄 Round 171 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0793, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0806, val=0.0790, patience=8/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 171 Summary - Client client_2
   Epochs: 28/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0070
   Val:   Loss=0.0793, RMSE=0.2815, R²=-0.0163
============================================================


============================================================
🔄 Round 172 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 172 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=-0.0241
   Val:   Loss=0.0865, RMSE=0.2940, R²=-0.0200
============================================================


============================================================
🔄 Round 173 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0907, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0780, val=0.0904, patience=6/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 173 Summary - Client client_2
   Epochs: 30/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=-0.0058
   Val:   Loss=0.0905, RMSE=0.3009, R²=-0.0141
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0838, RMSE: 0.2894, MAE: 0.2510, R²: 0.0025

============================================================
🔄 Round 176 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0673 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0673, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0673, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0673, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0673, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0672, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0673)

============================================================
📊 Round 176 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0142
   Val:   Loss=0.0673, RMSE=0.2595, R²=-0.0017
============================================================


============================================================
🔄 Round 178 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 178 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0144
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0155
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0838, RMSE: 0.2894, MAE: 0.2510, R²: 0.0026

============================================================
🔄 Round 183 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 183 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=-0.0145
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0042
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0838, RMSE: 0.2894, MAE: 0.2510, R²: 0.0027

📊 Round 183 Test Metrics:
   Loss: 0.0838, RMSE: 0.2894, MAE: 0.2510, R²: 0.0026

============================================================
🔄 Round 186 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0844, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0797, val=0.0842, patience=5/15, lr=0.000001
   • Epoch  31/100: train=0.0796, val=0.0840, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 186 Summary - Client client_2
   Epochs: 31/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=-0.0060
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0101
============================================================


============================================================
🔄 Round 187 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 187 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=-0.0168
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0016
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0838, RMSE: 0.2894, MAE: 0.2510, R²: 0.0026

📊 Round 187 Test Metrics:
   Loss: 0.0838, RMSE: 0.2894, MAE: 0.2510, R²: 0.0026

============================================================
🔄 Round 190 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 190 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0147
   Val:   Loss=0.0807, RMSE=0.2840, R²=-0.0038
============================================================


📊 Round 190 Test Metrics:
   Loss: 0.0838, RMSE: 0.2894, MAE: 0.2510, R²: 0.0026

============================================================
🔄 Round 191 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 191 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0150
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0104
============================================================


============================================================
🔄 Round 196 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0943 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0942, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0942, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0941, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0941, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0938, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0774, val=0.0935, patience=9/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0938)

============================================================
📊 Round 196 Summary - Client client_2
   Epochs: 27/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2781, R²=-0.0053
   Val:   Loss=0.0938, RMSE=0.3062, R²=-0.0249
============================================================


============================================================
🔄 Round 197 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 197 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0204
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0028
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0838, RMSE: 0.2894, MAE: 0.2510, R²: 0.0025

============================================================
🔄 Round 200 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 200 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0130
   Val:   Loss=0.0807, RMSE=0.2840, R²=-0.0081
============================================================


============================================================
🔄 Round 202 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 202 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0150
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0056
============================================================


============================================================
🔄 Round 203 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0878, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0790, val=0.0875, patience=9/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 203 Summary - Client client_2
   Epochs: 27/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=-0.0046
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0286
============================================================


============================================================
🔄 Round 204 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0801, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0804, val=0.0798, patience=5/15, lr=0.000001
   • Epoch  31/100: train=0.0804, val=0.0797, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 204 Summary - Client client_2
   Epochs: 31/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0025
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0264
============================================================


📊 Round 204 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2511, R²: 0.0023

📊 Round 204 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2511, R²: 0.0023

📊 Round 204 Test Metrics:
   Loss: 0.0838, RMSE: 0.2894, MAE: 0.2510, R²: 0.0024

============================================================
🔄 Round 208 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 208 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2836, R²=-0.0139
   Val:   Loss=0.0825, RMSE=0.2873, R²=-0.0071
============================================================


============================================================
🔄 Round 211 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0841, patience=4/15, lr=0.000001
   ✓ Epoch  11/100: train=0.0797, val=0.0838 (↓), lr=0.000001
   • Epoch  21/100: train=0.0796, val=0.0834, patience=10/15, lr=0.000001
   • Epoch  31/100: train=0.0796, val=0.0832, patience=6/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 211 Summary - Client client_2
   Epochs: 40/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=-0.0046
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0340
============================================================


📊 Round 211 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2511, R²: 0.0022

============================================================
🔄 Round 213 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0945 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0944, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0944, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0944, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0943, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0942, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0945)

============================================================
📊 Round 213 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=-0.0118
   Val:   Loss=0.0945, RMSE=0.3074, R²=-0.0092
============================================================


📊 Round 213 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2511, R²: 0.0022

📊 Round 213 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2511, R²: 0.0022

============================================================
🔄 Round 215 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 215 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0145
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0042
============================================================


============================================================
🔄 Round 216 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 216 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0173
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0069
============================================================


📊 Round 216 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2511, R²: 0.0023

============================================================
🔄 Round 218 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0849, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0794, val=0.0846, patience=9/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 218 Summary - Client client_2
   Epochs: 27/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=-0.0040
   Val:   Loss=0.0848, RMSE=0.2913, R²=-0.0309
============================================================


============================================================
🔄 Round 219 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 219 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0088
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0190
============================================================


============================================================
🔄 Round 220 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 220 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0121
   Val:   Loss=0.0739, RMSE=0.2718, R²=-0.0060
============================================================


📊 Round 220 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2511, R²: 0.0021

============================================================
🔄 Round 221 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 221 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=-0.0134
   Val:   Loss=0.0833, RMSE=0.2887, R²=-0.0028
============================================================


📊 Round 221 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2511, R²: 0.0021

============================================================
🔄 Round 222 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 222 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0127
   Val:   Loss=0.0825, RMSE=0.2873, R²=-0.0073
============================================================


📊 Round 222 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2511, R²: 0.0023

============================================================
🔄 Round 227 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0740, patience=4/15, lr=0.000001
   ✓ Epoch  11/100: train=0.0823, val=0.0737 (↓), lr=0.000001
   • Epoch  21/100: train=0.0822, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 227 Summary - Client client_2
   Epochs: 26/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0031
   Val:   Loss=0.0737, RMSE=0.2714, R²=-0.0482
============================================================


============================================================
🔄 Round 228 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 228 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0121
   Val:   Loss=0.0786, RMSE=0.2804, R²=-0.0084
============================================================


📊 Round 228 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2511, R²: 0.0022

============================================================
🔄 Round 230 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 230 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0105
   Val:   Loss=0.0757, RMSE=0.2751, R²=-0.0144
============================================================


📊 Round 230 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2511, R²: 0.0023

📊 Round 230 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2510, R²: 0.0023

============================================================
🔄 Round 232 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 232 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0195
   Val:   Loss=0.0766, RMSE=0.2768, R²=-0.0018
============================================================


📊 Round 232 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2510, R²: 0.0023

📊 Round 232 Test Metrics:
   Loss: 0.0838, RMSE: 0.2894, MAE: 0.2510, R²: 0.0024

============================================================
🔄 Round 236 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 236 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0162
   Val:   Loss=0.0804, RMSE=0.2836, R²=0.0034
============================================================


============================================================
🔄 Round 237 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 237 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=-0.0177
   Val:   Loss=0.0786, RMSE=0.2804, R²=-0.0027
============================================================


📊 Round 237 Test Metrics:
   Loss: 0.0838, RMSE: 0.2894, MAE: 0.2510, R²: 0.0023

============================================================
🔄 Round 239 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0787, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0807, val=0.0784, patience=8/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 239 Summary - Client client_2
   Epochs: 28/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=-0.0059
   Val:   Loss=0.0786, RMSE=0.2804, R²=-0.0179
============================================================


📊 Round 239 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2510, R²: 0.0023

📊 Round 239 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2510, R²: 0.0023

============================================================
🔄 Round 241 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 241 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=-0.0158
   Val:   Loss=0.0823, RMSE=0.2868, R²=-0.0044
============================================================


============================================================
🔄 Round 242 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 242 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0106
   Val:   Loss=0.0794, RMSE=0.2817, R²=-0.0170
============================================================


📊 Round 242 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2510, R²: 0.0023

📊 Round 242 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2510, R²: 0.0023

📊 Round 242 Test Metrics:
   Loss: 0.0838, RMSE: 0.2894, MAE: 0.2510, R²: 0.0023

============================================================
🔄 Round 247 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 247 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=-0.0157
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0018
============================================================


============================================================
🔄 Round 248 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0876, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0787, val=0.0874, patience=6/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 248 Summary - Client client_2
   Epochs: 30/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=-0.0062
   Val:   Loss=0.0875, RMSE=0.2958, R²=-0.0101
============================================================


📊 Round 248 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2510, R²: 0.0022

📊 Round 248 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2510, R²: 0.0022

📊 Round 248 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2510, R²: 0.0022

📊 Round 248 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2510, R²: 0.0022

============================================================
🔄 Round 257 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0862, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0787, val=0.0859, patience=6/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 257 Summary - Client client_2
   Epochs: 30/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=-0.0040
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0171
============================================================


📊 Round 257 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2511, R²: 0.0020

============================================================
🔄 Round 263 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 263 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2826, R²=-0.0117
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0107
============================================================


============================================================
🔄 Round 264 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0839, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0796, val=0.0836, patience=9/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 264 Summary - Client client_2
   Epochs: 27/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0067
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0154
============================================================


============================================================
🔄 Round 265 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 265 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0119
   Val:   Loss=0.0821, RMSE=0.2866, R²=-0.0087
============================================================


📊 Round 265 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2511, R²: 0.0020

============================================================
🔄 Round 267 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0805, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0805, val=0.0801, patience=9/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 267 Summary - Client client_2
   Epochs: 27/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0059
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0277
============================================================


============================================================
🔄 Round 269 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0782, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0814, val=0.0779, patience=9/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 269 Summary - Client client_2
   Epochs: 27/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0063
   Val:   Loss=0.0781, RMSE=0.2796, R²=-0.0343
============================================================


============================================================
🔄 Round 270 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 270 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0129
   Val:   Loss=0.0789, RMSE=0.2808, R²=-0.0049
============================================================


📊 Round 270 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2511, R²: 0.0019

📊 Round 270 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2511, R²: 0.0019

============================================================
🔄 Round 279 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 279 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0121
   Val:   Loss=0.0797, RMSE=0.2822, R²=-0.0071
============================================================


📊 Round 279 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2510, R²: 0.0021

📊 Round 279 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2510, R²: 0.0021

📊 Round 279 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2510, R²: 0.0021

📊 Round 279 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2510, R²: 0.0022

============================================================
🔄 Round 285 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0723, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0723, patience=4/15, lr=0.000001
   ✓ Epoch  11/100: train=0.0831, val=0.0720 (↓), lr=0.000001
   • Epoch  21/100: train=0.0829, val=0.0716, patience=10/15, lr=0.000001
   • Epoch  31/100: train=0.0829, val=0.0714, patience=5/15, lr=0.000001
   • Epoch  41/100: train=0.0828, val=0.0712, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0715)

============================================================
📊 Round 285 Summary - Client client_2
   Epochs: 41/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0043
   Val:   Loss=0.0715, RMSE=0.2673, R²=-0.0291
============================================================


📊 Round 285 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2511, R²: 0.0020

📊 Round 285 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2510, R²: 0.0021

============================================================
🔄 Round 289 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 289 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2803, R²=-0.0134
   Val:   Loss=0.0904, RMSE=0.3007, R²=-0.0090
============================================================


📊 Round 289 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2510, R²: 0.0021

============================================================
🔄 Round 294 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 294 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0130
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0135
============================================================


============================================================
🔄 Round 297 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0803, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0804, val=0.0800, patience=7/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 297 Summary - Client client_2
   Epochs: 29/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0085
   Val:   Loss=0.0802, RMSE=0.2831, R²=-0.0038
============================================================


============================================================
🔄 Round 298 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 298 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0182
   Val:   Loss=0.0780, RMSE=0.2792, R²=-0.0055
============================================================


📊 Round 298 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2510, R²: 0.0021

============================================================
🔄 Round 299 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 299 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0128
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0106
============================================================


📊 Round 299 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2510, R²: 0.0021

============================================================
🔄 Round 301 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0849, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0796, val=0.0847, patience=5/15, lr=0.000001
   • Epoch  31/100: train=0.0795, val=0.0845, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 301 Summary - Client client_2
   Epochs: 31/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=-0.0061
   Val:   Loss=0.0848, RMSE=0.2911, R²=-0.0086
============================================================


📊 Round 301 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2511, R²: 0.0019

📊 Round 301 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2511, R²: 0.0019

============================================================
🔄 Round 305 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 305 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0122
   Val:   Loss=0.0765, RMSE=0.2766, R²=-0.0123
============================================================


============================================================
🔄 Round 306 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 306 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0103
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0170
============================================================


============================================================
🔄 Round 308 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 308 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=-0.0148
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0061
============================================================


============================================================
🔄 Round 309 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 309 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0198
   Val:   Loss=0.0828, RMSE=0.2877, R²=0.0101
============================================================


============================================================
🔄 Round 312 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 312 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0157
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0032
============================================================


============================================================
🔄 Round 313 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 313 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=-0.0160
   Val:   Loss=0.0800, RMSE=0.2829, R²=0.0026
============================================================


📊 Round 313 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2511, R²: 0.0019

📊 Round 313 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2511, R²: 0.0019

============================================================
🔄 Round 321 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0833, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0795, val=0.0831, patience=5/15, lr=0.000001
   • Epoch  31/100: train=0.0794, val=0.0829, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 321 Summary - Client client_2
   Epochs: 31/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=-0.0052
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0125
============================================================


📊 Round 321 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2511, R²: 0.0018

============================================================
🔄 Round 325 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0818, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0803, val=0.0815, patience=9/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 325 Summary - Client client_2
   Epochs: 27/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0048
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0268
============================================================


📊 Round 325 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2511, R²: 0.0017

============================================================
🔄 Round 326 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 326 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0160
   Val:   Loss=0.0741, RMSE=0.2722, R²=-0.0029
============================================================


📊 Round 326 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2511, R²: 0.0018

============================================================
🔄 Round 327 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 327 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0167
   Val:   Loss=0.0784, RMSE=0.2799, R²=0.0024
============================================================


📊 Round 327 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2510, R²: 0.0019

📊 Round 327 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2510, R²: 0.0019

📊 Round 327 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2510, R²: 0.0019

📊 Round 327 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2510, R²: 0.0019

============================================================
🔄 Round 334 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 334 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0196
   Val:   Loss=0.0768, RMSE=0.2772, R²=-0.0041
============================================================


📊 Round 334 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2510, R²: 0.0019

📊 Round 334 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2510, R²: 0.0019

============================================================
🔄 Round 339 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 339 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0146
   Val:   Loss=0.0760, RMSE=0.2757, R²=-0.0031
============================================================


📊 Round 339 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2510, R²: 0.0019

============================================================
🔄 Round 340 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 340 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0179
   Val:   Loss=0.0763, RMSE=0.2762, R²=-0.0017
============================================================


============================================================
🔄 Round 341 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 341 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=-0.0175
   Val:   Loss=0.0886, RMSE=0.2976, R²=-0.0010
============================================================


============================================================
🔄 Round 342 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0730, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0821, val=0.0728, patience=8/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 342 Summary - Client client_2
   Epochs: 28/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0063
   Val:   Loss=0.0730, RMSE=0.2701, R²=-0.0143
============================================================


📊 Round 342 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2511, R²: 0.0017

============================================================
🔄 Round 344 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0851, patience=2/15, lr=0.000001
   ✓ Epoch  21/100: train=0.0792, val=0.0847 (↓), lr=0.000001
   • Epoch  31/100: train=0.0791, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 344 Summary - Client client_2
   Epochs: 36/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=-0.0040
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0280
============================================================


📊 Round 344 Test Metrics:
   Loss: 0.0838, RMSE: 0.2896, MAE: 0.2511, R²: 0.0016

============================================================
🔄 Round 347 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 347 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=-0.0145
   Val:   Loss=0.0770, RMSE=0.2776, R²=-0.0041
============================================================


============================================================
🔄 Round 348 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 348 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=-0.0149
   Val:   Loss=0.0898, RMSE=0.2997, R²=-0.0027
============================================================


📊 Round 348 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2511, R²: 0.0017

📊 Round 348 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2511, R²: 0.0017

============================================================
🔄 Round 353 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 353 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=-0.0162
   Val:   Loss=0.0816, RMSE=0.2857, R²=0.0047
============================================================


📊 Round 353 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2511, R²: 0.0017

============================================================
🔄 Round 357 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0881, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0785, val=0.0877, patience=9/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 357 Summary - Client client_2
   Epochs: 27/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=-0.0061
   Val:   Loss=0.0880, RMSE=0.2967, R²=-0.0147
============================================================


📊 Round 357 Test Metrics:
   Loss: 0.0838, RMSE: 0.2896, MAE: 0.2511, R²: 0.0016

📊 Round 357 Test Metrics:
   Loss: 0.0838, RMSE: 0.2896, MAE: 0.2511, R²: 0.0016

============================================================
🔄 Round 359 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 359 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0118
   Val:   Loss=0.0785, RMSE=0.2802, R²=-0.0094
============================================================


============================================================
🔄 Round 360 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0829, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0800, val=0.0827, patience=7/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 360 Summary - Client client_2
   Epochs: 29/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=-0.0047
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0172
============================================================


============================================================
🔄 Round 361 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 361 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0119
   Val:   Loss=0.0809, RMSE=0.2844, R²=-0.0075
============================================================


📊 Round 361 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2511, R²: 0.0015

============================================================
🔄 Round 362 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0784, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0812, val=0.0782, patience=7/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 362 Summary - Client client_2
   Epochs: 29/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0057
   Val:   Loss=0.0783, RMSE=0.2799, R²=-0.0147
============================================================


============================================================
🔄 Round 363 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0735, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0820, val=0.0732, patience=6/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 363 Summary - Client client_2
   Epochs: 30/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=-0.0062
   Val:   Loss=0.0733, RMSE=0.2708, R²=-0.0069
============================================================


============================================================
🔄 Round 364 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0719 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0719, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0718, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0717, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0719)

============================================================
📊 Round 364 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0096
   Val:   Loss=0.0719, RMSE=0.2682, R²=-0.0117
============================================================


📊 Round 364 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2511, R²: 0.0012

============================================================
🔄 Round 367 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0638 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0638, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0638, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0638, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0638, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0638, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0638)

============================================================
📊 Round 367 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0141
   Val:   Loss=0.0638, RMSE=0.2526, R²=0.0046
============================================================


📊 Round 367 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2511, R²: 0.0012

============================================================
🔄 Round 369 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 369 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0088
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0158
============================================================


============================================================
🔄 Round 371 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0745, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0819, val=0.0742, patience=7/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 371 Summary - Client client_2
   Epochs: 29/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0057
   Val:   Loss=0.0744, RMSE=0.2727, R²=-0.0172
============================================================


============================================================
🔄 Round 372 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 372 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0084
   Val:   Loss=0.0791, RMSE=0.2812, R²=-0.0175
============================================================


📊 Round 372 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2511, R²: 0.0011

============================================================
🔄 Round 373 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0836, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0798, val=0.0833, patience=8/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 373 Summary - Client client_2
   Epochs: 28/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0020
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0350
============================================================


📊 Round 373 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2512, R²: 0.0010

============================================================
🔄 Round 374 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0872, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0785, val=0.0869, patience=6/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 374 Summary - Client client_2
   Epochs: 30/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=-0.0053
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0115
============================================================


📊 Round 374 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2512, R²: 0.0009

============================================================
🔄 Round 377 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 377 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0086
   Val:   Loss=0.0739, RMSE=0.2719, R²=-0.0115
============================================================


📊 Round 377 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2512, R²: 0.0009

============================================================
🔄 Round 380 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 380 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0125
   Val:   Loss=0.0797, RMSE=0.2824, R²=0.0003
============================================================


============================================================
🔄 Round 381 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 381 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0119
   Val:   Loss=0.0751, RMSE=0.2741, R²=-0.0056
============================================================


============================================================
🔄 Round 384 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0758, patience=4/15, lr=0.000001
   ✓ Epoch  11/100: train=0.0816, val=0.0755 (↓), lr=0.000001
   • Epoch  21/100: train=0.0816, val=0.0752, patience=10/15, lr=0.000001
   • Epoch  31/100: train=0.0815, val=0.0749, patience=5/15, lr=0.000001
   • Epoch  41/100: train=0.0815, val=0.0747, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 384 Summary - Client client_2
   Epochs: 41/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0014
   Val:   Loss=0.0750, RMSE=0.2739, R²=-0.0540
============================================================


============================================================
🔄 Round 387 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0832, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0793, val=0.0830, patience=6/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 387 Summary - Client client_2
   Epochs: 30/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=-0.0021
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0174
============================================================


📊 Round 387 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2511, R²: 0.0011

============================================================
🔄 Round 391 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0770, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0812, val=0.0767, patience=7/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 391 Summary - Client client_2
   Epochs: 29/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0033
   Val:   Loss=0.0769, RMSE=0.2773, R²=-0.0159
============================================================


============================================================
🔄 Round 392 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0813, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0800, val=0.0810, patience=9/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 392 Summary - Client client_2
   Epochs: 27/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=-0.0029
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0335
============================================================


============================================================
🔄 Round 394 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 394 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0098
   Val:   Loss=0.0744, RMSE=0.2727, R²=-0.0083
============================================================


📊 Round 394 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2512, R²: 0.0009

============================================================
🔄 Round 395 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0774, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0810, val=0.0772, patience=6/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 395 Summary - Client client_2
   Epochs: 30/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0042
   Val:   Loss=0.0773, RMSE=0.2780, R²=-0.0137
============================================================


📊 Round 395 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2512, R²: 0.0009

============================================================
🔄 Round 399 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 399 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=-0.0120
   Val:   Loss=0.0894, RMSE=0.2990, R²=-0.0057
============================================================


============================================================
🔄 Round 403 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 403 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0127
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0028
============================================================


📊 Round 403 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2511, R²: 0.0011

📊 Round 403 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2511, R²: 0.0011

============================================================
🔄 Round 410 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 410 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=-0.0111
   Val:   Loss=0.0794, RMSE=0.2819, R²=-0.0073
============================================================


📊 Round 410 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2511, R²: 0.0012

============================================================
🔄 Round 411 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 411 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0129
   Val:   Loss=0.0754, RMSE=0.2745, R²=-0.0061
============================================================


📊 Round 411 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2511, R²: 0.0011

============================================================
🔄 Round 412 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0944 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0944, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0944, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0944, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0945, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0946, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0944)

============================================================
📊 Round 412 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2781, R²=-0.0155
   Val:   Loss=0.0944, RMSE=0.3073, R²=-0.0078
============================================================


📊 Round 412 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2511, R²: 0.0011

============================================================
🔄 Round 413 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 413 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0128
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0007
============================================================


📊 Round 413 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2511, R²: 0.0011

📊 Round 413 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2511, R²: 0.0011

============================================================
🔄 Round 415 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 415 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=-0.0093
   Val:   Loss=0.0907, RMSE=0.3012, R²=-0.0148
============================================================


📊 Round 415 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2511, R²: 0.0011

============================================================
🔄 Round 416 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0779, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0813, val=0.0775, patience=8/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 416 Summary - Client client_2
   Epochs: 28/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0037
   Val:   Loss=0.0778, RMSE=0.2789, R²=-0.0328
============================================================


📊 Round 416 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2511, R²: 0.0010

============================================================
🔄 Round 418 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0773, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0814, val=0.0770, patience=8/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 418 Summary - Client client_2
   Epochs: 28/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0041
   Val:   Loss=0.0772, RMSE=0.2779, R²=-0.0298
============================================================


📊 Round 418 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2511, R²: 0.0009

============================================================
🔄 Round 421 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 421 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=-0.0112
   Val:   Loss=0.0778, RMSE=0.2789, R²=-0.0045
============================================================


📊 Round 421 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2511, R²: 0.0009

============================================================
🔄 Round 424 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 424 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0106
   Val:   Loss=0.0807, RMSE=0.2842, R²=-0.0092
============================================================


📊 Round 424 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2511, R²: 0.0010

📊 Round 424 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2511, R²: 0.0010

============================================================
🔄 Round 428 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 428 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0147
   Val:   Loss=0.0785, RMSE=0.2802, R²=-0.0085
============================================================


📊 Round 428 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2511, R²: 0.0010

📊 Round 428 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2511, R²: 0.0010

📊 Round 428 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2511, R²: 0.0011

============================================================
🔄 Round 432 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 432 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=-0.0145
   Val:   Loss=0.0795, RMSE=0.2819, R²=0.0013
============================================================


============================================================
🔄 Round 433 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0804, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0805, val=0.0802, patience=7/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 433 Summary - Client client_2
   Epochs: 29/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0041
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0188
============================================================


📊 Round 433 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2511, R²: 0.0010

📊 Round 433 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2511, R²: 0.0010

============================================================
🔄 Round 437 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 437 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0118
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0049
============================================================


📊 Round 437 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2511, R²: 0.0010

============================================================
🔄 Round 439 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 439 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=-0.0098
   Val:   Loss=0.0904, RMSE=0.3007, R²=-0.0116
============================================================


📊 Round 439 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2511, R²: 0.0011

============================================================
🔄 Round 441 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0766, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0812, val=0.0763, patience=8/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 441 Summary - Client client_2
   Epochs: 28/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0046
   Val:   Loss=0.0766, RMSE=0.2767, R²=-0.0189
============================================================


📊 Round 441 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2511, R²: 0.0009

============================================================
🔄 Round 444 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0745, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0820, val=0.0742, patience=9/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 444 Summary - Client client_2
   Epochs: 27/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0015
   Val:   Loss=0.0745, RMSE=0.2730, R²=-0.0486
============================================================


📊 Round 444 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2512, R²: 0.0008

============================================================
🔄 Round 445 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 445 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0121
   Val:   Loss=0.0815, RMSE=0.2854, R²=-0.0017
============================================================


📊 Round 445 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2512, R²: 0.0008

============================================================
🔄 Round 448 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 448 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=-0.0107
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0058
============================================================


📊 Round 448 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2512, R²: 0.0008

📊 Round 448 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2512, R²: 0.0008

📊 Round 448 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2511, R²: 0.0008

📊 Round 448 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2511, R²: 0.0009

============================================================
🔄 Round 457 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 457 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=-0.0089
   Val:   Loss=0.0811, RMSE=0.2849, R²=-0.0121
============================================================


============================================================
🔄 Round 458 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 458 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0087
   Val:   Loss=0.0844, RMSE=0.2904, R²=-0.0142
============================================================


📊 Round 458 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2511, R²: 0.0009

📊 Round 458 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2511, R²: 0.0009

============================================================
🔄 Round 462 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0783, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0808, val=0.0781, patience=7/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 462 Summary - Client client_2
   Epochs: 29/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0051
   Val:   Loss=0.0783, RMSE=0.2797, R²=-0.0118
============================================================


📊 Round 462 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2511, R²: 0.0009

📊 Round 462 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2511, R²: 0.0009

📊 Round 462 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2511, R²: 0.0010

============================================================
🔄 Round 468 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 468 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0106
   Val:   Loss=0.0840, RMSE=0.2899, R²=-0.0093
============================================================


📊 Round 468 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2511, R²: 0.0010

============================================================
🔄 Round 469 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 469 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0095
   Val:   Loss=0.0765, RMSE=0.2765, R²=-0.0129
============================================================


============================================================
🔄 Round 470 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 470 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0097
   Val:   Loss=0.0800, RMSE=0.2828, R²=-0.0124
============================================================


============================================================
🔄 Round 471 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 471 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=-0.0132
   Val:   Loss=0.0854, RMSE=0.2923, R²=-0.0001
============================================================


📊 Round 471 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2511, R²: 0.0009

============================================================
🔄 Round 473 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 473 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=-0.0100
   Val:   Loss=0.0891, RMSE=0.2985, R²=-0.0106
============================================================


============================================================
🔄 Round 474 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0798, patience=4/15, lr=0.000001
   ✓ Epoch  11/100: train=0.0808, val=0.0795 (↓), lr=0.000001
   • Epoch  21/100: train=0.0807, val=0.0791, patience=10/15, lr=0.000001
   • Epoch  31/100: train=0.0807, val=0.0788, patience=5/15, lr=0.000001
   • Epoch  41/100: train=0.0807, val=0.0787, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 474 Summary - Client client_2
   Epochs: 41/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0019
   Val:   Loss=0.0790, RMSE=0.2810, R²=-0.0590
============================================================


📊 Round 474 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2512, R²: 0.0007

============================================================
🔄 Round 475 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 475 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0111
   Val:   Loss=0.0786, RMSE=0.2803, R²=-0.0042
============================================================


📊 Round 475 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2512, R²: 0.0007

============================================================
🔄 Round 476 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 476 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0100
   Val:   Loss=0.0794, RMSE=0.2817, R²=-0.0066
============================================================


📊 Round 476 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2512, R²: 0.0007

============================================================
🔄 Round 478 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 478 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0076
   Val:   Loss=0.0745, RMSE=0.2730, R²=-0.0183
============================================================


📊 Round 478 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2512, R²: 0.0007

📊 Round 478 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2511, R²: 0.0008

📊 Round 478 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2511, R²: 0.0008

📊 Round 478 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2511, R²: 0.0008

============================================================
🔄 Round 487 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 487 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0113
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0075
============================================================


📊 Round 487 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2511, R²: 0.0008

📊 Round 487 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2511, R²: 0.0008

============================================================
🔄 Round 490 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 490 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=-0.0120
   Val:   Loss=0.0860, RMSE=0.2932, R²=-0.0037
============================================================


============================================================
🔄 Round 491 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 491 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0131
   Val:   Loss=0.0786, RMSE=0.2804, R²=-0.0014
============================================================


📊 Round 491 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2511, R²: 0.0008

📊 Round 491 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2511, R²: 0.0008

📊 Round 491 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2511, R²: 0.0008

📊 Round 491 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2511, R²: 0.0008

============================================================
🔄 Round 495 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0732, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0821, val=0.0729, patience=7/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 495 Summary - Client client_2
   Epochs: 29/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0041
   Val:   Loss=0.0731, RMSE=0.2703, R²=-0.0181
============================================================


============================================================
🔄 Round 496 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 496 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2829, R²=-0.0097
   Val:   Loss=0.0833, RMSE=0.2885, R²=-0.0095
============================================================


============================================================
🔄 Round 499 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 499 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=-0.0154
   Val:   Loss=0.0867, RMSE=0.2945, R²=-0.0022
============================================================


============================================================
🔄 Round 500 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 500 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0109
   Val:   Loss=0.0819, RMSE=0.2863, R²=-0.0051
============================================================


📊 Round 500 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2511, R²: 0.0007

📊 Round 500 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2511, R²: 0.0007

============================================================
🔄 Round 510 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 510 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=-0.0110
   Val:   Loss=0.0813, RMSE=0.2852, R²=-0.0075
============================================================


📊 Round 510 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2511, R²: 0.0008

============================================================
🔄 Round 512 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 512 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2826, R²=-0.0111
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0073
============================================================


📊 Round 512 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2511, R²: 0.0008

📊 Round 512 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2511, R²: 0.0008

📊 Round 512 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2511, R²: 0.0008

📊 Round 512 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2511, R²: 0.0008

============================================================
🔄 Round 519 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 519 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0170
   Val:   Loss=0.0757, RMSE=0.2752, R²=0.0011
============================================================


============================================================
🔄 Round 520 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 520 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=-0.0111
   Val:   Loss=0.0793, RMSE=0.2815, R²=-0.0062
============================================================


============================================================
🔄 Round 521 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0718 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0718, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0717, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0717, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0717, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0716, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 521 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0127
   Val:   Loss=0.0718, RMSE=0.2679, R²=0.0019
============================================================


📊 Round 521 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2511, R²: 0.0008

============================================================
🔄 Round 522 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 522 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0120
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0028
============================================================


📊 Round 522 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2511, R²: 0.0008

📊 Round 522 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2511, R²: 0.0009

============================================================
🔄 Round 529 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 529 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=-0.0145
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0018
============================================================


📊 Round 529 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2511, R²: 0.0009

============================================================
🔄 Round 530 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0914, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0777, val=0.0911, patience=9/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 530 Summary - Client client_2
   Epochs: 27/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=-0.0051
   Val:   Loss=0.0914, RMSE=0.3023, R²=-0.0198
============================================================


============================================================
🔄 Round 531 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0746, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0816, val=0.0744, patience=7/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 531 Summary - Client client_2
   Epochs: 29/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0040
   Val:   Loss=0.0745, RMSE=0.2730, R²=-0.0184
============================================================


============================================================
🔄 Round 534 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0875, patience=4/15, lr=0.000001
   ✓ Epoch  11/100: train=0.0788, val=0.0872 (↓), lr=0.000001
   • Epoch  21/100: train=0.0787, val=0.0868, patience=10/15, lr=0.000001
   • Epoch  31/100: train=0.0787, val=0.0866, patience=5/15, lr=0.000001
   • Epoch  41/100: train=0.0786, val=0.0864, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 534 Summary - Client client_2
   Epochs: 41/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=-0.0010
   Val:   Loss=0.0867, RMSE=0.2945, R²=-0.0345
============================================================


📊 Round 534 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2512, R²: 0.0004

============================================================
🔄 Round 537 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0768, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0813, val=0.0765, patience=7/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 537 Summary - Client client_2
   Epochs: 29/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0026
   Val:   Loss=0.0767, RMSE=0.2770, R²=-0.0703
============================================================


📊 Round 537 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2512, R²: 0.0006

📊 Round 537 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2511, R²: 0.0007

📊 Round 537 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2511, R²: 0.0007

============================================================
🔄 Round 544 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0929 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0929, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0928, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0928, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0927, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0925, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0774, val=0.0922, patience=8/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 544 Summary - Client client_2
   Epochs: 28/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=-0.0022
   Val:   Loss=0.0924, RMSE=0.3040, R²=-0.0335
============================================================


============================================================
🔄 Round 545 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0708 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0707, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0707, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0707, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0707, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0706, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0708)

============================================================
📊 Round 545 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0124
   Val:   Loss=0.0708, RMSE=0.2660, R²=-0.0009
============================================================


📊 Round 545 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2512, R²: 0.0005

============================================================
🔄 Round 546 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0773, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.0812, val=0.0769, patience=11/15, lr=0.000001
   • Epoch  31/100: train=0.0811, val=0.0766, patience=7/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 546 Summary - Client client_2
   Epochs: 39/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0009
   Val:   Loss=0.0768, RMSE=0.2771, R²=-0.0461
============================================================


📊 Round 546 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2512, R²: 0.0005

============================================================
🔄 Round 551 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 551 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0082
   Val:   Loss=0.0778, RMSE=0.2790, R²=-0.0152
============================================================


============================================================
🔄 Round 552 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0980 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0979, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0979, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0978, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0978, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0976, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0980)

============================================================
📊 Round 552 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2764, R²=-0.0090
   Val:   Loss=0.0980, RMSE=0.3130, R²=-0.0115
============================================================


📊 Round 552 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2512, R²: 0.0005

============================================================
🔄 Round 553 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 553 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=-0.0084
   Val:   Loss=0.0791, RMSE=0.2813, R²=-0.0142
============================================================


============================================================
🔄 Round 554 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 554 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0087
   Val:   Loss=0.0771, RMSE=0.2777, R²=-0.0161
============================================================


📊 Round 554 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2511, R²: 0.0006

============================================================
🔄 Round 555 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 555 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0121
   Val:   Loss=0.0786, RMSE=0.2804, R²=-0.0034
============================================================


📊 Round 555 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2511, R²: 0.0006

📊 Round 555 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2511, R²: 0.0006

============================================================
🔄 Round 557 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 557 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0122
   Val:   Loss=0.0743, RMSE=0.2725, R²=-0.0027
============================================================


============================================================
🔄 Round 558 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0807, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0803, val=0.0804, patience=9/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 558 Summary - Client client_2
   Epochs: 27/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0028
   Val:   Loss=0.0806, RMSE=0.2840, R²=-0.0280
============================================================


📊 Round 558 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2512, R²: 0.0004

📊 Round 558 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2512, R²: 0.0005

============================================================
🔄 Round 561 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 561 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0104
   Val:   Loss=0.0810, RMSE=0.2845, R²=-0.0089
============================================================


📊 Round 561 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2512, R²: 0.0004

📊 Round 561 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2511, R²: 0.0005

============================================================
🔄 Round 563 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0750, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0817, val=0.0748, patience=7/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 563 Summary - Client client_2
   Epochs: 29/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0044
   Val:   Loss=0.0749, RMSE=0.2738, R²=-0.0110
============================================================


📊 Round 563 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2512, R²: 0.0004

📊 Round 563 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2512, R²: 0.0004

📊 Round 563 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2512, R²: 0.0004

📊 Round 563 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2512, R²: 0.0004

📊 Round 563 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2511, R²: 0.0005

============================================================
🔄 Round 569 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0812, patience=2/15, lr=0.000001
   ✓ Epoch  21/100: train=0.0802, val=0.0807 (↓), lr=0.000001
   • Epoch  31/100: train=0.0802, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 569 Summary - Client client_2
   Epochs: 36/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0009
   Val:   Loss=0.0807, RMSE=0.2842, R²=-0.0739
============================================================


📊 Round 569 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2512, R²: 0.0004

📊 Round 569 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2512, R²: 0.0005

============================================================
🔄 Round 574 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 574 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0136
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0035
============================================================


============================================================
🔄 Round 575 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0798, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0805, val=0.0795, patience=8/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 575 Summary - Client client_2
   Epochs: 28/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=-0.0044
   Val:   Loss=0.0797, RMSE=0.2824, R²=-0.0130
============================================================


📊 Round 575 Test Metrics:
   Loss: 0.0840, RMSE: 0.2897, MAE: 0.2512, R²: 0.0003

📊 Round 575 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2512, R²: 0.0004

📊 Round 575 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2512, R²: 0.0004

📊 Round 575 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2512, R²: 0.0004

📊 Round 575 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2511, R²: 0.0005

📊 Round 575 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2511, R²: 0.0005

============================================================
🔄 Round 585 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 585 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0096
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0127
============================================================


============================================================
🔄 Round 586 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 586 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0149
   Val:   Loss=0.0767, RMSE=0.2770, R²=-0.0014
============================================================


📊 Round 586 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2511, R²: 0.0005

📊 Round 586 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2511, R²: 0.0005

📊 Round 586 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2511, R²: 0.0005

============================================================
🔄 Round 592 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 592 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0180
   Val:   Loss=0.0752, RMSE=0.2743, R²=-0.0074
============================================================


📊 Round 592 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2511, R²: 0.0005

📊 Round 592 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2511, R²: 0.0006

📊 Round 592 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2511, R²: 0.0006

============================================================
🔄 Round 599 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0881, patience=4/15, lr=0.000001
   ✓ Epoch  11/100: train=0.0785, val=0.0878 (↓), lr=0.000001
   • Epoch  21/100: train=0.0784, val=0.0874, patience=10/15, lr=0.000001
   • Epoch  31/100: train=0.0783, val=0.0871, patience=7/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 599 Summary - Client client_2
   Epochs: 39/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=-0.0012
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0425
============================================================


============================================================
🔄 Round 600 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 600 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=-0.0091
   Val:   Loss=0.0777, RMSE=0.2787, R²=-0.0132
============================================================


📊 Round 600 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2512, R²: 0.0004

📊 Round 600 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2512, R²: 0.0004

============================================================
🔄 Round 605 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 605 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=-0.0149
   Val:   Loss=0.0858, RMSE=0.2929, R²=0.0025
============================================================


📊 Round 605 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2511, R²: 0.0004

============================================================
🔄 Round 609 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 609 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=-0.0105
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0086
============================================================


📊 Round 609 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2511, R²: 0.0004

============================================================
🔄 Round 610 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0785, patience=4/15, lr=0.000001
   ✓ Epoch  11/100: train=0.0811, val=0.0782 (↓), lr=0.000001
   • Epoch  21/100: train=0.0809, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 610 Summary - Client client_2
   Epochs: 26/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0052
   Val:   Loss=0.0782, RMSE=0.2796, R²=-0.0161
============================================================


📊 Round 610 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2512, R²: 0.0003

============================================================
🔄 Round 611 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 611 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0157
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0010
============================================================


📊 Round 611 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2512, R²: 0.0003

============================================================
🔄 Round 614 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0797, patience=4/15, lr=0.000001
   ✓ Epoch  11/100: train=0.0806, val=0.0794 (↓), lr=0.000001
   • Epoch  21/100: train=0.0804, val=0.0790, patience=10/15, lr=0.000001
   • Epoch  31/100: train=0.0804, val=0.0788, patience=5/15, lr=0.000001
   • Epoch  41/100: train=0.0803, val=0.0786, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 614 Summary - Client client_2
   Epochs: 41/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=-0.0010
   Val:   Loss=0.0789, RMSE=0.2809, R²=-0.0262
============================================================


============================================================
🔄 Round 615 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 615 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0086
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0101
============================================================


============================================================
🔄 Round 617 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 617 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0122
   Val:   Loss=0.0781, RMSE=0.2794, R²=0.0002
============================================================


📊 Round 617 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2512, R²: 0.0002

📊 Round 617 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2512, R²: 0.0002

============================================================
🔄 Round 620 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 620 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=-0.0120
   Val:   Loss=0.0879, RMSE=0.2964, R²=-0.0032
============================================================


📊 Round 620 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2512, R²: 0.0003

📊 Round 620 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2512, R²: 0.0003

============================================================
🔄 Round 624 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 624 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0094
   Val:   Loss=0.0785, RMSE=0.2802, R²=-0.0108
============================================================


📊 Round 624 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2512, R²: 0.0003

============================================================
🔄 Round 626 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0768, patience=4/15, lr=0.000001
   ✓ Epoch  11/100: train=0.0812, val=0.0765 (↓), lr=0.000001
   • Epoch  21/100: train=0.0811, val=0.0762, patience=10/15, lr=0.000001
   • Epoch  31/100: train=0.0810, val=0.0759, patience=5/15, lr=0.000001
   • Epoch  41/100: train=0.0810, val=0.0757, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 626 Summary - Client client_2
   Epochs: 41/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0009
   Val:   Loss=0.0760, RMSE=0.2757, R²=-0.0286
============================================================


📊 Round 626 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2512, R²: 0.0003

📊 Round 626 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2512, R²: 0.0003

============================================================
🔄 Round 631 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0894, patience=4/15, lr=0.000001
   ✓ Epoch  11/100: train=0.0783, val=0.0891 (↓), lr=0.000001
   • Epoch  21/100: train=0.0782, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 631 Summary - Client client_2
   Epochs: 26/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=-0.0036
   Val:   Loss=0.0891, RMSE=0.2985, R²=-0.0266
============================================================


📊 Round 631 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2512, R²: 0.0002

============================================================
🔄 Round 632 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 632 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0122
   Val:   Loss=0.0847, RMSE=0.2911, R²=-0.0032
============================================================


📊 Round 632 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2512, R²: 0.0002

============================================================
🔄 Round 637 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0665 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0665, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0665, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0665, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0665, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0664, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0665)

============================================================
📊 Round 637 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0116
   Val:   Loss=0.0665, RMSE=0.2580, R²=0.0002
============================================================


📊 Round 637 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2512, R²: 0.0002

============================================================
🔄 Round 638 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 638 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0071
   Val:   Loss=0.0830, RMSE=0.2880, R²=-0.0195
============================================================


============================================================
🔄 Round 640 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 640 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=-0.0132
   Val:   Loss=0.0882, RMSE=0.2970, R²=0.0006
============================================================


============================================================
🔄 Round 641 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 641 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0110
   Val:   Loss=0.0749, RMSE=0.2737, R²=-0.0064
============================================================


============================================================
🔄 Round 642 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0725, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 642 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0080
   Val:   Loss=0.0728, RMSE=0.2698, R²=-0.0179
============================================================


📊 Round 642 Test Metrics:
   Loss: 0.0840, RMSE: 0.2897, MAE: 0.2512, R²: 0.0003

============================================================
🔄 Round 646 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 646 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=-0.0092
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0118
============================================================


============================================================
🔄 Round 647 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0708 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0709, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0709, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0710, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0710, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0713, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0708)

============================================================
📊 Round 647 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0193
   Val:   Loss=0.0708, RMSE=0.2661, R²=-0.0089
============================================================


📊 Round 647 Test Metrics:
   Loss: 0.0840, RMSE: 0.2897, MAE: 0.2512, R²: 0.0003

📊 Round 647 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2512, R²: 0.0002

📊 Round 647 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2512, R²: 0.0003

============================================================
🔄 Round 652 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 652 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=-0.0079
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0155
============================================================


📊 Round 652 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2511, R²: 0.0004

============================================================
🔄 Round 655 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0868, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0788, val=0.0865, patience=8/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 655 Summary - Client client_2
   Epochs: 28/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=-0.0044
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.0148
============================================================


============================================================
🔄 Round 656 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 656 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=-0.0097
   Val:   Loss=0.0909, RMSE=0.3015, R²=-0.0105
============================================================


============================================================
🔄 Round 657 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 657 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0125
   Val:   Loss=0.0788, RMSE=0.2806, R²=-0.0003
============================================================


============================================================
🔄 Round 661 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0855, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0791, val=0.0852, patience=5/15, lr=0.000001
   • Epoch  31/100: train=0.0790, val=0.0851, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 661 Summary - Client client_2
   Epochs: 31/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=-0.0029
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0110
============================================================


============================================================
🔄 Round 662 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 662 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0097
   Val:   Loss=0.0782, RMSE=0.2796, R²=-0.0059
============================================================


📊 Round 662 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2512, R²: 0.0000

📊 Round 662 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2512, R²: 0.0000

============================================================
🔄 Round 664 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0790, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0808, val=0.0787, patience=7/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 664 Summary - Client client_2
   Epochs: 29/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0043
   Val:   Loss=0.0789, RMSE=0.2809, R²=-0.0135
============================================================


📊 Round 664 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2512, R²: -0.0001

📊 Round 664 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2512, R²: -0.0001

============================================================
🔄 Round 668 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 668 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=-0.0093
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0083
============================================================


📊 Round 668 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2512, R²: 0.0000

📊 Round 668 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2512, R²: 0.0000

📊 Round 668 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2512, R²: 0.0000

📊 Round 668 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2512, R²: 0.0001

============================================================
🔄 Round 677 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0755, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.0817, val=0.0751, patience=11/15, lr=0.000001
   • Epoch  31/100: train=0.0816, val=0.0748, patience=8/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 677 Summary - Client client_2
   Epochs: 38/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0015
   Val:   Loss=0.0750, RMSE=0.2739, R²=-0.0436
============================================================


📊 Round 677 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2512, R²: 0.0001

============================================================
🔄 Round 679 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 679 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0130
   Val:   Loss=0.0820, RMSE=0.2863, R²=-0.0005
============================================================


📊 Round 679 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2512, R²: 0.0001

============================================================
🔄 Round 683 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 683 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=-0.0094
   Val:   Loss=0.0809, RMSE=0.2844, R²=-0.0114
============================================================


📊 Round 683 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2512, R²: 0.0001

============================================================
🔄 Round 685 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 685 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0147
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0016
============================================================


📊 Round 685 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2512, R²: 0.0001

============================================================
🔄 Round 691 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 691 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0102
   Val:   Loss=0.0763, RMSE=0.2762, R²=-0.0084
============================================================


============================================================
🔄 Round 692 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0795, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0806, val=0.0792, patience=7/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 692 Summary - Client client_2
   Epochs: 29/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0047
   Val:   Loss=0.0794, RMSE=0.2817, R²=-0.0082
============================================================


============================================================
🔄 Round 694 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 694 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=-0.0088
   Val:   Loss=0.0827, RMSE=0.2875, R²=-0.0111
============================================================


============================================================
🔄 Round 695 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0788, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0809, val=0.0786, patience=6/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 695 Summary - Client client_2
   Epochs: 30/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0033
   Val:   Loss=0.0787, RMSE=0.2805, R²=-0.0117
============================================================


============================================================
🔄 Round 696 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 696 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=-0.0087
   Val:   Loss=0.0869, RMSE=0.2947, R²=-0.0100
============================================================


📊 Round 696 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2512, R²: -0.0001

============================================================
🔄 Round 698 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 698 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=-0.0121
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0036
============================================================


📊 Round 698 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2512, R²: -0.0001

📊 Round 698 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2512, R²: -0.0001

📊 Round 698 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2512, R²: -0.0002

============================================================
🔄 Round 708 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 708 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0096
   Val:   Loss=0.0771, RMSE=0.2777, R²=-0.0067
============================================================


📊 Round 708 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2512, R²: -0.0001

============================================================
🔄 Round 710 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0922, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0922, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0918, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.0778, val=0.0914, patience=11/15, lr=0.000001
   • Epoch  31/100: train=0.0777, val=0.0911, patience=7/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 710 Summary - Client client_2
   Epochs: 39/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2783, R²=-0.0008
   Val:   Loss=0.0913, RMSE=0.3022, R²=-0.0327
============================================================


📊 Round 710 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2512, R²: -0.0002

============================================================
🔄 Round 714 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 714 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0100
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0050
============================================================


============================================================
🔄 Round 715 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0935 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0934, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0933, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0933, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0932, patience=4/15, lr=0.000001
   ✓ Epoch  11/100: train=0.0774, val=0.0930 (↓), lr=0.000001
   • Epoch  21/100: train=0.0773, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0930)

============================================================
📊 Round 715 Summary - Client client_2
   Epochs: 26/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=-0.0038
   Val:   Loss=0.0930, RMSE=0.3049, R²=-0.0215
============================================================


📊 Round 715 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2512, R²: -0.0003

============================================================
🔄 Round 716 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0723, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0723, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0725, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 716 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0133
   Val:   Loss=0.0723, RMSE=0.2689, R²=-0.0029
============================================================


============================================================
🔄 Round 717 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0843, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0793, val=0.0840, patience=6/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 717 Summary - Client client_2
   Epochs: 30/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=-0.0035
   Val:   Loss=0.0841, RMSE=0.2901, R²=-0.0103
============================================================


============================================================
🔄 Round 718 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 718 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2870, R²=-0.0100
   Val:   Loss=0.0734, RMSE=0.2709, R²=-0.0016
============================================================


📊 Round 718 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2512, R²: -0.0003

============================================================
🔄 Round 720 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 720 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0140
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0037
============================================================


📊 Round 720 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2512, R²: -0.0003

============================================================
🔄 Round 723 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 723 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0080
   Val:   Loss=0.0778, RMSE=0.2789, R²=-0.0106
============================================================


============================================================
🔄 Round 724 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 724 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2829, R²=-0.0094
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0061
============================================================


📊 Round 724 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2512, R²: -0.0002

📊 Round 724 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2512, R²: -0.0002

📊 Round 724 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2512, R²: -0.0002

============================================================
🔄 Round 727 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 727 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2822, R²=-0.0127
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0040
============================================================


📊 Round 727 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2512, R²: -0.0002

============================================================
🔄 Round 731 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 731 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0138
   Val:   Loss=0.0808, RMSE=0.2843, R²=0.0001
============================================================


📊 Round 731 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2512, R²: -0.0001

============================================================
🔄 Round 732 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 732 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=-0.0129
   Val:   Loss=0.0776, RMSE=0.2785, R²=0.0040
============================================================


📊 Round 732 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2512, R²: -0.0001

============================================================
🔄 Round 737 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0774, patience=4/15, lr=0.000001
   ✓ Epoch  11/100: train=0.0813, val=0.0771 (↓), lr=0.000001
   • Epoch  21/100: train=0.0812, val=0.0767, patience=10/15, lr=0.000001
   • Epoch  31/100: train=0.0811, val=0.0764, patience=6/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 737 Summary - Client client_2
   Epochs: 40/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0002
   Val:   Loss=0.0766, RMSE=0.2768, R²=-0.0688
============================================================


📊 Round 737 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2512, R²: -0.0002

============================================================
🔄 Round 738 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0882, patience=4/15, lr=0.000001
   ✓ Epoch  11/100: train=0.0785, val=0.0879 (↓), lr=0.000001
   • Epoch  21/100: train=0.0784, val=0.0875, patience=10/15, lr=0.000001
   • Epoch  31/100: train=0.0784, val=0.0872, patience=6/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 738 Summary - Client client_2
   Epochs: 40/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=-0.0006
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0472
============================================================


📊 Round 738 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2512, R²: -0.0003

📊 Round 738 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2512, R²: -0.0002

📊 Round 738 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2512, R²: -0.0002

📊 Round 738 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2512, R²: -0.0002

============================================================
🔄 Round 745 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 745 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0083
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0138
============================================================


📊 Round 745 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2512, R²: -0.0001

============================================================
🔄 Round 748 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 748 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0096
   Val:   Loss=0.0784, RMSE=0.2800, R²=-0.0107
============================================================


📊 Round 748 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2512, R²: -0.0000

📊 Round 748 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2512, R²: -0.0000

============================================================
🔄 Round 751 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0769, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0812, val=0.0766, patience=9/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 751 Summary - Client client_2
   Epochs: 27/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0049
   Val:   Loss=0.0769, RMSE=0.2773, R²=-0.0170
============================================================


============================================================
🔄 Round 752 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0710 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0710, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0710, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0710, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0709, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0709, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0710)

============================================================
📊 Round 752 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0113
   Val:   Loss=0.0710, RMSE=0.2665, R²=-0.0047
============================================================


============================================================
🔄 Round 753 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0796, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0803, val=0.0793, patience=8/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 753 Summary - Client client_2
   Epochs: 28/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0045
   Val:   Loss=0.0795, RMSE=0.2819, R²=-0.0131
============================================================


============================================================
🔄 Round 754 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 754 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0131
   Val:   Loss=0.0831, RMSE=0.2882, R²=-0.0001
============================================================


📊 Round 754 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2512, R²: -0.0004

============================================================
🔄 Round 756 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 756 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=-0.0192
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0057
============================================================


============================================================
🔄 Round 757 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 757 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0104
   Val:   Loss=0.0727, RMSE=0.2696, R²=-0.0047
============================================================


============================================================
🔄 Round 758 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0800, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0803, val=0.0798, patience=5/15, lr=0.000001
   • Epoch  31/100: train=0.0802, val=0.0796, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 758 Summary - Client client_2
   Epochs: 31/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0032
   Val:   Loss=0.0799, RMSE=0.2826, R²=-0.0140
============================================================


📊 Round 758 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2512, R²: -0.0006

============================================================
🔄 Round 760 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0810, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0800, val=0.0807, patience=7/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 760 Summary - Client client_2
   Epochs: 29/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=-0.0020
   Val:   Loss=0.0809, RMSE=0.2845, R²=-0.0213
============================================================


📊 Round 760 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2513, R²: -0.0007

============================================================
🔄 Round 761 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 761 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0079
   Val:   Loss=0.0767, RMSE=0.2770, R²=-0.0073
============================================================


📊 Round 761 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2513, R²: -0.0007

============================================================
🔄 Round 764 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 764 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=-0.0094
   Val:   Loss=0.0853, RMSE=0.2920, R²=-0.0020
============================================================


📊 Round 764 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2513, R²: -0.0007

📊 Round 764 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2513, R²: -0.0006

============================================================
🔄 Round 768 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0809, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0803, val=0.0806, patience=9/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 768 Summary - Client client_2
   Epochs: 27/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0012
   Val:   Loss=0.0809, RMSE=0.2844, R²=-0.0354
============================================================


📊 Round 768 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2513, R²: -0.0007

============================================================
🔄 Round 770 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 770 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0103
   Val:   Loss=0.0773, RMSE=0.2781, R²=0.0026
============================================================


============================================================
🔄 Round 771 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 771 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0141
   Val:   Loss=0.0764, RMSE=0.2764, R²=0.0039
============================================================


📊 Round 771 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2512, R²: -0.0006

============================================================
🔄 Round 772 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 772 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=-0.0068
   Val:   Loss=0.0902, RMSE=0.3003, R²=-0.0154
============================================================


📊 Round 772 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2512, R²: -0.0006

📊 Round 772 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2512, R²: -0.0005

📊 Round 772 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2512, R²: -0.0004

============================================================
🔄 Round 776 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 776 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0120
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0026
============================================================


📊 Round 776 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2512, R²: -0.0003

============================================================
🔄 Round 780 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 780 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=-0.0120
   Val:   Loss=0.0790, RMSE=0.2811, R²=0.0002
============================================================


📊 Round 780 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2512, R²: -0.0003

📊 Round 780 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2512, R²: -0.0003

============================================================
🔄 Round 782 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 782 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=-0.0153
   Val:   Loss=0.0853, RMSE=0.2921, R²=0.0011
============================================================


============================================================
🔄 Round 783 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0924 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0922, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0921, patience=4/15, lr=0.000001
   ✓ Epoch  11/100: train=0.0776, val=0.0919 (↓), lr=0.000001
   • Epoch  21/100: train=0.0775, val=0.0915, patience=10/15, lr=0.000001
   • Epoch  31/100: train=0.0775, val=0.0912, patience=5/15, lr=0.000001
   • Epoch  41/100: train=0.0774, val=0.0910, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 783 Summary - Client client_2
   Epochs: 41/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2783, R²=-0.0019
   Val:   Loss=0.0913, RMSE=0.3022, R²=-0.0254
============================================================


❌ Client client_2 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8692 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8692 {grpc_message:"Socket closed", grpc_status:14}"
>
