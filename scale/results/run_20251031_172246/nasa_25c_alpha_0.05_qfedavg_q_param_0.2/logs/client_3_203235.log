[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fda4ece1-03c9-48db-be5e-39288c5b6c44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b52f9b38-ab48-4ec2-b02c-152f72fe8bc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65f93788-d063-4210-a6bc-0aff186847d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ba68e10-b109-43f3-98ef-7fc209653480
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message abd023db-e445-4a40-a279-d6ef7279dad8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 640a0cc3-24fb-489a-b34d-01f8faf2975e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 161cb141-3d2d-48bb-915c-6d8c9ccdb87f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e79b4ea-8eca-456f-82fc-5e0d80f26333
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e550717-d167-4945-92c1-430bc875482c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55b54a25-8f53-452d-8bef-f87edcf7af1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9dd3ee1b-24dd-4bd2-a1aa-83f1ae7c3afe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c81a37d3-3a2a-45e9-ab17-3de749af34b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5baf2b6-7066-4a07-8370-912c6befb054
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 425052ae-a1c5-49ad-bea6-8134e77db5f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bea3ca6d-2ff2-4f8d-877c-2a2f09c6272d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ab75437-7d79-4a32-8b76-99a0271a1ca7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ecfc2ce-41bd-44f5-9d8d-2da2ea71a4d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 552ad8df-2cb6-4f4f-a097-18db1065825b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f59e1ef-112b-4c1b-b299-c2dba2f67053
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6cf79feb-b508-4aaa-bec6-6d827f6ca849
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 163bbd7c-546e-467a-9449-d86624c8d075
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a7ab62a-b153-4c98-930f-ac22a7642199
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8bd7b5a4-1b1f-495c-85a3-2665f8633a0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 075492a8-5eed-40ae-a1eb-408b839c9bd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c607fd1-454e-4560-8fc5-20701c111682
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e93a60fc-7b64-49f1-a601-bb4d1dc04a7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81f4b2d3-0d81-45f8-89ef-2c3460c36ebd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61068241-2f68-4a72-b367-c39b706b61ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5e88ad7-a585-40c3-819e-aaec5f83509c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14347bbc-9c51-40c7-93de-9035891df5c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58dec4bf-7263-4891-9e02-09974e6b70f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00f6dd37-c7e9-42a2-91b1-fabe3bea05f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18ab65eb-b921-4559-92e0-504f44e02b43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2cb8eb6-52be-49bd-a402-09fcdb3d16ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bce26508-bc38-4085-939e-2cf1b44106f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ab9fada-5366-43c3-baca-c0ad0a82309a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 024f2283-3bf3-4b95-81f2-f934ea02d103
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61833721-1e0f-473c-a3b4-7a3f080241e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8fc82b2f-0783-488c-95ed-e3559db7876a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5422bbd-56f8-4767-8700-201c9aa2238e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f2443ea-db78-461f-bc61-70ea9b995038
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee0d5789-50fd-444d-ae04-d36968ca67d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4bbc5cdc-8476-47f5-bd97-aee637cc7719
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1b99dba-e68f-442b-bf1d-ce7a467a637a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2151124-e080-412e-ae14-575350c867a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e000bb0-f61c-4f24-b033-f827aab43a1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7ea2ad2-c076-443c-8fc3-ecca08c5fd68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 256b7521-4e26-4f81-9ee1-a976d3643921
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39c1bd32-2f02-4f2b-9964-5b85bbd96ea2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46637ebf-3f52-4ccc-b68d-57af7115cce7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e40a5bcc-5f37-4009-9df8-6c32d734b132
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49cddacf-bd3b-4142-9dd6-d0f9fadc0cf3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6dff298-7fe4-48c8-b73d-aa64c88cf30d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92da176f-8fc2-43f7-b2d9-672420c916ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71bf2f21-2607-4419-b637-fb06c3f4c726
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e8b13f6-07ae-4800-8b16-24fe9cd8cb46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07642711-42f0-4415-9e33-726692d897ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 181e69ba-307e-4621-aab9-996ec2f95dda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa9430b8-ce7d-40d2-8ff0-20d42d921aff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81666edc-ea1a-4097-9687-87ea7dc222ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1758e5c-a761-4008-932d-46d70de5ddaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9148304-fd42-4360-9963-f9e6cf8d6158
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d23a11e2-1894-4fdc-abb7-54d5e7848113
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f60b36b-5fe4-4f52-9d05-4c0281b6a8e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5511e473-aa5e-4248-a3d5-0c5892a4c218
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f1b0a1b-6cf3-4d21-9b3e-8668bb0bea1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 425d546f-7ddf-4bb1-a62d-d7eb432985ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b2117c2-ec8b-4bb8-a3e7-f9d3d8a15b15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23e9394a-20c6-406d-801a-2a4345db87a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 221d0614-722c-4572-ae90-3758be2d4335
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c4e88e4-0ebf-4a07-98b1-3c93cae750d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6bf57393-5455-4eda-8299-e4bccb9c883e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb328ed0-edd1-450d-8eb4-0331ef684d34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81e412e8-1499-4b44-a513-0bab86710008
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9da15e40-e790-41be-9f28-00a2a645ac05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b327d795-9b37-47f0-b4cb-92a8eece6dec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c4b0bbc-aa96-4ec8-8ebc-d7b9645178ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f171946e-5a45-490f-9391-38945f5f49aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07ddfad4-11b0-43e4-808c-9dc855729f62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11d189bb-e5df-42a4-b841-411b8cb12ce7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 380a9226-b59a-4345-9253-7915add8bb71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e3ee75d-5ab3-4666-bc92-c8b62d98f0e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8f16ca3-095a-4c79-8680-e64ba41b10af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9030aae0-fd64-458c-a478-965b8a207d0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f64390b-082e-4347-9940-3a6f37efeffe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62777e83-352b-4ed0-8dab-c0a30e98f16f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80145243-8c08-4610-be92-7d29fbbd6db6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53e93ff6-dba8-4b0a-a95a-6eaad9786d95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 022cb8c4-e73d-423e-a0e1-8ae6ad72072c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76465d0d-d867-442e-bf1c-3a97d9859b42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5eef475a-43c3-4259-904d-7285a7feedb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 892500e4-be15-4807-a159-33d4aaad8933
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0ea9292-8d46-4fdf-a2bc-129aed8462f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a5cba17-87d4-40bb-9492-6f7c436dff4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c49039a-41e4-4c6e-bcb5-73275808e288
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee5d15a0-566e-4dae-8bd2-9c8490284d35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 440bab54-0acf-47c4-91ae-7177ffbf14a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d3af2b3-55ab-46a8-a567-c77d2f1d5c2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54f90a1a-bfa7-4374-ae29-98c82a693c93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 646efa74-5a32-4e28-a421-947b5f4fd8fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 753b9e9a-596c-406e-a55c-80081a343462
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa8fe78d-980e-48ac-a71f-e2b6aff37010
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca97008a-c989-445e-b38b-caca23acf772
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f33b575-d35f-47c3-ad1f-cce8ce3a119f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d9b263a-eefd-403a-98fa-f0df53ee3f9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c580446-e0ee-4586-9ddc-bc2bbace2680
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21d560b9-0428-41e5-9ae2-6c9207c22ced
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1760eb1b-de43-46f1-b24f-79eae3a9522c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6533493e-ffc8-48c4-94d4-5f6744621fa2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43278303-22c6-413b-b34c-9f258a0300b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 093826c1-3d17-4def-b527-cfbdbc710d83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d30d9f83-07be-415f-8025-db48e6ee1ed4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38938699-8017-480d-8dfd-5127bcc6a7c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84214d92-a018-4df7-8a5a-871b1053dfdb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message acbe8142-9bb3-4d65-b0fa-8a8ed6824829
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0bc1165-41f9-48dc-972a-cfd7098463ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 433d1ce5-71d0-43ab-a070-80dc35e93717
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4088bea2-d793-41ec-a9df-5426279157dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5b625d0-f6ce-487f-a144-abba449dc85e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5605989e-71e4-4379-ab34-502d072ee72f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59a7fad4-4c37-4c63-a15e-3b6017ec1dd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c536961-b554-4392-b7fb-afee0e0f6411
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9c20295-59bd-4433-a866-bdfef900a139
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3bd7434e-11f7-4563-83e9-fc08a5579ad7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a20b5ed9-8725-4399-b9cc-dfde8358ce15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9951cab-86b7-4096-8f84-b3d47d75dbc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c70221d-ed44-4a22-9f44-a235eb040452
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dae1182a-5102-44a1-8ee5-e5c7a6bee24d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5311144-d5a4-4ee9-baf5-a91bb6ce5db2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 653176ea-95ff-438d-bc8f-387b954d5504
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7311ca9d-3ea7-4fb2-ba32-81d7c4701d3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ddbbe1e-ee2c-43e8-8d24-7850bd1001b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd64928d-c0c5-4a3a-8cee-24f5e9b581d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 437ade84-99ca-47ac-9647-af671594933e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ecb0a3c6-d43d-4bef-b89d-678e2801d339
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac4e4344-165c-4f0b-8b25-9088aa35a0b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2d219f8-d32b-4d78-af95-2c068ccc82ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1982fb5-1535-41e2-b748-5bdbfb6785eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 358fb8b6-d076-4f06-9ee9-49868030990b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e95387db-886c-4360-829b-219a3b70b888
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fdc2460e-f3d9-4b89-98b1-dc5e677f49f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9550afc-cc5d-40fa-8649-048a1641963d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 207bb648-3a2f-4efe-827c-a577abcbbc3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7dcd6c9d-c59d-4327-b801-6212bcc0feae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4149a608-7b49-4cf1-966b-76a0d8b9b0bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b4d68de-0b8c-4b67-8e5e-be2356401fae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5aec1d31-5b9c-4bbb-be49-a95f7148f5d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6fb678d4-abd4-41b7-a7e5-0fde8ea30e92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60bfaa53-ceef-407e-9a2d-12df03cd5893
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86621fe2-bb6f-4950-808e-4e23a9e96b38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68480623-ecdb-423e-a1d2-6ea711be0d62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57255133-681f-4dca-a54a-23e0e6f3a144
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5e9faac-20ce-4601-8487-b9be273942ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0d3f2ff-16ad-49b6-b541-a6ae370cc125
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1d56c54-e7c6-49ae-ab43-c02a3b33a6d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 761463a9-ed41-43bb-b982-888a9039c84c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba930912-3372-485e-a1fe-3105f18be8a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95197a02-910b-4c63-b671-1d28ae985d34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a468b3a-3f82-41d5-af7e-dc426c4dfbe3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14470136-4fb7-41b9-a802-99547db23b27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64674379-fa7a-46df-8a2e-8457f5df428e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ab0de1f-8ad5-47ac-aa0d-7ffa3ada34a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 910b7407-13d6-43d7-a84d-d61b70f91091
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ef17c8d-ac74-4da2-bd4c-08fc63702cf7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d7c6ba4-f2b2-4074-8b79-866af6e33e5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50b95ac0-29e3-4060-8b28-dffcf2de6bb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b91f04f-6381-4df0-bffd-7436898f97eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a12445f-b139-44bc-9187-d826b991295a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3ed2d5f-349b-4713-8317-96772f471971
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31ca34c0-2402-4ed5-9bc4-6ec5eb3c380c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 022568fd-b7ae-404d-ae5e-4fb11bdee21e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7de61d2c-de6f-4249-863f-1d3445356436
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0de73191-d04d-437e-9318-4ff264f947c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91e268ef-cc6e-41b4-904b-01c983ede385
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 720e1233-9889-437d-b626-bf69450eb04e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70b704bb-7fb1-4df2-9f4c-56a480f299e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0680357-14e2-4a6e-aa51-7e1c96fb96da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f72517b-2e4c-423b-b459-e32e97959efb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4fdf831f-4c1e-41dc-91b8-666bad92a92d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f968c9e2-3643-4492-b260-fcee152c565b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4bd4300c-5d29-47c0-a514-52be12987add
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3054b080-880f-4cbc-843e-ca67f9884c06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ed8c119-58c4-43eb-be5c-24d7c6f58921
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 084c7fcf-5599-4549-84d6-0037d3ebfb1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 602de0dd-4718-4a58-932f-e228f99ff235
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d53c9b5c-9e65-4b92-b84a-a8ca616e5b92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98add09e-c2f1-4c06-bf0c-015435d967a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16bffb46-715b-4611-9ec6-78c45a37ac27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0611b0e-dd71-406c-b3b3-62b8aba38345
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 274867fc-9e2a-466e-9d67-dde25a889f51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ddac804-b0d1-4d66-8738-9d32618ccd77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d54f08a1-5e8c-410b-9cc2-55180765a7e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message caaa511c-c607-40f1-bfef-fae1661838bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88829884-5f4a-4974-b5db-5c525ef018a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 477b3060-4a00-4cfd-bd00-bcd695691bd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c29dd859-5d7d-4b63-bcda-625b78bce0ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 557faf99-1400-497f-93e5-eeb9eff24ca6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1514a98a-98f4-49ae-aff6-ae5a4c1fb9ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message acc470cb-981c-4232-8fa5-d7d907defd16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f338261-fe0f-454d-97e4-34aada4e5ba9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 535acab7-b093-42f8-8a55-3e0a77f4f747
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3c1672c-3306-4038-a3b7-3a316f2e73c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b54f14e4-d5b1-4036-b59a-da65df9df38e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9d6a3de-f9ee-4c25-8bb9-14c2b5367d60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49bce4b1-76cd-4a45-b356-40e539fbb96a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e0ded21-e0b5-443c-a460-b444e31da554
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30fc0eda-0c51-44f1-8fd4-cf657ab2805e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15056072-f842-4e9c-8f7f-6b24e04d30d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c44336ac-7c75-4a46-a317-030b5f876065
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ff0fd3c-98f0-43f7-b687-22ed8ff3981f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b325b389-fba3-4af1-ad5e-44f60ff998cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae95bc49-20bc-4c43-9f99-0faa019d70f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4856a98d-c3f2-43aa-a964-1516b5f5094d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e84fac27-f93c-486a-982c-2743a90f2e0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2180a940-dcd5-473f-856e-1c654b2f2969
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36917a55-ac49-4142-9da8-2e777b31247f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f14f7ab-c6af-4576-92a0-dcae2d652185
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b298065b-f68f-45d7-8fea-37d398479a45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f40444e-eeb0-43d9-9f0d-ed8b45974591
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c2d9c58-fba7-4ee0-9784-933d864e9f91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b357d547-7a28-49d3-be33-251229908913
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee48d7cf-ba5a-4893-bdcb-8684e89f7e58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8bd61ffd-5b8b-4507-b994-f863804f992f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7fc8316-6e8d-4606-a2f3-0645fe4fda2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eda85199-dfc8-48d8-91c5-7891af5192e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 370a9d08-9155-4a13-b971-966f6d431104
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9e1df87-fb9f-446a-b2f9-fa911739219b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7f4bb33-b41c-4d2d-bcdc-f1c84ea6e705
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 025ac742-34ac-484b-b0e4-61a781e8c3eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b515331a-90e1-482e-829f-6346ab1d8779
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8eb81e2-9641-4e22-870d-29ea689001b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d1cdd49-ba35-4d2a-b2ed-f225e4ca5209
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61529d99-415a-4b2a-838b-553845c6b852
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0643a09-87e7-4532-995d-96d4c6290681
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a6c0c7f-839e-45f8-89ea-1716e63c485d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ae3e4bb-8aaa-4602-9e3b-0d3f891faf22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 869c5505-ff79-4cab-b8bc-93c4ca8614cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4e75320-0843-45d2-b649-2c65865d67a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d43b9e7-a36c-4cc5-9b4b-4611e1b03ce2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91391c71-7661-433b-a764-24c147e75b9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47dc11cf-2878-4af2-a539-bbebd08f2dc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05b9c483-5de2-428c-bcbb-431b2cf30a52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab292783-5009-4646-a48c-d822e513b618
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bdc00687-415d-4b07-bd32-ae0e62243552
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d6c387f-fcb1-4a6b-93ef-8e032e05dd1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0776fe7-b198-42b2-aae1-6e133c9ec006
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96837bfe-8c1d-4203-8b13-415396b42f31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c381b30-b9f2-45fc-aeed-55b5f4d9c5b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb45456b-749e-4bc6-aded-690f8d327fcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10d93a5d-8911-4196-adfc-66b199bd6d7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88c73f68-480f-4c89-b082-8ae752ede7bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d159b7e-172d-4c58-8fe8-6fef12cc1f2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62304767-a7ee-47f1-80f7-62c4f826c496
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf234c72-4b86-4743-8418-945587ff6e9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a48993f4-9b73-46eb-b16d-dac6a108df2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8326d0f-9c0a-4fb5-9992-023efb192500
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0430ed5f-6174-4bf4-8870-5756289c199a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57a44501-f231-4d5f-a172-1b2e44b896a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80a88978-1d78-4de3-8447-f8388e629f20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58164507-71a9-4037-a6a3-fc690ac1e818
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24c0331b-a5c4-449a-901d-6adb57b2bb6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5984788-142b-478b-9b66-e4c456f5550c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1875744e-0038-49ae-9b6d-c54019581a65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1dcafda3-6a9e-4362-9b0b-937a396454cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33e0672e-0445-42e3-a9c0-90fa1008a548
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c13fe16d-0e34-4e9e-a416-3b0a8827b68a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 348d9d9e-ed9a-4020-b6aa-c36c02db22ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eafe40fa-955c-455c-af97-65fe2a736d32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8370e1d-cd69-4e5f-bc5b-9791484a3fe8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9dc515d8-0486-49fd-b420-3c87d708507e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6a4256d-f3b1-4a77-ac52-b6e96630217b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08623e63-1534-4223-b7dd-2b76c7b583de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8286b0e6-3e2b-4608-8789-c712d2a6fa11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 904e27d8-68b3-4d31-b9f5-6d543ada5eb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b697d19-a6e2-40b5-ad59-89c0cf7360be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca36959f-39bd-4f95-8d97-0485faa29f81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a4e7d35-b715-4725-a2c5-62d1875ce263
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e256b712-d38c-45ca-b975-6c03fb911c90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 242f37d8-37d8-4bff-ba51-aeef7d0d690f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9145fc6f-f32e-409a-b27a-c3e9ed5c6ae9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d9e4ca0-0e57-4a81-b0af-30fddd168bcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c31f7cb2-4f58-402f-9518-3c8f77e72cc1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message faa618ba-7694-4553-818d-6040ca0f5cbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef337073-a125-4fc5-b7d9-90e7cfae24ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7dc2e077-9d2e-44d0-9ed8-e3d81f13289f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e593f090-92b2-45ae-bf85-0f7552da9429
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 756d53b2-f1ab-441d-96fc-148b422f776d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e505d471-839c-4646-a348-69bdcad1e815
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32a90426-7ac6-4f00-899b-6ba5b0c90ac8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58aae0f6-101c-4d60-b040-962ee7630450
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1d27a76-dbf2-4e61-b500-173601710d28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bfb84716-07c4-4958-875b-8a571d2a1eee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be41782e-aae1-49f5-9b96-6d6b1a21371c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4bc0fc5d-e1c7-422f-a606-524d303459b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c14d0214-746f-4ef2-8318-704efa831c85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1ba8e68-f975-4a82-914d-90def8fce63c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08225a4a-8a21-4497-9702-b0683bfc7e19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 177a08b5-a5f7-432a-a06e-4765ca6ed9d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0583d988-0bb2-4a96-992c-6f1b33efc284
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85cb63ea-e007-4b5c-bd34-f83562ddb16b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9cc61bde-680a-40a5-b01d-95a3d6118fd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e846d403-772c-4df8-abc5-b6e0cd2c3cf9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0541ae18-3995-44dc-85d9-a35cf3885f16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 571c12a9-36df-495a-b6d0-ec96c47a9e84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4fe2eaa-a866-45fb-a955-ad0df5f568b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb0ac7d0-84eb-4f3f-820d-da6e78ecfa00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f6375ac-c8f1-416e-bf2d-3a00d5a4ed28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51825ae3-8c75-41cc-9f60-e351a908ca00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b733b8c-7009-4b78-94b8-50961c413699
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c22a36fe-7b91-4404-975a-eeaf37620ed4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f92cd312-6f60-4884-8bb8-b299320f1ebf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de972046-1aaa-4b9a-90bb-3c44edca21bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab027a48-d475-4abe-8215-ba3ae02c61b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c34e0d7-2bc0-496a-8227-7f946b0d3e41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93123305-405e-4fbe-a687-b62ae1e2743a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c1491ef-d619-479f-9636-692e6f97e475
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2210e62e-7856-4845-a091-6175a7c915a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70fe7c60-e284-495f-88e2-82866b890fa3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ed42abd-08f8-4bf2-b0da-84e45b9df2f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e867037-d4c7-41eb-9a86-821c78d75c3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a27f6f84-df14-4f27-ad34-fc19323c7616
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e2354f3-46d1-49d9-8c7e-6845cb5090c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5cf6761a-f301-4ee6-84b7-ad7eddcfc587
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79d9d7a0-7b17-48a1-94b1-e45430bd1040
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c79a549f-daf5-4ca3-aada-0dbd7562b4d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8abc25e2-5600-4123-95c2-6b701f077cdf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae3ef7fd-c802-4c19-a13e-a06e7b82d51a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37210cd2-2e2b-4a1f-b22c-50905b9bb33b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72be6cb4-7a64-4b0f-9a66-1f12faf11946
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47dd21c8-9452-4cc7-9926-981d24932695
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a814e3d-2dab-4dfb-8f26-b9899f94dd0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08f843cc-48b4-417a-aec0-f39c18e79ffc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2fec2d8-75ac-4c2c-9409-09f7d2732fd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e963376a-6c0b-4773-852a-9f8ed3e118f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9704f3b9-a64b-4f91-8163-cbe07c27b0db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42acfc9b-ccf1-43ed-a4e0-9079bcc78302
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97ed21c0-fb18-4296-a43e-d9c2e11f5952
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e8a7461-1570-4a6d-8141-fbeda9d6340b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3c1b285-4b0f-48ef-9fee-db0b0f9ae05c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a52dc3e-2f41-4ec1-a838-6157fac8913e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf08f7cb-a5d9-4834-a7e3-60e86f022a66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c367a5a5-fde8-4106-8473-5c203dee8a0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0e25af2-52b2-466c-8146-c5c0b58e6c72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e456ec00-2a7c-45fc-a346-afd5c98bdfc1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7b56532-2410-4488-91d0-2dd6f5e39dc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19a6388c-e3de-4fdd-bac6-9a6045129c70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77c37f55-8cdf-424e-8a73-87d5ad85c337
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 768f3d19-fa31-4157-b31a-b5524e484767
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c1605f0-57b9-4351-a2f4-a02bf3577a31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c41a235e-545b-4d6c-a303-77521798963e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a5a45d1-fb86-4eef-9a0a-e36ef3b64b57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a00c1270-227f-4771-bdbc-1ec84d9c1abd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 720dd5b1-55be-4906-8f26-533066322512
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a8b022a-91e4-410e-996a-9f384a0d5e7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e379e8de-c383-4f05-8acd-924a2e9cfa46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa6d206c-bcb2-4886-8b66-86ce1f3898bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b2b82db-9e38-4aa5-ae50-f904890d3a89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64a60c00-4b30-4c9c-8eab-83de6a0ba408
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f865f1c5-06b7-4f55-bcb9-27c6ba0bee86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message daa5fe0d-b67e-4c78-808c-6ea829d0567f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e2153d8-6dfa-4657-8586-4c0895298850
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d639eefb-4fb7-4b92-971d-a9576e98830e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ecf2f4d-be85-4420-9af3-0c75ccf7863c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9ea35c3-42c6-4754-82dd-1c430a42062f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0daedd1-e331-4c6a-abc6-e1ff21943071
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b511532e-7f8d-4328-8321-1eba8d219bf0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 003553ba-8391-4288-8c72-6a5ba4027e52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42903105-ee1c-42d0-964c-5cf43bc78092
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06288a3e-b40a-4a4b-a0a1-878a8bde3c01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 919130e1-a199-43be-9eac-3e19084ca0fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce64a0b1-b389-4b23-a889-f28412668c93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e674ac35-13fc-43f4-95cb-863dc382f290
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81afc291-5a75-4b37-8f00-c8359494f4a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0205f84-1703-4419-842d-903195927c89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ccfa561-3a15-46b6-b6bf-0a1e2ca9e6d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd30b77a-9b23-4600-aa96-4fb9bdecb79f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae63e6a2-739b-4f28-963f-20bc5659c389
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e95c666-7c4a-4395-a961-670291dbd488
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ccfa85a6-2e48-47d6-8c5d-4fda9018bfeb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 733aa96a-8926-4dc6-b75f-665e25490904
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96eb664a-35cf-4a95-8f84-b21592968d18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d35d338-e9c5-42c5-8593-12e4cd1bb195
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6da40f6-5ff0-4efe-adeb-eee4efb3e34f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07c7c060-eaca-44ec-addf-d7b793799f1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6cdd2038-10e0-4500-8e2c-25592d415b50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e37acc89-e41b-47a4-9520-1b0c9d3b4002
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea3cc878-9401-4553-a4b2-c040912b946f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74a893e0-385e-4fb7-bd47-14d2140eb6a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5b0864e-95df-4bc7-9e76-e09f141a771f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e36c7e0-daed-479f-a09a-eee6c892b544
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c43a78ed-ba98-482d-8cb4-242df3234968
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1a426a0-0644-40d3-9b2b-9e6bfe9e28f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04cd2bfe-4e7b-4400-b24a-1d78757fdd71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad7aa3ed-3457-42cb-bc5e-56c4b0e9bb00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96982297-99f1-494e-941a-8238e47ca9f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b69612b6-dd2c-49f6-87c6-bcd4be16ea3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10805d6f-a4a9-443d-ac1d-94a4b1f85c76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5d706df-814d-4b81-98b7-b2b4df3f8313
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec77bcc6-c4cd-4752-b897-5507b027421c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ccba71c4-d7ad-4d71-b678-8d62fd1d09ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5bcd641d-cc86-4a58-8247-d5726a65ed84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 121f182b-0573-429b-85a4-2795bb713d85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 184e6eb0-dac7-475b-86ae-4bd687ee1ae0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1032abf-0a4c-4e07-8ff7-a6603d9677f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10f1f154-73e9-4586-9033-87500a79e9c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3d20488-55d5-430e-b07e-ddf4d0954e0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 079ee6ce-311c-4e06-bde6-d0f3134b0921
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00b8768c-e3b4-4df4-9844-e7c527584e8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19aa5a70-2976-40d7-862e-92e75b9d2b83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0492e97-0efe-493f-b624-71fa263ad645
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a617472a-6d1d-4e90-a281-90d776312052
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74707efd-9050-440d-94fe-c2636d8e8422
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e3630d4-ded4-4a43-868b-08b81ed77a90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25094f9a-7a91-449f-a1b3-f130af746bec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2145815e-227f-499e-8af5-430a65c8d8a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2078388-1a07-4656-8e2a-cc84d6b623f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea5862d0-e001-4cdf-b52c-051f68fbcb3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1de27ead-ce93-4045-907b-f3908ecb05fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a98063d-4339-4df6-acbe-acb492215c86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bca949e8-7340-451a-8ca0-eb806f64e37b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca12b4ab-7ebf-4298-9fc5-1028cc53d771
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71275c9c-682e-4113-b4b9-0e519efdb92e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b202c1b-36fc-4ac8-a39a-d870dbbe5a64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a097e1b-69e1-401e-8edf-26735182a2a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f515037f-08d3-4678-b963-c6fefedb48f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ccfd3cf0-3a87-494d-8934-95aa7a956665
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4bd476a5-e86f-4858-9e08-23419a8a8a38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b77e553b-e198-477a-9220-c4850b818803
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf254214-a4cd-4cf5-9f73-4f942d0874b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e443f20-a683-4dfc-8867-7d34c3551bf1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf67fa0c-03b7-435c-b14d-ca44d66b26d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c52c2f40-a26c-43ee-b576-a61636f57416
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4aba608a-98cf-46d1-8dcc-b49758393660
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 689d3ac5-3550-4d37-b7e9-f673be9d46cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d821683-c9ec-4ddf-8bb9-657817f493ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c97dcdb-4e5f-4bc4-a906-cc1e6662f0b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f61026fa-765d-4523-a930-12ce47e0e647
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3bb85fd-41ac-466a-87d2-167318b1dabb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8417c58e-9c55-488e-83b5-b1cde0291ec3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c55bcb26-92ae-4212-9264-9256387511c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00447ec3-8c95-4aa8-883c-90598e881069
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59c5a2f2-c75d-4c81-b7d6-1738f49a618a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b30f756-9565-458e-bfa7-932a0e138d4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db6e394a-a2db-4793-b872-8e628fb0646b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce00dc68-7ca1-4fb1-9423-29bef72dde8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b083b2d1-a231-4c4f-ab5b-e09d40c30fbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 382505ea-30ae-4aba-8367-56a71375c6da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 935334eb-5464-457f-be22-46882424d741
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 689a2763-db3d-4ee0-ad80-de09d51f9912
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b288bf79-d10b-4488-8b2f-7c80717eed08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53dede3e-8372-4569-ba97-74c5b3f5206f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad6af527-7481-4acb-9289-e3d6758aea5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5224b2e3-786a-49e8-8eb5-e9d50612f3a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44cc5c37-a9c2-45a7-a774-284e9b0f74de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd37a649-6d5d-4150-b81d-39e192a97907
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ba289eb-698c-400f-835c-14fdd5725abb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a800b6bb-0047-409c-8b85-8fe4bb5cde03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 412873d8-b958-4efc-a91a-ba1d1a46b240
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a774004a-abbe-49b1-8f0e-e4d7fb6ce2aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c066b54-65cb-4b60-b0b5-695ad1ded60a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04a09fd5-d1d4-406c-b1a9-075205f6f131
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8ab85f5-b989-4e7e-846d-02a896a0b9e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28b3df87-561a-41a8-9f41-1b99114bda3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 379d0f3c-c4f1-4960-86bc-83027e885582
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60ff1043-3e64-4e0e-a89f-09cb3572824d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 776bc74e-3341-4932-b2a3-672928563d48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 715f7257-2c10-4228-8b70-2adf55b10469
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65eb8cb9-342a-4b51-add6-0f4b024661a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bbd6423c-6f60-47ff-9239-037792665266
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62d2e46f-b226-408a-9224-7af78bd070d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f03e718-3197-4ebe-9b0a-0f8201f0e4e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34f26259-1937-4c0a-9491-013907adadb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8fe1ac52-b48e-475b-b716-d7dd2a441900
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70703308-74e6-4320-830c-4240295427d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c47f2bc9-71d7-4838-a149-063f6cf05a74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2b39fd9-b601-4edd-ba3f-4b566e2df098
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6fe3ec6e-43a6-42a6-bc2c-000a6c4e1a90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8de989c-6ce2-4fe7-939e-3121982ea865
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a31de9b-e16d-40c3-a73f-e2f24062851e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1040539-2e11-46f5-b7ce-98e7cfdbc0ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23c0175b-e02e-41fb-9d4d-ea9a52bbb356
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8772070-3b31-475b-9c65-cdf7e842eab8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e45076d9-3f1e-4461-907d-d8e51d2313fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9e2f44e-e232-4dba-9c70-47e33e4488ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fea6a533-a792-4db5-a071-c0c9f543ca50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54c92b92-2d59-4b42-a455-cfd9bc0ef74d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 891ddd76-a717-416b-8475-88d99199c395
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2957307a-2c69-4511-9c9b-ece74ee9c518
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00d00a2c-6f3b-48d7-88ad-8005a272daf8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f067df7-c724-430e-8c9b-d4eefac9e2d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2eaced31-ec8b-47cf-8d89-399224fba0f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f724066e-16ed-44be-aba4-cf7272f89092
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b0f0a06-6ac4-4cb6-a703-9d22a3b06967
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60975876-87b2-4110-a75f-7438aa42792a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1888951a-c7c8-4bfd-9a1a-6e521113e5ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a2c1708-fd3c-40e2-8cc5-2671d683562f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f969df9c-2aea-45d7-9b88-2c3e7acec19e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9209ef43-a018-4c95-9ad6-3f0dceed478b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 055deccf-66dd-4124-830b-8b3a1ba00670
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 843ae08a-6681-4ec7-9e0c-0c250397b790
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6f51a7b-8bc0-4907-86af-b5ab28db27d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c32b4164-505a-4b73-a58b-8f2acd54a079
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d254cc1a-56dd-47e7-b4ee-beeda1d95ef6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb9eb761-e67c-434b-8d14-66d5bc9dc2e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9965dae-9929-4db2-8f8c-e86eba9157d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae9e2a0c-0562-4622-96c8-abfbc4f0c63e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68264997-48c9-43b4-89e2-0c1b7b458efb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba791df8-5b61-4d75-bad8-ddd5b687d921
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5681e68-234d-4e5a-905d-068c6d0c1873
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4e688e9-9ac2-4e8b-92da-49785d15b669
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d31352e8-9a17-42be-a942-f2e891b7912f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1841fcf-d096-4388-8900-92734858ec45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6273d263-b006-44c0-a39a-a71e3e90e4c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0e56074-27ab-4144-9ad6-8a687879aa8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78b748d6-fe2a-44a1-8867-ddf7dbbf8973
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5efd52c-fb15-4e04-88dd-3b47db638051
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c2d49f9-6ce1-4e9c-a5ba-81d8047ef0a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77e20347-91a5-443d-b5d7-6fec2df38a0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0444779f-ec91-4933-be2f-ccbbc444b583
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d94c57ec-4080-4099-8448-6cd7eed3adad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b3ee663-7c29-4447-a112-6a3dd3b57d9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 102050d4-05e8-4317-b4d3-d8f5171258cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c230c03-99b0-410f-b17e-e9a2e2744ad0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ec1415c-2417-4917-bbd5-a4d0c794f551
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32228a59-cdf7-43be-a84d-b41de2a1e0a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 663823d2-eafd-4725-bdf5-83a1df4d1112
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb1e8305-1419-4c24-8049-3d2855026449
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87a36098-303b-4bba-8138-5accf2139903
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c8776c8-0bdc-45d6-a37a-549b7f0bd22c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b41114c7-a0dc-40b2-9c63-cfbaa46610dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 305f969d-b50b-45ed-9562-7a81dd037859
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aeb8b30e-ebaa-48bb-b7ed-5f9b28d3c272
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ce0dfe4-2bf2-4742-bb3b-49197289d962
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31d188ff-f54d-481b-8a24-9969fcfd6de9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef2064c3-de9c-438f-9ede-c95026199b6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d7492b7-eb01-401c-86a5-612c8279b0fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a3e2a0a-04be-44b6-a829-6469c805c1d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a660425-7a4a-4ae5-a079-6f8764ac111b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c0ec085-48fc-4f70-a50e-2e7fbc280bb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99825ae3-7b6d-40f7-9e69-ec92b3cd643a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6dc2ee7-8b39-4926-ad74-d2b8c1d2021d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55592a5e-05c3-4b33-a221-ec180b9e0b08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d08fafd-4941-49c4-89a6-b4534e3a42cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6248d588-2d7e-4e65-bd04-586704778ff5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c67a0e17-e1e0-4fec-8cf1-bf82d30828de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae76be0f-77a7-4005-b5c0-571802267af1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4b3330b-ebaa-4457-9506-cf451ca64d82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87e3b807-932d-4784-a716-70a39b955fb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eccd5c89-a3de-4d0e-9fcc-4f9a6d742878
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87a6f1c4-c983-42ff-9c30-f3b9cadf0a14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5340bc44-f67b-4c91-b302-efdd30c37ef2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 113bd1ab-ba40-4469-8222-d787bef7fae5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98f8e556-8b4c-47df-a18a-9b9175b21c2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d550df3-8ab7-4181-87cc-f8619bd0a4ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5aaa1aa-8d0f-4a12-9948-c59bbccf8475
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f0f9b4d-35fd-431d-9110-0f00c25913c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7b7a8f7-d5d9-41cc-a205-c2d9504fb2cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14046579-d712-4203-bc25-90dd6f6fe175
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff092589-9b3a-45d5-912b-398ff9342bb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 740a5a6e-786c-4bc3-89d0-fea2992d28d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0406832-e37c-411c-ae06-cb3a2788bf4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a2cde9c-f201-49a5-95ae-43e20f5fd28c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f9c6332-f18b-403f-83f6-919ef01f03a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6544f793-30e7-43f4-8588-7226a35a0461
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ef08b6a-f371-4227-bf69-dddfcfda588a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f734747-3505-4411-8cd7-6fc47a19aa40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f23472e-81c4-459c-baea-eb24b10a5d0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bed628a0-6f87-4dda-bd1a-448db00392c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dcbfff08-7501-42d6-9a6c-7029211eccf3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7fa8b968-f6f1-4913-9bb2-f5b9d470e092
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd8f335a-a0cf-496c-983e-38bc95cf888a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4abcac96-12be-4d30-a9f7-1561ebc0425f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd6b29ea-8b0a-4f3f-9152-fa01ce778b04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da3aee20-9214-4767-b8e8-102bbb5549cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fdb0242f-8e35-408c-b9f0-6b72c740ef19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e6756a4-88ac-4e6f-b2b6-9abe87915c16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2488978a-f9e1-4e80-aede-816eae57ec66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13501a97-7964-42da-877c-89f4f47e61d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24cd47b2-ac59-425b-84c8-ba349e03f2f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e1cf64f-19b3-4149-8f12-14069c6602e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e1678e4-672e-4f33-9986-b04065a9f7ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df8c04bd-4020-45cb-ae42-819566781e8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6b4deff-277e-42eb-8210-29c7a977e7d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b6c4e22-c7cf-4dce-81a4-5ec6082dc279
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dfc7a0b7-fa2b-4381-adb6-1f741ab39535
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93fc0161-2929-495c-8911-596eca0e8ca5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62d1d1e3-6828-44c9-a65a-cd37975bb8fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f248f907-2bac-4aa5-90cf-05f3d948921b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97980858-64c4-43d9-a12c-1e9e64e4e947
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1cacc140-c08c-4225-b8a8-3de5e63e0b79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ca765ad-47ac-479c-97e7-6eba013447ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b9448d5-07ca-47c6-9b82-8f3a28dcd9eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9db52eaa-a65d-4ac0-9064-e9211c0217d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f4bb894-20b9-4871-bafb-77fce651a2a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73bf1899-ecdb-47cf-ab7d-5a2f44b235fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0d044a7-bad0-42d7-a2c4-73b96e24ede5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 580fe95e-1765-4900-b033-631b364b9f94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6982c69-3c21-4485-a3ee-c4db2fe881fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c7efb9d-c155-46e9-9f80-e03f3039a808
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ede0bca-f73e-4c09-8f06-23394a9771b6
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8692 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_3
Server: localhost:8692
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_3
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_3/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_3/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_3/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_3/test_labels.txt

📊 Raw data loaded:
   Train: X=(4483, 24), y=(4483,)
   Test:  X=(1121, 24), y=(1121,)

⚠️  Limiting training data: 4483 → 800 samples
⚠️  Limiting test data: 1121 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_3 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 1 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.3560, val=0.1847 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.1039, val=0.0991 (↓), lr=0.001000
   ✓ Epoch   3/100: train=0.0866, val=0.0814 (↓), lr=0.001000
   • Epoch   4/100: train=0.0804, val=0.0868, patience=1/15, lr=0.001000
   • Epoch   5/100: train=0.0814, val=0.0852, patience=2/15, lr=0.001000
   📉 Epoch 9: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0803, val=0.0856, patience=8/15, lr=0.000500
   📉 Epoch 17: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 1 Summary - Client client_3
   Epochs: 18/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0031
   Val:   Loss=0.0814, RMSE=0.2854, R²=-0.0186
============================================================


============================================================
🔄 Round 2 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.4436, val=0.4564 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.3513, val=0.3657 (↓), lr=0.000250
   ✓ Epoch   3/100: train=0.2494, val=0.2167 (↓), lr=0.000250
   ✓ Epoch   4/100: train=0.1083, val=0.0897 (↓), lr=0.000250
   • Epoch   5/100: train=0.0809, val=0.0904, patience=1/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0785, val=0.0916, patience=7/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 2 Summary - Client client_3
   Epochs: 19/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=-0.0041
   Val:   Loss=0.0897, RMSE=0.2995, R²=-0.0101
============================================================


📊 Round 2 Test Metrics:
   Loss: 0.4996, RMSE: 0.7068, MAE: 0.6457, R²: -5.0369

============================================================
🔄 Round 6 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.4625, val=0.4881 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.4219, val=0.4485 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.3883, val=0.4156 (↓), lr=0.000063
   📉 Epoch 4: LR reduced 0.000063 → 0.000031
   ✓ Epoch   4/100: train=0.3584, val=0.3841 (↓), lr=0.000031
   ✓ Epoch   5/100: train=0.3362, val=0.3682 (↓), lr=0.000031
   ✓ Epoch  11/100: train=0.2193, val=0.2355 (↓), lr=0.000031
   📉 Epoch 12: LR reduced 0.000031 → 0.000016
   📉 Epoch 20: LR reduced 0.000016 → 0.000008
   ✓ Epoch  21/100: train=0.0997, val=0.1116 (↓), lr=0.000008
   📉 Epoch 28: LR reduced 0.000008 → 0.000004
   ✓ Epoch  31/100: train=0.0858, val=0.0940 (↓), lr=0.000004
   📉 Epoch 36: LR reduced 0.000004 → 0.000002
   • Epoch  41/100: train=0.0832, val=0.0901, patience=1/15, lr=0.000002
   📉 Epoch 44: LR reduced 0.000002 → 0.000001
   • Epoch  51/100: train=0.0825, val=0.0889, patience=3/15, lr=0.000001
   • Epoch  61/100: train=0.0820, val=0.0880, patience=1/15, lr=0.000001
   • Epoch  71/100: train=0.0816, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  81/100: train=0.0813, val=0.0866, patience=6/15, lr=0.000001
   • Epoch  91/100: train=0.0811, val=0.0861, patience=7/15, lr=0.000001

============================================================
📊 Round 6 Summary - Client client_3
   Epochs: 100/100
   LR: 0.000063 → 0.000001 (6 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0033
   Val:   Loss=0.0856, RMSE=0.2927, R²=-0.0448
============================================================


============================================================
🔄 Round 7 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.4861, val=0.4526 (↓), lr=0.000001
   ✓ Epoch   2/100: train=0.4850, val=0.4515 (↓), lr=0.000001
   ✓ Epoch   3/100: train=0.4839, val=0.4505 (↓), lr=0.000001
   ✓ Epoch   4/100: train=0.4829, val=0.4497 (↓), lr=0.000001
   ✓ Epoch   5/100: train=0.4821, val=0.4489 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.4778, val=0.4449 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.4724, val=0.4398 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.4678, val=0.4355 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.4637, val=0.4316 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.4599, val=0.4280 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.4563, val=0.4246 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.4528, val=0.4213 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.4494, val=0.4180 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.4460, val=0.4148 (↓), lr=0.000001

============================================================
📊 Round 7 Summary - Client client_3
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.4435, RMSE=0.6659, R²=-4.4648
   Val:   Loss=0.4120, RMSE=0.6419, R²=-4.1073
============================================================


📊 Round 7 Test Metrics:
   Loss: 0.4869, RMSE: 0.6978, MAE: 0.6358, R²: -4.8837

📊 Round 7 Test Metrics:
   Loss: 0.4690, RMSE: 0.6849, MAE: 0.6216, R²: -4.6675

============================================================
🔄 Round 12 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.4401, val=0.4225 (↓), lr=0.000001
   • Epoch   2/100: train=0.4397, val=0.4220, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.4392, val=0.4216 (↓), lr=0.000001
   • Epoch   4/100: train=0.4388, val=0.4211, patience=1/15, lr=0.000001
   ✓ Epoch   5/100: train=0.4383, val=0.4207 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.4356, val=0.4181 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.4313, val=0.4139 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.4271, val=0.4098 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.4230, val=0.4057 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.4188, val=0.4016 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.4147, val=0.3976 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.4106, val=0.3935 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.4064, val=0.3895 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.4022, val=0.3854 (↓), lr=0.000001

============================================================
📊 Round 12 Summary - Client client_3
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.3986, RMSE=0.6313, R²=-3.9045
   Val:   Loss=0.3817, RMSE=0.6178, R²=-3.7363
============================================================


============================================================
🔄 Round 13 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.4122, val=0.4430 (↓), lr=0.000001
   • Epoch   2/100: train=0.4118, val=0.4426, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.4114, val=0.4422 (↓), lr=0.000001
   • Epoch   4/100: train=0.4110, val=0.4418, patience=1/15, lr=0.000001
   ✓ Epoch   5/100: train=0.4107, val=0.4414 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.4083, val=0.4390 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.4045, val=0.4350 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.4006, val=0.4310 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.3966, val=0.4269 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.3927, val=0.4228 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.3886, val=0.4187 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.3846, val=0.4144 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.3804, val=0.4101 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.3762, val=0.4058 (↓), lr=0.000001

============================================================
📊 Round 13 Summary - Client client_3
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.3714, RMSE=0.6094, R²=-3.6124
   Val:   Loss=0.4018, RMSE=0.6339, R²=-3.8253
============================================================


============================================================
🔄 Round 15 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.3836, val=0.3279 (↓), lr=0.000001
   • Epoch   2/100: train=0.3831, val=0.3275, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.3826, val=0.3270 (↓), lr=0.000001
   • Epoch   4/100: train=0.3821, val=0.3266, patience=1/15, lr=0.000001
   ✓ Epoch   5/100: train=0.3817, val=0.3262 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.3788, val=0.3236 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.3741, val=0.3193 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.3693, val=0.3150 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.3646, val=0.3106 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.3598, val=0.3063 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.3550, val=0.3019 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.3501, val=0.2975 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.3453, val=0.2931 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.3404, val=0.2887 (↓), lr=0.000001

============================================================
📊 Round 15 Summary - Client client_3
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.3361, RMSE=0.5798, R²=-3.1065
   Val:   Loss=0.2846, RMSE=0.5335, R²=-2.7183
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.3575, RMSE: 0.5979, MAE: 0.5241, R²: -3.3192

============================================================
🔄 Round 16 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.3590, val=0.2927 (↓), lr=0.000001
   • Epoch   2/100: train=0.3586, val=0.2923, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.3581, val=0.2919 (↓), lr=0.000001
   • Epoch   4/100: train=0.3577, val=0.2915, patience=1/15, lr=0.000001
   ✓ Epoch   5/100: train=0.3572, val=0.2910 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.3545, val=0.2886 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.3499, val=0.2846 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.3452, val=0.2804 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.3406, val=0.2763 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.3358, val=0.2721 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.3310, val=0.2678 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.3261, val=0.2635 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.3211, val=0.2591 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.3160, val=0.2546 (↓), lr=0.000001

============================================================
📊 Round 16 Summary - Client client_3
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.3115, RMSE=0.5582, R²=-2.7347
   Val:   Loss=0.2505, RMSE=0.5005, R²=-2.5888
============================================================


============================================================
🔄 Round 19 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.2651, val=0.2899 (↓), lr=0.000001
   ✓ Epoch   2/100: train=0.2645, val=0.2891 (↓), lr=0.000001
   ✓ Epoch   3/100: train=0.2638, val=0.2884 (↓), lr=0.000001
   ✓ Epoch   4/100: train=0.2632, val=0.2877 (↓), lr=0.000001
   ✓ Epoch   5/100: train=0.2625, val=0.2870 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.2585, val=0.2827 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.2519, val=0.2756 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.2453, val=0.2684 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.2386, val=0.2612 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.2319, val=0.2539 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.2251, val=0.2465 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.2183, val=0.2391 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.2115, val=0.2317 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.2047, val=0.2243 (↓), lr=0.000001

============================================================
📊 Round 19 Summary - Client client_3
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1979, RMSE=0.4449, R²=-1.4124
   Val:   Loss=0.2176, RMSE=0.4665, R²=-1.8354
============================================================


============================================================
🔄 Round 20 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.2318, val=0.2408 (↓), lr=0.000001
   ✓ Epoch   2/100: train=0.2312, val=0.2402 (↓), lr=0.000001
   ✓ Epoch   3/100: train=0.2306, val=0.2396 (↓), lr=0.000001
   ✓ Epoch   4/100: train=0.2300, val=0.2389 (↓), lr=0.000001
   ✓ Epoch   5/100: train=0.2293, val=0.2383 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.2256, val=0.2344 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.2193, val=0.2279 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.2128, val=0.2213 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.2063, val=0.2146 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.1998, val=0.2079 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.1932, val=0.2011 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.1867, val=0.1944 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.1802, val=0.1876 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.1737, val=0.1809 (↓), lr=0.000001

============================================================
📊 Round 20 Summary - Client client_3
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1678, RMSE=0.4096, R²=-1.0732
   Val:   Loss=0.1749, RMSE=0.4183, R²=-1.1332
============================================================


============================================================
🔄 Round 21 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1971, val=0.1988 (↓), lr=0.000001
   ✓ Epoch   2/100: train=0.1965, val=0.1982 (↓), lr=0.000001
   ✓ Epoch   3/100: train=0.1958, val=0.1975 (↓), lr=0.000001
   ✓ Epoch   4/100: train=0.1951, val=0.1969 (↓), lr=0.000001
   ✓ Epoch   5/100: train=0.1944, val=0.1962 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.1904, val=0.1924 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.1838, val=0.1860 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.1771, val=0.1797 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.1706, val=0.1735 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.1641, val=0.1674 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.1578, val=0.1614 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.1516, val=0.1555 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.1456, val=0.1498 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.1397, val=0.1443 (↓), lr=0.000001

============================================================
📊 Round 21 Summary - Client client_3
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1345, RMSE=0.3667, R²=-0.7004
   Val:   Loss=0.1396, RMSE=0.3736, R²=-0.5617
============================================================


============================================================
🔄 Round 22 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1705, val=0.1575 (↓), lr=0.000001
   ✓ Epoch   2/100: train=0.1698, val=0.1569 (↓), lr=0.000001
   ✓ Epoch   3/100: train=0.1691, val=0.1563 (↓), lr=0.000001
   ✓ Epoch   4/100: train=0.1684, val=0.1557 (↓), lr=0.000001
   ✓ Epoch   5/100: train=0.1678, val=0.1551 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.1638, val=0.1515 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.1572, val=0.1457 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.1509, val=0.1401 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.1448, val=0.1347 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.1390, val=0.1296 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.1333, val=0.1247 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.1280, val=0.1201 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.1229, val=0.1158 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.1181, val=0.1117 (↓), lr=0.000001

============================================================
📊 Round 22 Summary - Client client_3
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1137, RMSE=0.3372, R²=-0.4220
   Val:   Loss=0.1083, RMSE=0.3291, R²=-0.2700
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.1166, RMSE: 0.3415, MAE: 0.2834, R²: -0.4089

============================================================
🔄 Round 24 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1044, val=0.1376 (↓), lr=0.000001
   ✓ Epoch   2/100: train=0.1041, val=0.1371 (↓), lr=0.000001
   • Epoch   3/100: train=0.1038, val=0.1366, patience=1/15, lr=0.000001
   ✓ Epoch   4/100: train=0.1034, val=0.1361 (↓), lr=0.000001
   • Epoch   5/100: train=0.1031, val=0.1356, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.1012, val=0.1327, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.0982, val=0.1281, patience=1/15, lr=0.000001
   • Epoch  31/100: train=0.0955, val=0.1238, patience=1/15, lr=0.000001
   • Epoch  41/100: train=0.0931, val=0.1197, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.0908, val=0.1159, patience=1/15, lr=0.000001
   • Epoch  61/100: train=0.0889, val=0.1125, patience=1/15, lr=0.000001
   • Epoch  71/100: train=0.0872, val=0.1093, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.0857, val=0.1064, patience=1/15, lr=0.000001
   • Epoch  91/100: train=0.0844, val=0.1038, patience=1/15, lr=0.000001

============================================================
📊 Round 24 Summary - Client client_3
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0464
   Val:   Loss=0.1017, RMSE=0.3190, R²=-0.2348
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0958, RMSE: 0.3095, MAE: 0.2626, R²: -0.1578

============================================================
🔄 Round 26 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 26 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0240
   Val:   Loss=0.0825, RMSE=0.2873, R²=0.0023
============================================================


============================================================
🔄 Round 27 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 27 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0059
   Val:   Loss=0.0830, RMSE=0.2882, R²=-0.0218
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2507, R²: -0.0166

============================================================
🔄 Round 29 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 29 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=-0.0074
   Val:   Loss=0.0863, RMSE=0.2937, R²=0.0039
============================================================


============================================================
🔄 Round 30 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 30 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0028
   Val:   Loss=0.0791, RMSE=0.2813, R²=-0.0008
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2501, R²: -0.0110

============================================================
🔄 Round 32 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 32 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0002
   Val:   Loss=0.0787, RMSE=0.2805, R²=-0.0052
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2500, R²: -0.0103

📊 Round 32 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2500, R²: -0.0101

============================================================
🔄 Round 35 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 35 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=-0.0020
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0025
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2499, R²: -0.0098

📊 Round 35 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2499, R²: -0.0097

============================================================
🔄 Round 37 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 37 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0001
   Val:   Loss=0.0777, RMSE=0.2788, R²=-0.0171
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2499, R²: -0.0096

📊 Round 37 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2499, R²: -0.0095

📊 Round 37 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2499, R²: -0.0093

============================================================
🔄 Round 41 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 41 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0012
   Val:   Loss=0.0748, RMSE=0.2735, R²=0.0073
============================================================


============================================================
🔄 Round 43 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 43 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0010
   Val:   Loss=0.0834, RMSE=0.2887, R²=0.0058
============================================================


============================================================
🔄 Round 44 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 44 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=-0.0001
   Val:   Loss=0.0863, RMSE=0.2938, R²=0.0002
============================================================


============================================================
🔄 Round 47 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 47 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0023
   Val:   Loss=0.0837, RMSE=0.2894, R²=-0.0042
============================================================


📊 Round 47 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2497, R²: -0.0080

============================================================
🔄 Round 49 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0678 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0678, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0679, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0679, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0679, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0681, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0678)

============================================================
📊 Round 49 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0034
   Val:   Loss=0.0678, RMSE=0.2604, R²=-0.0035
============================================================


============================================================
🔄 Round 51 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 51 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=-0.0003
   Val:   Loss=0.0782, RMSE=0.2796, R²=0.0083
============================================================


============================================================
🔄 Round 52 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 52 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0018
   Val:   Loss=0.0816, RMSE=0.2856, R²=-0.0014
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0834, RMSE: 0.2887, MAE: 0.2496, R²: -0.0074

============================================================
🔄 Round 54 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 54 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0016
   Val:   Loss=0.0814, RMSE=0.2854, R²=0.0134
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0833, RMSE: 0.2887, MAE: 0.2496, R²: -0.0070

📊 Round 54 Test Metrics:
   Loss: 0.0833, RMSE: 0.2887, MAE: 0.2496, R²: -0.0070

📊 Round 54 Test Metrics:
   Loss: 0.0833, RMSE: 0.2887, MAE: 0.2496, R²: -0.0070

============================================================
🔄 Round 57 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 57 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0038
   Val:   Loss=0.0861, RMSE=0.2935, R²=-0.0242
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0833, RMSE: 0.2886, MAE: 0.2496, R²: -0.0067

📊 Round 57 Test Metrics:
   Loss: 0.0833, RMSE: 0.2886, MAE: 0.2495, R²: -0.0064

============================================================
🔄 Round 62 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 62 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0028
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0046
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0833, RMSE: 0.2886, MAE: 0.2495, R²: -0.0064

📊 Round 62 Test Metrics:
   Loss: 0.0833, RMSE: 0.2886, MAE: 0.2495, R²: -0.0062

============================================================
🔄 Round 65 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 65 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0014
   Val:   Loss=0.0736, RMSE=0.2714, R²=0.0105
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0833, RMSE: 0.2886, MAE: 0.2495, R²: -0.0062

============================================================
🔄 Round 66 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 66 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0039
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0076
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0833, RMSE: 0.2886, MAE: 0.2495, R²: -0.0062

============================================================
🔄 Round 71 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 71 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0005
   Val:   Loss=0.0887, RMSE=0.2978, R²=0.0057
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0833, RMSE: 0.2886, MAE: 0.2495, R²: -0.0061

📊 Round 71 Test Metrics:
   Loss: 0.0833, RMSE: 0.2886, MAE: 0.2495, R²: -0.0061

📊 Round 71 Test Metrics:
   Loss: 0.0833, RMSE: 0.2886, MAE: 0.2495, R²: -0.0061

============================================================
🔄 Round 74 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 74 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0026
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0312
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0833, RMSE: 0.2886, MAE: 0.2495, R²: -0.0061

📊 Round 74 Test Metrics:
   Loss: 0.0833, RMSE: 0.2886, MAE: 0.2495, R²: -0.0061

============================================================
🔄 Round 77 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 77 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0024
   Val:   Loss=0.0747, RMSE=0.2733, R²=-0.0019
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0833, RMSE: 0.2886, MAE: 0.2495, R²: -0.0061

============================================================
🔄 Round 78 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 78 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2843, R²=0.0011
   Val:   Loss=0.0818, RMSE=0.2859, R²=0.0016
============================================================


============================================================
🔄 Round 79 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 79 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0055
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0286
============================================================


============================================================
🔄 Round 81 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 81 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0030
   Val:   Loss=0.0893, RMSE=0.2988, R²=-0.0344
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0833, RMSE: 0.2886, MAE: 0.2495, R²: -0.0061

============================================================
🔄 Round 84 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 84 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0005
   Val:   Loss=0.0771, RMSE=0.2777, R²=0.0103
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0833, RMSE: 0.2886, MAE: 0.2495, R²: -0.0061

📊 Round 84 Test Metrics:
   Loss: 0.0833, RMSE: 0.2885, MAE: 0.2494, R²: -0.0060

============================================================
🔄 Round 87 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 87 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0036
   Val:   Loss=0.0903, RMSE=0.3006, R²=-0.0059
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0833, RMSE: 0.2885, MAE: 0.2495, R²: -0.0060

============================================================
🔄 Round 91 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 91 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0019
   Val:   Loss=0.0753, RMSE=0.2744, R²=-0.0119
============================================================


============================================================
🔄 Round 93 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 93 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0014
   Val:   Loss=0.0819, RMSE=0.2861, R²=-0.0090
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0833, RMSE: 0.2885, MAE: 0.2495, R²: -0.0060

============================================================
🔄 Round 94 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 94 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=-0.0002
   Val:   Loss=0.0901, RMSE=0.3001, R²=0.0012
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0833, RMSE: 0.2885, MAE: 0.2495, R²: -0.0060

📊 Round 94 Test Metrics:
   Loss: 0.0833, RMSE: 0.2885, MAE: 0.2495, R²: -0.0060

============================================================
🔄 Round 97 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 97 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0021
   Val:   Loss=0.0771, RMSE=0.2776, R²=-0.0090
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0833, RMSE: 0.2885, MAE: 0.2494, R²: -0.0060

============================================================
🔄 Round 98 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 98 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0004
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0061
============================================================


============================================================
🔄 Round 99 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 99 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0022
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0001
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0833, RMSE: 0.2886, MAE: 0.2495, R²: -0.0061

============================================================
🔄 Round 100 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 100 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=0.0001
   Val:   Loss=0.0829, RMSE=0.2880, R²=0.0079
============================================================


============================================================
🔄 Round 101 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 101 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0019
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0005
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0833, RMSE: 0.2886, MAE: 0.2495, R²: -0.0062

============================================================
🔄 Round 102 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0931 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0931, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0931, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0931, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0931, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0932, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0931)

============================================================
📊 Round 102 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0018
   Val:   Loss=0.0931, RMSE=0.3051, R²=-0.0074
============================================================


============================================================
🔄 Round 103 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 103 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0032
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0056
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0833, RMSE: 0.2886, MAE: 0.2495, R²: -0.0063

============================================================
🔄 Round 104 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 104 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0000
   Val:   Loss=0.0832, RMSE=0.2885, R²=0.0065
============================================================


============================================================
🔄 Round 105 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 105 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0005
   Val:   Loss=0.0907, RMSE=0.3011, R²=-0.0014
============================================================


============================================================
🔄 Round 106 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 106 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0017
   Val:   Loss=0.0798, RMSE=0.2824, R²=-0.0212
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0833, RMSE: 0.2886, MAE: 0.2495, R²: -0.0062

📊 Round 106 Test Metrics:
   Loss: 0.0833, RMSE: 0.2886, MAE: 0.2495, R²: -0.0061

📊 Round 106 Test Metrics:
   Loss: 0.0833, RMSE: 0.2885, MAE: 0.2495, R²: -0.0060

============================================================
🔄 Round 112 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 112 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0006
   Val:   Loss=0.0726, RMSE=0.2694, R²=-0.0075
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0833, RMSE: 0.2885, MAE: 0.2494, R²: -0.0059

📊 Round 112 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2494, R²: -0.0059

📊 Round 112 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2494, R²: -0.0058

📊 Round 112 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2494, R²: -0.0057

============================================================
🔄 Round 120 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 120 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0001
   Val:   Loss=0.0836, RMSE=0.2892, R²=-0.0042
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2494, R²: -0.0057

📊 Round 120 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2494, R²: -0.0056

📊 Round 120 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2494, R²: -0.0056

============================================================
🔄 Round 125 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 125 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0010
   Val:   Loss=0.0823, RMSE=0.2868, R²=-0.0097
============================================================


============================================================
🔄 Round 129 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 129 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2849, R²=0.0014
   Val:   Loss=0.0806, RMSE=0.2840, R²=0.0020
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2494, R²: -0.0054

============================================================
🔄 Round 131 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 131 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=0.0010
   Val:   Loss=0.0882, RMSE=0.2970, R²=0.0004
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2493, R²: -0.0053

============================================================
🔄 Round 132 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 132 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0002
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0050
============================================================


============================================================
🔄 Round 134 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 134 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0033
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0140
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2494, R²: -0.0054

============================================================
🔄 Round 136 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0718 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0717, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0717, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0717, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0717, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0717, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 136 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0020
   Val:   Loss=0.0718, RMSE=0.2679, R²=-0.0009
============================================================


============================================================
🔄 Round 139 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 139 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0005
   Val:   Loss=0.0805, RMSE=0.2838, R²=-0.0067
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0053

============================================================
🔄 Round 142 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 142 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0015
   Val:   Loss=0.0862, RMSE=0.2935, R²=0.0020
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0053

============================================================
🔄 Round 144 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 144 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0007
   Val:   Loss=0.0783, RMSE=0.2799, R²=0.0067
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2493, R²: -0.0053

============================================================
🔄 Round 145 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 145 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0007
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0092
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2493, R²: -0.0053

📊 Round 145 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0053

============================================================
🔄 Round 150 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 150 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0021
   Val:   Loss=0.0809, RMSE=0.2844, R²=-0.0006
============================================================


============================================================
🔄 Round 154 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0711 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0711, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0711, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0711, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0711, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0711, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0711)

============================================================
📊 Round 154 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0017
   Val:   Loss=0.0711, RMSE=0.2666, R²=0.0007
============================================================


============================================================
🔄 Round 155 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 155 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=0.0049
   Val:   Loss=0.0749, RMSE=0.2738, R²=-0.0182
============================================================


============================================================
🔄 Round 156 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 156 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0018
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.0007
============================================================


============================================================
🔄 Round 159 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 159 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0015
   Val:   Loss=0.0726, RMSE=0.2694, R²=0.0108
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2494, R²: -0.0054

📊 Round 159 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0053

============================================================
🔄 Round 161 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 161 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0028
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0025
============================================================


============================================================
🔄 Round 162 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 162 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0012
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0115
============================================================


============================================================
🔄 Round 164 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 164 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0022
   Val:   Loss=0.0770, RMSE=0.2774, R²=-0.0018
============================================================


============================================================
🔄 Round 165 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 165 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0002
   Val:   Loss=0.0863, RMSE=0.2938, R²=0.0089
============================================================


============================================================
🔄 Round 167 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 167 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0008
   Val:   Loss=0.0732, RMSE=0.2705, R²=0.0130
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2493, R²: -0.0052

============================================================
🔄 Round 171 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 171 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0027
   Val:   Loss=0.0801, RMSE=0.2829, R²=-0.0037
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2493, R²: -0.0051

============================================================
🔄 Round 172 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 172 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2843, R²=0.0000
   Val:   Loss=0.0817, RMSE=0.2859, R²=0.0078
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2493, R²: -0.0051

============================================================
🔄 Round 173 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 173 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0020
   Val:   Loss=0.0775, RMSE=0.2784, R²=0.0001
============================================================


============================================================
🔄 Round 174 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 174 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0016
   Val:   Loss=0.0754, RMSE=0.2746, R²=-0.0021
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2493, R²: -0.0052

============================================================
🔄 Round 175 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 175 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=0.0030
   Val:   Loss=0.0781, RMSE=0.2795, R²=-0.0144
============================================================


============================================================
🔄 Round 177 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 177 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0008
   Val:   Loss=0.0876, RMSE=0.2960, R²=0.0049
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2493, R²: -0.0051

📊 Round 177 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2493, R²: -0.0051

============================================================
🔄 Round 181 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 181 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0034
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0059
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2493, R²: -0.0050

============================================================
🔄 Round 184 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 184 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0015
   Val:   Loss=0.0778, RMSE=0.2790, R²=0.0013
============================================================


============================================================
🔄 Round 185 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 185 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=-0.0016
   Val:   Loss=0.0879, RMSE=0.2965, R²=0.0066
============================================================


============================================================
🔄 Round 188 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0924 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0924, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0924, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 188 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0024
   Val:   Loss=0.0924, RMSE=0.3039, R²=-0.0023
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2493, R²: -0.0049

📊 Round 188 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2493, R²: -0.0049

============================================================
🔄 Round 196 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 196 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0002
   Val:   Loss=0.0843, RMSE=0.2903, R²=0.0071
============================================================


============================================================
🔄 Round 197 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 197 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0014
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0001
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2493, R²: -0.0049

📊 Round 197 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2493, R²: -0.0049

============================================================
🔄 Round 205 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 205 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0020
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0013
============================================================


============================================================
🔄 Round 206 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 206 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0001
   Val:   Loss=0.0834, RMSE=0.2888, R²=0.0054
============================================================


============================================================
🔄 Round 207 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 207 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0009
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0079
============================================================


============================================================
🔄 Round 208 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 208 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0027
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0298
============================================================


📊 Round 208 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2493, R²: -0.0049

============================================================
🔄 Round 210 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 210 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0009
   Val:   Loss=0.0748, RMSE=0.2735, R²=-0.0061
============================================================


📊 Round 210 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2493, R²: -0.0049

============================================================
🔄 Round 212 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0934 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0934, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0934, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0934, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0934, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0935, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0934)

============================================================
📊 Round 212 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2792, R²=0.0021
   Val:   Loss=0.0934, RMSE=0.3056, R²=-0.0066
============================================================


📊 Round 212 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2493, R²: -0.0050

============================================================
🔄 Round 214 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 214 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0010
   Val:   Loss=0.0891, RMSE=0.2985, R²=-0.0027
============================================================


📊 Round 214 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2493, R²: -0.0050

============================================================
🔄 Round 215 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 215 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0018
   Val:   Loss=0.0861, RMSE=0.2933, R²=-0.0006
============================================================


📊 Round 215 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2493, R²: -0.0050

📊 Round 215 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2493, R²: -0.0050

============================================================
🔄 Round 224 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 224 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0035
   Val:   Loss=0.0783, RMSE=0.2798, R²=-0.0062
============================================================


📊 Round 224 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2493, R²: -0.0049

📊 Round 224 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2493, R²: -0.0049

📊 Round 224 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2493, R²: -0.0047

📊 Round 224 Test Metrics:
   Loss: 0.0831, RMSE: 0.2884, MAE: 0.2493, R²: -0.0047

============================================================
🔄 Round 237 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 237 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0025
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0057
============================================================


📊 Round 237 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2493, R²: -0.0046

📊 Round 237 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2493, R²: -0.0047

📊 Round 237 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2493, R²: -0.0046

============================================================
🔄 Round 244 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 244 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=-0.0009
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0027
============================================================


============================================================
🔄 Round 246 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 246 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0040
   Val:   Loss=0.0823, RMSE=0.2868, R²=-0.0090
============================================================


📊 Round 246 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2492, R²: -0.0045

📊 Round 246 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2492, R²: -0.0046

📊 Round 246 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2492, R²: -0.0046

============================================================
🔄 Round 250 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 250 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0008
   Val:   Loss=0.0835, RMSE=0.2890, R²=0.0036
============================================================


============================================================
🔄 Round 251 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 251 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0026
   Val:   Loss=0.0846, RMSE=0.2908, R²=-0.0059
============================================================


============================================================
🔄 Round 253 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 253 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0013
   Val:   Loss=0.0744, RMSE=0.2727, R²=-0.0258
============================================================


📊 Round 253 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2492, R²: -0.0046

============================================================
🔄 Round 255 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 255 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0019
   Val:   Loss=0.0751, RMSE=0.2741, R²=-0.0087
============================================================


============================================================
🔄 Round 256 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 256 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0012
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0110
============================================================


📊 Round 256 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2492, R²: -0.0046

============================================================
🔄 Round 259 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 259 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=-0.0025
   Val:   Loss=0.0911, RMSE=0.3019, R²=-0.0316
============================================================


📊 Round 259 Test Metrics:
   Loss: 0.0831, RMSE: 0.2884, MAE: 0.2493, R²: -0.0047

📊 Round 259 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2492, R²: -0.0046

📊 Round 259 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2492, R²: -0.0046

📊 Round 259 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2492, R²: -0.0045

============================================================
🔄 Round 264 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 264 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2822, R²=0.0020
   Val:   Loss=0.0865, RMSE=0.2941, R²=0.0003
============================================================


============================================================
🔄 Round 265 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0954 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0954, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0955, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0955, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0955, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0958, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0954)

============================================================
📊 Round 265 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2783, R²=-0.0013
   Val:   Loss=0.0954, RMSE=0.3088, R²=-0.0185
============================================================


============================================================
🔄 Round 266 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 266 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0031
   Val:   Loss=0.0830, RMSE=0.2882, R²=-0.0037
============================================================


============================================================
🔄 Round 270 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 270 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=-0.0000
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.0044
============================================================


📊 Round 270 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2493, R²: -0.0046

📊 Round 270 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2492, R²: -0.0045

============================================================
🔄 Round 278 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 278 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=-0.0009
   Val:   Loss=0.0871, RMSE=0.2951, R²=0.0087
============================================================


============================================================
🔄 Round 279 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 279 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2842, R²=0.0002
   Val:   Loss=0.0822, RMSE=0.2867, R²=0.0075
============================================================


📊 Round 279 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2492, R²: -0.0043

============================================================
🔄 Round 286 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 286 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0015
   Val:   Loss=0.0835, RMSE=0.2890, R²=0.0023
============================================================


============================================================
🔄 Round 287 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 287 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=0.0016
   Val:   Loss=0.0919, RMSE=0.3031, R²=-0.0031
============================================================


============================================================
🔄 Round 288 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 288 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0010
   Val:   Loss=0.0791, RMSE=0.2812, R²=0.0039
============================================================


============================================================
🔄 Round 289 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 289 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0003
   Val:   Loss=0.0753, RMSE=0.2745, R²=-0.0435
============================================================


📊 Round 289 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2492, R²: -0.0042

============================================================
🔄 Round 291 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0670 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0670, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0670, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0670, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0670, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0670, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0670)

============================================================
📊 Round 291 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0014
   Val:   Loss=0.0670, RMSE=0.2589, R²=0.0021
============================================================


📊 Round 291 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2492, R²: -0.0041

📊 Round 291 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2492, R²: -0.0041

📊 Round 291 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2492, R²: -0.0041

📊 Round 291 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2492, R²: -0.0041

============================================================
🔄 Round 299 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 299 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0017
   Val:   Loss=0.0736, RMSE=0.2712, R²=0.0008
============================================================


============================================================
🔄 Round 302 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 302 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0019
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0004
============================================================


📊 Round 302 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2492, R²: -0.0042

📊 Round 302 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2492, R²: -0.0042

============================================================
🔄 Round 309 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 309 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0027
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0029
============================================================


============================================================
🔄 Round 311 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 311 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0000
   Val:   Loss=0.0780, RMSE=0.2792, R²=0.0053
============================================================


📊 Round 311 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2492, R²: -0.0042

📊 Round 311 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2492, R²: -0.0042

📊 Round 311 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2492, R²: -0.0041

============================================================
🔄 Round 319 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 319 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0001
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0375
============================================================


============================================================
🔄 Round 320 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 320 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0001
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0060
============================================================


============================================================
🔄 Round 322 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 322 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0012
   Val:   Loss=0.0889, RMSE=0.2981, R²=0.0029
============================================================


📊 Round 322 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2492, R²: -0.0041

📊 Round 322 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2492, R²: -0.0042

📊 Round 322 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2492, R²: -0.0041

============================================================
🔄 Round 331 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 331 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0027
   Val:   Loss=0.0836, RMSE=0.2892, R²=-0.0040
============================================================


📊 Round 331 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2491, R²: -0.0039

📊 Round 331 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2491, R²: -0.0039

============================================================
🔄 Round 337 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 337 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0003
   Val:   Loss=0.0844, RMSE=0.2904, R²=0.0057
============================================================


📊 Round 337 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2491, R²: -0.0039

============================================================
🔄 Round 338 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 338 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0010
   Val:   Loss=0.0792, RMSE=0.2814, R²=0.0091
============================================================


📊 Round 338 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2491, R²: -0.0039

📊 Round 338 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2491, R²: -0.0039

📊 Round 338 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2491, R²: -0.0039

============================================================
🔄 Round 341 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 341 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0012
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0072
============================================================


📊 Round 341 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2492, R²: -0.0040

============================================================
🔄 Round 343 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 343 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0021
   Val:   Loss=0.0897, RMSE=0.2994, R²=-0.0263
============================================================


📊 Round 343 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2492, R²: -0.0040

============================================================
🔄 Round 344 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 344 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0014
   Val:   Loss=0.0785, RMSE=0.2801, R²=0.0015
============================================================


============================================================
🔄 Round 345 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 345 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0017
   Val:   Loss=0.0904, RMSE=0.3007, R²=0.0018
============================================================


============================================================
🔄 Round 346 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 346 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0014
   Val:   Loss=0.0766, RMSE=0.2767, R²=0.0103
============================================================


📊 Round 346 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2492, R²: -0.0040

============================================================
🔄 Round 349 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 349 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0028
   Val:   Loss=0.0869, RMSE=0.2949, R²=-0.0050
============================================================


📊 Round 349 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2491, R²: -0.0039

============================================================
🔄 Round 351 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 351 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0033
   Val:   Loss=0.0909, RMSE=0.3016, R²=-0.0045
============================================================


============================================================
🔄 Round 353 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 353 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0008
   Val:   Loss=0.0805, RMSE=0.2838, R²=0.0051
============================================================


📊 Round 353 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2491, R²: -0.0039

============================================================
🔄 Round 354 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 354 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0028
   Val:   Loss=0.0833, RMSE=0.2887, R²=-0.0081
============================================================


📊 Round 354 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2491, R²: -0.0039

============================================================
🔄 Round 355 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 355 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0020
   Val:   Loss=0.0872, RMSE=0.2953, R²=0.0004
============================================================


============================================================
🔄 Round 357 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 357 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0004
   Val:   Loss=0.0879, RMSE=0.2965, R²=0.0055
============================================================


============================================================
🔄 Round 358 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 358 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0042
   Val:   Loss=0.0882, RMSE=0.2970, R²=-0.0083
============================================================


📊 Round 358 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2492, R²: -0.0040

📊 Round 358 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2492, R²: -0.0040

============================================================
🔄 Round 365 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 365 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0006
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0266
============================================================


📊 Round 365 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2492, R²: -0.0042

📊 Round 365 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2492, R²: -0.0041

📊 Round 365 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2492, R²: -0.0041

📊 Round 365 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2492, R²: -0.0041

============================================================
🔄 Round 372 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 372 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=-0.0009
   Val:   Loss=0.0883, RMSE=0.2971, R²=-0.0006
============================================================


📊 Round 372 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2492, R²: -0.0041

============================================================
🔄 Round 375 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 375 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0028
   Val:   Loss=0.0781, RMSE=0.2795, R²=-0.0030
============================================================


============================================================
🔄 Round 376 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 376 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=-0.0006
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0061
============================================================


📊 Round 376 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2492, R²: -0.0042

📊 Round 376 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2492, R²: -0.0040

📊 Round 376 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2492, R²: -0.0041

============================================================
🔄 Round 385 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 385 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0024
   Val:   Loss=0.0753, RMSE=0.2744, R²=-0.0206
============================================================


📊 Round 385 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2492, R²: -0.0041

============================================================
🔄 Round 386 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 386 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0016
   Val:   Loss=0.0750, RMSE=0.2739, R²=-0.0008
============================================================


📊 Round 386 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2492, R²: -0.0041

============================================================
🔄 Round 387 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 387 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0008
   Val:   Loss=0.0775, RMSE=0.2783, R²=0.0050
============================================================


============================================================
🔄 Round 388 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0717 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0717, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0717, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0717, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0717, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0717, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0717)

============================================================
📊 Round 388 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0007
   Val:   Loss=0.0717, RMSE=0.2678, R²=0.0058
============================================================


📊 Round 388 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2492, R²: -0.0040

============================================================
🔄 Round 394 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 394 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0003
   Val:   Loss=0.0761, RMSE=0.2758, R²=0.0009
============================================================


📊 Round 394 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0039

============================================================
🔄 Round 396 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 396 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0019
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0277
============================================================


============================================================
🔄 Round 397 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 397 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0022
   Val:   Loss=0.0839, RMSE=0.2896, R²=-0.0006
============================================================


📊 Round 397 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0039

============================================================
🔄 Round 398 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 398 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0001
   Val:   Loss=0.0783, RMSE=0.2799, R²=0.0001
============================================================


📊 Round 398 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0039

============================================================
🔄 Round 401 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 401 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0011
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0029
============================================================


📊 Round 401 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2491, R²: -0.0038

============================================================
🔄 Round 406 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 406 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0029
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0039
============================================================


📊 Round 406 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2491, R²: -0.0037

============================================================
🔄 Round 407 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 407 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0021
   Val:   Loss=0.0786, RMSE=0.2803, R²=-0.0010
============================================================


📊 Round 407 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2491, R²: -0.0037

============================================================
🔄 Round 408 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 408 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0016
   Val:   Loss=0.0877, RMSE=0.2962, R²=-0.0001
============================================================


============================================================
🔄 Round 409 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0707 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0707, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0707, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0707, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0707, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0707, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0707)

============================================================
📊 Round 409 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=0.0028
   Val:   Loss=0.0707, RMSE=0.2659, R²=-0.0097
============================================================


📊 Round 409 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2491, R²: -0.0036

============================================================
🔄 Round 412 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 412 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=-0.0006
   Val:   Loss=0.0749, RMSE=0.2737, R²=-0.0476
============================================================


============================================================
🔄 Round 414 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 414 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=-0.0001
   Val:   Loss=0.0876, RMSE=0.2959, R²=-0.0031
============================================================


============================================================
🔄 Round 416 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 416 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0025
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0022
============================================================


📊 Round 416 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2491, R²: -0.0037

============================================================
🔄 Round 417 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0723, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0723, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 417 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0009
   Val:   Loss=0.0723, RMSE=0.2689, R²=-0.0300
============================================================


============================================================
🔄 Round 418 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 418 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0019
   Val:   Loss=0.0849, RMSE=0.2913, R²=-0.0009
============================================================


📊 Round 418 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2491, R²: -0.0038

📊 Round 418 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2491, R²: -0.0037

============================================================
🔄 Round 423 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 423 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0007
   Val:   Loss=0.0828, RMSE=0.2877, R²=0.0040
============================================================


============================================================
🔄 Round 424 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 424 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0015
   Val:   Loss=0.0794, RMSE=0.2819, R²=-0.0034
============================================================


📊 Round 424 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2491, R²: -0.0036

============================================================
🔄 Round 432 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 432 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0019
   Val:   Loss=0.0791, RMSE=0.2813, R²=-0.0036
============================================================


📊 Round 432 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2491, R²: -0.0036

📊 Round 432 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2491, R²: -0.0036

📊 Round 432 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2491, R²: -0.0036

============================================================
🔄 Round 435 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 435 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0000
   Val:   Loss=0.0773, RMSE=0.2781, R²=-0.0029
============================================================


📊 Round 435 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2491, R²: -0.0035

============================================================
🔄 Round 438 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 438 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0003
   Val:   Loss=0.0784, RMSE=0.2799, R²=-0.0070
============================================================


============================================================
🔄 Round 439 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 439 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0014
   Val:   Loss=0.0752, RMSE=0.2742, R²=0.0023
============================================================


📊 Round 439 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2491, R²: -0.0035

============================================================
🔄 Round 441 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 441 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0002
   Val:   Loss=0.0783, RMSE=0.2799, R²=-0.0146
============================================================


============================================================
🔄 Round 444 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 444 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0009
   Val:   Loss=0.0773, RMSE=0.2780, R²=-0.0089
============================================================


📊 Round 444 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2491, R²: -0.0036

============================================================
🔄 Round 445 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0930 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0930, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0930, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0930, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0930, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0930, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0930)

============================================================
📊 Round 445 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=0.0029
   Val:   Loss=0.0930, RMSE=0.3049, R²=-0.0029
============================================================


📊 Round 445 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2491, R²: -0.0036

============================================================
🔄 Round 447 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 447 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0004
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0278
============================================================


📊 Round 447 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2491, R²: -0.0036

============================================================
🔄 Round 451 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 451 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0003
   Val:   Loss=0.0737, RMSE=0.2714, R²=-0.0176
============================================================


📊 Round 451 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2491, R²: -0.0036

============================================================
🔄 Round 453 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 453 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0003
   Val:   Loss=0.0753, RMSE=0.2745, R²=0.0097
============================================================


📊 Round 453 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2491, R²: -0.0035

============================================================
🔄 Round 455 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 455 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=0.0002
   Val:   Loss=0.0763, RMSE=0.2761, R²=0.0050
============================================================


📊 Round 455 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2491, R²: -0.0035

📊 Round 455 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2491, R²: -0.0035

📊 Round 455 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2491, R²: -0.0035

============================================================
🔄 Round 460 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 460 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0022
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0063
============================================================


📊 Round 460 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2491, R²: -0.0035

============================================================
🔄 Round 463 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 463 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0003
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0202
============================================================


============================================================
🔄 Round 465 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 465 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0005
   Val:   Loss=0.0895, RMSE=0.2992, R²=0.0048
============================================================


📊 Round 465 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2491, R²: -0.0034

============================================================
🔄 Round 466 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 466 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0002
   Val:   Loss=0.0757, RMSE=0.2751, R²=0.0016
============================================================


📊 Round 466 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2491, R²: -0.0034

============================================================
🔄 Round 468 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 468 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0015
   Val:   Loss=0.0749, RMSE=0.2737, R²=-0.0060
============================================================


📊 Round 468 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2491, R²: -0.0034

============================================================
🔄 Round 469 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 469 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0012
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0003
============================================================


📊 Round 469 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2491, R²: -0.0034

============================================================
🔄 Round 470 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 470 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0001
   Val:   Loss=0.0819, RMSE=0.2861, R²=0.0032
============================================================


============================================================
🔄 Round 472 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 472 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0014
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0101
============================================================


📊 Round 472 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2491, R²: -0.0034

============================================================
🔄 Round 474 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 474 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0003
   Val:   Loss=0.0791, RMSE=0.2813, R²=0.0034
============================================================


📊 Round 474 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2491, R²: -0.0035

============================================================
🔄 Round 476 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 476 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0001
   Val:   Loss=0.0799, RMSE=0.2826, R²=-0.0165
============================================================


============================================================
🔄 Round 477 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 477 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0016
   Val:   Loss=0.0869, RMSE=0.2947, R²=0.0010
============================================================


📊 Round 477 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2491, R²: -0.0034

============================================================
🔄 Round 482 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 482 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0004
   Val:   Loss=0.0772, RMSE=0.2779, R²=0.0070
============================================================


📊 Round 482 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2491, R²: -0.0033

============================================================
🔄 Round 484 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 484 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0016
   Val:   Loss=0.0847, RMSE=0.2910, R²=0.0013
============================================================


📊 Round 484 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2491, R²: -0.0033

📊 Round 484 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2491, R²: -0.0033

============================================================
🔄 Round 487 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 487 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0018
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0041
============================================================


📊 Round 487 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2491, R²: -0.0033

📊 Round 487 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2491, R²: -0.0033

============================================================
🔄 Round 492 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 492 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2863, R²=0.0008
   Val:   Loss=0.0774, RMSE=0.2783, R²=-0.0064
============================================================


📊 Round 492 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2491, R²: -0.0033

============================================================
🔄 Round 494 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 494 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0014
   Val:   Loss=0.0784, RMSE=0.2800, R²=-0.0000
============================================================


📊 Round 494 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2491, R²: -0.0033

📊 Round 494 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2491, R²: -0.0033

============================================================
🔄 Round 499 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 499 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0006
   Val:   Loss=0.0881, RMSE=0.2967, R²=0.0033
============================================================


📊 Round 499 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2491, R²: -0.0033

📊 Round 499 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2491, R²: -0.0033

============================================================
🔄 Round 503 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 503 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0004
   Val:   Loss=0.0788, RMSE=0.2807, R²=0.0089
============================================================


============================================================
🔄 Round 508 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 508 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0025
   Val:   Loss=0.0833, RMSE=0.2887, R²=-0.0028
============================================================


📊 Round 508 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2491, R²: -0.0032

============================================================
🔄 Round 509 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 509 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0023
   Val:   Loss=0.0740, RMSE=0.2720, R²=-0.0051
============================================================


============================================================
🔄 Round 511 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 511 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0017
   Val:   Loss=0.0801, RMSE=0.2830, R²=0.0005
============================================================


📊 Round 511 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2491, R²: -0.0032

============================================================
🔄 Round 512 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0936 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0936, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0936, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0936, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0936, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0936, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0936)

============================================================
📊 Round 512 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0018
   Val:   Loss=0.0936, RMSE=0.3060, R²=0.0001
============================================================


📊 Round 512 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2491, R²: -0.0032

============================================================
🔄 Round 513 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 513 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0015
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.0044
============================================================


============================================================
🔄 Round 514 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 514 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0012
   Val:   Loss=0.0822, RMSE=0.2868, R²=0.0024
============================================================


============================================================
🔄 Round 517 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0711 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0711, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0712, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0712, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0712, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0713, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0711)

============================================================
📊 Round 517 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0004
   Val:   Loss=0.0711, RMSE=0.2666, R²=-0.0304
============================================================


📊 Round 517 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2491, R²: -0.0032

📊 Round 517 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2491, R²: -0.0031

============================================================
🔄 Round 520 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 520 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0017
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0109
============================================================


============================================================
🔄 Round 521 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 521 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0025
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0026
============================================================


============================================================
🔄 Round 522 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 522 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0019
   Val:   Loss=0.0753, RMSE=0.2744, R²=-0.0055
============================================================


📊 Round 522 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2491, R²: -0.0031

============================================================
🔄 Round 524 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 524 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=0.0009
   Val:   Loss=0.0814, RMSE=0.2854, R²=-0.0092
============================================================


============================================================
🔄 Round 525 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 525 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0011
   Val:   Loss=0.0795, RMSE=0.2820, R²=0.0006
============================================================


📊 Round 525 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2490, R²: -0.0030

============================================================
🔄 Round 529 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 529 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=0.0013
   Val:   Loss=0.0914, RMSE=0.3023, R²=0.0016
============================================================


============================================================
🔄 Round 530 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 530 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0025
   Val:   Loss=0.0809, RMSE=0.2844, R²=-0.0035
============================================================


📊 Round 530 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2491, R²: -0.0031

============================================================
🔄 Round 532 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0924 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0924, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0924, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 532 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=0.0018
   Val:   Loss=0.0924, RMSE=0.3040, R²=-0.0034
============================================================


📊 Round 532 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2491, R²: -0.0032

📊 Round 532 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2491, R²: -0.0033

============================================================
🔄 Round 538 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 538 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=0.0005
   Val:   Loss=0.0766, RMSE=0.2767, R²=-0.0178
============================================================


📊 Round 538 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2491, R²: -0.0031

📊 Round 538 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2491, R²: -0.0031

============================================================
🔄 Round 541 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 541 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0001
   Val:   Loss=0.0778, RMSE=0.2789, R²=-0.0038
============================================================


📊 Round 541 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2490, R²: -0.0030

============================================================
🔄 Round 542 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 542 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0012
   Val:   Loss=0.0782, RMSE=0.2796, R²=0.0014
============================================================


📊 Round 542 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2490, R²: -0.0030

📊 Round 542 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2490, R²: -0.0030

📊 Round 542 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2491, R²: -0.0031

============================================================
🔄 Round 545 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 545 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0018
   Val:   Loss=0.0766, RMSE=0.2767, R²=-0.0060
============================================================


============================================================
🔄 Round 548 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 548 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0015
   Val:   Loss=0.0786, RMSE=0.2804, R²=-0.0015
============================================================


📊 Round 548 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2491, R²: -0.0031

============================================================
🔄 Round 550 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 550 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0006
   Val:   Loss=0.0792, RMSE=0.2814, R²=0.0047
============================================================


============================================================
🔄 Round 551 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 551 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0031
   Val:   Loss=0.0816, RMSE=0.2856, R²=-0.0072
============================================================


📊 Round 551 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2491, R²: -0.0031

============================================================
🔄 Round 553 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 553 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0027
   Val:   Loss=0.0730, RMSE=0.2701, R²=-0.0042
============================================================


📊 Round 553 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2490, R²: -0.0030

============================================================
🔄 Round 554 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 554 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0007
   Val:   Loss=0.0833, RMSE=0.2886, R²=0.0040
============================================================


📊 Round 554 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2490, R²: -0.0030

============================================================
🔄 Round 555 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 555 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0018
   Val:   Loss=0.0779, RMSE=0.2791, R²=-0.0020
============================================================


============================================================
🔄 Round 557 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0934 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0934, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0935, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0935, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0935, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0935, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0934)

============================================================
📊 Round 557 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2792, R²=0.0019
   Val:   Loss=0.0934, RMSE=0.3057, R²=-0.0051
============================================================


============================================================
🔄 Round 558 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 558 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0007
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0019
============================================================


📊 Round 558 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2491, R²: -0.0030

📊 Round 558 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2491, R²: -0.0030

📊 Round 558 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2491, R²: -0.0030

📊 Round 558 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2490, R²: -0.0030

📊 Round 558 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2490, R²: -0.0029

📊 Round 558 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2490, R²: -0.0030

============================================================
🔄 Round 570 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 570 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=0.0012
   Val:   Loss=0.0731, RMSE=0.2703, R²=-0.0248
============================================================


============================================================
🔄 Round 572 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 572 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0009
   Val:   Loss=0.0749, RMSE=0.2737, R²=-0.0076
============================================================


📊 Round 572 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2491, R²: -0.0030

📊 Round 572 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2490, R²: -0.0029

============================================================
🔄 Round 578 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 578 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0007
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0042
============================================================


============================================================
🔄 Round 579 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 579 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0001
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0069
============================================================


============================================================
🔄 Round 586 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 586 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=0.0014
   Val:   Loss=0.0915, RMSE=0.3025, R²=-0.0003
============================================================


============================================================
🔄 Round 587 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 587 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0004
   Val:   Loss=0.0833, RMSE=0.2886, R²=0.0033
============================================================


============================================================
🔄 Round 590 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 590 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0022
   Val:   Loss=0.0813, RMSE=0.2852, R²=-0.0033
============================================================


📊 Round 590 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2490, R²: -0.0028

============================================================
🔄 Round 593 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0695 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0695, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0695, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0695, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0695, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0695, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0695)

============================================================
📊 Round 593 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0022
   Val:   Loss=0.0695, RMSE=0.2637, R²=-0.0045
============================================================


📊 Round 593 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2490, R²: -0.0027

📊 Round 593 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2490, R²: -0.0027

============================================================
🔄 Round 597 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 597 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=0.0004
   Val:   Loss=0.0815, RMSE=0.2854, R²=0.0022
============================================================


📊 Round 597 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2490, R²: -0.0027

📊 Round 597 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2490, R²: -0.0028

============================================================
🔄 Round 601 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 601 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0016
   Val:   Loss=0.0782, RMSE=0.2796, R²=-0.0009
============================================================


📊 Round 601 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2490, R²: -0.0028

📊 Round 601 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2490, R²: -0.0028

============================================================
🔄 Round 605 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 605 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0004
   Val:   Loss=0.0743, RMSE=0.2727, R²=-0.0291
============================================================


📊 Round 605 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2490, R²: -0.0028

============================================================
🔄 Round 608 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 608 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=0.0032
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0163
============================================================


📊 Round 608 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2490, R²: -0.0027

============================================================
🔄 Round 609 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 609 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0013
   Val:   Loss=0.0765, RMSE=0.2766, R²=0.0011
============================================================


📊 Round 609 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2490, R²: -0.0027

============================================================
🔄 Round 612 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 612 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0003
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.0057
============================================================


📊 Round 612 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2490, R²: -0.0028

============================================================
🔄 Round 613 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 613 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0018
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0101
============================================================


============================================================
🔄 Round 615 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 615 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2871, R²=0.0023
   Val:   Loss=0.0754, RMSE=0.2747, R²=-0.0033
============================================================


============================================================
🔄 Round 617 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 617 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0005
   Val:   Loss=0.0772, RMSE=0.2779, R²=0.0042
============================================================


============================================================
🔄 Round 618 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 618 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0001
   Val:   Loss=0.0732, RMSE=0.2706, R²=0.0052
============================================================


📊 Round 618 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2490, R²: -0.0028

============================================================
🔄 Round 620 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 620 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0017
   Val:   Loss=0.0800, RMSE=0.2828, R²=-0.0054
============================================================


📊 Round 620 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2490, R²: -0.0027

============================================================
🔄 Round 623 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 623 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0011
   Val:   Loss=0.0738, RMSE=0.2716, R²=-0.0127
============================================================


============================================================
🔄 Round 624 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 624 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0017
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0075
============================================================


📊 Round 624 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2490, R²: -0.0027

============================================================
🔄 Round 625 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 625 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0009
   Val:   Loss=0.0730, RMSE=0.2701, R²=-0.0056
============================================================


📊 Round 625 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2490, R²: -0.0027

📊 Round 625 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2490, R²: -0.0028

============================================================
🔄 Round 629 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 629 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0010
   Val:   Loss=0.0854, RMSE=0.2923, R²=0.0017
============================================================


📊 Round 629 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2490, R²: -0.0027

============================================================
🔄 Round 631 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 631 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0004
   Val:   Loss=0.0757, RMSE=0.2752, R²=-0.0084
============================================================


📊 Round 631 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2490, R²: -0.0027

📊 Round 631 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2490, R²: -0.0027

============================================================
🔄 Round 638 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 638 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=0.0005
   Val:   Loss=0.0843, RMSE=0.2904, R²=0.0041
============================================================


📊 Round 638 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2490, R²: -0.0027

📊 Round 638 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2490, R²: -0.0026

============================================================
🔄 Round 640 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 640 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0003
   Val:   Loss=0.0765, RMSE=0.2766, R²=-0.0126
============================================================


============================================================
🔄 Round 641 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 641 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0033
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0097
============================================================


📊 Round 641 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2490, R²: -0.0026

📊 Round 641 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2490, R²: -0.0026

============================================================
🔄 Round 645 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 645 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0021
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.0037
============================================================


📊 Round 645 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2490, R²: -0.0026

📊 Round 645 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2490, R²: -0.0026

============================================================
🔄 Round 648 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 648 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=-0.0003
   Val:   Loss=0.0875, RMSE=0.2958, R²=0.0066
============================================================


📊 Round 648 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2490, R²: -0.0026

============================================================
🔄 Round 650 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 650 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=0.0004
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0233
============================================================


============================================================
🔄 Round 651 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 651 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0023
   Val:   Loss=0.0768, RMSE=0.2772, R²=-0.0047
============================================================


📊 Round 651 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2490, R²: -0.0026

📊 Round 651 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2490, R²: -0.0025

============================================================
🔄 Round 654 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 654 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0020
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0311
============================================================


============================================================
🔄 Round 655 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 655 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0006
   Val:   Loss=0.0852, RMSE=0.2920, R²=0.0046
============================================================


============================================================
🔄 Round 659 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0691 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0691, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0691, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0691, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0691, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0691, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0691)

============================================================
📊 Round 659 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0007
   Val:   Loss=0.0691, RMSE=0.2628, R²=-0.0011
============================================================


📊 Round 659 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2490, R²: -0.0026

============================================================
🔄 Round 660 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 660 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0007
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.0009
============================================================


============================================================
🔄 Round 662 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 662 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0014
   Val:   Loss=0.0857, RMSE=0.2928, R²=-0.0250
============================================================


📊 Round 662 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2490, R²: -0.0028

📊 Round 662 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2490, R²: -0.0027

============================================================
🔄 Round 669 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 669 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0001
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0187
============================================================


📊 Round 669 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2490, R²: -0.0027

📊 Round 669 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2490, R²: -0.0026

============================================================
🔄 Round 672 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 672 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=0.0011
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0106
============================================================


📊 Round 672 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2490, R²: -0.0026

============================================================
🔄 Round 673 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 673 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0010
   Val:   Loss=0.0858, RMSE=0.2929, R²=0.0026
============================================================


============================================================
🔄 Round 674 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 674 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0003
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0442
============================================================


============================================================
🔄 Round 677 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 677 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0021
   Val:   Loss=0.0833, RMSE=0.2887, R²=-0.0024
============================================================


📊 Round 677 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2490, R²: -0.0025

============================================================
🔄 Round 679 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 679 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=0.0006
   Val:   Loss=0.0751, RMSE=0.2740, R²=-0.0313
============================================================


📊 Round 679 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2490, R²: -0.0025

============================================================
🔄 Round 680 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 680 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0003
   Val:   Loss=0.0872, RMSE=0.2953, R²=0.0015
============================================================


📊 Round 680 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2490, R²: -0.0025

📊 Round 680 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2490, R²: -0.0025

============================================================
🔄 Round 682 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 682 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=0.0012
   Val:   Loss=0.0799, RMSE=0.2826, R²=-0.0017
============================================================


📊 Round 682 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2490, R²: -0.0025

============================================================
🔄 Round 689 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 689 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0004
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0038
============================================================


📊 Round 689 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2490, R²: -0.0024

📊 Round 689 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2490, R²: -0.0024

📊 Round 689 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2490, R²: -0.0024

============================================================
🔄 Round 692 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 692 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0006
   Val:   Loss=0.0857, RMSE=0.2928, R²=-0.0092
============================================================


============================================================
🔄 Round 693 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 693 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0008
   Val:   Loss=0.0863, RMSE=0.2937, R²=0.0013
============================================================


============================================================
🔄 Round 694 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 694 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0008
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0037
============================================================


📊 Round 694 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2490, R²: -0.0025

============================================================
🔄 Round 696 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 696 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0014
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0096
============================================================


============================================================
🔄 Round 697 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 697 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2843, R²=-0.0006
   Val:   Loss=0.0819, RMSE=0.2862, R²=0.0085
============================================================


📊 Round 697 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2490, R²: -0.0026

📊 Round 697 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2490, R²: -0.0026

============================================================
🔄 Round 702 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 702 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0006
   Val:   Loss=0.0806, RMSE=0.2840, R²=-0.0144
============================================================


============================================================
🔄 Round 703 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 703 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0022
   Val:   Loss=0.0816, RMSE=0.2856, R²=-0.0021
============================================================


============================================================
🔄 Round 704 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 704 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0009
   Val:   Loss=0.0803, RMSE=0.2833, R²=0.0032
============================================================


📊 Round 704 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2490, R²: -0.0026

============================================================
🔄 Round 705 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 705 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0002
   Val:   Loss=0.0745, RMSE=0.2729, R²=0.0024
============================================================


📊 Round 705 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2490, R²: -0.0026

📊 Round 705 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2490, R²: -0.0025

📊 Round 705 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2490, R²: -0.0026

📊 Round 705 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2490, R²: -0.0026

============================================================
🔄 Round 709 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 709 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0008
   Val:   Loss=0.0766, RMSE=0.2767, R²=0.0023
============================================================


============================================================
🔄 Round 710 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 710 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=-0.0005
   Val:   Loss=0.0887, RMSE=0.2978, R²=0.0052
============================================================


============================================================
🔄 Round 712 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 712 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0015
   Val:   Loss=0.0766, RMSE=0.2768, R²=-0.0151
============================================================


📊 Round 712 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2490, R²: -0.0026

============================================================
🔄 Round 713 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 713 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0003
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0050
============================================================


============================================================
🔄 Round 714 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0678 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0678, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0678, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0678, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0678, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0678, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0678)

============================================================
📊 Round 714 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0023
   Val:   Loss=0.0678, RMSE=0.2604, R²=-0.0039
============================================================


📊 Round 714 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2490, R²: -0.0026

============================================================
🔄 Round 716 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 716 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0005
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0047
============================================================


📊 Round 716 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2490, R²: -0.0026

============================================================
🔄 Round 719 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0928 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0928, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0928, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0929, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0929, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0929, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0928)

============================================================
📊 Round 719 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0009
   Val:   Loss=0.0928, RMSE=0.3047, R²=-0.0044
============================================================


📊 Round 719 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2490, R²: -0.0026

📊 Round 719 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2490, R²: -0.0026

📊 Round 719 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2490, R²: -0.0025

============================================================
🔄 Round 725 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 725 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0001
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0123
============================================================


📊 Round 725 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2490, R²: -0.0025

============================================================
🔄 Round 727 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 727 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0007
   Val:   Loss=0.0870, RMSE=0.2949, R²=-0.0034
============================================================


============================================================
🔄 Round 729 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 729 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=0.0017
   Val:   Loss=0.0883, RMSE=0.2971, R²=-0.0090
============================================================


📊 Round 729 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2490, R²: -0.0024

============================================================
🔄 Round 731 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 731 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0018
   Val:   Loss=0.0772, RMSE=0.2779, R²=-0.0060
============================================================


📊 Round 731 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2490, R²: -0.0023

============================================================
🔄 Round 732 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 732 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0005
   Val:   Loss=0.0812, RMSE=0.2849, R²=-0.0024
============================================================


📊 Round 732 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2490, R²: -0.0023

============================================================
🔄 Round 733 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 733 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0002
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0151
============================================================


============================================================
🔄 Round 739 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 739 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0014
   Val:   Loss=0.0889, RMSE=0.2982, R²=0.0006
============================================================


📊 Round 739 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2490, R²: -0.0023

============================================================
🔄 Round 740 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 740 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0006
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0045
============================================================


============================================================
🔄 Round 741 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 741 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0014
   Val:   Loss=0.0736, RMSE=0.2713, R²=-0.0036
============================================================


📊 Round 741 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2490, R²: -0.0023

============================================================
🔄 Round 742 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 742 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0016
   Val:   Loss=0.0796, RMSE=0.2822, R²=-0.0087
============================================================


============================================================
🔄 Round 743 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 743 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2842, R²=0.0011
   Val:   Loss=0.0824, RMSE=0.2870, R²=0.0017
============================================================


📊 Round 743 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2490, R²: -0.0023

============================================================
🔄 Round 747 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 747 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2835, R²=0.0003
   Val:   Loss=0.0840, RMSE=0.2898, R²=0.0028
============================================================


📊 Round 747 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2489, R²: -0.0022

============================================================
🔄 Round 749 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 749 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0003
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0068
============================================================


📊 Round 749 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2489, R²: -0.0021

============================================================
🔄 Round 751 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 751 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=0.0014
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0014
============================================================


📊 Round 751 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2489, R²: -0.0022

============================================================
🔄 Round 753 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0927, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0927, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0927, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 753 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0002
   Val:   Loss=0.0926, RMSE=0.3043, R²=-0.0041
============================================================


📊 Round 753 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2490, R²: -0.0023

============================================================
🔄 Round 754 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 754 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0009
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0025
============================================================


📊 Round 754 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2490, R²: -0.0023

📊 Round 754 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2490, R²: -0.0023

============================================================
🔄 Round 756 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 756 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2863, R²=0.0012
   Val:   Loss=0.0776, RMSE=0.2785, R²=-0.0042
============================================================


📊 Round 756 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2490, R²: -0.0023

📊 Round 756 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2490, R²: -0.0023

============================================================
🔄 Round 759 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 759 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0019
   Val:   Loss=0.0744, RMSE=0.2727, R²=-0.0015
============================================================


📊 Round 759 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2490, R²: -0.0024

📊 Round 759 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2490, R²: -0.0025

============================================================
🔄 Round 761 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 761 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0019
   Val:   Loss=0.0837, RMSE=0.2894, R²=-0.0011
============================================================


📊 Round 761 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2490, R²: -0.0025

📊 Round 761 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2490, R²: -0.0025

📊 Round 761 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2490, R²: -0.0025

============================================================
🔄 Round 766 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 766 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0013
   Val:   Loss=0.0880, RMSE=0.2967, R²=0.0000
============================================================


============================================================
🔄 Round 767 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0959 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0959, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0959, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0959, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0959, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0960, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0959)

============================================================
📊 Round 767 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2781, R²=0.0011
   Val:   Loss=0.0959, RMSE=0.3097, R²=-0.0008
============================================================


============================================================
🔄 Round 768 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 768 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=-0.0006
   Val:   Loss=0.0863, RMSE=0.2938, R²=0.0080
============================================================


📊 Round 768 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2490, R²: -0.0025

============================================================
🔄 Round 769 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 769 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0004
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0068
============================================================


📊 Round 769 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2490, R²: -0.0025

📊 Round 769 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2490, R²: -0.0023

============================================================
🔄 Round 771 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 771 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0003
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0021
============================================================


📊 Round 771 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2490, R²: -0.0023

============================================================
🔄 Round 774 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 774 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2871, R²=0.0010
   Val:   Loss=0.0755, RMSE=0.2748, R²=-0.0126
============================================================


📊 Round 774 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2490, R²: -0.0022

📊 Round 774 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2489, R²: -0.0021

📊 Round 774 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2489, R²: -0.0021

============================================================
🔄 Round 781 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 781 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0010
   Val:   Loss=0.0796, RMSE=0.2822, R²=-0.0084
============================================================


📊 Round 781 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2489, R²: -0.0021

============================================================
🔄 Round 783 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 783 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0010
   Val:   Loss=0.0888, RMSE=0.2980, R²=-0.0024
============================================================


📊 Round 783 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2490, R²: -0.0022

============================================================
🔄 Round 784 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 784 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0014
   Val:   Loss=0.0810, RMSE=0.2845, R²=-0.0092
============================================================


============================================================
🔄 Round 785 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 785 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0017
   Val:   Loss=0.0790, RMSE=0.2810, R²=-0.0031
============================================================


❌ Client client_3 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8692 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8692 {grpc_message:"Socket closed", grpc_status:14}"
>
