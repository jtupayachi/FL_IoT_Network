[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 784a665e-22cf-48f8-9e5a-2dc0c1e4aa18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38564a93-a9e9-455f-895c-c21257fc39ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 779f259f-2257-4fd3-99f1-eb529f787a04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6861e234-1f2d-43fb-981a-31241cdda90c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 206b0ba2-bd82-453d-bf96-fdc50408e7b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37aa58e7-0521-4fc8-b4dc-bd135f258df2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3cdb73f5-22c6-4829-b891-b9f05fc2d3e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 277a1c06-d578-4c53-b257-16168d1d0c6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3cd3dfda-457e-4972-8375-83015a749201
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b124ad6-049a-4de7-8c27-1ad3ab34eb7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c7a6c80-b1f5-4548-850b-aec9b05f2d3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1f76d63-c2bd-43c5-802e-8edcbe2c4631
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1826e05d-e36f-4d35-9e2b-166c20b32ab0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b07f616a-ec92-4f64-bf5a-820b0b0e3422
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63196906-0316-47ab-968d-8e30bc90d711
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71042a33-8660-418c-ad1e-9a2762ef0abf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60f125a7-339a-418d-be6c-8a81b1a1861f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 021cef88-b0e2-4c00-b4ec-d6b14a7c538b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39db4e21-8c99-43ce-8f6b-a09216a4c7f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71fc2755-d1ae-4e42-b4d3-325c25d0de5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d56f07b-b383-4e3f-9d0c-1ab171541bd8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 335498c4-fbb9-4f87-a331-1ef650797e98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe716fd8-a73b-485c-bc02-0bc22222ae15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec3d709b-560b-4879-8a15-fd43ad782c04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2c3a828-ffd3-4d91-8782-214579327a44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e46445ca-f3bf-4bf6-94c4-934fb139e708
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 646a9ddc-3339-4c9f-97f1-22ee1f6a27f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 064fff52-b95c-4d4e-80e3-dfff4ebccb5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6fdec6d4-cccb-4ac5-9ac9-4c9b31b42cfe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03623919-0a13-495e-9248-787e58b16fa3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e9cc70b-a20b-4dcc-8168-3156abf1471b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a14a8291-1763-4590-85da-27de2c6cf973
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f94889f-091b-476e-aa29-df7f7389dcd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f69a637-4c3a-4918-b6a2-57e0c09110b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19e73196-ddc1-4810-b914-d2f932ecd071
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6e41843-2a64-4e49-93bd-5a58590f6fc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db1f20b1-0752-4bdf-9897-b5759f0a20c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad621ef0-8f0c-4ab9-9150-e3c06cf3584e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed676a99-1260-4f30-9335-8a598d719717
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b31ebe77-f86f-439e-aae0-ed721b3bdff6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 405cfad2-ebcf-4da7-8512-0c77f4c88f25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 555eb7f7-2a77-4471-ac11-d390ba25ca06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7e2c96d-4557-4ca9-94cf-60125537b084
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7f5ace5-1bfd-44b8-8f96-fe7ea2abefbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ef9df99-8655-43ee-b371-ca3355ba5d18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 227f210b-3465-45dc-a6f3-f379e1d18cb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 070c2cac-58d4-429c-ac89-88c59fa8fdf7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2329110-a44b-4c9b-ae10-55803cb263e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 227a50a7-508e-45c9-ac10-c3d7e90c0227
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8cd40778-ac39-4f98-822c-5e2bd8dc6731
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16dec065-7c57-4a38-80a3-d5c8d7997c8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fbcafa02-0f83-4c2f-9e45-d015dc80e724
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0181d52b-7cd7-4c2e-ad9b-569892cc1906
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da10886e-ce14-47e2-aa7b-6b1329369e73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0715da86-2584-4737-9c98-dfb7b137c31e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13eb9170-ee01-4463-ac0a-4c6ef7fb6647
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c8ea96b-7ede-4bf2-b0ce-403f0111220b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e979f6c-a010-4cb6-a334-c8c23907c010
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 713a4d8c-0ba6-4b53-9e1c-b929d930b371
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7366de96-ab49-4928-9099-581503401430
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb951d7e-26a6-4501-9494-dc3ea7e9bda1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a6e6e94-e7d4-4b29-8382-96f8cd5bda9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e58f832d-5db2-4b97-bac6-f12fbc781ee0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0204a17-49d0-408e-899e-1ef7916ac07d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da00fb0b-ab1e-473c-a622-4ad1461d12be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dae71803-2849-493b-8463-ee7645df48eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28bf428c-09b1-4868-a1d8-7cab4d7e918c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b446032-a55f-45d6-84d6-4656e517aac8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 484ae605-5e9b-4be6-918e-72df41958014
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75b43ecf-c844-48a2-94d4-bfd514b3a49f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 759a4307-5b8c-4426-949d-58d7f36c44ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64e34cd8-5945-4673-95e8-d1effeb45c53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93729590-9293-4d14-bce2-c80bfc0f8d83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74e11dfd-fe34-497b-8f20-5a944c69be84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9a60a18-0d26-4301-b3ae-32f280528fcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82c3d645-a0f1-48b2-b2cb-b6629955bd3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f36effe-eb51-4418-89fa-e41a9f34dcda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da99aeda-c500-44fc-8c56-f97c2b619d15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5675aeb5-7609-4dea-bc77-2efcfb3f1743
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9d10fcf-fe59-4979-8fc5-be99fe2d9d26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36722dd3-edae-4cad-9a7b-ab981d3ce89b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 028d0bb6-b7c8-4607-a1d6-bf339af48d28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0ab3baf-551d-43a3-a2c7-01aa16d06eea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7039a21-eb82-4561-97ba-1c29b324f975
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d411174-b3da-4e74-bd37-58103e226182
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b75c9ef8-3269-4ecd-837a-bed509439fd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b232855-43f0-4e69-87a3-87cb2f2efc2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a49c1d1-0c3e-4bc3-8e23-49dd419ba536
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ab6eccf-a5da-4a90-b77e-253ae330d940
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb033ac5-db74-4ae3-b1c5-66e01693ed1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17e35886-0ffd-4195-ae37-388d9c0639b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6db8c7dc-979b-4634-b977-c18faabe476b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 716bbdde-9468-4bb5-9ff5-c4a424a40d9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cae77e0b-3545-4bec-a07c-a3dedc2de6d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22c6a69a-5f9e-414e-8682-90c4c1e124ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89be9dbb-eefe-406e-96bc-2fe66d50e42a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0cea280b-c406-44d5-90b9-c55727c687d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8c73ef5-be74-4e64-83d8-ee5779b9bbe6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a834ce86-579b-4af2-8792-74edb648aba9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a4b8450-be1d-4a66-ad86-5d3510a201ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f432d3af-fe52-4d32-9336-ca7c481acb69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c5dc4fa-1375-4297-9e6b-188ccd3aa8fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81719ac6-cf7a-4a60-8dad-f1399c2e28a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce9847e5-9592-47bb-ab4c-92e75b37dec0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message feb1a20c-22f2-4a1c-b3f7-d856f2f623b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7aab6621-87f1-4f71-8602-3ce3bb2add38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dcee8725-b484-4e95-b64e-c0a572ad2ac3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc07cf7c-4369-4f44-96bc-b58cd1b975ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5720869e-a9ea-4c5e-b9a6-335c4fa12b95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58aa2527-7ccb-4ec9-a39a-4bf04a0c2df4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 602de5fe-859f-42ea-be6e-de60922878e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4298a4be-7b51-41dc-91fc-5dd7159d082a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a01dec2-5e63-44ba-97a5-8b8feed438be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 347c27db-6b50-4e8b-8870-9547d71e9f07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0238e4a8-5579-4a59-89f9-2fb7d62d51a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8a76780-4ba4-4e9d-a70b-6212ca497f9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de5b1d8e-dbba-4a2b-a814-3badc0d8e1b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a857c58d-d540-424e-88bf-2b9af9f20f80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9715b99-5ae6-482b-9c37-896f7c6a51a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5727342d-04cd-4f64-b260-e8433c8560e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b217327-a407-4499-9b2b-70a93da06c66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3fa19dc3-48b2-4a3e-99e8-70416218e4f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a17db6a4-47ac-48d6-8e0a-517bbc61d1f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d3645cc-2bb6-4812-b49c-2ea148b3d528
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b536e2c9-7cd6-447a-a441-d40d5c3849d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd6341a2-3e6f-4ce4-8e40-8fbe45da014a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f94dc213-0edb-40f0-b139-00dbec395c80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 776bbe49-011f-420e-af11-3fd8b3143edd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b30a523d-7835-4673-843a-12417d3812e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6359e289-f515-4d8d-8618-5ee6e9167974
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d4b70db-6e27-480a-b5bc-46f52b996c06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 486999a4-4b14-4c25-bbd0-4ab19ce8eac3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c78b7ea-f734-423a-b3f1-cc3677457a02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12d7fced-fa84-4dfb-b067-6ca63f612e5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 257ae508-d12f-4f46-b584-bfe34c3eb980
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38390b17-8b86-4f2a-8acf-5a6efbc2e3e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6f01759-6105-429e-b54a-e8f34d06c841
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ccfae4d2-eef5-4789-9f6b-b15d09fc98c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4d0caec-5ae7-479f-a3d8-0deae7be6079
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7120e477-5eb6-4b63-939d-acddc0593b90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7349011-fb14-4bb2-9d6d-8f4695ab2a8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 629033a1-e7e1-4e24-9ff2-f40bacdfb335
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd28dd37-1177-409b-bf33-62c9797e26b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef7ef42d-4447-491c-b6fd-ccf4ae8ed7f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0faa02ef-41f0-4b7d-a357-37449f5772c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e97e54d-f63b-4791-af02-1cbf53d2ab2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6eff39b8-4349-4c24-b679-2b597920584a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e91be234-ab32-47c6-a381-d7ce9ada5190
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d977d443-a9b1-482d-8cd4-4f8600569ee2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6419e3ed-6745-4d7f-8369-0d2258dfde2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07a6e53a-928c-488b-bb90-e8a5909fb094
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1b1cdfa-9ed8-4868-90ec-36437ec226aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66a0cb21-9059-4deb-b673-ec71dabc4bb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c872719f-c083-4672-974d-f84a45226e5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c64eccb-4935-4d1b-8451-103598c37188
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41025b7e-47cf-4b50-945d-0e6a6bf3167d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50330608-9967-435f-9cb5-7de5bb05c183
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e721a85d-3620-44a9-bb40-287829c4a5cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75eb4715-c743-4cbb-b1e1-eaefb2277433
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31700fbf-48e8-4b1b-ad20-d517753de1a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ef81608-77d8-42f0-979b-4f60565634a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2fc9f684-b7dc-49cd-82d8-723c6029002c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be8c6093-cfc8-4517-a489-e2024dbe56bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a2ec5b4-b25d-4ebc-8ef9-511c26d2dd80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 439167e1-5b94-4d17-9dc9-7b0181f2f5ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8318503-a320-40b5-9e7d-11438ebb8093
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b2a4324-a255-40aa-bf52-4392bbef9870
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 770269c2-1222-45bb-828e-108f6001cfdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55f94001-3b55-43bc-8d93-d783a624485a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2297e6f4-ad3f-4004-a82f-022df7a7eac5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 391627df-fb42-4814-b2f1-279260b829fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24c9cc2d-3dec-48f7-a104-345add1035ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6cd3480b-8463-4bc4-a196-6cd1e2ea9250
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29e7400d-dd67-4f3f-ba13-42e1a993b892
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fac784a5-cde1-48a0-945b-b88b49eef911
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09885514-eac4-4127-8564-dba681595a88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4454a7b-1f3b-41e8-acde-66c1ef4c7c3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e221a555-714b-4a13-8ab0-f7692adbd45e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f46784a2-ad2a-4f27-9502-1333442e5c68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2c7fbd6-a63b-4951-8321-d6dc128b12c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2252d09-e73e-481e-beb2-86f97287c48c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18088cf7-227d-4e51-82f0-b63503318c7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ddd561fc-6374-4375-b8f0-233ef7c81b63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f31dad0a-7823-4598-b766-0ecb0f894e4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41ccf534-89e8-4cf3-8b39-1e231fd0fc04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 098b8151-5e90-42be-9e53-c338eb0ae1e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 233f8182-6339-463b-b9ff-29e066bf79b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d018d2d1-0c1f-4564-8dc5-b676e66dcc06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64a798c7-60aa-479e-98a6-8525304a65bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0ebbcd1-ea87-46c3-9f27-25806aef8bfe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f77dc0b6-d5f0-47b8-bfa3-96b30e8bcae4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cec9aaf9-2ea5-4e6a-b700-8254ec174987
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a44e9503-be6b-4c0f-a609-c29e7bdd0a20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d624324-0225-45b8-8030-2157233f0da1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f763e61-6400-44f7-8913-399d202409c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2fc8261-c31e-43a0-a8cb-a7ddf53f2a1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4a653f6-fd1b-47bf-add1-4c2b374c7dd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14d4725b-3289-4828-aef6-41be3c9c831f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7bc69341-618e-4920-b32b-7266fe0d6e5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1f0cba3-4718-44af-9db4-a1250dfdb887
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1afc0a9-c52c-4c64-befe-336627d28280
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6b0b532-1be9-4f0a-8cb7-37a4a400772d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d732f1a-4283-4fe8-b920-972ff4f18b31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86904f6e-e21d-425e-a871-038564c1ca32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b0c5663-cb52-4912-b764-d92fbb0ef0bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 778f17ea-f97e-475d-934d-b7daa5af17d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06d2887e-3a29-4360-a7db-52839500ba1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b790a6e-ca42-4400-b1d1-60dee20436f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 194dbfd5-3945-41aa-8767-b59876d39300
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3bdd2e48-c8f3-432d-8bbb-f1102200a3f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7ab9d60-83b3-428f-a0dd-00f3170618f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 135043ae-a7c7-470e-8b8f-1309792a00b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 338f486c-8247-4300-bc3f-8b9948d0a470
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0fb407d6-c113-4adb-a3e9-4934acaae521
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef0cef3d-89c4-4a62-a9d5-8e884487c935
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a9dd9c7-89a1-4145-a2aa-534138528069
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60901343-4460-44cb-80b9-0f81513694ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 185f6a15-d10c-438b-b71e-e384c8f15317
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70096049-73ba-4aca-904f-b945e9de499b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 339cb689-ac50-43a2-9cd3-886947ec2206
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f8fb0d1-2f8c-414e-a6f7-0faa92479281
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d09aa0b-18cc-4cc6-86c0-cf4de20f097d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e5d0de7-a811-4ca0-a7b0-c2fd1166ff18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5558bcc4-6e9e-4adc-81f8-980f28ed08aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e514ca25-6238-4a39-a715-c9fe3eee50b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 313afa33-2ea2-4850-a137-d0a94ed79418
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87303d37-e44c-4f46-8784-026ee616f8f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e46031f0-aa86-4b79-a56f-ed3810578b54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d9e4fd0-0204-4ac5-87a8-c6df20af5299
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fbb29ad7-3769-4df9-ba17-4d6ec7b1de74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84f4710a-9e47-4d0b-966c-0d1bab6a3044
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd7939b2-7044-41b5-a1f4-b45fde768751
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 245d0106-7a6b-49fa-9765-f886d352e439
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a2b9b68-30d4-41be-8b02-a99350b4e3d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7952f783-2dc1-4182-bacc-d3586ce2e9de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0daf2b85-01d6-4a3f-aad3-28e35db679b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60803996-897e-4f8f-b467-85e822f893e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29b58574-2c50-4a38-a785-d9ab7e61ff80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77f17420-7c35-4e1e-bb9d-7366211364ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55857a97-7e4e-47c3-b703-09a13e343372
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8a96bac-efd2-4f48-8ba5-04fe5ae16174
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35b663e4-7cf0-480e-b268-2f7245f1ddc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dcf1e1ad-ca92-46f9-85e0-4c544b09cce5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30aeb662-ba54-4cbc-bd0f-56fe886d9cde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e915eee-72ec-4ddd-9867-db6eb954d0e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7366592d-fb2a-45cc-9a51-3bd65b8886e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16d18a02-0184-47a5-b7a8-159b8954db1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36e6f783-90a6-4e05-9e17-8271132cfbc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a07c306-3f73-4d3a-bf9a-f4ecd22e43ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dbcc09e6-79f0-4d90-9b71-8c3b6a90177f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ba3219b-815d-4abf-9e90-39d94b3b76f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f22ca296-29e3-43a7-b0c8-18649a3f1457
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d754960-08cc-41ab-896e-7313980b3939
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f874c49f-4963-4f42-844b-2ee1cdc73245
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d651e89-0acf-4c97-b9a5-7a35e8c9e990
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dffd2a84-279d-4cc4-bcf1-fe16f6f5c05e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a03b43e9-0fbc-4a74-8969-bcb2a8c42c5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8fb7396-decc-459e-8a50-2f485424d0cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9fefce8b-f6e6-433e-a189-926581d349dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b5ae93f-df70-4d52-9390-38b0ce584bb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2116bba-15a3-4615-86e5-f3ed563261aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f2849b4-3d2b-48d5-9c7c-cb1bf8934d38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0291fa4-2d60-4354-8343-df13bd71d3b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a344ffda-6c5f-4edf-bd60-fa0016f98c60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e468fcc7-56e8-43fd-8c13-6d2238d8d7d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0cfdfe3-52dc-4630-a382-27d63014c6c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a603a473-71be-445c-b537-bb7d0d0f5f5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9431512e-7e10-4e03-93e8-96b3966df0ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9bfcaa23-9fd1-4dfb-b9ac-1971ab63a25b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0bc2cf0-37d6-4292-bfa8-eca9022461c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 042500fd-8b97-48ec-ab32-7b4c057f9a15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5950f506-d41c-4170-9e03-ee337b7bfdbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af1837c1-2857-4fb8-b441-813ef2da478a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e99c5bf-028b-4477-9169-490b22eec68e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e16f5b2-ad67-4850-8fac-4cdc0b23f292
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e01ba4d-3979-4679-95e7-d99e7a819db0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 919f2df0-46e2-401f-82a3-6c8ee04bb8ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5eaed86-4488-4857-b1c7-c9139d96cf6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a802cc5-cfa5-4f26-8cc2-ad223ecce4cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75754df4-811d-4dec-af87-3d0e2c832343
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de6ac636-4437-4074-8220-964f8adac6d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2bfba127-c6fc-4b75-b25e-d81e98248a07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94e9d772-2b02-46f2-82d3-0a2dca77b0e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8b8c040-6830-4f63-a7c8-edb15ec7f10e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55565506-a8ed-4aec-91cc-d6fa541ce8d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8988c9e7-5651-43ac-b319-b4138e871204
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b88e3a57-c858-4d0f-9e4b-2180596baa9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d31543d6-9c82-49d6-93c5-f34044d1bdd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed6f189c-62e5-4781-8f0c-abe7850be2fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7125c999-ef76-4d96-9342-6791bc9906fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4aecb83a-4043-4612-a33f-e0ca30754054
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2fe410af-bf7d-4608-b096-f6c00d856d69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20f6738b-8fef-4ddd-93c9-9fbd4877c8cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc42e7ca-461f-4a3d-8265-18def04b15c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e7f6be0-df82-4c48-831f-9cdff807b22a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1ba15a3-8fcb-4a79-aa7c-874c87b68b79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76c4c705-0071-4f85-bc37-d7dfdac89acb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96a8f937-53df-4406-9018-0dcbdecbafa6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0babac8e-014f-4431-a37d-471c4bfaf32e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d28fde32-efa4-44e2-b75b-452869b8ae46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8c5ca00-acb6-4b40-99f1-273c01247082
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 190d4a2d-f1a5-42a2-bf69-d921c3cc71ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d57fe578-fe92-4140-9609-eee061e8385e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aade5106-07a0-42a2-9c41-12b0af57c16b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b1b05cb-ba87-479c-a99f-ec83553778ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71d3a15f-d3a1-4a94-b7c6-034dd4eb2cd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6a81fdb-9292-47d7-b2a2-cb16244862f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b33eb96-631c-4bb8-a3d8-ae91ec93713b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc7dd854-4aff-4ff4-b47c-c2bfa9b245a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1d00187-2db5-44fa-9eb7-a92a49075dab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fef9f6cb-d432-4a55-a604-f6305d073810
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4abc57de-ee8c-4c09-ab70-3577c5ce2302
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 004af4dd-f77b-4f7d-9e0d-af8d2639c522
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 880a7061-e9a2-4950-b20e-6aba1a08baf9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24ec8dd3-41aa-46cf-991f-f293bca6d7a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9fb9cdd-ddde-4462-9731-f79f4856544f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c66ea3f7-65cd-4cdd-b8fa-7e5a9c7af227
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3694d4de-8d58-4470-8480-16e5d3256da2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f09c588-252d-41bc-b3fa-43333d313e20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e258c7bb-19ae-4431-bb1a-3906809aa7e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5394927e-2dd2-4f1e-aeac-27ed4a29a693
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8071f53a-954c-4d5b-83b7-df9764d2115e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f02ceec3-da44-4f99-a37b-100ef3127478
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b84e1b4-00cb-4066-8161-d18592f2b33a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f0b8d27-759a-47f1-b442-41eab04c0450
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f17056a0-3776-4d78-af69-779b6a57238f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7fb7e8a8-59d0-4f54-ac00-85f34f6dbcc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1443b749-15b9-40cf-bb77-02aff0fd2b3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6e5d7f9-8239-4618-9ed4-0c1a11d16e2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 684c5936-69f8-4964-a39a-862f91d0ea66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5456938d-02e8-422a-84aa-a907f8fabf02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef4c7fae-d9af-4135-9f36-75ceaa6b92dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55417785-9b53-4bf8-9c72-485c4037e4a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6df854c-4e55-4910-9f5c-181e809c7750
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 877d4a5f-6d93-45fe-bd80-c30231a9a64f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16f1e2a1-d28e-42c1-8496-54b5fa97a408
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a48b0cd-8dd7-47ae-b6a2-f22850882897
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 162357c7-19f6-40ae-9cff-06742e69ff34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4014c1e-2536-4d7b-8156-bd212aa7c66f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a63d8fc1-6711-4e6e-87e2-222146b33f7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69cebf93-b530-49b4-91f5-2945652b7fd8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf46ef63-c52f-4f12-973e-44e5547fce01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d923fe68-ac35-4cb8-9f88-5f7e00876950
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70cc0db2-d5a1-4193-9571-b35618f9b745
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3518b18-a4f8-4a69-8983-9f9efbe83229
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8dd4757d-aece-4093-9430-7205f3bd47ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d533448-5ee0-47f0-8dd1-0018c5d05388
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bdb383c2-8c9e-4519-834a-5e45955f8265
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9b3b007-a638-4f12-8258-6f8e4e572e1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0ce5b54-4a76-46b1-89da-be3d0e70f6c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57968977-f35b-4662-96d3-3a886ccfb2ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc6f35ee-1672-4859-ad35-b59f5246a73f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 690437ad-d7e5-4b0c-b59b-ddfab4b405a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c4d8b9d-799a-4799-9eb1-ac096489e4c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 295f85f5-bc2e-4b2a-b74b-7dcc0d6d0f6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d79fa20-f870-460f-bd72-6d1555989daf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f414e790-dc2d-48ef-986d-bcb423457ddb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42cc9394-38fc-4be7-874d-a8c2b8661339
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6dbfdd81-952b-4105-95a5-a05d0ccbf0f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27a0764c-8d18-42a2-9203-02a970ebe24d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37f65225-4f65-4d98-b366-56d20ed3fccf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fabcad06-740c-4d87-b57e-f6471e8eb50b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a059a75e-5624-458d-80c1-58d53701e42f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c58bd84d-1772-4288-b018-74d46524104f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4c45e8b-c525-4b33-a5bb-3fb40c69de1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d3feacb-7a92-4eb9-bd29-2f5627bc6411
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 650ad2ae-2d6b-4183-95c9-6b9677321917
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e71f901b-b65e-4acc-9156-1878b47a80b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa1cf5bd-7681-416c-ae22-5a5b9ee2b3fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4da2d9cb-f1f3-462e-b34f-cc27a81377a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb1c1daf-a00e-41d8-9a2f-f5a088d94689
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 318cc467-84b2-4270-9329-5b9799f875e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c540f4f5-b599-42e9-83ef-edf6fdfc4258
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a0f3624-dea1-43b5-afa4-c9c83841fa2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d55c788e-0781-440c-b7fa-1ad06f0e97be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b82f329-c29e-4273-9a38-516ff4dcc687
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44ee0079-2529-478e-9fa4-2e7d309414d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d021ef9-bf17-4ab9-b3de-c639e436ba3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d299251-68a8-4f5f-9547-4448bafcf10c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c73358be-d3fb-4e2a-9dbc-18ec01e1634b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ede5d19e-b742-4b7e-a706-60f2e096c6e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83a4171b-7890-489f-9926-aad2c19fa74f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 849f526c-f647-4614-945e-f61eb8c354fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51785669-25d0-487a-b68e-b9a1f7b019d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb44d15e-1255-470d-899d-7f0e49c67d22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d65f1c7-07af-4528-b886-a13d7fc1ee03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 763f106f-59fb-4319-9b00-3b678ff84c27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56d87c0c-69ac-4019-8353-72eb29c8217a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 201b3375-630a-46f6-b8e7-39267bc9b9cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f24144b1-e0ed-4ec2-bc38-fc30d53d6cab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a72b6ee7-afab-40e7-b09e-b0fe3ed1e601
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e384c308-bfd2-4c89-b68b-a356d4757265
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5573b1e7-11bc-45fc-bc8f-5659ecbfcdf3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e0b5a4d-98ce-4d97-be40-2b0dd3071d32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4ac9262-f31c-49a1-9235-0f7c25dd2f9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e293c4d4-1226-4bb8-ba2d-130ec8476c3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27780c19-35e4-4e56-a236-c626971d823a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ddc9a43-65ec-4eb2-9cfc-3c6879ff116d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e0b5c2e-2bb6-4577-b5b5-ae2be5a09193
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70e05b00-4611-4726-8803-afbd2a1512b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3bee7a74-1075-43e1-b39a-c5e9d0fdbc01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba86a42e-0074-4606-97aa-12d37973ed71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ff97fc2-a443-41e6-9338-41c5c7e48a98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 926cafa4-9490-4340-94ab-fa5da22cf431
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message acf62c45-627d-47e8-80e7-d683d34b1431
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 524c2ed6-a654-4d58-a842-35768b202752
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5625a575-dbfb-4e77-a561-9ff739825e4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6901cb8-877d-4019-9676-4cc4157afe6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fffdd9ed-eee9-40f5-b92e-2b2ce95a66a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 638ce713-03b3-4a72-ae9f-12b639d619d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d1e7596-77f1-40cd-a6fa-1720dee7b944
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ebda24b-158c-444f-9784-ec528163dcd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 401c2e63-705f-4bf3-90d8-0a0ad7902538
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8c8388f-2899-4ea4-beaf-0b1aca7a40da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b70cd5be-f1ef-4ada-a8bc-85448aedd0a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3bb3b226-d51e-404a-a0bf-002ab505d388
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84d8036d-2905-4a3d-a525-99316ed732c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc636f78-6a26-4a48-b538-04a4b888c242
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c3312e4-ec2e-4110-8ef9-b9ce7ec9d112
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54ee2e49-900f-4175-83f8-d13afcc64d3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67270827-b605-44d6-908c-e9fd1891811d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0134526-0c76-4df6-8ea9-870cae965b23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4611d0c-e76b-4bda-b267-5b4aea0aec38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a66efbb-442f-4b87-b518-e44e18605eb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67ce7b8e-4e8d-4670-b710-927a1d2ef864
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bae85010-5f49-4af4-a0be-39232e77428b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6c34f43-956c-45f6-be6e-7684c60bce52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5310d0f7-83e9-45d9-9d96-73036181ecb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4617b32c-7149-4c40-a2c3-792fe00d296d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16b634b6-be7d-4d30-8c0f-394a1e571e78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00140d7a-1bd0-4278-a580-2f3303009d0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a18ea35-0e14-4306-a041-1461d77e1e27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c05db04d-4bc1-4b35-bf80-9bd8f957d3c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81ef630a-09a8-40ac-ac65-4c9bad1f2dc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f08e3469-b6fb-4efd-9c2b-e864ed3a34a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a59e39c8-4170-4bcc-bb02-7a3d28a17187
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8e1e4dd-e9fb-473e-a8ce-7b002b7eb50c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c30346d-a4e9-428d-bda3-ca993e0060de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a06e587-0b5a-47d3-b912-8e8e677b102a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 401bdb2d-2a15-46b4-a896-cdd6511e6709
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message afde20a4-8525-4af5-b0af-8f35cd144064
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23961b02-794f-4928-b26a-01d13967908e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a91b58cc-212d-45bf-8f12-4b906dafc456
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77fb3393-9302-4d45-8d46-f6a2956b470f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bbf70da5-0837-41a2-98c1-42eea95a18ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a48a40d-9cb9-4230-b28a-dde2e32cbfff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53fb7828-b253-4c33-bef5-e742994fdcae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ebd3f320-da7b-4a4b-9508-8425672934d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6622481-2938-4259-8030-00dc420e30f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7cda5098-4ad3-4be1-9395-ee09c9bd0446
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4d2c69a-8d56-4278-9725-d66f62049ee4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f533c07-fcd9-40f7-8a51-612e8abaa1fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71c94400-7366-4acf-90d1-afec73f629b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c79016dd-3248-463d-bf70-479795ef837c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb49eec6-d920-4e05-b997-312a85fa707b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bde6f471-db69-4d0b-b119-b8c4f11e9bc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 274da612-4782-4c67-9686-c7373ab91ba5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 652b6074-161f-483d-a515-7e1dde336abb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c114670-1129-42fa-91dd-f3baa323fdbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35a01641-8b75-4a50-b77e-56740dea2425
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88f457d3-b69f-423c-8407-848464f54fd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ada995a9-9fcd-4171-af21-119c300c7275
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be59d8a2-6e37-4eec-92a2-2e18b02c9124
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30c86234-ad4b-41fd-99e6-8bfa121b3119
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23bfe685-cfc0-4892-b9e8-cfb5bae7032c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1530a3d4-befc-40a4-a8c1-ce721e69622b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74bd3143-3e88-48b6-82b9-5f1160038b90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8b9eae8-e044-4ee9-b237-6bde92f4935a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e24d38b8-7399-4aae-b857-ec3dc74f718d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0729c799-542a-40af-8816-76d3222d74b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 903888fd-fa21-4324-95c8-2e488b88e519
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 107daede-4a42-4fda-8a17-bc3c89b41335
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 215d6b50-d05d-4302-b8cb-e8842549e9c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 608102a3-dc53-452f-906a-d0259d6a0a32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5f17ee2-4f1f-4873-9978-e2862e9ced5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62df32d9-794f-4864-9c5d-d588de932cc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cef28ed3-a9a6-43f5-ab28-6fc5f39ef73c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc3d475e-b225-4be4-8bca-af52c5630332
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d01eb94c-6bd2-496c-9606-9e599ade3edf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44b6448d-6703-4736-b492-eebb47ed81c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4ce0175-fd82-48f0-8ac7-3448c472dc03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3405a4a-8e61-41d9-84d3-6a899d206586
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfea341a-3f75-47a4-808a-22cac1c0d8d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 542e6272-f183-4827-8cf0-999e643bba2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a243e4de-c54a-487d-97e8-340525b303d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fcc8d3ce-13a2-4388-aa92-1b65135ff189
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 639ab2b5-2e6f-422d-aab8-019e3a08bd1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5601aae-addf-447c-98b7-fc2128944173
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe047e0c-5ca8-4103-8ada-9c9a0e49c2e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4190e709-c778-4074-8558-179be099d36a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 939d598e-a84d-43c3-bc3b-c331b014bbbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a94b2902-cb10-408b-9c84-d488c34ddc27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6a21772-b720-4b30-bc6b-6cfb2aec005a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a540b202-f7d3-4e35-85d7-8234da565b4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8bbd02bf-541e-4ee6-9d47-3541e57748c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9e263eb-b9c9-4c6e-b42b-91e77796aa3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff7a8842-8cfc-41f7-b2b0-bdeab0ecd3d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6724d0c3-627a-4d2c-b6d5-c9c7564e9187
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96e50664-c0fe-45ff-a85c-bab871e99688
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f77edd9-7c40-43df-9652-ee037acac435
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06da94f2-c283-45fa-b0e5-278b5258ca42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb8eb0b5-de8a-4a9e-8aa1-2d7d223eb0dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 336f75dc-3228-4540-8885-520ef07c7ba7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d72e165d-e860-4bd1-8012-af931bb081fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8d5e8a2-d51a-4dfe-8a5b-fab66e667e3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5261921c-17b1-45fe-9812-e96cc8ab521e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55647a84-ac07-413a-ae7c-d91f735842e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9da9921c-97ff-4f6f-8b41-4e4f81143376
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4612e75d-8aea-467e-878d-ac9e2eb7c8af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c676254d-af76-4f29-95ea-9aa1426b97ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1dff4321-28b8-4ac2-a51b-c601e22b124a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e097b4b-2bd3-4594-bbce-d8813503a88c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3dff635-9f94-43d7-bc30-a5deccd6aa9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58994b65-87ad-4cb3-a2ae-4d86eb1d2a49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb41fbe5-c7dd-4827-9be6-2afc497e3769
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58e8e507-27cc-4be4-8a6d-67b547837613
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56597fb8-35d5-459d-8585-c49cf0ce0153
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bff08959-3436-47bf-be66-4b43cd17aeb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8068481-0b4f-4c97-980b-31dd44268640
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d7a0215-4853-42a0-84d2-3856d8879e24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d85ace89-87f9-498b-8507-7b1bff75c982
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e429109-7170-474c-b4b3-965eae500e14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16c3953c-effb-4dc1-8a3f-511052ee112e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ceb4eaa1-1dc4-4377-9c2d-2ec669c0c959
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cab4f138-9ec8-49f0-a3c4-bdf0613ba756
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8adfc77b-8072-4113-bb44-427cee8f2e2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 534fe1fc-4b5b-4deb-9a12-47f7c991c7f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5f89e3e-0c9a-4229-bd41-8c9af6ae7860
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5cc3917d-d881-4dad-aa13-a60a71a2da9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84723a69-cb91-446c-9c81-ef54ef7216ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39781549-a25b-4f4b-b74c-19e7376db033
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3c0ffab-7ba4-4560-a4fb-0b3de9679da6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa96bcaa-9c64-4d0c-8b08-509ead9f7a87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84b1a826-aec5-4e5c-bc30-656c6b1c52ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5cb52ce1-d1e0-433c-bd9a-fc6414ef2c41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 864b285a-fb81-48e5-9274-3722f65665c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 681743ea-1a18-4dcc-8c49-574c25399c47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9263c7aa-b3b9-4cf2-9f63-89a58c66569b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1da5a3be-2f73-4d95-9ca7-d31f76940053
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b3ce1d6-66c6-49e3-baf5-e96c3ba9a9db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7699e27e-d125-433b-8291-639bb736b876
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28f33a4d-4f48-4ac3-abdb-28764ff7f547
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f909612-d470-4b17-ac44-537fb0802afc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b58f9c3-9888-4e24-b37e-8f9fa850db22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 083a79b6-d628-4035-854b-a6b887b4e392
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2449853-2554-4e5f-bb6b-79f22442bc6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd7ecfe2-712c-49d4-a0eb-b4ab5c494b2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de7bc68e-97e4-41c4-b143-7e4a4963b115
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d56a39c-b19e-48c4-bf02-bc9e02f370ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74c12bdb-ed90-47f9-b029-d20a2ce3abc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4b098b3-d76e-4dcf-903c-7b565d426d8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f90c2ca-7da9-48d5-9d27-6a94ca455bab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69c56bac-5925-4573-adf9-17a82457a801
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0db27f21-f699-4ead-802f-4f3942b6f9f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64e6785a-c039-4e1f-9b0b-f000abb871a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 270b0c7e-48e1-4c9b-8222-1e5fb1377a18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f37104c2-e01e-4548-bfce-11398785a103
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cde24d76-f599-4a10-bc5f-bc57171c2b84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4caac67-48fe-43e4-8f48-9d384679e23f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d77dd354-f28c-4ff1-99d6-052c4cb435bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 211c3113-55df-4399-8120-afdc541ba00f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e58478e8-2f03-441a-81c8-3224fe156a48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 261633b2-1ba8-4f94-8869-02b4825b97a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59f76db3-a203-4e1b-997f-5f1161319980
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c17781a8-684e-4d06-8cad-d7cae0f25e39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 005357d9-bddd-4667-91b3-2d96e22d3eb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a78efae-f130-4ad7-88de-bcd79e6ae6cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c760e5d-076e-4bc8-b267-8e7a4483d377
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38058e91-a93d-4da4-a0ca-bd427bb0a4ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8999b8ad-2fbc-46a5-b4b0-3d905cb0bc9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9edab98-5b48-43d6-962d-35114ebd5859
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46c2b20c-2cd2-4bf5-8ac7-0c45e49f22f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b73c431b-7204-4f2f-bd3f-e8fe161970b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ee21ba4-5b55-4eca-bf47-38816a2ce8c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d05eb1c7-af77-432b-9f42-eb80f84b0719
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e3c96c3-683f-4b73-86ad-12802755ca08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd277f25-92c2-4a30-aafa-8f6f5853d849
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6b60009-44bb-46bc-be79-ea9be78b9ee8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba5c1bf6-10bc-4f9c-98f3-0cd105a9a753
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 356d8b1a-4cce-4ef6-891b-c2d7d2e8d6bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e791036c-d33d-43fc-a450-32860391e956
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce5632e0-ab02-4590-bc39-e0fea5efa714
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 602bd69a-0e98-4fe1-87fa-0b0d50a78971
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a4dc216-8ca9-483b-abe7-f4bccb2e2b90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 725ebca0-54c1-484d-8d54-76ebbff3d4f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 841eea17-34e4-444f-b6bd-eae16625304a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 548c8a2e-ddfb-4fff-a365-59b3d7e4b153
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d3ff5dd-55a4-4b7e-b375-4dd6ff672daf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b731d8ca-e96c-4ed9-a2f9-296fdc984832
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 306af1fd-97bf-4a20-afa3-c2f2ed388936
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62e9790d-a508-4d7e-9a69-1766ba1b00c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6bcb223a-1251-4414-97e1-f2640794f82d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f59785da-9c44-4108-81fe-6a09b13dbd09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a4b95c9-1202-4ec1-835c-fff0248fadbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c47cfac-ea1b-4f23-82d4-22e8e29f682a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8fa447f9-a0ca-4e4e-9ea5-3e08c59d7615
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e8b706f-2504-4a04-949c-567cd6a98f37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c7ef4a5-8f0e-468e-8fa5-60b5e6f771e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e823199e-5050-4453-b328-a5c9fe939fa6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45874e78-3526-4258-89c8-ae4ba5542dfe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4abbcb5f-a952-4193-a344-2a78e7cf09f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93ad2ecc-395d-4165-84b4-2fff564a18d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 973554f3-327d-438b-8ab2-9916516f3c9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76d0318d-c988-4871-8ec9-e36df41971d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba2e973b-4ada-4b19-8bf5-cd97d081e1d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2765796-499f-4812-845c-17ea4393dc21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6fa87f1-8217-4973-8d83-fef26965dd53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e09fcd9d-ed36-402b-8d9c-4d2a08387f9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9fe80f6-3f0d-4e1a-ad49-52ce029a1ed6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba9bebf4-b880-4d5e-940e-8515e30a47bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51b256ae-0e4d-4250-b5e0-f1ced996108b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a98f2067-4a61-4fb4-aeb3-ef9d3430b18a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb426a32-c8ae-480a-b4c8-ed89755ff892
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef0f04e8-3d60-4e41-94ce-39e7f2984d6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4130c90f-769d-4caf-8b3e-55d04c5c317e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4dfe801c-951c-475e-92d8-9b6f0c356ffd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0fa4196-bf08-4eda-859c-893a7d47e240
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da28e2dc-002d-4427-86ca-89ad62a2ebf1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33dbf7a6-870f-4ebc-876a-c856f4394d5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e86be1b-03e9-4a51-9eaa-01dee8744084
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe99d797-76f3-4d95-b229-01cb26721822
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c52adc98-c98b-434e-8cdb-dd0bf8a0d918
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5bb8d906-252f-4534-a4b4-42b2fbd4117e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd0d2457-92ae-45c9-bf30-46eedd293c7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e86dbddb-3b24-4a83-9aff-63840221ff93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2269eac9-f771-4d3e-bbb6-06cfd4f97762
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc9c2203-4580-4a22-adc8-b4d8405d0659
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8692 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_4
Server: localhost:8692
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_4
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_4/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_4/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_4/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_4/test_labels.txt

📊 Raw data loaded:
   Train: X=(5467, 24), y=(5467,)
   Test:  X=(1367, 24), y=(1367,)

⚠️  Limiting training data: 5467 → 800 samples
⚠️  Limiting test data: 1367 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_4 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.5023, RMSE: 0.7087, MAE: 0.6464, R²: -4.9499

============================================================
🔄 Round 3 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.3705, val=0.1011 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.1102, val=0.0674 (↓), lr=0.001000
   • Epoch   3/100: train=0.0903, val=0.0756, patience=1/15, lr=0.001000
   • Epoch   4/100: train=0.0880, val=0.0699, patience=2/15, lr=0.001000
   • Epoch   5/100: train=0.0881, val=0.0716, patience=3/15, lr=0.001000
   📉 Epoch 8: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0871, val=0.0724, patience=9/15, lr=0.000500
   📉 Epoch 16: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0674)

============================================================
📊 Round 3 Summary - Client client_4
   Epochs: 17/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0925, RMSE=0.3042, R²=-0.0555
   Val:   Loss=0.0674, RMSE=0.2597, R²=-0.0022
============================================================


============================================================
🔄 Round 4 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.4429, val=0.3864 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.3459, val=0.2931 (↓), lr=0.000250
   ✓ Epoch   3/100: train=0.2312, val=0.1450 (↓), lr=0.000250
   ✓ Epoch   4/100: train=0.1016, val=0.0805 (↓), lr=0.000250
   ✓ Epoch   5/100: train=0.0879, val=0.0786 (↓), lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0855, val=0.0788, patience=6/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 4 Summary - Client client_4
   Epochs: 20/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0858, RMSE=0.2928, R²=0.0021
   Val:   Loss=0.0786, RMSE=0.2804, R²=0.0016
============================================================


============================================================
🔄 Round 5 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.4702, val=0.4515 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.4315, val=0.4158 (↓), lr=0.000063
   📉 Epoch 3: LR reduced 0.000063 → 0.000031
   ✓ Epoch   3/100: train=0.4001, val=0.3874 (↓), lr=0.000031
   ✓ Epoch   4/100: train=0.3796, val=0.3742 (↓), lr=0.000031
   ✓ Epoch   5/100: train=0.3667, val=0.3611 (↓), lr=0.000031
   📉 Epoch 11: LR reduced 0.000031 → 0.000016
   ✓ Epoch  11/100: train=0.2825, val=0.2727 (↓), lr=0.000016
   📉 Epoch 19: LR reduced 0.000016 → 0.000008
   ✓ Epoch  21/100: train=0.1794, val=0.1740 (↓), lr=0.000008
   📉 Epoch 27: LR reduced 0.000008 → 0.000004
   ✓ Epoch  31/100: train=0.1396, val=0.1349 (↓), lr=0.000004
   📉 Epoch 35: LR reduced 0.000004 → 0.000002
   ✓ Epoch  41/100: train=0.1265, val=0.1219 (↓), lr=0.000002
   📉 Epoch 43: LR reduced 0.000002 → 0.000001
   ✓ Epoch  51/100: train=0.1217, val=0.1171 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.1182, val=0.1135 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.1150, val=0.1102 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.1120, val=0.1071 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.1093, val=0.1042 (↓), lr=0.000001

============================================================
📊 Round 5 Summary - Client client_4
   Epochs: 100/100
   LR: 0.000063 → 0.000001 (6 reductions)
   Train: Loss=0.1069, RMSE=0.3269, R²=-0.2427
   Val:   Loss=0.1018, RMSE=0.3190, R²=-0.2972
============================================================


📊 Round 5 Test Metrics:
   Loss: 0.4775, RMSE: 0.6910, MAE: 0.6270, R²: -4.6568

============================================================
🔄 Round 7 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.4646, val=0.4986 (↓), lr=0.000001
   ✓ Epoch   2/100: train=0.4637, val=0.4977 (↓), lr=0.000001
   ✓ Epoch   3/100: train=0.4629, val=0.4969 (↓), lr=0.000001
   ✓ Epoch   4/100: train=0.4621, val=0.4961 (↓), lr=0.000001
   ✓ Epoch   5/100: train=0.4614, val=0.4954 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.4580, val=0.4919 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.4535, val=0.4872 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.4496, val=0.4831 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.4461, val=0.4795 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.4428, val=0.4760 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.4396, val=0.4727 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.4365, val=0.4694 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.4335, val=0.4662 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.4305, val=0.4631 (↓), lr=0.000001

============================================================
📊 Round 7 Summary - Client client_4
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.4287, RMSE=0.6548, R²=-3.9698
   Val:   Loss=0.4603, RMSE=0.6785, R²=-5.0178
============================================================


📊 Round 7 Test Metrics:
   Loss: 0.4713, RMSE: 0.6865, MAE: 0.6220, R²: -4.5826

============================================================
🔄 Round 8 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.4680, val=0.4582 (↓), lr=0.000001
   • Epoch   2/100: train=0.4676, val=0.4578, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.4672, val=0.4574 (↓), lr=0.000001
   • Epoch   4/100: train=0.4669, val=0.4571, patience=1/15, lr=0.000001
   ✓ Epoch   5/100: train=0.4665, val=0.4567 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.4643, val=0.4545 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.4608, val=0.4510 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.4574, val=0.4477 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.4541, val=0.4444 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.4508, val=0.4412 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.4475, val=0.4380 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.4443, val=0.4348 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.4411, val=0.4317 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.4379, val=0.4285 (↓), lr=0.000001

============================================================
📊 Round 8 Summary - Client client_4
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.4350, RMSE=0.6595, R²=-4.1315
   Val:   Loss=0.4256, RMSE=0.6524, R²=-4.1017
============================================================


============================================================
🔄 Round 10 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.4573, val=0.4143 (↓), lr=0.000001
   • Epoch   2/100: train=0.4570, val=0.4140, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.4566, val=0.4136 (↓), lr=0.000001
   • Epoch   4/100: train=0.4562, val=0.4133, patience=1/15, lr=0.000001
   ✓ Epoch   5/100: train=0.4558, val=0.4129 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.4535, val=0.4108 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.4499, val=0.4073 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.4462, val=0.4040 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.4426, val=0.4006 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.4390, val=0.3972 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.4354, val=0.3938 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.4318, val=0.3904 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.4281, val=0.3870 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.4244, val=0.3835 (↓), lr=0.000001

============================================================
📊 Round 10 Summary - Client client_4
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.4209, RMSE=0.6488, R²=-3.9863
   Val:   Loss=0.3803, RMSE=0.6167, R²=-3.5381
============================================================


📊 Round 10 Test Metrics:
   Loss: 0.4345, RMSE: 0.6592, MAE: 0.5916, R²: -4.1468

📊 Round 10 Test Metrics:
   Loss: 0.3991, RMSE: 0.6317, MAE: 0.5609, R²: -3.7277

============================================================
🔄 Round 14 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.4028, val=0.3621 (↓), lr=0.000001
   • Epoch   2/100: train=0.4024, val=0.3617, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.4019, val=0.3612 (↓), lr=0.000001
   • Epoch   4/100: train=0.4015, val=0.3608, patience=1/15, lr=0.000001
   ✓ Epoch   5/100: train=0.4010, val=0.3604 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.3983, val=0.3578 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.3937, val=0.3536 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.3892, val=0.3494 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.3847, val=0.3451 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.3802, val=0.3409 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.3756, val=0.3366 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.3711, val=0.3323 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.3665, val=0.3280 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.3618, val=0.3236 (↓), lr=0.000001

============================================================
📊 Round 14 Summary - Client client_4
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.3575, RMSE=0.5979, R²=-3.2039
   Val:   Loss=0.3196, RMSE=0.5654, R²=-2.9244
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.3717, RMSE: 0.6097, MAE: 0.5359, R²: -3.4029

============================================================
🔄 Round 15 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.3709, val=0.3585 (↓), lr=0.000001
   • Epoch   2/100: train=0.3705, val=0.3581, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.3701, val=0.3577 (↓), lr=0.000001
   • Epoch   4/100: train=0.3697, val=0.3573, patience=1/15, lr=0.000001
   ✓ Epoch   5/100: train=0.3693, val=0.3569 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.3668, val=0.3545 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.3627, val=0.3505 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.3585, val=0.3465 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.3542, val=0.3423 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.3499, val=0.3381 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.3455, val=0.3338 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.3410, val=0.3295 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.3365, val=0.3251 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.3319, val=0.3206 (↓), lr=0.000001

============================================================
📊 Round 15 Summary - Client client_4
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.3266, RMSE=0.5714, R²=-2.9068
   Val:   Loss=0.3166, RMSE=0.5626, R²=-2.5968
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.3457, RMSE: 0.5880, MAE: 0.5111, R²: -3.0954

📊 Round 15 Test Metrics:
   Loss: 0.3176, RMSE: 0.5635, MAE: 0.4829, R²: -2.7621

📊 Round 15 Test Metrics:
   Loss: 0.2709, RMSE: 0.5205, MAE: 0.4346, R²: -2.2088

============================================================
🔄 Round 19 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.2629, val=0.2892 (↓), lr=0.000001
   ✓ Epoch   2/100: train=0.2622, val=0.2884 (↓), lr=0.000001
   ✓ Epoch   3/100: train=0.2614, val=0.2876 (↓), lr=0.000001
   ✓ Epoch   4/100: train=0.2607, val=0.2868 (↓), lr=0.000001
   ✓ Epoch   5/100: train=0.2599, val=0.2860 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.2555, val=0.2814 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.2485, val=0.2739 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.2416, val=0.2666 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.2347, val=0.2594 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.2279, val=0.2522 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.2212, val=0.2450 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.2144, val=0.2378 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.2077, val=0.2306 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.2009, val=0.2234 (↓), lr=0.000001

============================================================
📊 Round 19 Summary - Client client_4
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1936, RMSE=0.4399, R²=-1.3206
   Val:   Loss=0.2169, RMSE=0.4658, R²=-1.4556
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.2357, RMSE: 0.4855, MAE: 0.3985, R²: -1.7922

📊 Round 19 Test Metrics:
   Loss: 0.2002, RMSE: 0.4474, MAE: 0.3628, R²: -1.3710

============================================================
🔄 Round 21 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1982, val=0.1938 (↓), lr=0.000001
   ✓ Epoch   2/100: train=0.1975, val=0.1931 (↓), lr=0.000001
   ✓ Epoch   3/100: train=0.1969, val=0.1925 (↓), lr=0.000001
   ✓ Epoch   4/100: train=0.1962, val=0.1918 (↓), lr=0.000001
   ✓ Epoch   5/100: train=0.1955, val=0.1911 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.1915, val=0.1872 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.1849, val=0.1806 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.1784, val=0.1742 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.1720, val=0.1679 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.1657, val=0.1617 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.1596, val=0.1557 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.1537, val=0.1498 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.1479, val=0.1441 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.1424, val=0.1387 (↓), lr=0.000001

============================================================
📊 Round 21 Summary - Client client_4
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1373, RMSE=0.3705, R²=-0.6164
   Val:   Loss=0.1339, RMSE=0.3660, R²=-0.6163
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.1709, RMSE: 0.4134, MAE: 0.3334, R²: -1.0243

============================================================
🔄 Round 22 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1722, val=0.1535 (↓), lr=0.000001
   ✓ Epoch   2/100: train=0.1716, val=0.1529 (↓), lr=0.000001
   ✓ Epoch   3/100: train=0.1710, val=0.1523 (↓), lr=0.000001
   ✓ Epoch   4/100: train=0.1703, val=0.1518 (↓), lr=0.000001
   ✓ Epoch   5/100: train=0.1697, val=0.1512 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.1659, val=0.1478 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.1597, val=0.1422 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.1536, val=0.1369 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.1478, val=0.1318 (↓), lr=0.000001
   • Epoch  51/100: train=0.1422, val=0.1268, patience=1/15, lr=0.000001
   • Epoch  61/100: train=0.1368, val=0.1222, patience=1/15, lr=0.000001
   • Epoch  71/100: train=0.1317, val=0.1177, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.1268, val=0.1135, patience=1/15, lr=0.000001
   • Epoch  91/100: train=0.1222, val=0.1096, patience=1/15, lr=0.000001

============================================================
📊 Round 22 Summary - Client client_4
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1180, RMSE=0.3436, R²=-0.3907
   Val:   Loss=0.1064, RMSE=0.3261, R²=-0.2913
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0860, RMSE: 0.2932, MAE: 0.2529, R²: -0.0183

============================================================
🔄 Round 30 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 30 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0082
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0063
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2525, R²: -0.0026

📊 Round 30 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2525, R²: -0.0021

============================================================
🔄 Round 32 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 32 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0047
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0188
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0846, RMSE: 0.2908, MAE: 0.2525, R²: -0.0017

============================================================
🔄 Round 33 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 33 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0061
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0090
============================================================


============================================================
🔄 Round 37 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0957 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0957, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0957, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0957, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0958, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0958, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0957)

============================================================
📊 Round 37 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0063
   Val:   Loss=0.0957, RMSE=0.3093, R²=-0.0272
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0845, RMSE: 0.2907, MAE: 0.2525, R²: -0.0014

📊 Round 37 Test Metrics:
   Loss: 0.0845, RMSE: 0.2907, MAE: 0.2525, R²: -0.0013

📊 Round 37 Test Metrics:
   Loss: 0.0845, RMSE: 0.2907, MAE: 0.2525, R²: -0.0012

📊 Round 37 Test Metrics:
   Loss: 0.0845, RMSE: 0.2907, MAE: 0.2525, R²: -0.0009

📊 Round 37 Test Metrics:
   Loss: 0.0845, RMSE: 0.2907, MAE: 0.2525, R²: -0.0007

============================================================
🔄 Round 45 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 45 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0051
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0090
============================================================


============================================================
🔄 Round 47 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0927, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 47 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0066
   Val:   Loss=0.0926, RMSE=0.3044, R²=-0.0022
============================================================


============================================================
🔄 Round 48 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0930 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0931, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0931, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0931, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0931, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0932, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0930)

============================================================
📊 Round 48 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0049
   Val:   Loss=0.0930, RMSE=0.3050, R²=-0.0418
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0845, RMSE: 0.2906, MAE: 0.2525, R²: -0.0005

============================================================
🔄 Round 50 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 50 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0065
   Val:   Loss=0.0853, RMSE=0.2920, R²=-0.0136
============================================================


============================================================
🔄 Round 51 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 51 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0033
   Val:   Loss=0.0803, RMSE=0.2833, R²=-0.0136
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0845, RMSE: 0.2906, MAE: 0.2526, R²: -0.0005

============================================================
🔄 Round 52 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 52 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=-0.0053
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0339
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0845, RMSE: 0.2906, MAE: 0.2526, R²: -0.0004

📊 Round 52 Test Metrics:
   Loss: 0.0845, RMSE: 0.2906, MAE: 0.2526, R²: -0.0004

📊 Round 52 Test Metrics:
   Loss: 0.0845, RMSE: 0.2906, MAE: 0.2526, R²: -0.0004

📊 Round 52 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2526, R²: -0.0004

============================================================
🔄 Round 58 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 58 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0052
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0136
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2527, R²: -0.0003

============================================================
🔄 Round 60 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 60 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0020
   Val:   Loss=0.0869, RMSE=0.2948, R²=-0.0194
============================================================


============================================================
🔄 Round 61 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 61 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0024
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0179
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2527, R²: -0.0003

============================================================
🔄 Round 63 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 63 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0050
   Val:   Loss=0.0855, RMSE=0.2925, R²=-0.0071
============================================================


============================================================
🔄 Round 65 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 65 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0050
   Val:   Loss=0.0853, RMSE=0.2920, R²=-0.0089
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0845, RMSE: 0.2906, MAE: 0.2527, R²: -0.0004

📊 Round 65 Test Metrics:
   Loss: 0.0845, RMSE: 0.2906, MAE: 0.2527, R²: -0.0004

============================================================
🔄 Round 69 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 69 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=-0.0065
   Val:   Loss=0.0765, RMSE=0.2766, R²=-0.0152
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2527, R²: -0.0004

📊 Round 69 Test Metrics:
   Loss: 0.0845, RMSE: 0.2906, MAE: 0.2527, R²: -0.0004

============================================================
🔄 Round 71 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0936 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0936, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0936, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0936, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0936, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0936, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0936)

============================================================
📊 Round 71 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0058
   Val:   Loss=0.0936, RMSE=0.3060, R²=-0.0042
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0845, RMSE: 0.2906, MAE: 0.2527, R²: -0.0004

============================================================
🔄 Round 75 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 75 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0056
   Val:   Loss=0.0860, RMSE=0.2932, R²=-0.0045
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0845, RMSE: 0.2906, MAE: 0.2527, R²: -0.0004

📊 Round 75 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2527, R²: -0.0003

============================================================
🔄 Round 79 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 79 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0037
   Val:   Loss=0.0879, RMSE=0.2965, R²=-0.0118
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2527, R²: -0.0003

📊 Round 79 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2527, R²: -0.0003

📊 Round 79 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2527, R²: -0.0003

============================================================
🔄 Round 85 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 85 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2954, R²=-0.0083
   Val:   Loss=0.0757, RMSE=0.2751, R²=-0.0093
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2527, R²: -0.0004

============================================================
🔄 Round 87 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 87 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0067
   Val:   Loss=0.0892, RMSE=0.2987, R²=-0.0072
============================================================


============================================================
🔄 Round 88 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 88 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0060
   Val:   Loss=0.0867, RMSE=0.2945, R²=-0.0030
============================================================


============================================================
🔄 Round 89 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 89 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0051
   Val:   Loss=0.0788, RMSE=0.2808, R²=-0.0099
============================================================


============================================================
🔄 Round 91 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0940 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0940, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0940, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0940, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0940, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0940, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0940)

============================================================
📊 Round 91 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0056
   Val:   Loss=0.0940, RMSE=0.3066, R²=-0.0057
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2527, R²: -0.0003

============================================================
🔄 Round 94 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 94 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=-0.0056
   Val:   Loss=0.0885, RMSE=0.2974, R²=-0.0268
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2527, R²: -0.0003

📊 Round 94 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2527, R²: -0.0002

============================================================
🔄 Round 102 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 102 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0048
   Val:   Loss=0.0789, RMSE=0.2810, R²=-0.0077
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2526, R²: -0.0002

============================================================
🔄 Round 103 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 103 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0040
   Val:   Loss=0.0872, RMSE=0.2952, R²=-0.0178
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2526, R²: -0.0002

============================================================
🔄 Round 109 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 109 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0059
   Val:   Loss=0.0914, RMSE=0.3024, R²=-0.0092
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2526, R²: -0.0002

============================================================
🔄 Round 110 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 110 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=-0.0052
   Val:   Loss=0.0756, RMSE=0.2750, R²=-0.0051
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2527, R²: -0.0002

============================================================
🔄 Round 113 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0697 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0697, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0697, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0697, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0697, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0697, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0697)

============================================================
📊 Round 113 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2978, R²=-0.0044
   Val:   Loss=0.0697, RMSE=0.2640, R²=-0.0196
============================================================


============================================================
🔄 Round 114 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 114 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0058
   Val:   Loss=0.0816, RMSE=0.2856, R²=-0.0015
============================================================


============================================================
🔄 Round 115 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 115 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0058
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0244
============================================================


============================================================
🔄 Round 116 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 116 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=-0.0068
   Val:   Loss=0.0812, RMSE=0.2850, R²=0.0030
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2527, R²: -0.0003

============================================================
🔄 Round 118 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 118 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=-0.0061
   Val:   Loss=0.0747, RMSE=0.2733, R²=0.0006
============================================================


============================================================
🔄 Round 120 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 120 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0069
   Val:   Loss=0.0847, RMSE=0.2909, R²=0.0022
============================================================


============================================================
🔄 Round 121 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 121 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=-0.0045
   Val:   Loss=0.0773, RMSE=0.2780, R²=-0.0067
============================================================


============================================================
🔄 Round 122 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 122 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0052
   Val:   Loss=0.0865, RMSE=0.2942, R²=-0.0045
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2527, R²: -0.0002

============================================================
🔄 Round 123 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 123 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0060
   Val:   Loss=0.0902, RMSE=0.3004, R²=-0.0008
============================================================


============================================================
🔄 Round 124 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 124 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0037
   Val:   Loss=0.0878, RMSE=0.2964, R²=-0.0099
============================================================


============================================================
🔄 Round 125 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 125 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0060
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0005
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2527, R²: -0.0002

📊 Round 125 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2528, R²: -0.0003

============================================================
🔄 Round 128 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 128 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0068
   Val:   Loss=0.0907, RMSE=0.3012, R²=-0.0071
============================================================


============================================================
🔄 Round 129 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 129 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0027
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0171
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2528, R²: -0.0003

============================================================
🔄 Round 132 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 132 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=-0.0055
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.0042
============================================================


============================================================
🔄 Round 133 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0971 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0971, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0971, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0971, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0971, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0971, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0971)

============================================================
📊 Round 133 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0064
   Val:   Loss=0.0971, RMSE=0.3116, R²=-0.0024
============================================================


============================================================
🔄 Round 134 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0961 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0961, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0961, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0961, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0961, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0961, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0961)

============================================================
📊 Round 134 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0044
   Val:   Loss=0.0961, RMSE=0.3100, R²=-0.0179
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2528, R²: -0.0003

📊 Round 134 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2528, R²: -0.0003

============================================================
🔄 Round 141 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 141 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0050
   Val:   Loss=0.0910, RMSE=0.3017, R²=-0.0056
============================================================


============================================================
🔄 Round 144 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 144 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0071
   Val:   Loss=0.0829, RMSE=0.2880, R²=-0.0094
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2528, R²: -0.0003

============================================================
🔄 Round 146 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 146 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=-0.0057
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0065
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2528, R²: -0.0003

============================================================
🔄 Round 147 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 147 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=-0.0109
   Val:   Loss=0.0762, RMSE=0.2761, R²=-0.0378
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2528, R²: -0.0003

============================================================
🔄 Round 148 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 148 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0031
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0124
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2527, R²: -0.0002

📊 Round 148 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2527, R²: -0.0002

============================================================
🔄 Round 153 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 153 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0025
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0189
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2527, R²: -0.0002

============================================================
🔄 Round 154 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 154 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0041
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0143
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2527, R²: -0.0002

============================================================
🔄 Round 155 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 155 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0046
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0075
============================================================


============================================================
🔄 Round 156 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 156 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0034
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0167
============================================================


============================================================
🔄 Round 157 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 157 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0046
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0101
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2527, R²: -0.0001

============================================================
🔄 Round 162 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 162 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2915, R²=-0.0065
   Val:   Loss=0.0847, RMSE=0.2910, R²=0.0025
============================================================


============================================================
🔄 Round 163 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 163 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0061
   Val:   Loss=0.0812, RMSE=0.2849, R²=-0.0065
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2527, R²: -0.0001

📊 Round 163 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2527, R²: -0.0001

📊 Round 163 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2527, R²: -0.0001

============================================================
🔄 Round 167 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0989 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0989, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0989, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0989, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0989, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0989, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0989)

============================================================
📊 Round 167 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0063
   Val:   Loss=0.0989, RMSE=0.3145, R²=0.0013
============================================================


============================================================
🔄 Round 168 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 168 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0064
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0172
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2527, R²: -0.0002

📊 Round 168 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2528, R²: -0.0002

📊 Round 168 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2528, R²: -0.0002

============================================================
🔄 Round 172 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0923, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 172 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=-0.0052
   Val:   Loss=0.0923, RMSE=0.3038, R²=-0.0035
============================================================


============================================================
🔄 Round 173 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 173 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=-0.0065
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0038
============================================================


============================================================
🔄 Round 174 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 174 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0048
   Val:   Loss=0.0863, RMSE=0.2937, R²=-0.0044
============================================================


============================================================
🔄 Round 176 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 176 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=-0.0061
   Val:   Loss=0.0775, RMSE=0.2784, R²=0.0010
============================================================


============================================================
🔄 Round 178 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0924 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0924, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0924, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 178 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0044
   Val:   Loss=0.0924, RMSE=0.3040, R²=-0.0050
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2527, R²: -0.0001

📊 Round 178 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2527, R²: -0.0002

============================================================
🔄 Round 182 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 182 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0072
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0138
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2527, R²: -0.0002

============================================================
🔄 Round 184 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 184 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0070
   Val:   Loss=0.0902, RMSE=0.3003, R²=-0.0154
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2527, R²: -0.0001

📊 Round 184 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2527, R²: -0.0001

============================================================
🔄 Round 189 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 189 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0042
   Val:   Loss=0.0894, RMSE=0.2990, R²=-0.0067
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2527, R²: -0.0002

============================================================
🔄 Round 190 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 190 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0060
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0106
============================================================


📊 Round 190 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2527, R²: -0.0002

📊 Round 190 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2527, R²: -0.0002

📊 Round 190 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2528, R²: -0.0002

============================================================
🔄 Round 197 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 197 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0049
   Val:   Loss=0.0766, RMSE=0.2768, R²=-0.0178
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2527, R²: -0.0001

📊 Round 197 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2527, R²: -0.0001

📊 Round 197 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2527, R²: -0.0001

============================================================
🔄 Round 203 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 203 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0065
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0049
============================================================


📊 Round 203 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2527, R²: -0.0000

============================================================
🔄 Round 206 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 206 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2923, R²=-0.0016
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0160
============================================================


📊 Round 206 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2527, R²: -0.0001

============================================================
🔄 Round 208 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 208 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0055
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0051
============================================================


============================================================
🔄 Round 209 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 209 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=-0.0044
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0110
============================================================


📊 Round 209 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2527, R²: -0.0001

============================================================
🔄 Round 210 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 210 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=-0.0056
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0067
============================================================


📊 Round 210 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2527, R²: -0.0000

============================================================
🔄 Round 212 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 212 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0057
   Val:   Loss=0.0887, RMSE=0.2978, R²=-0.0047
============================================================


📊 Round 212 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2527, R²: -0.0000

============================================================
🔄 Round 213 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 213 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0056
   Val:   Loss=0.0789, RMSE=0.2809, R²=-0.0003
============================================================


============================================================
🔄 Round 214 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 214 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=-0.0077
   Val:   Loss=0.0905, RMSE=0.3008, R²=-0.0317
============================================================


📊 Round 214 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: -0.0000

============================================================
🔄 Round 215 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.1012 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.1013, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.1013, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.1014, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.1014, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.1017, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1012)

============================================================
📊 Round 215 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0058
   Val:   Loss=0.1012, RMSE=0.3181, R²=-0.0400
============================================================


============================================================
🔄 Round 217 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 217 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0046
   Val:   Loss=0.0894, RMSE=0.2990, R²=-0.0151
============================================================


📊 Round 217 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0000

📊 Round 217 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0000

============================================================
🔄 Round 222 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 222 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2937, R²=-0.0047
   Val:   Loss=0.0793, RMSE=0.2815, R²=-0.0181
============================================================


📊 Round 222 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0000

📊 Round 222 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2527, R²: -0.0000

============================================================
🔄 Round 227 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0929 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0930, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0930, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0930, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0930, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0930, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0929)

============================================================
📊 Round 227 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0049
   Val:   Loss=0.0929, RMSE=0.3049, R²=-0.0034
============================================================


📊 Round 227 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: -0.0000

📊 Round 227 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2527, R²: -0.0000

📊 Round 227 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2527, R²: -0.0001

📊 Round 227 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2527, R²: -0.0001

============================================================
🔄 Round 235 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 235 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2959, R²=-0.0044
   Val:   Loss=0.0741, RMSE=0.2722, R²=-0.0049
============================================================


============================================================
🔄 Round 236 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 236 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=-0.0039
   Val:   Loss=0.0773, RMSE=0.2781, R²=-0.0088
============================================================


============================================================
🔄 Round 237 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 237 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0014
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0163
============================================================


📊 Round 237 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2527, R²: -0.0001

============================================================
🔄 Round 240 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 240 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0036
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0071
============================================================


============================================================
🔄 Round 241 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 241 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=-0.0049
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0049
============================================================


============================================================
🔄 Round 242 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 242 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0014
   Val:   Loss=0.0903, RMSE=0.3005, R²=-0.0164
============================================================


============================================================
🔄 Round 243 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 243 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0031
   Val:   Loss=0.0812, RMSE=0.2849, R²=-0.0362
============================================================


============================================================
🔄 Round 244 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 244 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0057
   Val:   Loss=0.0767, RMSE=0.2770, R²=-0.0000
============================================================


============================================================
🔄 Round 245 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 245 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0036
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0100
============================================================


📊 Round 245 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2528, R²: -0.0001

📊 Round 245 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2527, R²: -0.0001

📊 Round 245 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2527, R²: -0.0000

============================================================
🔄 Round 249 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 249 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0035
   Val:   Loss=0.0860, RMSE=0.2932, R²=-0.0072
============================================================


============================================================
🔄 Round 250 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 250 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=-0.0046
   Val:   Loss=0.0769, RMSE=0.2774, R²=-0.0034
============================================================


📊 Round 250 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2527, R²: -0.0000

📊 Round 250 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2527, R²: -0.0000

📊 Round 250 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2527, R²: -0.0000

============================================================
🔄 Round 253 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 253 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0053
   Val:   Loss=0.0920, RMSE=0.3033, R²=-0.0062
============================================================


============================================================
🔄 Round 255 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 255 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2911, R²=-0.0047
   Val:   Loss=0.0853, RMSE=0.2920, R²=-0.0094
============================================================


📊 Round 255 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2527, R²: -0.0000

📊 Round 255 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2527, R²: -0.0000

============================================================
🔄 Round 262 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 262 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0028
   Val:   Loss=0.0876, RMSE=0.2959, R²=-0.0091
============================================================


============================================================
🔄 Round 264 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 264 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=-0.0053
   Val:   Loss=0.0849, RMSE=0.2913, R²=-0.0060
============================================================


============================================================
🔄 Round 265 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 265 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0052
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0000
============================================================


📊 Round 265 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0000

============================================================
🔄 Round 266 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 266 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0049
   Val:   Loss=0.0785, RMSE=0.2802, R²=-0.0104
============================================================


📊 Round 266 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0000

============================================================
🔄 Round 268 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 268 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0051
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0111
============================================================


📊 Round 268 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0000

============================================================
🔄 Round 269 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 269 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2920, R²=-0.0045
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0129
============================================================


📊 Round 269 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0001

============================================================
🔄 Round 271 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0937 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0937, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0937, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0937, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0937, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0937, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0937)

============================================================
📊 Round 271 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0039
   Val:   Loss=0.0937, RMSE=0.3062, R²=-0.0043
============================================================


📊 Round 271 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0000

============================================================
🔄 Round 272 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 272 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0044
   Val:   Loss=0.0857, RMSE=0.2928, R²=-0.0023
============================================================


📊 Round 272 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0000

============================================================
🔄 Round 273 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 273 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0062
   Val:   Loss=0.0886, RMSE=0.2977, R²=-0.0297
============================================================


📊 Round 273 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0000

============================================================
🔄 Round 276 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 276 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=-0.0031
   Val:   Loss=0.0779, RMSE=0.2791, R²=-0.0090
============================================================


📊 Round 276 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0000

📊 Round 276 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0000

============================================================
🔄 Round 278 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 278 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0052
   Val:   Loss=0.0905, RMSE=0.3009, R²=0.0010
============================================================


📊 Round 278 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0000

============================================================
🔄 Round 279 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 279 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0052
   Val:   Loss=0.0777, RMSE=0.2787, R²=-0.0054
============================================================


============================================================
🔄 Round 280 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 280 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0048
   Val:   Loss=0.0892, RMSE=0.2986, R²=-0.0019
============================================================


============================================================
🔄 Round 281 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 281 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0037
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0067
============================================================


============================================================
🔄 Round 282 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 282 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0056
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0001
============================================================


============================================================
🔄 Round 283 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 283 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0046
   Val:   Loss=0.0833, RMSE=0.2887, R²=-0.0040
============================================================


📊 Round 283 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2528, R²: -0.0001

============================================================
🔄 Round 285 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 285 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=-0.0021
   Val:   Loss=0.0776, RMSE=0.2785, R²=-0.0144
============================================================


📊 Round 285 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0000

📊 Round 285 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0000

📊 Round 285 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2528, R²: -0.0001

============================================================
🔄 Round 289 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 289 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0041
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0153
============================================================


📊 Round 289 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2528, R²: -0.0001

📊 Round 289 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2528, R²: -0.0001

============================================================
🔄 Round 295 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 295 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0037
   Val:   Loss=0.0898, RMSE=0.2997, R²=-0.0080
============================================================


============================================================
🔄 Round 299 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 299 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0037
   Val:   Loss=0.0869, RMSE=0.2948, R²=-0.0061
============================================================


📊 Round 299 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2528, R²: -0.0001

============================================================
🔄 Round 300 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 300 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0033
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0088
============================================================


============================================================
🔄 Round 302 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 302 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0031
   Val:   Loss=0.0906, RMSE=0.3009, R²=-0.0069
============================================================


============================================================
🔄 Round 303 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0711 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0711, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0711, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0711, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0711, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0711, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0711)

============================================================
📊 Round 303 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2971, R²=-0.0044
   Val:   Loss=0.0711, RMSE=0.2666, R²=-0.0050
============================================================


📊 Round 303 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0000

============================================================
🔄 Round 308 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 308 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0048
   Val:   Loss=0.0842, RMSE=0.2901, R²=-0.0022
============================================================


============================================================
🔄 Round 309 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 309 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0036
   Val:   Loss=0.0859, RMSE=0.2932, R²=-0.0107
============================================================


============================================================
🔄 Round 310 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 310 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=-0.0036
   Val:   Loss=0.0837, RMSE=0.2892, R²=-0.0195
============================================================


📊 Round 310 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0000

============================================================
🔄 Round 311 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 311 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0027
   Val:   Loss=0.0806, RMSE=0.2838, R²=-0.0092
============================================================


============================================================
🔄 Round 312 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 312 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0041
   Val:   Loss=0.0862, RMSE=0.2935, R²=-0.0223
============================================================


============================================================
🔄 Round 313 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 313 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0068
   Val:   Loss=0.0783, RMSE=0.2799, R²=-0.0015
============================================================


📊 Round 313 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0000

============================================================
🔄 Round 315 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 315 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0038
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0044
============================================================


============================================================
🔄 Round 316 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 316 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0045
   Val:   Loss=0.0865, RMSE=0.2942, R²=-0.0060
============================================================


📊 Round 316 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0000

============================================================
🔄 Round 318 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 318 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2920, R²=-0.0031
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0079
============================================================


============================================================
🔄 Round 320 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 320 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0039
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0044
============================================================


📊 Round 320 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0001

============================================================
🔄 Round 324 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 324 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=-0.0066
   Val:   Loss=0.0801, RMSE=0.2831, R²=-0.0351
============================================================


📊 Round 324 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0001

============================================================
🔄 Round 329 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 329 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0039
   Val:   Loss=0.0805, RMSE=0.2838, R²=-0.0155
============================================================


============================================================
🔄 Round 330 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 330 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2945, R²=-0.0037
   Val:   Loss=0.0771, RMSE=0.2777, R²=-0.0074
============================================================


============================================================
🔄 Round 331 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 331 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0028
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0199
============================================================


📊 Round 331 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: -0.0000

============================================================
🔄 Round 333 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0963 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0963, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0963, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0963, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0964, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0964, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0963)

============================================================
📊 Round 333 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0051
   Val:   Loss=0.0963, RMSE=0.3104, R²=-0.0060
============================================================


📊 Round 333 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2528, R²: -0.0001

============================================================
🔄 Round 338 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 338 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=-0.0030
   Val:   Loss=0.0893, RMSE=0.2988, R²=-0.0082
============================================================


============================================================
🔄 Round 340 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 340 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0029
   Val:   Loss=0.0907, RMSE=0.3012, R²=-0.0160
============================================================


📊 Round 340 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2528, R²: -0.0001

📊 Round 340 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0000

📊 Round 340 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0001

📊 Round 340 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0001

============================================================
🔄 Round 347 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 347 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0062
   Val:   Loss=0.0833, RMSE=0.2887, R²=-0.0405
============================================================


============================================================
🔄 Round 353 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 353 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0061
   Val:   Loss=0.0789, RMSE=0.2809, R²=-0.0100
============================================================


📊 Round 353 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0001

📊 Round 353 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0001

============================================================
🔄 Round 361 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 361 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0014
   Val:   Loss=0.0844, RMSE=0.2906, R²=-0.0124
============================================================


============================================================
🔄 Round 362 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 362 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=-0.0035
   Val:   Loss=0.0833, RMSE=0.2887, R²=-0.0049
============================================================


============================================================
🔄 Round 363 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 363 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0032
   Val:   Loss=0.0865, RMSE=0.2940, R²=-0.0070
============================================================


📊 Round 363 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2526, R²: 0.0002

============================================================
🔄 Round 364 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 364 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=-0.0033
   Val:   Loss=0.0817, RMSE=0.2857, R²=-0.0041
============================================================


📊 Round 364 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2526, R²: 0.0002

📊 Round 364 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2526, R²: 0.0002

============================================================
🔄 Round 370 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 370 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0020
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0088
============================================================


📊 Round 370 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2526, R²: 0.0002

📊 Round 370 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2526, R²: 0.0002

📊 Round 370 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2526, R²: 0.0002

============================================================
🔄 Round 379 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 379 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0037
   Val:   Loss=0.0896, RMSE=0.2994, R²=-0.0017
============================================================


============================================================
🔄 Round 380 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 380 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0033
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0104
============================================================


📊 Round 380 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2526, R²: 0.0002

============================================================
🔄 Round 382 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 382 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0040
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0003
============================================================


============================================================
🔄 Round 383 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 383 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0039
   Val:   Loss=0.0899, RMSE=0.2998, R²=-0.0008
============================================================


📊 Round 383 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2526, R²: 0.0002

============================================================
🔄 Round 384 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 384 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0040
   Val:   Loss=0.0913, RMSE=0.3021, R²=-0.0043
============================================================


============================================================
🔄 Round 385 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0922, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0923, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 385 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0028
   Val:   Loss=0.0921, RMSE=0.3034, R²=-0.0366
============================================================


📊 Round 385 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2526, R²: 0.0002

============================================================
🔄 Round 388 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 388 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0031
   Val:   Loss=0.0887, RMSE=0.2979, R²=-0.0047
============================================================


📊 Round 388 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2526, R²: 0.0002

============================================================
🔄 Round 389 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 389 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0038
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0009
============================================================


📊 Round 389 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0002

============================================================
🔄 Round 390 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 390 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0045
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0012
============================================================


============================================================
🔄 Round 391 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 391 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0043
   Val:   Loss=0.0827, RMSE=0.2875, R²=0.0005
============================================================


📊 Round 391 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2526, R²: 0.0002

============================================================
🔄 Round 393 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0974 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0974, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0974, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0974, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0974, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0974, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0974)

============================================================
📊 Round 393 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0028
   Val:   Loss=0.0974, RMSE=0.3121, R²=-0.0055
============================================================


============================================================
🔄 Round 395 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 395 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2949, R²=-0.0045
   Val:   Loss=0.0761, RMSE=0.2758, R²=-0.0042
============================================================


📊 Round 395 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2526, R²: 0.0002

📊 Round 395 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2526, R²: 0.0002

============================================================
🔄 Round 398 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 398 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0032
   Val:   Loss=0.0790, RMSE=0.2810, R²=-0.0054
============================================================


============================================================
🔄 Round 400 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 400 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0015
   Val:   Loss=0.0856, RMSE=0.2927, R²=-0.0099
============================================================


📊 Round 400 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2526, R²: 0.0002

📊 Round 400 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2526, R²: 0.0002

📊 Round 400 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0002

============================================================
🔄 Round 403 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 403 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0025
   Val:   Loss=0.0895, RMSE=0.2992, R²=-0.0084
============================================================


============================================================
🔄 Round 406 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 406 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0035
   Val:   Loss=0.0861, RMSE=0.2935, R²=-0.0038
============================================================


📊 Round 406 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0001

📊 Round 406 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0001

============================================================
🔄 Round 409 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0960 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0961, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0961, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0961, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0961, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0962, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0960)

============================================================
📊 Round 409 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0020
   Val:   Loss=0.0960, RMSE=0.3099, R²=-0.0148
============================================================


📊 Round 409 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0001

📊 Round 409 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0001

📊 Round 409 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0001

============================================================
🔄 Round 412 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 412 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0037
   Val:   Loss=0.0799, RMSE=0.2826, R²=-0.0016
============================================================


📊 Round 412 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0001

📊 Round 412 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0001

============================================================
🔄 Round 416 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 416 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0014
   Val:   Loss=0.0811, RMSE=0.2847, R²=-0.0111
============================================================


============================================================
🔄 Round 417 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0967 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0967, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0967, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0967, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0967, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0968, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0967)

============================================================
📊 Round 417 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0025
   Val:   Loss=0.0967, RMSE=0.3109, R²=-0.0101
============================================================


============================================================
🔄 Round 418 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 418 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0025
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0127
============================================================


📊 Round 418 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2526, R²: 0.0002

============================================================
🔄 Round 419 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 419 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0022
   Val:   Loss=0.0852, RMSE=0.2918, R²=-0.0085
============================================================


📊 Round 419 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0002

============================================================
🔄 Round 421 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 421 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0061
   Val:   Loss=0.0830, RMSE=0.2882, R²=-0.0100
============================================================


📊 Round 421 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0002

============================================================
🔄 Round 422 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 422 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0035
   Val:   Loss=0.0825, RMSE=0.2873, R²=-0.0056
============================================================


============================================================
🔄 Round 423 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 423 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0031
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0035
============================================================


============================================================
🔄 Round 424 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 424 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0033
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0057
============================================================


============================================================
🔄 Round 425 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0932 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0932, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0932, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0932, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0932, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0931, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0932)

============================================================
📊 Round 425 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0033
   Val:   Loss=0.0932, RMSE=0.3052, R²=-0.0027
============================================================


📊 Round 425 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0002

📊 Round 425 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0002

============================================================
🔄 Round 427 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 427 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0040
   Val:   Loss=0.0899, RMSE=0.2999, R²=-0.0002
============================================================


📊 Round 427 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0002

============================================================
🔄 Round 429 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0927, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0927, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 429 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0011
   Val:   Loss=0.0926, RMSE=0.3044, R²=-0.0141
============================================================


============================================================
🔄 Round 430 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 430 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0037
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0028
============================================================


📊 Round 430 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0001

📊 Round 430 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0001

============================================================
🔄 Round 432 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 432 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0033
   Val:   Loss=0.0766, RMSE=0.2768, R²=-0.0028
============================================================


📊 Round 432 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0001

📊 Round 432 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0001

============================================================
🔄 Round 440 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 440 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0055
   Val:   Loss=0.0763, RMSE=0.2762, R²=-0.0071
============================================================


📊 Round 440 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0002

============================================================
🔄 Round 443 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 443 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0057
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0115
============================================================


📊 Round 443 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2526, R²: 0.0002

============================================================
🔄 Round 445 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 445 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=-0.0031
   Val:   Loss=0.0815, RMSE=0.2854, R²=-0.0036
============================================================


📊 Round 445 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2526, R²: 0.0002

============================================================
🔄 Round 446 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 446 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0025
   Val:   Loss=0.0900, RMSE=0.2999, R²=-0.0163
============================================================


📊 Round 446 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2526, R²: 0.0002

📊 Round 446 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2526, R²: 0.0002

============================================================
🔄 Round 450 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 450 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=-0.0035
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0014
============================================================


============================================================
🔄 Round 451 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 451 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0038
   Val:   Loss=0.0857, RMSE=0.2928, R²=-0.0021
============================================================


============================================================
🔄 Round 452 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 452 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0024
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0070
============================================================


📊 Round 452 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0002

============================================================
🔄 Round 453 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 453 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0028
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0044
============================================================


📊 Round 453 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0002

============================================================
🔄 Round 456 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 456 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2939, R²=-0.0048
   Val:   Loss=0.0784, RMSE=0.2800, R²=-0.0118
============================================================


📊 Round 456 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0002

============================================================
🔄 Round 461 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 461 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0045
   Val:   Loss=0.0798, RMSE=0.2824, R²=-0.0177
============================================================


📊 Round 461 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0001

============================================================
🔄 Round 463 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 463 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2908, R²=-0.0040
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0008
============================================================


📊 Round 463 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0001

============================================================
🔄 Round 465 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 465 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0045
   Val:   Loss=0.0828, RMSE=0.2877, R²=0.0019
============================================================


============================================================
🔄 Round 466 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 466 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0037
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0014
============================================================


============================================================
🔄 Round 467 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 467 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0023
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0065
============================================================


📊 Round 467 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0001

============================================================
🔄 Round 468 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 468 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2921, R²=-0.0070
   Val:   Loss=0.0824, RMSE=0.2871, R²=0.0072
============================================================


============================================================
🔄 Round 470 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 470 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=-0.0042
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0016
============================================================


📊 Round 470 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0001

============================================================
🔄 Round 471 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 471 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0054
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0082
============================================================


============================================================
🔄 Round 473 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 473 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2920, R²=-0.0032
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0046
============================================================


📊 Round 473 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0001

============================================================
🔄 Round 474 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0975 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0975, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0975, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0975, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0975, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0975, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0975)

============================================================
📊 Round 474 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0035
   Val:   Loss=0.0975, RMSE=0.3122, R²=-0.0033
============================================================


📊 Round 474 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2526, R²: 0.0002

============================================================
🔄 Round 475 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 475 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0030
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0123
============================================================


============================================================
🔄 Round 478 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 478 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0040
   Val:   Loss=0.0887, RMSE=0.2978, R²=-0.0033
============================================================


============================================================
🔄 Round 479 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 479 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2892, R²=-0.0042
   Val:   Loss=0.0891, RMSE=0.2985, R²=-0.0224
============================================================


📊 Round 479 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0001

============================================================
🔄 Round 481 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 481 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0065
   Val:   Loss=0.0907, RMSE=0.3011, R²=-0.0071
============================================================


📊 Round 481 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0001

============================================================
🔄 Round 483 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 483 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0041
   Val:   Loss=0.0849, RMSE=0.2914, R²=0.0008
============================================================


============================================================
🔄 Round 484 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 484 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0025
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0052
============================================================


📊 Round 484 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0001

📊 Round 484 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0002

============================================================
🔄 Round 486 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 486 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0031
   Val:   Loss=0.0864, RMSE=0.2940, R²=-0.0027
============================================================


📊 Round 486 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0001

📊 Round 486 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0001

============================================================
🔄 Round 488 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 488 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0042
   Val:   Loss=0.0869, RMSE=0.2947, R²=-0.0098
============================================================


============================================================
🔄 Round 490 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 490 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0020
   Val:   Loss=0.0837, RMSE=0.2894, R²=-0.0135
============================================================


📊 Round 490 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0001

📊 Round 490 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0001

============================================================
🔄 Round 492 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 492 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0013
   Val:   Loss=0.0859, RMSE=0.2930, R²=-0.0121
============================================================


============================================================
🔄 Round 497 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 497 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0051
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0022
============================================================


📊 Round 497 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0001

============================================================
🔄 Round 498 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 498 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0021
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0186
============================================================


============================================================
🔄 Round 503 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 503 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0026
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0061
============================================================


============================================================
🔄 Round 505 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 505 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=-0.0031
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0184
============================================================


📊 Round 505 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0001

============================================================
🔄 Round 508 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 508 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0017
   Val:   Loss=0.0827, RMSE=0.2875, R²=-0.0086
============================================================


📊 Round 508 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0001

📊 Round 508 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0001

📊 Round 508 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0001

============================================================
🔄 Round 511 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 511 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0037
   Val:   Loss=0.0893, RMSE=0.2988, R²=-0.0013
============================================================


📊 Round 511 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0001

============================================================
🔄 Round 512 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 512 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0013
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0110
============================================================


📊 Round 512 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0001

📊 Round 512 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0001

📊 Round 512 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0001

============================================================
🔄 Round 521 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 521 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0008
   Val:   Loss=0.0886, RMSE=0.2976, R²=-0.0269
============================================================


📊 Round 521 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0001

============================================================
🔄 Round 523 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0708 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0708, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0708, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0708, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0708, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0708, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0708)

============================================================
📊 Round 523 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2970, R²=-0.0023
   Val:   Loss=0.0708, RMSE=0.2661, R²=-0.0061
============================================================


📊 Round 523 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0001

============================================================
🔄 Round 526 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 526 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0037
   Val:   Loss=0.0901, RMSE=0.3002, R²=-0.0022
============================================================


📊 Round 526 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0001

============================================================
🔄 Round 528 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0964 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0964, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0964, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0964, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0964, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0965, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0964)

============================================================
📊 Round 528 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0013
   Val:   Loss=0.0964, RMSE=0.3104, R²=-0.0382
============================================================


📊 Round 528 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0001

============================================================
🔄 Round 531 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 531 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=-0.0024
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0095
============================================================


============================================================
🔄 Round 533 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 533 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=-0.0020
   Val:   Loss=0.0768, RMSE=0.2771, R²=-0.0066
============================================================


📊 Round 533 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0002

📊 Round 533 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2526, R²: 0.0002

📊 Round 533 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2526, R²: 0.0002

📊 Round 533 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2526, R²: 0.0002

📊 Round 533 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0002

============================================================
🔄 Round 539 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 539 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=-0.0032
   Val:   Loss=0.0741, RMSE=0.2722, R²=-0.0030
============================================================


============================================================
🔄 Round 543 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 543 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0032
   Val:   Loss=0.0903, RMSE=0.3004, R²=-0.0338
============================================================


📊 Round 543 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0002

📊 Round 543 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2526, R²: 0.0002

============================================================
🔄 Round 549 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 549 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0041
   Val:   Loss=0.0881, RMSE=0.2969, R²=-0.0315
============================================================


📊 Round 549 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0002

============================================================
🔄 Round 553 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 553 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0044
   Val:   Loss=0.0860, RMSE=0.2932, R²=-0.0002
============================================================


📊 Round 553 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0001

📊 Round 553 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0001

============================================================
🔄 Round 556 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 556 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0037
   Val:   Loss=0.0795, RMSE=0.2820, R²=0.0011
============================================================


📊 Round 556 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0001

============================================================
🔄 Round 558 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 558 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2911, R²=-0.0040
   Val:   Loss=0.0847, RMSE=0.2910, R²=0.0017
============================================================


📊 Round 558 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0002

============================================================
🔄 Round 559 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 559 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0021
   Val:   Loss=0.0765, RMSE=0.2766, R²=-0.0075
============================================================


============================================================
🔄 Round 562 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 562 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=-0.0034
   Val:   Loss=0.0874, RMSE=0.2957, R²=-0.0041
============================================================


📊 Round 562 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0002

📊 Round 562 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0002

============================================================
🔄 Round 567 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 567 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0015
   Val:   Loss=0.0889, RMSE=0.2982, R²=-0.0144
============================================================


📊 Round 567 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0002

📊 Round 567 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0002

============================================================
🔄 Round 572 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 572 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0034
   Val:   Loss=0.0787, RMSE=0.2806, R²=0.0001
============================================================


============================================================
🔄 Round 573 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 573 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0032
   Val:   Loss=0.0761, RMSE=0.2758, R²=-0.0075
============================================================


============================================================
🔄 Round 574 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 574 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0023
   Val:   Loss=0.0914, RMSE=0.3023, R²=-0.0045
============================================================


📊 Round 574 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0002

============================================================
🔄 Round 576 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 576 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0036
   Val:   Loss=0.0893, RMSE=0.2988, R²=-0.0055
============================================================


📊 Round 576 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2526, R²: 0.0002

============================================================
🔄 Round 578 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 578 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=-0.0025
   Val:   Loss=0.0844, RMSE=0.2904, R²=-0.0048
============================================================


📊 Round 578 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0002

📊 Round 578 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0002

============================================================
🔄 Round 581 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0951 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0951, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0952, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0952, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0952, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0953, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0951)

============================================================
📊 Round 581 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0047
   Val:   Loss=0.0951, RMSE=0.3084, R²=-0.0064
============================================================


============================================================
🔄 Round 583 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 583 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0028
   Val:   Loss=0.0926, RMSE=0.3043, R²=-0.0032
============================================================


============================================================
🔄 Round 584 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 584 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0031
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0038
============================================================


============================================================
🔄 Round 585 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 585 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0015
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0079
============================================================


============================================================
🔄 Round 590 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 590 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=-0.0013
   Val:   Loss=0.0887, RMSE=0.2979, R²=-0.0090
============================================================


📊 Round 590 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0001

============================================================
🔄 Round 591 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 591 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0016
   Val:   Loss=0.0848, RMSE=0.2913, R²=-0.0131
============================================================


📊 Round 591 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0001

============================================================
🔄 Round 593 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 593 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=-0.0029
   Val:   Loss=0.0815, RMSE=0.2854, R²=-0.0197
============================================================


📊 Round 593 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0001

📊 Round 593 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0001

============================================================
🔄 Round 599 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 599 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0027
   Val:   Loss=0.0796, RMSE=0.2822, R²=-0.0048
============================================================


📊 Round 599 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0001

============================================================
🔄 Round 601 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 601 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0035
   Val:   Loss=0.0879, RMSE=0.2965, R²=-0.0037
============================================================


============================================================
🔄 Round 603 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 603 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0059
   Val:   Loss=0.0845, RMSE=0.2907, R²=0.0096
============================================================


============================================================
🔄 Round 605 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 605 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0027
   Val:   Loss=0.0899, RMSE=0.2998, R²=-0.0298
============================================================


============================================================
🔄 Round 607 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 607 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2896, R²=-0.0039
   Val:   Loss=0.0883, RMSE=0.2972, R²=0.0008
============================================================


============================================================
🔄 Round 608 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0935 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0935, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0935, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0935, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0935, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0935, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0935)

============================================================
📊 Round 608 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=-0.0015
   Val:   Loss=0.0935, RMSE=0.3058, R²=-0.0080
============================================================


📊 Round 608 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0001

============================================================
🔄 Round 609 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 609 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0013
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0110
============================================================


============================================================
🔄 Round 610 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 610 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=-0.0029
   Val:   Loss=0.0888, RMSE=0.2980, R²=-0.0067
============================================================


============================================================
🔄 Round 611 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 611 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0018
   Val:   Loss=0.0848, RMSE=0.2911, R²=-0.0095
============================================================


📊 Round 611 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0002

📊 Round 611 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2526, R²: 0.0002

============================================================
🔄 Round 617 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 617 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0022
   Val:   Loss=0.0891, RMSE=0.2985, R²=-0.0043
============================================================


============================================================
🔄 Round 618 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 618 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2932, R²=-0.0022
   Val:   Loss=0.0799, RMSE=0.2826, R²=-0.0164
============================================================


📊 Round 618 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0001

📊 Round 618 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0001

============================================================
🔄 Round 624 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 624 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0020
   Val:   Loss=0.0900, RMSE=0.3000, R²=-0.0165
============================================================


📊 Round 624 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0001

============================================================
🔄 Round 627 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 627 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0028
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0146
============================================================


📊 Round 627 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0002

📊 Round 627 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0001

📊 Round 627 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0001

📊 Round 627 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0002

📊 Round 627 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0002

📊 Round 627 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0002

📊 Round 627 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0002

📊 Round 627 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0002

📊 Round 627 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0002

============================================================
🔄 Round 641 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 641 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0018
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0072
============================================================


============================================================
🔄 Round 642 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 642 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=-0.0033
   Val:   Loss=0.0770, RMSE=0.2774, R²=-0.0006
============================================================


============================================================
🔄 Round 644 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 644 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0008
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0131
============================================================


📊 Round 644 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0001

============================================================
🔄 Round 649 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0940 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0941, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0941, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0941, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0942, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0944, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0940)

============================================================
📊 Round 649 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0049
   Val:   Loss=0.0940, RMSE=0.3067, R²=-0.0216
============================================================


============================================================
🔄 Round 652 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 652 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=-0.0019
   Val:   Loss=0.0790, RMSE=0.2812, R²=-0.0073
============================================================


📊 Round 652 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0001

============================================================
🔄 Round 653 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0936 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0936, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0936, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0936, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0936, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0936, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0936)

============================================================
📊 Round 653 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0019
   Val:   Loss=0.0936, RMSE=0.3059, R²=-0.0082
============================================================


============================================================
🔄 Round 655 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 655 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2932, R²=-0.0050
   Val:   Loss=0.0799, RMSE=0.2826, R²=-0.0071
============================================================


📊 Round 655 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0001

============================================================
🔄 Round 657 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 657 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0013
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0129
============================================================


📊 Round 657 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0001

============================================================
🔄 Round 658 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 658 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0022
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0052
============================================================


📊 Round 658 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0001

============================================================
🔄 Round 659 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 659 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0021
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0089
============================================================


============================================================
🔄 Round 660 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 660 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0035
   Val:   Loss=0.0854, RMSE=0.2922, R²=0.0003
============================================================


📊 Round 660 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0001

============================================================
🔄 Round 662 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 662 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=-0.0031
   Val:   Loss=0.0784, RMSE=0.2801, R²=-0.0022
============================================================


📊 Round 662 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0002

📊 Round 662 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0002

============================================================
🔄 Round 664 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 664 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0023
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0060
============================================================


============================================================
🔄 Round 665 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 665 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0021
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0245
============================================================


📊 Round 665 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2526, R²: 0.0002

============================================================
🔄 Round 666 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 666 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0031
   Val:   Loss=0.0844, RMSE=0.2904, R²=-0.0021
============================================================


============================================================
🔄 Round 667 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 667 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0032
   Val:   Loss=0.0899, RMSE=0.2999, R²=-0.0012
============================================================


============================================================
🔄 Round 672 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 672 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0017
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0065
============================================================


📊 Round 672 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0002

============================================================
🔄 Round 673 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 673 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0020
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0062
============================================================


📊 Round 673 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0001

📊 Round 673 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0001

============================================================
🔄 Round 675 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 675 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0011
   Val:   Loss=0.0869, RMSE=0.2949, R²=-0.0082
============================================================


📊 Round 675 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0001

============================================================
🔄 Round 676 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 676 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0025
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0029
============================================================


📊 Round 676 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0001

📊 Round 676 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0001

============================================================
🔄 Round 679 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 679 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0033
   Val:   Loss=0.0916, RMSE=0.3026, R²=0.0000
============================================================


📊 Round 679 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0001

📊 Round 679 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0001

============================================================
🔄 Round 681 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 681 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0036
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0092
============================================================


============================================================
🔄 Round 684 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 684 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0030
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0135
============================================================


============================================================
🔄 Round 685 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 685 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=-0.0039
   Val:   Loss=0.0829, RMSE=0.2880, R²=-0.0025
============================================================


📊 Round 685 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0001

📊 Round 685 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0001

============================================================
🔄 Round 688 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 688 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0014
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0075
============================================================


============================================================
🔄 Round 689 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 689 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0029
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0026
============================================================


📊 Round 689 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0001

📊 Round 689 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0001

============================================================
🔄 Round 692 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 692 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0013
   Val:   Loss=0.0784, RMSE=0.2801, R²=-0.0109
============================================================


📊 Round 692 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0001

📊 Round 692 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0001

============================================================
🔄 Round 695 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 695 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=-0.0032
   Val:   Loss=0.0762, RMSE=0.2761, R²=0.0007
============================================================


📊 Round 695 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0002

============================================================
🔄 Round 697 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 697 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0023
   Val:   Loss=0.0911, RMSE=0.3018, R²=-0.0041
============================================================


📊 Round 697 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0002

============================================================
🔄 Round 700 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 700 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0036
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0006
============================================================


📊 Round 700 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2526, R²: 0.0002

📊 Round 700 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2526, R²: 0.0002

============================================================
🔄 Round 705 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 705 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0029
   Val:   Loss=0.0808, RMSE=0.2843, R²=0.0001
============================================================


📊 Round 705 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2526, R²: 0.0002

============================================================
🔄 Round 706 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 706 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0034
   Val:   Loss=0.0849, RMSE=0.2913, R²=-0.0021
============================================================


📊 Round 706 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2526, R²: 0.0002

📊 Round 706 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2526, R²: 0.0002

============================================================
🔄 Round 710 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 710 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=-0.0010
   Val:   Loss=0.0814, RMSE=0.2852, R²=-0.0087
============================================================


📊 Round 710 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2526, R²: 0.0002

📊 Round 710 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2526, R²: 0.0002

============================================================
🔄 Round 712 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 712 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2904, R²=-0.0019
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0196
============================================================


📊 Round 712 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2526, R²: 0.0002

📊 Round 712 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2526, R²: 0.0002

📊 Round 712 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2526, R²: 0.0002

📊 Round 712 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2526, R²: 0.0002

============================================================
🔄 Round 718 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 718 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0023
   Val:   Loss=0.0900, RMSE=0.3000, R²=-0.0135
============================================================


📊 Round 718 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2526, R²: 0.0002

============================================================
🔄 Round 721 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 721 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0033
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0197
============================================================


📊 Round 721 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2526, R²: 0.0002

📊 Round 721 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2526, R²: 0.0002

📊 Round 721 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0002

📊 Round 721 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0002

============================================================
🔄 Round 729 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 729 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0028
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0023
============================================================


============================================================
🔄 Round 730 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 730 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0025
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0120
============================================================


📊 Round 730 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0002

📊 Round 730 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0001

============================================================
🔄 Round 734 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 734 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0021
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0107
============================================================


============================================================
🔄 Round 736 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 736 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2920, R²=-0.0014
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0426
============================================================


📊 Round 736 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0001

============================================================
🔄 Round 737 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 737 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0017
   Val:   Loss=0.0775, RMSE=0.2784, R²=-0.0276
============================================================


============================================================
🔄 Round 739 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 739 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0016
   Val:   Loss=0.0818, RMSE=0.2861, R²=-0.0075
============================================================


📊 Round 739 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0001

============================================================
🔄 Round 740 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 740 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0026
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0052
============================================================


============================================================
🔄 Round 742 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 742 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0027
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0112
============================================================


============================================================
🔄 Round 743 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 743 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=-0.0020
   Val:   Loss=0.0791, RMSE=0.2812, R²=-0.0140
============================================================


📊 Round 743 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0001

📊 Round 743 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0001

📊 Round 743 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0001

============================================================
🔄 Round 746 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 746 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0038
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0143
============================================================


============================================================
🔄 Round 749 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0947 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0947, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0947, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0947, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0947, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0947, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0947)

============================================================
📊 Round 749 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=-0.0010
   Val:   Loss=0.0947, RMSE=0.3077, R²=-0.0079
============================================================


📊 Round 749 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0001

============================================================
🔄 Round 754 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 754 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0037
   Val:   Loss=0.0792, RMSE=0.2813, R²=0.0024
============================================================


============================================================
🔄 Round 755 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0931 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0931, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0931, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0932, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0932, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0932, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0931)

============================================================
📊 Round 755 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0037
   Val:   Loss=0.0931, RMSE=0.3052, R²=-0.0035
============================================================


============================================================
🔄 Round 756 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 756 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0021
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0067
============================================================


📊 Round 756 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0002

============================================================
🔄 Round 759 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 759 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0008
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0093
============================================================


📊 Round 759 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2526, R²: 0.0002

📊 Round 759 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2526, R²: 0.0002

📊 Round 759 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2526, R²: 0.0002

============================================================
🔄 Round 762 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0964 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0964, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0964, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0964, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0964, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0964, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0964)

============================================================
📊 Round 762 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=-0.0025
   Val:   Loss=0.0964, RMSE=0.3105, R²=-0.0011
============================================================


📊 Round 762 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2526, R²: 0.0002

📊 Round 762 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2526, R²: 0.0002

============================================================
🔄 Round 764 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 764 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=-0.0024
   Val:   Loss=0.0765, RMSE=0.2766, R²=-0.0029
============================================================


📊 Round 764 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2526, R²: 0.0002

============================================================
🔄 Round 765 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 765 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0025
   Val:   Loss=0.0780, RMSE=0.2792, R²=-0.0022
============================================================


📊 Round 765 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2526, R²: 0.0002

📊 Round 765 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2526, R²: 0.0002

============================================================
🔄 Round 770 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 770 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0023
   Val:   Loss=0.0803, RMSE=0.2833, R²=-0.0008
============================================================


============================================================
🔄 Round 771 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 771 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0012
   Val:   Loss=0.0876, RMSE=0.2959, R²=-0.0101
============================================================


📊 Round 771 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2526, R²: 0.0002

📊 Round 771 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0001

============================================================
🔄 Round 776 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 776 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0020
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0035
============================================================


📊 Round 776 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0001

============================================================
🔄 Round 777 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 777 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0030
   Val:   Loss=0.0848, RMSE=0.2913, R²=-0.0332
============================================================


============================================================
🔄 Round 778 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 778 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0010
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0073
============================================================


📊 Round 778 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0001

============================================================
🔄 Round 780 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 780 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0026
   Val:   Loss=0.0764, RMSE=0.2764, R²=-0.0037
============================================================


📊 Round 780 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0001

============================================================
🔄 Round 783 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0714 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0714, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0714, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0713, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0713, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0713, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0714)

============================================================
📊 Round 783 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2967, R²=-0.0015
   Val:   Loss=0.0714, RMSE=0.2671, R²=-0.0073
============================================================


📊 Round 783 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2527, R²: 0.0001

❌ Client client_4 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8692 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8692 {grpc_status:14, grpc_message:"Socket closed"}"
>
