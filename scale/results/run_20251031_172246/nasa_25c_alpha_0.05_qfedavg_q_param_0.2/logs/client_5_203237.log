[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 796680f1-6b4f-4c9b-a926-c4404e802aab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c2fcfb9-a619-4a0b-95a3-89009ff15dc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7066d3db-2c98-4344-8805-76ecfb7ce772
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 113872de-1170-44fc-8f3f-39f6c1d4e009
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba96351c-5d85-4623-842f-e2a36daefac1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ecc105a5-7583-48b3-beb1-4e3c0181a7a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46e4a43c-b4b4-43dd-b903-c1bd3ded5509
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20049d85-2143-4a87-a5c7-747c84b68a54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab459e34-41b2-4b31-ba6d-2e476e414d6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c3bcf6a-e2e7-44e5-9903-6b92789d5305
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f83d3a7-a854-4211-a05c-16aa42e45010
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78a60bbb-ff56-48d3-8e0b-504f26779def
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac602db8-3c93-4192-b7b3-8f04898ade78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2d45aeb-81e6-48af-a34d-18cd9ddde9cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23cb6c1c-f2c8-44b4-91a9-3dec9770cdad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b87ac9b0-8a88-41e6-9d85-5a11c9fb9d93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86620481-f9b9-4dce-95ce-bdf7d8d82260
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b5694a8-d30a-44cc-a7b2-b1ff3b70a54d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a28b9ffd-0ce4-4761-8642-ca739ca73817
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b4482ec-8139-4380-bdcb-b9261532d7ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e02eaf2b-4ddd-44a0-9145-94f02da3b7ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fccf0def-abc3-47c1-b41d-e2aca7fdb2e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71e56f1e-735a-43ea-829e-ede1eb3a05e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eee58469-9602-4900-a3c9-d2b6e094709e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99c6904f-03cf-4592-b1a6-dfb19ebe244e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c11ef251-4056-4253-993c-07121aa44024
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07225a36-1d40-4112-8e27-9058a09ee1ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7df46ed1-65cf-49a1-bed5-42b5189e9663
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 545120fc-6a5a-46ee-ba40-230480a80eed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24c938b9-7b5e-47d6-9eb9-2e5415146117
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 274f545e-ebd9-4a1f-b9b7-810bb6f0f636
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2036e7ef-cbf6-4cf0-8567-cdac02975e66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48b7badc-ade8-4973-8ffc-64f87b560768
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05e0003c-c6ae-4fae-b56c-02a4faaf624e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70c8a82d-aeb0-4c49-8389-2d0aee1223f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cebbc5c4-5bc6-4d62-85bb-a26ebfe8d461
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f27d3bdc-4867-4a45-a3fa-9d6bc7d41bd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5db50306-bc6d-44d5-9907-eae4370298c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56ee97c4-7697-4676-93f0-bb01a0c0c566
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ff147ce-4589-467f-b501-27c3185da7ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2cf9fb03-694b-4b59-b7d1-f4f5739955d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da1e07b1-275e-43f2-ab1a-2de1217465e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a20fd70f-0026-4e00-a048-46beefccad2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6fa9f7a3-c16f-4551-af20-7eb800b61334
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c58fcbd-ef26-450d-b0dc-2887110e66d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac6a4115-7454-4883-8e31-a679d0720537
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39ed5cf1-b4a0-44df-97ee-6ba6ede9a744
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message defba40a-b88d-4b8c-9c6f-1353a335d16c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2302c6be-1a0e-41b1-b8da-118c657e4ea7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc8c0197-78c0-407e-997f-a1e40085e26e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d13f7dc-baab-415b-96f5-9be8dd7793d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 625f6ab6-71f2-4e90-ba7e-47f10bbae199
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3238ced6-6dd3-4f6d-8099-ebb913fd1ade
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a43de2a4-936a-43b6-b22d-37620b3dd08f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4407d6a6-dffb-44fd-abdc-90fb3335515c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 538c3f72-8994-4960-a0fa-7f680526a514
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b53c0eb-144c-40e6-b49f-9b921c80f671
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6dd3939-4849-4e46-a88c-d229e5b1f639
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c338ad6-2c4e-4efd-9748-a9bdecbdf026
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec900564-8e7a-45b3-86af-6b9b7d75ae47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6eb40b95-4539-4d3d-80ca-3a8ede7c1621
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4983e6f8-763b-4753-b824-fd310dfa5b39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4a2fefa-be6d-4911-90cb-f450e850e176
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de92f7ca-2f4b-4bcc-bdba-c8b9bd71c2bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4062d40c-2e48-4d03-898c-dc750b7cb453
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9484ab31-7acc-42c2-808f-7265dc4f715e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14f8a435-872f-4f02-9185-02f5a4438c4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f1f613a-1f3f-492f-962a-ec7f099fcf63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c2685be-0bce-49d1-bfc7-19f465fe742a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1090c737-0137-4daf-83c6-04b886e9dd8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e91b48db-58ac-4464-911a-bdc8408401e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2384b956-e5ab-40a3-9dce-0ad306a914db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73c60b0f-5345-4c3a-bd12-0973b11c0451
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1e966c7-e400-4446-8252-7bdf4a8282d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29455382-db07-4675-b778-fd42e2c3bc9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b4e90a9-c896-4e89-b1f3-e558e3ddd2ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13801e2e-0d9d-474b-9761-fa21e96080f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bad16f97-9959-43ae-93f8-13d65b9caeae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d2c8e32-2c3c-48a2-8402-4a8bfbd0c0f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59aac6a2-12d8-4594-b072-67281fe8ad42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f9b1f53-700c-43a8-8889-5386fb911c68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c94e21e4-1a7a-412a-94c5-1041802cd21e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3165281c-c901-4c23-9a5f-de218c31e332
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7e28394-625c-40cd-b336-ed74de0d6d13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb40b515-5252-4828-9ca6-6efcef8ae1ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c6158d9-7e62-4c67-8038-e0ab8be21fe8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d63444ea-3aad-431a-8e6c-657747b92b83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5d10bf9-1252-417a-855c-99860cafe6fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99b35c9b-54e9-43fb-98a5-680b493208ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17ea6521-3a7c-4179-89e7-9b9ce9f2e7ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36334922-c5ec-4d34-903b-a75f99f91521
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff422d34-5521-4206-8a68-e662a4400445
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0889a261-cca2-4d3b-8bce-a3f4f17628e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aac57114-ff71-4cf2-b794-ea64378bb4de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 897bf06c-d4aa-42e4-b457-f6a3c36c8f33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4fecac5-3bf5-48ca-bca7-80a049a59a9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c577bea-8b73-42a2-a5a2-22d05143988b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02cd99e8-7fe1-40d1-8f34-bae998328c98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44f4510b-9d99-4403-a32f-7fc07efff49d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f31a5768-5e3f-47dc-8fef-bc17219218b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33841cd3-2755-495e-9e0b-4ee7b2f74b2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc35f01c-3de8-4400-990b-e2ead4309cd8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c7d2cac-8089-4ece-bd53-b824085cd4d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3bcc4d4f-bb54-4c81-9bd4-4559538c2091
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message faa5420f-1ed6-4141-a358-870de21b84fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 559a75c4-73a0-4ad0-865d-4f32f1b4b3ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b058288f-77fb-4369-a588-10a2b10e430f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2e911eb-eb62-42a4-bcd2-2ecfa4993e5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5bed28f9-55f1-497b-8131-f4ccc84c1ece
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f285db6e-1cc1-4b27-a4dc-98caeef7f1ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a74dc30-2f37-4f42-8995-c5ffb0534e83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19bab950-de3c-4078-8903-b3b34d2b1251
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9624c7b4-40a3-4005-8bd5-639554f0a074
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32567585-09f1-43e0-9d0b-12bcc58b5a53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92c26046-8a34-4f23-ad88-160ad5c4c6d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97737e6e-86de-4573-b395-998fc8f45248
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 988f59cd-ff4a-4a0a-84ea-c6767937e140
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f752fd3-f9d0-46aa-a671-c396c77c7b3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b37b998-a0a8-4448-9a3e-257b03e63e67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7de7806d-9f39-4c7d-ad67-8d00f615b70f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 426f5dd4-bc7b-4528-8ea3-8b4c20b82512
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 542f97ac-67b2-4ec5-83a4-4f33d8febccd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac697aa5-837d-42b2-a943-43af02c864b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 173e5b06-f544-4cae-b3f0-ea3c8f0ba91d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f1f4ec0-51cf-4452-a999-43d56181d298
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd1d3c24-5c34-4a4d-9b22-6767a532d3f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41e4f202-98da-464d-a63b-e75e42821e02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce6bf610-779e-492d-b0f2-815ee106b5e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a392527-72df-41d0-8e4d-130ff7581b9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1803b5b-fa74-4c1f-a2fd-149e9683526e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4eb462e1-1f4f-4e2e-947e-48b1c3b448ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea462e93-d7da-4e9c-9d4b-574a942b92d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb19ea84-450f-4832-b42c-7f67215fec91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 299f8296-965f-4fd7-8fc0-30ad289a2357
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3ccf4b2-b207-454c-a9ae-7f24bd6c5b25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de18168c-9b07-4023-8e9d-54408a510053
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eee848cd-debc-4745-bfb1-c807b6926ece
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 022be310-e219-464b-955f-cebed601c09b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b24f063d-8df4-4644-8fc0-8040c798ce99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68a685cd-c8f0-4686-a082-65822f2ab704
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 155367f2-1a9e-4f71-a36c-3d9ac587eb1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9242a3fe-1361-4cc1-a793-729fe89ac0b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37f1621c-b481-4122-be6b-0cc79d948454
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd42df99-a9e5-424c-9bc1-6c62d5ac8c75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d10967fa-5dad-4e92-b4a6-3215fb0eb00b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c293a51-f1e3-4a7d-8a13-8a4624ed9fc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e753c402-242e-415f-9583-a2d0aa145dee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c19044a9-78aa-4e6d-ae1d-30472ecde6dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35a38f92-b1a7-4046-9d14-54572d0ee254
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f7c9919-1fd9-4722-bacc-fecdb4b31bbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f04f06f-caad-4fef-8370-f80920c47d7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7c7f114-38db-4003-ae88-2a7ffc9c667d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 820099af-b9ee-4463-b1b2-0bc6929d53dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f0c7216-0c11-4460-9848-b677b4de65d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0d84578-b771-4903-bef6-78d30b05d16e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f21e2695-e4ff-4688-8be3-820a860d7de8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58ab2c5a-2c02-43ff-8631-c68af3986cef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db5148fd-e029-4464-99b7-d04a96704026
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e71c85f7-e2b1-425e-813c-e01bad0ce41b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6e06360-2bee-4765-b537-7d0fe560f318
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8955006-fed5-4b53-b932-c0b86c56a8a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d7477e8-feb0-49f0-b206-953bc33158dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c0e8867-f088-420c-84f4-8acd06f5ae29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7c0ee5e-e326-4adb-bc43-fa898faaa486
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c20f63a-e0b0-405a-922f-b19312de16a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f5cde63-08a5-4833-ba56-47e6249914c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e1bd11f-b124-4248-8d21-fa34600c9144
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f84ab7d-fd29-401c-88c4-bb8dcdeae1cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d787ba4-92de-4f29-a4e5-6d9b194f89af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc008b82-d049-48e2-a4c0-1b78c73a49c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b754e2f5-6b7f-47a5-9775-3a1e34597e88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54df2b1f-e000-4564-a07c-7be1c85ee808
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e505519-a380-4dd8-960d-1dfc9db2e184
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1bf7343e-57c5-4a76-98eb-9e2efca37d47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message afd1baf1-5895-404e-a60f-0a4b200157c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 462af0a2-108a-4a64-9d48-d10428a20ed2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d577558-3494-4ac1-909d-1811d47057b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ae4b9be-620e-43a9-8541-e98c3f4f66bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f312a17a-7042-4290-afbe-ecb306466d9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 033dbe6d-b128-40ec-9183-5e7ea6425b9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8cdce60-f86a-4a54-8a24-ed5510dad702
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07cf76b5-6212-4184-9c2c-fc29daf862ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f578803b-f4eb-4345-832b-e0c714af2790
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 137046a7-9c6d-4881-a348-50bb191403bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c439dc8-81a6-4a66-83d9-0656842a1fd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c31216f7-e047-4c67-a63e-e19d619f8237
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1299edf9-865d-4b8d-93a1-220dfaded4f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7afb3dc-5764-4b57-af0f-f84f7057ba06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7dd09431-2f9b-455e-9610-1823c2c9c800
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d32c00a8-c656-4c58-bd99-9d5937197b1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ca06ebf-ae2e-44d6-a4fc-00fab99da7db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b827e27a-f12e-4f42-8c3c-491ec7bb9da7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 794b9778-a9b0-4f54-9ff0-454a545c0eec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70d9c5f8-073e-4f3e-beb3-823282613e5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1070324a-6e01-46e5-ab04-23fedbc715a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d96d757-0130-4454-be0f-d62b11b14771
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6c802c9-a654-4807-a39b-028a1ad778c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 947c2d7b-cdf4-4740-af2f-564a90b2d68d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04501ee7-7591-4fea-86e3-9a70a5c13097
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cfa04549-e2cd-4f85-97d0-f42225d36610
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c84865c-b390-4286-b312-5190f1ecb4f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f17c0cf9-4a5b-4520-9988-d7d202a298a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74b7f0ce-5554-4d32-bc7e-5ed6cb03bbef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfe24e4c-1dba-4869-bc20-2d1ea4d58bf4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65047b2a-da14-4286-bf3f-c065a5069af8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98f79a1e-1c8c-407b-994b-9171092a2ce7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1cd8496e-037e-4c2a-94b6-b72507a35816
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f280d8d9-be06-477a-8fcd-2298e014e691
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b7560c5-9de8-4e5f-ac43-f44dd8670ed6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9dda67e0-6580-4d3c-a697-48978c84f09e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8848bd98-c69a-45fe-93b8-b947522f19fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34498d98-16b1-4aac-b68d-e33b323f5b23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a4cf010-3aac-461b-afb5-3cc7ab008877
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7f9ed57-68d9-4ff9-9de9-f601fcf22ddb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2896e8b1-879e-4243-9eb4-74b4984b3daf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac709f2c-1227-446c-b434-31038af87cd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4dfda809-3c68-441e-96a8-8ff51a282f74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc908826-0f23-46e5-b561-f69e68460c47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a025fc35-969d-4971-9d4a-84fbf9d7b47b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 055ce896-0b42-4b62-8720-dc24b5fb3a04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1c31fa3-81c8-4c1c-a6b6-14a82b812ae8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4eb6c372-778f-47b3-9431-e5aaba6a44f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb960a11-fbaa-4d29-aeb2-2aeff9cef56a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51e8b0dc-4b09-49b3-a498-092d148e55b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd9a7686-faaa-4423-93c9-8d437e54e6a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1260e93b-718c-442f-b7c7-a8081e2b96b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 200d992c-6a4e-4d13-9ecb-3f5c64ee5723
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 070c5e68-6285-4a9d-87b6-c5b1cabf815b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c80627cf-4689-49d6-83cc-19e0a741fa5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7cd8242c-5c66-47ef-8420-39efa76bc5d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9a7faea-14c7-445e-99b4-c82ab3073301
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a8f4691-66f5-45e7-b7cb-e6fdc5a148a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5b2497d-af8c-42ec-9e19-f2dbdf643709
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c05eae4-d6c7-4bde-a980-636d3d904b74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9823d1d-ecc7-4911-bf7a-16b40ea1766e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e095a105-a4d9-43dd-bb73-003e03274be4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b797ee9f-02af-4b8b-b881-a2491b8c5deb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 905da28e-ccc4-4081-92d6-4425a29016dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message beb0eeba-cbd8-4ce5-b124-9b1b34ba733d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a803113-57c5-4c1f-a30b-053f65d4f9be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0720090f-2490-4462-b0a1-f2baec970e65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 262abd42-4c20-4f47-b650-1c59f2ec7db7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1362817-197c-4c71-b046-1e68e25473a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b198f2d-b923-4dee-b1ec-91c073b5a909
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4fcb85aa-8e85-4479-ab95-9681a9d70c07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d0f8a38-431e-4491-bfae-ad06c88583fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f067605-24f8-4994-9614-21cab9ab126a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4149dd62-8f5e-4640-a196-79e528c1ffed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40377e32-136c-482f-8941-628518363a71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a05c5996-538e-45ef-a48b-fc72185c0764
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2998d73-f01b-4142-8866-27920bac9580
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd9bfb2c-3e0a-4286-a135-63ecadeb9c02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b53ea94e-3808-4345-a2b2-87fdea73da17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e04312cf-32cf-4536-bde8-0e80aeda747e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7023a9d-2497-475a-b479-24b9caeb444b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 884bd48e-3b03-4595-9e4d-31032e1e1768
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f07e8717-2ea0-4dfb-a943-eb1e5ab16274
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd0f68c9-8f89-496c-ae8d-4fee7be70080
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c50295c1-f37e-4927-9033-f5848ebf5315
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bfdc5855-9c7e-4acf-b3ad-97d2f162e2b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f026a101-c6ea-44bd-a53b-9c872f99b095
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message adaac044-5d54-41de-8e50-adfc95172d0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe30e8fb-ec38-4041-9401-d470480c160c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d48b702-4c3f-4e30-a210-a10febdad170
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2dd994f7-1e4f-4eb3-94e3-1e14c58a349e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 614ee5f3-2e0b-40bb-aef4-86dcef35eeb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 873c3750-8bad-4ca9-b2ee-d6dce0645431
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e902f40-8776-4bd2-9301-542ab9c9e86c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 837d439c-ff5b-4dc4-8543-da8d459f211a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d2a49bc-a625-4095-bcae-f2de2f0235db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15cb67d8-9930-4500-939d-90da843a2550
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f5a2cc8-f864-4a55-9488-4aa6ed37419c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fae29a95-396f-4c14-83a6-842b38232ca9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e90c1f1a-de7b-4108-8569-143ae4c6e95b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8768a9fb-1049-4aab-87ae-1b83a412e143
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3d85f65-ce87-4e96-b2d4-b3cdb77d19cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c93467d7-fd9c-40cc-b24f-4d973e9ad03f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae75db23-a454-4757-a86f-374fabb34a5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3de74cd6-9da3-42b3-bee0-0fe355e6b8f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01ae48fa-6b65-4990-970d-c192190c2ceb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15131102-14ca-4377-8abb-a1455ac987e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8bc0917-9725-4357-8b1b-7fbeabd09bf2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1910a91e-fa93-4582-8fe1-d2c3cf7b3a98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18c26b13-8392-423a-8e3b-4ba6838f50ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22effeb7-781d-4b55-a806-a35b796fdcf6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 439cba7a-03d9-40c5-a440-237a19de6171
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 418618a6-f69a-4915-bb02-791dea2ebecf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da305a2a-e648-4363-9ece-bb08cc4c93f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 665285e2-cae2-49a9-aa8f-fe4f47339a8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eedc1c09-5e97-4996-a681-43f355b16511
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d167561-7063-48cf-9db6-3549a4980464
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b08cb3d5-06f9-4f62-a2a0-8a66010030db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02744951-d05f-431e-bc18-26e441f00cfc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0bcba36c-053f-45a1-9949-badc4b767667
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36766be9-71bb-4ad7-8217-0a8c15d967b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12efaf77-1471-444a-9951-f36e0a91dfcb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3040cb96-8cef-47d8-8b5d-89cc0cda204d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3738dbf4-2dea-4893-8544-820a9235995f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f01a44e-1034-4979-b1ba-b665a12f2cd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d19caae-0d14-45f0-8e3d-dc537d5b27ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7f7c07a-4664-42f9-baa4-654ba2e446cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7e31704-ef19-47af-9884-75c261902f63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf268ba0-1713-4e62-8076-16f1e801a3c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12221348-0f0f-49f3-b63d-3d6957d03cef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68771df8-66ee-41bd-98a1-2a7ef96b03ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e31746e8-de31-4a52-bcc2-f9349a4a4690
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e60c6228-819b-4a48-87dd-b376cd5a4e4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 359674a4-23d7-48d2-a38c-74dda8268ecc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f4c4eda-15c2-48c4-b2fb-aadcd192709d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 529ff41a-3e01-45f9-97b3-571e57dce307
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e823a481-80b3-453f-8de4-068a6d25108e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f64ec582-0be3-4592-83cb-3e403cbbf6a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02669124-382f-4d2e-be8c-fabd8765f039
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90b8fa07-8a04-4d01-985d-33e1fb70bc0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7777ed04-b89a-436f-adeb-599cd699b040
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7eb5cf4-8de0-4eb6-a8d3-5a728fe546ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0019f6fc-9a71-46b0-822f-5a1a039bc0cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0bff02e6-f056-40ed-b67d-412472177d0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c34dc686-3453-4959-b75d-99726bc7ddc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0969871-f1e3-464b-8961-118cdd4de108
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76d518a2-dc39-42df-bacc-e5bd3f9f0f3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8157442a-6854-4bdb-86fc-19686739edd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 515e7da5-c563-428a-bdfc-60bcc3a5793a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1cf029d6-b425-442c-a986-7ba34036f941
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f99cbe0c-05ca-46e7-b0da-906f832abd19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 896622c3-abb6-4c9f-91cc-0b28bac23df1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09416a9d-b30d-4dfd-bd6d-a3bb7f3f0984
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd532f6d-87c9-4349-91e8-9419743c9743
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 537d48ad-51df-499e-a4cd-7080b3339656
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22a25c8e-aa22-48fc-848e-dac825bc65e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c279005-3fed-4f5e-9c45-a1f6102d224a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16801167-5c5c-4f73-9ec3-354bb54f0c49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 682d1f4b-6a47-4e7e-8e78-c914a4603154
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91b839fe-f4d0-4e97-b873-14d3d4d31e22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b058f24-b065-4669-9862-9c2567dc4e2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee3442cc-1a6b-4d4a-9381-27557533a697
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a51ba8b-9fe2-4edf-9ee5-ea8e878e73b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2affb7f3-4a95-446e-9c12-5139fb49a0df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88e9a2d4-4f69-491f-8f13-cbb3dd529e17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f02e52e-81ae-40eb-80aa-45af41a330a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe231ab8-0b66-475b-9fe3-21ab1235b23f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e390b5a-1e3f-40f2-aded-737c7f099518
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfcc99f2-9110-4f2b-81b8-076e5454c92c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 234a1cb8-2a11-486d-a4c2-4f75bd8bf667
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5bdb3e3e-7917-40b9-9192-15bf82d20a44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d22c40a-8de5-457b-91f3-f0a0439143df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54b2e310-50f4-40f4-9c32-84790ecd983e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55fb3358-606a-491f-b001-9e796764f8bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 231d28d8-bbb1-4f68-afe3-3dfceb59546f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99d42071-60bd-492d-b5e7-e0f096f5f018
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38993f7b-5f28-4a8d-9ac9-3bee41e1d494
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd4e0868-017f-4050-8743-1333a7fd12c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f011e8f0-2c73-455c-92ba-a0016116ed4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c776f589-2494-40a4-8d99-e63206317f54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91e0d712-3d62-4d23-a040-82260a2167a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1935d15f-c01a-4bb6-b6e8-e5e3b69897c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a3fd32b-abff-4fe5-bf90-2431347b0507
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5982b595-90ec-447e-bcf3-9f7f5a36ac3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7a21532-4348-48bd-8f03-52eeacb73309
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89906be1-ba38-449c-988a-99c9ad89531c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d505ffa3-8a33-4272-93de-a5a6e72edae8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c454b7fc-4ee2-4fa2-9e6e-5d11eba2770f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01a07f4e-5dc5-400d-b328-0932902b4a6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9200fac3-eb6b-4fd5-98ba-6708c8c32fb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 990aef73-020b-46ae-a4d0-c489aafe0c04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fbe2e8f2-4cb5-4233-86ef-2e16c36d4b53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca3e8804-1244-4990-8c46-c3b74b8f94af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00267a54-5726-4745-bb9e-33d8ffc7f907
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f8b9dc5-a735-4f3d-a4f4-c110740c38ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ae44d12-97aa-4702-931f-0d5ab2fc72b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58206f40-a7d5-4ac4-b8b3-923a24b41105
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb265f85-fa5b-4d1f-9847-489bad188552
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77067022-00b7-4583-8e64-e2903a41a856
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3bf31506-2fff-493b-9648-7be658ff5371
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9bec93a-562f-49fe-9d70-4de551c91bc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3af9a82-cbfb-4766-82b4-a374a4beecfc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e7b5bee-1405-48d4-88f6-781c88684b3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 036e9370-663f-479a-a0d0-cf3f1bc3e14d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0fb65125-8139-4b3d-bab4-bfc9833ff5bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5e8a723-a922-4bb7-82a4-fca12ade2204
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c62c0dd-c53d-4e43-a753-56faa4eb2509
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c57ac1c9-f995-433c-a67f-dbc4b79073ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c67773bb-b677-4d20-9373-c75613b60378
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45ebf6e2-c892-4b85-8d3e-d66786a43fc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07bb6521-e1e5-4369-a2c6-dc2155ee7455
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6662a00-dcd1-4651-a65e-9f6a0f4391ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d959a5c-71fe-42e4-a2b9-0d5c20047202
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19fdfbae-2c5b-429c-b84b-591ecc91c67c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06c0b997-3c67-43a4-9c56-c46dfb5e919a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1cf538de-cd4f-4e69-9e5f-74ef6b898acb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1279b558-888b-4a21-8406-cdeff3933128
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 192d91ae-2268-413a-82ae-415b5711e2c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8419879-39fc-451b-a39e-c4a3b9cd54cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b54f9093-f201-4a91-9619-f85be3dcee02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1bcd429-3ce6-47fb-b939-b1c816604243
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b46834cf-a1b2-4ea1-8d9b-3af69b1fbc7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b6aa60c-6cea-4d1f-958f-4f2778d7efa1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d8f0e78-83a4-4c0c-bae8-1c01d6a5072f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3706a18d-fbfd-44b0-8739-193600aa215d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02453ef8-9208-4c67-a281-1590f911ffe8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5dddf4d8-3fc2-4acd-9564-b28e885f9784
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f67e740-6591-48a8-9d5f-8d24649466eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b8e324c-0ef9-445e-a031-4b2535b8fc18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81c50100-9f8b-41f0-86c8-9c7bc558479e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 878e2cde-d310-46c7-b0e8-d00093dfb7d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 892511a3-5ba9-4c5b-8baa-a1c126d12106
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 842009e0-dabf-4847-bd4a-ef071ea20b1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4cf85356-db44-4999-9cc2-a1dc052d4acb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0010fbe8-c8db-4f3c-8537-81aa7b93b3f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6fab3f23-f80e-42e4-9180-68dc6b4c5b9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1026136a-107b-4de8-919a-9b961d2ea476
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2ce9e05-618e-42c4-895d-a20c9b702398
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d13c96c-1c73-44eb-a0ba-78a427616d16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa8d20b9-94b6-4e84-9e13-8650ba326616
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6bbd312-fcdd-4c85-86ff-3ee581ac7124
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 760da560-0b28-41b4-8dfb-5465e0ed7e16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3ea2102-1158-4fe5-9092-f88244367cb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0c6647e-b62d-4a43-8236-9584a4c17f8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a011943-cd2d-4112-98d3-5642589fd4c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02ef9c22-07aa-424c-b0b9-fca1789b0201
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fee09c07-6107-4681-ab3f-31da73688ac5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36175b8d-a586-42b9-8b9b-db7c44d8bb13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e20e2981-990b-43c5-a075-7bb1ba3a37a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b200c2f-9236-43bb-ab7e-7bcc3dc02326
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0773d6cf-3f39-4a75-9ccb-3fccffae62f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91540c4e-e477-454d-83ca-7b58a5673eda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30cd4d67-46f1-4d26-9073-6a9cb9004f05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62f9b30e-fbb1-4c0b-a96b-b2c2637646d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a0ce6be-1590-45e8-92b7-e89ba8c22056
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d6d46b3-70d3-4ea4-9073-b155a3e0ea72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ea9ab0c-f585-4ec9-9080-ab4a02cf9111
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58cd81e0-1734-45d8-9e53-10f432e06b34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ece11f0e-6878-47df-841e-e1fc294b245c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62dc2c03-32dd-486f-a12c-00178b9d6ebe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13917caa-3d78-4448-88ea-21136907de39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36623162-a119-4800-8d91-6aecb539dad9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f589de13-be6a-44eb-9915-6a92bcfd648a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7de621a-f9e9-444b-802e-99fc963c8121
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0954ae93-b93b-456f-9d70-5f693ce0ed15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0bf93a88-21c1-49ea-8fdf-868b9534d3d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e255c1ce-03af-4d5f-9b7e-9de3c4733922
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 918ef1c8-9c74-4508-932d-b967fd077267
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2c15526-8701-4d57-acd7-2b63a8f77da9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66015dc8-20be-476d-96fd-5f0a7538f18f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74382cce-8803-4454-b2a5-c0cf88a82fc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5032b91b-cd45-4645-a45f-a133646873d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5b7fb15-6591-414c-b4db-8587b54ba42e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfd5cdf1-ee89-4a24-a6e0-420b64659bfc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bbbda4a3-76d2-4cd8-bca4-f316538c2e54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b5c244a-8409-44f6-9760-b840c9e3e52f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32ef7a37-c711-4092-a0e2-9152ac86f0e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45128722-0247-4763-b3c0-f453f954256a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0dbbae07-d40f-48dc-acd2-ebd5f08074e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a3e3a96-7bb2-4236-bf9c-2ed138b11a7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bfa50319-fd21-4856-9273-20e811744420
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d02f642-5401-4a25-8788-c479d63d34b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9b3d634-915b-4596-910f-151c57fdc59a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf834d23-0ec9-4a20-90f5-c8b21b156c37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 564d8bf0-e6a2-4994-9b74-16746888f7c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bbcbfd8c-25a7-420f-aeb2-50d54b01d08d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13f547d2-c7b0-4f4f-a578-8643f14703e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cfe4f46f-bee4-4796-9009-dcc4f82ad0eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1052b2e-0ac3-409e-8b5a-f5b39df4daa4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a6a90b4-43bc-444c-843b-ac23895310d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7feca88d-24a4-49de-9ba6-930a329b3bf7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aed4493c-3278-4eff-8193-aaf0e8223731
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a17caa08-e137-470f-a8cf-c8995c312b54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76c29ec5-0b8d-4f6f-95f5-3d9203819391
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 225e4fe6-4b63-454d-839c-5f4ee27f55d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6403a1d-8b41-43c0-9a6a-e2bc9a841a52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84bad952-5e1a-4ab5-ad1b-bc81b2f57395
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48c49c29-73d6-4312-9c41-b0966b3b91e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cfc10ddf-bfdb-4390-86fb-20df6785691d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d5818b2-3772-4794-9edf-04a3f880b117
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 478a75db-d862-41c7-b4c2-4ed432777750
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5af9b82c-cfcf-44a7-95cd-2840032983cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2fd18d59-d508-45e5-a97a-4cf73b30dc41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0331aa9-5078-48b0-9246-f0103b03c52b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf48659b-269d-4503-8280-116bfec47a11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 816b2815-d4dc-4885-8980-3b53bb2e19c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35318627-48eb-4deb-8444-979af10630ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c90ed620-1abd-48d2-920a-63b85b58df7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b345f23c-497d-485a-8e57-22e5f088c1b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 724dc531-6c97-4151-8746-7ea946ad0211
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b18e636-41da-49b4-a67c-f503d3ecbe89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 753d14af-b254-4398-a546-6a5671506dbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2fc321dd-087d-4612-8c51-115f8cb3a31e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 739fb592-54bf-490d-856a-46f8a77d2ade
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 752212a0-5789-4321-9bcf-88a19a79d8d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85d84999-411f-4ff6-9b70-73fde3cc5651
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6ff3446-c5b1-4fa1-94ff-67e805c42b86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45e349ab-fda2-4bdf-8f53-9099cb7db3c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a2fe4d5-90b5-4ba2-9606-f312b787f1df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 915c8058-569b-4133-a432-439f707a9d05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84256972-d327-4a1b-a6fc-9b2ad56a2cac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f35b94c-31a7-496c-9491-a9fc15c4c421
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94542a0a-843a-461c-903f-74e855c28da3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8f94036-d03d-4d94-8b50-5d7b537be5e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 344d5ab1-b91f-4988-974b-db89a904667a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee675f3a-2b11-4b39-807a-67082601510f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8a83337-03b8-40ca-81dc-0b0e1994786e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05b0192a-5b2f-499c-93a2-04b65428fbf3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f89d316-8336-4c95-a387-711d71710945
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90718099-2117-4c10-afa7-97a2a458434b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2793896-73c3-4fc7-8f9c-a0262e55724f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f65ff32-133e-4778-aaca-3c242a277362
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a94e47c7-1b85-46e1-afdc-9d2528b0fa8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b55b7f9-2e65-407d-8096-1155354cf65b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e43ed3ad-0bc5-470d-96dd-d0dd4cfe134e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0ac8323-ec18-4859-914d-0f026a144241
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f08e313-4401-4b7d-8956-f9a126fd88e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03d04ac3-d007-4c49-a54d-b1594a960da2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25698bc4-5c7e-4b28-8d38-ec23b1856b1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21d89200-3110-4fa9-8f3a-d30d1f1f7386
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8596b360-6182-4257-949d-b9eeb8d8d750
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f2c6923-fc5c-42eb-8636-6f3eb7aca766
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7fdfd95f-c416-4f37-8399-bb88a2f38d8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 189d8e2e-8517-40f5-9113-affc4fd66565
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88566a00-ed0a-4c4f-b46d-48e70286471e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64a360ae-a033-4ec9-8657-bf0bb743af2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55b99f90-6df2-4b0b-af80-ebb6b1797c36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30c424cf-d009-4d9a-a910-670b814412e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23b843f6-4101-4091-8ec0-1301fa98cc98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf2a6ffc-bfb1-450a-843b-11a3e8a20abe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f20c373-ab09-4118-8b7d-1cc66a9c8c30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60854699-5d70-4e00-bd3e-838cc66b7747
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc4449f2-560a-429d-84d3-3de4e994cdc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81769400-269d-4e96-a85f-253b8f04a14f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98f8fd31-7db8-4e2a-98d1-d57cbe5ac06b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1ce4b3f-5c99-4897-814e-0e1554277a38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4ac6fc5-05a2-4437-92c8-9a5438b15d88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8721a97b-5132-4c1e-acda-bcc2a5b5adef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b737ea96-5854-49e5-b608-36ad344b0d04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 784f9302-76e0-47ad-868d-bec92d6a0e7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee45bfe5-dd0d-43d3-b665-eeb22501ea42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85fd1e82-a872-4a8e-9b7b-073e9bb1928a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4623e1d9-164d-4035-95de-da4b36a74b7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71f60219-5d7d-4d1a-87e6-fc46f7d2ab3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45b1ba3a-829f-4a51-bab1-c1d9abd4d401
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d59242a-8382-428b-884f-8d495a04b7d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e0b7a42-3350-4cf5-b5db-69d1e258dd69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f359241e-a7ef-42b8-8fce-bf980a839b96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27629c5f-7d13-4843-904b-08eaec8363fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94fa8eea-d002-49ff-a244-ab910d022294
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a19b8cd6-f262-4618-ae22-59ea13f4a04b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dddfcd74-82eb-4d81-82bc-8215ebd67e06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35e0db0a-caa9-433f-bbd6-07d84f921241
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 465a5a3d-2254-4507-8b52-4773cc0f81ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75e17b6a-378d-4d61-a50c-aa192a114d7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7addb047-143a-4735-b979-f52f010724d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 982a5cf9-2009-4e7f-9ea1-aa2353f8f341
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe9fe847-5dfe-4a0e-a99d-de3d7b472499
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6c31455-06c8-4d02-a940-8d71a5109b3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f002473-2cef-4fc9-b7e1-0ebc9a910357
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e121ecbe-50c6-4d8c-9e3c-ac2445c61ac8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 007ec3e7-83b1-4312-acdb-9e1665de4ed2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 318c2626-b2c2-4294-8360-4f620933d9d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 076f0a2c-3e5b-4e70-9f25-abe3b5afb8c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bcf53e6b-ee93-48e7-9255-0b7fac379350
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26b6b898-41b8-47ed-8ca6-517181bbcb38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1a1089c-4e58-445f-aab6-8427250e874a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2eced545-3415-4e78-8ca3-cc5d5590a416
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4661c237-f64c-43d1-8a5a-7bb9017333c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f1f6fde-b746-49de-8304-470044485267
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc682800-2dce-4e26-ab09-27f4d8700c8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27a707a6-90d6-44e9-8ffb-19d1c95ef639
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1db532f3-0292-4cf4-baa8-ea7850a92aa4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb0e4721-6a5e-40d4-92d3-59e8793ea7e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message debdfa47-a85f-4bcd-9e7d-737f49ec0249
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a15f311-dd7c-4373-999e-7bba134abd0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfc5116b-9685-459d-8d90-c0d128d36be3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5efde150-ba0a-4bf5-a8aa-6daf2983cf28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b50401c-292c-49b3-956d-e6e92b3d9de0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18a1d6d4-a2e9-44c2-977d-838e2e75408b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 331eb838-cc1b-434d-a2a5-fb37e6606500
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65e06ff3-9325-446e-a9df-84f97536dc3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36c3e1af-3839-454f-b19f-0aeed30ad8a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9b43bf9-d090-400f-9059-4a65480646ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d4163dd-9924-47b2-b917-a951448eeabf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a796331-4aa2-4008-b258-345ade54fb33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9b64b66-9aab-4864-8ef7-0676bc60bac8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d19d874-be0e-44da-a497-7899e74c5a2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5abd71a-e0eb-4d6e-98fd-f0320202772c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4631aff-d12a-4cd0-8909-55802459502d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 014b066a-4202-484d-ae45-c1617735ef17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53e8803b-a8e8-40e4-9646-c8bb15868e4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a319d98c-9ea5-43c0-b912-011cae982825
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8e49c66-079a-4e37-8249-9bdfefa2da59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a031956e-ef6c-47c2-8915-7783c2d034d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3fb09ea-e994-4431-9780-e84990091258
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59c4d924-15a7-4198-bd18-b01670aa68f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 622ba55c-1ce7-41f7-8059-f1a8329b779d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfde6d8a-a4e0-4f1c-84d1-a808cce1f06c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5579c83c-31fd-4cf1-af36-4db8e05f6520
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1b92549-5d46-4fb5-8217-4ed04dea631c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49d4c2e9-24db-45d2-b139-2b494bb605bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c66b6c17-bbdd-4073-aaba-e4d8cc137c9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 061c0ac3-82ce-444b-acc7-0a90a9f74994
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03782cf3-50a5-4b5d-b085-e59c8c9d9029
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5846f590-ca48-4015-9980-b78df6f879df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9615b70-dd13-41a6-bdf3-7387b6f04089
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb19d27f-7e9a-4837-8b59-e113e6fc51b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b54b47d9-a386-4812-858c-e85438ac62b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84e452a6-b7c8-4f44-a668-c16e784f23c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9825e94c-42b0-4560-abd5-b504fbd86c26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 518ed1ec-d192-48b8-8621-1fe77664d4ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1f23b5d-e5ba-4b37-b9f8-bf37ec3c2b8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message efd84855-d8d2-4fdc-9ccf-eb9cc2958688
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8aac6212-63de-4c62-9b27-3777a0df5e7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b43daad1-6ca4-40d3-aa87-be79f98f0bfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e7acb37-2b3a-495d-85c8-5c7d2752b624
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed2705a7-f3df-47e3-83eb-8c246d0bf0d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb419731-5474-46ed-b792-686615c51a16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32e5b566-9079-44fa-9e06-016eeaf3a765
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76321f71-41c5-4afb-992d-43fa2cc14b29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7f6addb-2aba-42ce-a6e6-7e13645c0ba7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e363523e-6897-482d-ac39-b9a6ebab369e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8921cd7-165f-417c-9e97-b796cbd3369d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90c49178-6198-4992-a320-5d3c28d790ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d57d26f1-1d52-4f35-946b-06312ea7e2b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07f2a66b-5122-4002-8017-677eeea061de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08838baa-6560-4e7d-8b76-35f2259090aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68758ea4-7b9e-49ce-9084-156223a788f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85cb2fd4-ac23-42b2-b837-72a3404b2e9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b714156-d49f-40bb-b4d8-d6a86ccd39d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02ecea51-723e-43b8-9578-451a5e86a3d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02aef592-6f9f-4f74-9974-600de926db21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3ca06cd-9943-45e0-8b13-3aeb2729ef6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0687cdab-ce14-451a-b989-f592374f6eb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a5001af-386b-4489-8a2e-f18fd8dd1351
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4f1ff86-8610-4c2a-97e8-35611ccf4892
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d2a6ad3-4cfb-40e3-8984-243ce3f9f852
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 265507d4-b982-4983-ae5b-2033a3582553
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4be85dd-31b9-472c-947a-7ee3cf1a9d7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97263470-106a-4910-91f2-b15158de8a62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e36b6e0-dee3-4a02-8680-19c30aa0d8c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fdc343db-fa3b-41cb-bef5-e44bfc7fc82f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dce99202-e2c6-47e5-a893-8f6ce5f2ddae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87e91cdd-9922-46e2-9e80-01457ca01986
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed1dc8f6-0513-4559-9807-ef82a3e8740b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05b3aa39-a7d3-41c8-8197-eac575ca30b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d548593e-4cf4-4744-8a1e-3a3a75e0eadb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c1672d8-a71d-49c6-a74f-ead392edaa6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a23bf0f4-9f9b-4edf-a280-56dd317622d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1f689af-fade-4983-bbff-5ce6a729c532
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64d20346-6122-4f7e-83d2-dc7a81221598
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23a34d1e-510b-40c9-8275-1f7c8f42f245
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1b2bd32-23e4-4fd7-8de7-5e5898825428
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d73ee1a-cc59-4323-a726-fd5ee35e13cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73f0cd95-139b-41eb-a149-09989f5464b3
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8692 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_5
Server: localhost:8692
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_5
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_5/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_5/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_5/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_5/test_labels.txt

📊 Raw data loaded:
   Train: X=(5354, 24), y=(5354,)
   Test:  X=(1339, 24), y=(1339,)

⚠️  Limiting training data: 5354 → 800 samples
⚠️  Limiting test data: 1339 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_5 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.5133, RMSE: 0.7164, MAE: 0.6505, R²: -4.6970

📊 Round 0 Test Metrics:
   Loss: 0.5116, RMSE: 0.7152, MAE: 0.6492, R²: -4.6782

📊 Round 0 Test Metrics:
   Loss: 0.4946, RMSE: 0.7033, MAE: 0.6359, R²: -4.4897

============================================================
🔄 Round 6 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.3317, val=0.0810 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0933, val=0.0710 (↓), lr=0.001000
   • Epoch   3/100: train=0.0842, val=0.0756, patience=1/15, lr=0.001000
   • Epoch   4/100: train=0.0843, val=0.0723, patience=2/15, lr=0.001000
   • Epoch   5/100: train=0.0836, val=0.0728, patience=3/15, lr=0.001000
   📉 Epoch 8: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0831, val=0.0728, patience=9/15, lr=0.000500
   📉 Epoch 16: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0710)

============================================================
📊 Round 6 Summary - Client client_5
   Epochs: 17/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0869, RMSE=0.2947, R²=-0.0370
   Val:   Loss=0.0710, RMSE=0.2664, R²=-0.0045
============================================================


📊 Round 6 Test Metrics:
   Loss: 0.4885, RMSE: 0.6989, MAE: 0.6311, R²: -4.4220

============================================================
🔄 Round 8 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.4232, val=0.3466 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.2999, val=0.2083 (↓), lr=0.000250
   ✓ Epoch   3/100: train=0.1377, val=0.0784 (↓), lr=0.000250
   • Epoch   4/100: train=0.0845, val=0.0794, patience=1/15, lr=0.000250
   • Epoch   5/100: train=0.0822, val=0.0785, patience=2/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0819, val=0.0786, patience=8/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 8 Summary - Client client_5
   Epochs: 18/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0003
   Val:   Loss=0.0784, RMSE=0.2801, R²=0.0015
============================================================


============================================================
🔄 Round 9 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.4454, val=0.4393 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.4031, val=0.3991 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.3662, val=0.3646 (↓), lr=0.000063
   ✓ Epoch   4/100: train=0.3324, val=0.3306 (↓), lr=0.000063
   📉 Epoch 5: LR reduced 0.000063 → 0.000031
   ✓ Epoch   5/100: train=0.2961, val=0.2906 (↓), lr=0.000031
   ✓ Epoch  11/100: train=0.1329, val=0.1375 (↓), lr=0.000031
   📉 Epoch 13: LR reduced 0.000031 → 0.000016
   📉 Epoch 21: LR reduced 0.000016 → 0.000008
   • Epoch  21/100: train=0.0791, val=0.0942, patience=1/15, lr=0.000008
   📉 Epoch 29: LR reduced 0.000008 → 0.000004
   ✓ Epoch  31/100: train=0.0783, val=0.0935 (↓), lr=0.000004
   📉 Epoch 37: LR reduced 0.000004 → 0.000002
   • Epoch  41/100: train=0.0782, val=0.0935, patience=10/15, lr=0.000002
   📉 Epoch 45: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0935)

============================================================
📊 Round 9 Summary - Client client_5
   Epochs: 46/100 (early stopped)
   LR: 0.000063 → 0.000001 (6 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0035
   Val:   Loss=0.0935, RMSE=0.3058, R²=-0.0103
============================================================


📊 Round 9 Test Metrics:
   Loss: 0.4541, RMSE: 0.6739, MAE: 0.6033, R²: -4.0406

📊 Round 9 Test Metrics:
   Loss: 0.3284, RMSE: 0.5731, MAE: 0.4882, R²: -2.6453

============================================================
🔄 Round 17 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.3228, val=0.3000 (↓), lr=0.000001
   ✓ Epoch   2/100: train=0.3218, val=0.2990 (↓), lr=0.000001
   ✓ Epoch   3/100: train=0.3208, val=0.2980 (↓), lr=0.000001
   ✓ Epoch   4/100: train=0.3198, val=0.2970 (↓), lr=0.000001
   ✓ Epoch   5/100: train=0.3188, val=0.2961 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.3138, val=0.2914 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.3067, val=0.2847 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.3003, val=0.2785 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.2942, val=0.2727 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.2882, val=0.2670 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.2822, val=0.2613 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.2762, val=0.2556 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.2702, val=0.2498 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.2641, val=0.2440 (↓), lr=0.000001

============================================================
📊 Round 17 Summary - Client client_5
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.2589, RMSE=0.5088, R²=-2.1473
   Val:   Loss=0.2387, RMSE=0.4886, R²=-2.0794
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.3083, RMSE: 0.5552, MAE: 0.4680, R²: -2.4217

============================================================
🔄 Round 18 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.2971, val=0.3107 (↓), lr=0.000001
   ✓ Epoch   2/100: train=0.2966, val=0.3102 (↓), lr=0.000001
   • Epoch   3/100: train=0.2961, val=0.3097, patience=1/15, lr=0.000001
   ✓ Epoch   4/100: train=0.2956, val=0.3091 (↓), lr=0.000001
   • Epoch   5/100: train=0.2951, val=0.3087, patience=1/15, lr=0.000001
   ✓ Epoch  11/100: train=0.2922, val=0.3056 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.2872, val=0.3006 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.2821, val=0.2954 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.2769, val=0.2901 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.2715, val=0.2845 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.2659, val=0.2789 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.2601, val=0.2730 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.2543, val=0.2671 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.2483, val=0.2609 (↓), lr=0.000001

============================================================
📊 Round 18 Summary - Client client_5
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.2415, RMSE=0.4914, R²=-2.0250
   Val:   Loss=0.2553, RMSE=0.5053, R²=-1.9200
============================================================


============================================================
🔄 Round 20 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.2333, val=0.2499 (↓), lr=0.000001
   ✓ Epoch   2/100: train=0.2326, val=0.2492 (↓), lr=0.000001
   ✓ Epoch   3/100: train=0.2320, val=0.2485 (↓), lr=0.000001
   ✓ Epoch   4/100: train=0.2313, val=0.2478 (↓), lr=0.000001
   ✓ Epoch   5/100: train=0.2307, val=0.2471 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.2267, val=0.2429 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.2201, val=0.2358 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.2134, val=0.2287 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.2068, val=0.2215 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.2001, val=0.2144 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.1934, val=0.2072 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.1868, val=0.2000 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.1802, val=0.1929 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.1736, val=0.1858 (↓), lr=0.000001

============================================================
📊 Round 20 Summary - Client client_5
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1674, RMSE=0.4091, R²=-1.0452
   Val:   Loss=0.1795, RMSE=0.4237, R²=-1.2738
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.1805, RMSE: 0.4249, MAE: 0.3437, R²: -1.0038

📊 Round 20 Test Metrics:
   Loss: 0.1501, RMSE: 0.3874, MAE: 0.3152, R²: -0.6660

============================================================
🔄 Round 23 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1464, val=0.1194 (↓), lr=0.000001
   • Epoch   2/100: train=0.1457, val=0.1190, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.1451, val=0.1185 (↓), lr=0.000001
   • Epoch   4/100: train=0.1444, val=0.1180, patience=1/15, lr=0.000001
   ✓ Epoch   5/100: train=0.1438, val=0.1175 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.1400, val=0.1148 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.1339, val=0.1104 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.1282, val=0.1064 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.1229, val=0.1028 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.1179, val=0.0994 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.1133, val=0.0965 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.1090, val=0.0938 (↓), lr=0.000001
   • Epoch  81/100: train=0.1051, val=0.0915, patience=1/15, lr=0.000001
   • Epoch  91/100: train=0.1015, val=0.0894, patience=2/15, lr=0.000001

============================================================
📊 Round 23 Summary - Client client_5
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0985, RMSE=0.3138, R²=-0.2284
   Val:   Loss=0.0879, RMSE=0.2965, R²=-0.0626
============================================================


============================================================
🔄 Round 25 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0926, val=0.0985 (↓), lr=0.000001
   • Epoch   2/100: train=0.0924, val=0.0982, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0922, val=0.0980, patience=2/15, lr=0.000001
   ✓ Epoch   4/100: train=0.0920, val=0.0978 (↓), lr=0.000001
   • Epoch   5/100: train=0.0918, val=0.0975, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.0907, val=0.0962, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.0891, val=0.0940, patience=2/15, lr=0.000001
   ✓ Epoch  31/100: train=0.0876, val=0.0921 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.0864, val=0.0905 (↓), lr=0.000001
   • Epoch  51/100: train=0.0853, val=0.0890, patience=2/15, lr=0.000001
   • Epoch  61/100: train=0.0844, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  71/100: train=0.0837, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  81/100: train=0.0831, val=0.0856, patience=3/15, lr=0.000001
   ✓ Epoch  91/100: train=0.0826, val=0.0848 (↓), lr=0.000001

============================================================
📊 Round 25 Summary - Client client_5
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0140
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0332
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0913, RMSE: 0.3022, MAE: 0.2616, R²: -0.0138

📊 Round 25 Test Metrics:
   Loss: 0.0911, RMSE: 0.3018, MAE: 0.2613, R²: -0.0110

============================================================
🔄 Round 30 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 30 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0165
   Val:   Loss=0.0757, RMSE=0.2751, R²=0.0123
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0906, RMSE: 0.3010, MAE: 0.2609, R²: -0.0054

📊 Round 30 Test Metrics:
   Loss: 0.0905, RMSE: 0.3009, MAE: 0.2609, R²: -0.0047

📊 Round 30 Test Metrics:
   Loss: 0.0905, RMSE: 0.3008, MAE: 0.2609, R²: -0.0046

============================================================
🔄 Round 36 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 36 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0057
   Val:   Loss=0.0824, RMSE=0.2870, R²=0.0008
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0905, RMSE: 0.3008, MAE: 0.2609, R²: -0.0041

============================================================
🔄 Round 37 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 37 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0021
   Val:   Loss=0.0754, RMSE=0.2747, R²=-0.0175
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0905, RMSE: 0.3008, MAE: 0.2608, R²: -0.0041

============================================================
🔄 Round 39 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 39 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0048
   Val:   Loss=0.0882, RMSE=0.2970, R²=-0.0014
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0904, RMSE: 0.3007, MAE: 0.2608, R²: -0.0039

📊 Round 39 Test Metrics:
   Loss: 0.0904, RMSE: 0.3007, MAE: 0.2608, R²: -0.0038

============================================================
🔄 Round 45 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 45 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0045
   Val:   Loss=0.0799, RMSE=0.2826, R²=-0.0034
============================================================


📊 Round 45 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2608, R²: -0.0025

📊 Round 45 Test Metrics:
   Loss: 0.0902, RMSE: 0.3004, MAE: 0.2607, R²: -0.0014

============================================================
🔄 Round 56 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0939 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0939, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0939, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0939, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0939, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0939, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0939)

============================================================
📊 Round 56 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=-0.0040
   Val:   Loss=0.0939, RMSE=0.3065, R²=0.0050
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0902, RMSE: 0.3003, MAE: 0.2607, R²: -0.0010

============================================================
🔄 Round 59 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 59 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0008
   Val:   Loss=0.0756, RMSE=0.2750, R²=-0.0029
============================================================


============================================================
🔄 Round 61 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 61 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0019
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0122
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0902, RMSE: 0.3003, MAE: 0.2607, R²: -0.0006

============================================================
🔄 Round 62 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 62 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2829, R²=-0.0053
   Val:   Loss=0.0869, RMSE=0.2947, R²=-0.0188
============================================================


============================================================
🔄 Round 63 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 63 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0027
   Val:   Loss=0.0761, RMSE=0.2758, R²=-0.0053
============================================================


============================================================
🔄 Round 64 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 64 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0009
   Val:   Loss=0.0859, RMSE=0.2930, R²=-0.0079
============================================================


============================================================
🔄 Round 66 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 66 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0017
   Val:   Loss=0.0848, RMSE=0.2913, R²=-0.0206
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0901, RMSE: 0.3002, MAE: 0.2607, R²: -0.0004

============================================================
🔄 Round 68 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 68 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0021
   Val:   Loss=0.0867, RMSE=0.2944, R²=0.0006
============================================================


============================================================
🔄 Round 69 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 69 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0016
   Val:   Loss=0.0742, RMSE=0.2724, R²=0.0006
============================================================


============================================================
🔄 Round 70 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 70 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0005
   Val:   Loss=0.0786, RMSE=0.2803, R²=-0.0001
============================================================


============================================================
🔄 Round 72 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0936 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0937, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0937, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0937, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0937, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0937, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0936)

============================================================
📊 Round 72 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2799, R²=-0.0033
   Val:   Loss=0.0936, RMSE=0.3060, R²=-0.0088
============================================================


============================================================
🔄 Round 73 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 73 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2864, R²=0.0014
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0178
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0901, RMSE: 0.3002, MAE: 0.2607, R²: -0.0004

📊 Round 73 Test Metrics:
   Loss: 0.0901, RMSE: 0.3002, MAE: 0.2607, R²: -0.0004

📊 Round 73 Test Metrics:
   Loss: 0.0901, RMSE: 0.3002, MAE: 0.2607, R²: -0.0005

============================================================
🔄 Round 78 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 78 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0009
   Val:   Loss=0.0859, RMSE=0.2931, R²=0.0006
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0901, RMSE: 0.3002, MAE: 0.2607, R²: -0.0005

📊 Round 78 Test Metrics:
   Loss: 0.0901, RMSE: 0.3002, MAE: 0.2607, R²: -0.0004

============================================================
🔄 Round 81 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 81 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=-0.0024
   Val:   Loss=0.0812, RMSE=0.2849, R²=0.0070
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0901, RMSE: 0.3002, MAE: 0.2607, R²: -0.0004

📊 Round 81 Test Metrics:
   Loss: 0.0901, RMSE: 0.3002, MAE: 0.2607, R²: -0.0004

📊 Round 81 Test Metrics:
   Loss: 0.0901, RMSE: 0.3002, MAE: 0.2607, R²: -0.0004

============================================================
🔄 Round 84 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 84 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0006
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0019
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0901, RMSE: 0.3002, MAE: 0.2607, R²: -0.0003

============================================================
🔄 Round 87 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 87 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0024
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0262
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0901, RMSE: 0.3002, MAE: 0.2607, R²: -0.0004

📊 Round 87 Test Metrics:
   Loss: 0.0901, RMSE: 0.3002, MAE: 0.2607, R²: -0.0004

============================================================
🔄 Round 89 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 89 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2857, R²=-0.0017
   Val:   Loss=0.0804, RMSE=0.2836, R²=0.0038
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0901, RMSE: 0.3002, MAE: 0.2607, R²: -0.0005

============================================================
🔄 Round 90 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 90 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0003
   Val:   Loss=0.0764, RMSE=0.2763, R²=-0.0067
============================================================


============================================================
🔄 Round 91 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 91 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0000
   Val:   Loss=0.0908, RMSE=0.3014, R²=-0.0121
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0901, RMSE: 0.3002, MAE: 0.2607, R²: -0.0005

📊 Round 91 Test Metrics:
   Loss: 0.0902, RMSE: 0.3003, MAE: 0.2607, R²: -0.0007

============================================================
🔄 Round 102 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 102 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0024
   Val:   Loss=0.0765, RMSE=0.2766, R²=-0.0151
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0902, RMSE: 0.3003, MAE: 0.2607, R²: -0.0008

📊 Round 102 Test Metrics:
   Loss: 0.0902, RMSE: 0.3003, MAE: 0.2607, R²: -0.0008

============================================================
🔄 Round 104 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 104 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0002
   Val:   Loss=0.0769, RMSE=0.2773, R²=-0.0155
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0902, RMSE: 0.3003, MAE: 0.2607, R²: -0.0010

============================================================
🔄 Round 106 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 106 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0009
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0026
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0902, RMSE: 0.3003, MAE: 0.2607, R²: -0.0010

============================================================
🔄 Round 108 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 108 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0007
   Val:   Loss=0.0847, RMSE=0.2911, R²=-0.0015
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0902, RMSE: 0.3003, MAE: 0.2607, R²: -0.0007

============================================================
🔄 Round 109 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 109 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0026
   Val:   Loss=0.0775, RMSE=0.2784, R²=-0.0010
============================================================


============================================================
🔄 Round 111 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 111 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0020
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0120
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0901, RMSE: 0.3002, MAE: 0.2607, R²: -0.0005

============================================================
🔄 Round 114 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 114 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0014
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0087
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0901, RMSE: 0.3002, MAE: 0.2607, R²: -0.0005

📊 Round 114 Test Metrics:
   Loss: 0.0901, RMSE: 0.3002, MAE: 0.2607, R²: -0.0005

============================================================
🔄 Round 118 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 118 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0016
   Val:   Loss=0.0809, RMSE=0.2845, R²=-0.0050
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0901, RMSE: 0.3002, MAE: 0.2607, R²: -0.0003

============================================================
🔄 Round 119 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 119 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0001
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0053
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0901, RMSE: 0.3002, MAE: 0.2607, R²: -0.0003

📊 Round 119 Test Metrics:
   Loss: 0.0901, RMSE: 0.3002, MAE: 0.2607, R²: -0.0003

📊 Round 119 Test Metrics:
   Loss: 0.0901, RMSE: 0.3002, MAE: 0.2607, R²: -0.0002

📊 Round 119 Test Metrics:
   Loss: 0.0901, RMSE: 0.3002, MAE: 0.2607, R²: -0.0001

============================================================
🔄 Round 126 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 126 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0054
   Val:   Loss=0.0851, RMSE=0.2916, R²=0.0096
============================================================


============================================================
🔄 Round 127 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 127 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0036
   Val:   Loss=0.0812, RMSE=0.2850, R²=0.0133
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0901, RMSE: 0.3002, MAE: 0.2607, R²: 0.0000

📊 Round 127 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2607, R²: 0.0002

📊 Round 127 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2607, R²: 0.0002

📊 Round 127 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2607, R²: 0.0001

📊 Round 127 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2607, R²: 0.0001

📊 Round 127 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2607, R²: 0.0001

============================================================
🔄 Round 137 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 137 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0019
   Val:   Loss=0.0870, RMSE=0.2949, R²=-0.0141
============================================================


============================================================
🔄 Round 138 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 138 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0026
   Val:   Loss=0.0880, RMSE=0.2967, R²=-0.0087
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2607, R²: 0.0002

📊 Round 138 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2607, R²: 0.0002

============================================================
🔄 Round 140 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 140 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0002
   Val:   Loss=0.0854, RMSE=0.2923, R²=-0.0090
============================================================


============================================================
🔄 Round 141 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 141 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=-0.0002
   Val:   Loss=0.0897, RMSE=0.2995, R²=-0.0047
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2607, R²: 0.0002

📊 Round 141 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2607, R²: 0.0002

📊 Round 141 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2607, R²: 0.0002

📊 Round 141 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2607, R²: 0.0002

============================================================
🔄 Round 148 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 148 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0018
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0157
============================================================


============================================================
🔄 Round 149 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 149 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0014
   Val:   Loss=0.0836, RMSE=0.2892, R²=-0.0064
============================================================


============================================================
🔄 Round 150 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 150 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0011
   Val:   Loss=0.0765, RMSE=0.2766, R²=-0.0058
============================================================


============================================================
🔄 Round 152 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 152 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0010
   Val:   Loss=0.0817, RMSE=0.2857, R²=-0.0047
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2607, R²: 0.0001

📊 Round 152 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2607, R²: 0.0001

============================================================
🔄 Round 155 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 155 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0010
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0188
============================================================


============================================================
🔄 Round 156 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 156 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0001
   Val:   Loss=0.0809, RMSE=0.2844, R²=-0.0020
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2607, R²: 0.0001

============================================================
🔄 Round 158 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 158 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2849, R²=-0.0016
   Val:   Loss=0.0823, RMSE=0.2870, R²=0.0033
============================================================


============================================================
🔄 Round 159 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 159 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0035
   Val:   Loss=0.0774, RMSE=0.2782, R²=0.0067
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2607, R²: 0.0001

============================================================
🔄 Round 163 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 163 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0003
   Val:   Loss=0.0872, RMSE=0.2953, R²=0.0006
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0901, RMSE: 0.3002, MAE: 0.2607, R²: -0.0001

============================================================
🔄 Round 167 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 167 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0014
   Val:   Loss=0.0824, RMSE=0.2871, R²=0.0043
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2607, R²: 0.0001

📊 Round 167 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2607, R²: 0.0003

============================================================
🔄 Round 170 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 170 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0009
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.0186
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2607, R²: 0.0003

📊 Round 170 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2607, R²: 0.0002

============================================================
🔄 Round 172 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0978 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0978, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0978, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0978, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0978, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0978, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0978)

============================================================
📊 Round 172 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=-0.0006
   Val:   Loss=0.0978, RMSE=0.3128, R²=-0.0008
============================================================


============================================================
🔄 Round 173 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 173 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0015
   Val:   Loss=0.0858, RMSE=0.2930, R²=-0.0061
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2607, R²: 0.0001

============================================================
🔄 Round 176 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0934 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0934, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0934, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0934, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0934, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0934, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0934)

============================================================
📊 Round 176 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0035
   Val:   Loss=0.0934, RMSE=0.3055, R²=-0.0235
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2607, R²: 0.0002

============================================================
🔄 Round 178 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 178 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0022
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0093
============================================================


============================================================
🔄 Round 179 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 179 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0039
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0384
============================================================


============================================================
🔄 Round 180 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 180 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0015
   Val:   Loss=0.0790, RMSE=0.2811, R²=0.0052
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2607, R²: 0.0002

📊 Round 180 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2607, R²: 0.0003

📊 Round 180 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2607, R²: 0.0003

📊 Round 180 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2607, R²: 0.0003

📊 Round 180 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2607, R²: 0.0003

📊 Round 180 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2606, R²: 0.0003

============================================================
🔄 Round 188 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 188 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0016
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0065
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2606, R²: 0.0003

📊 Round 188 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2606, R²: 0.0004

📊 Round 188 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2606, R²: 0.0004

============================================================
🔄 Round 191 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 191 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=0.0006
   Val:   Loss=0.0858, RMSE=0.2930, R²=-0.0029
============================================================


📊 Round 191 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2606, R²: 0.0004

📊 Round 191 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2606, R²: 0.0004

============================================================
🔄 Round 194 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 194 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=-0.0035
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0152
============================================================


📊 Round 194 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2606, R²: 0.0004

📊 Round 194 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2606, R²: 0.0004

============================================================
🔄 Round 196 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0949 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0949, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0949, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0949, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0949, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0949, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0949)

============================================================
📊 Round 196 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2792, R²=0.0025
   Val:   Loss=0.0949, RMSE=0.3080, R²=-0.0132
============================================================


📊 Round 196 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2606, R²: 0.0003

============================================================
🔄 Round 199 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 199 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0024
   Val:   Loss=0.0789, RMSE=0.2809, R²=-0.0102
============================================================


📊 Round 199 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2606, R²: 0.0003

============================================================
🔄 Round 201 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 201 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0002
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0098
============================================================


📊 Round 201 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2606, R²: 0.0003

============================================================
🔄 Round 202 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 202 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0007
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0048
============================================================


📊 Round 202 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2606, R²: 0.0002

============================================================
🔄 Round 204 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 204 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0005
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0044
============================================================


📊 Round 204 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2606, R²: 0.0001

============================================================
🔄 Round 205 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 205 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0005
   Val:   Loss=0.0829, RMSE=0.2880, R²=-0.0356
============================================================


============================================================
🔄 Round 206 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 206 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0016
   Val:   Loss=0.0836, RMSE=0.2892, R²=-0.0093
============================================================


📊 Round 206 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2606, R²: 0.0003

============================================================
🔄 Round 210 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 210 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0010
   Val:   Loss=0.0844, RMSE=0.2906, R²=-0.0275
============================================================


📊 Round 210 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2606, R²: 0.0001

============================================================
🔄 Round 215 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 215 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2877, R²=-0.0009
   Val:   Loss=0.0759, RMSE=0.2755, R²=0.0023
============================================================


📊 Round 215 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2606, R²: 0.0002

📊 Round 215 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2606, R²: 0.0001

============================================================
🔄 Round 219 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 219 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0008
   Val:   Loss=0.0774, RMSE=0.2782, R²=0.0018
============================================================


============================================================
🔄 Round 221 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 221 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=-0.0003
   Val:   Loss=0.0911, RMSE=0.3019, R²=-0.0004
============================================================


============================================================
🔄 Round 222 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 222 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0034
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.0085
============================================================


============================================================
🔄 Round 223 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 223 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0010
   Val:   Loss=0.0885, RMSE=0.2975, R²=-0.0082
============================================================


📊 Round 223 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2606, R²: 0.0001

📊 Round 223 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2606, R²: 0.0002

============================================================
🔄 Round 226 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 226 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0005
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0038
============================================================


📊 Round 226 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2606, R²: 0.0003

============================================================
🔄 Round 227 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 227 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0025
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0120
============================================================


============================================================
🔄 Round 228 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 228 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=-0.0041
   Val:   Loss=0.0905, RMSE=0.3008, R²=0.0056
============================================================


📊 Round 228 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2606, R²: 0.0002

============================================================
🔄 Round 230 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 230 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0007
   Val:   Loss=0.0768, RMSE=0.2771, R²=0.0019
============================================================


📊 Round 230 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2606, R²: 0.0004

📊 Round 230 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2606, R²: 0.0004

📊 Round 230 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2606, R²: 0.0004

============================================================
🔄 Round 234 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 234 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=-0.0007
   Val:   Loss=0.0863, RMSE=0.2938, R²=0.0003
============================================================


📊 Round 234 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2606, R²: 0.0005

📊 Round 234 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2606, R²: 0.0005

📊 Round 234 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2606, R²: 0.0005

============================================================
🔄 Round 241 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 241 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0040
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0001
============================================================


📊 Round 241 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2606, R²: 0.0005

📊 Round 241 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2606, R²: 0.0005

============================================================
🔄 Round 245 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 245 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0009
   Val:   Loss=0.0789, RMSE=0.2809, R²=-0.0135
============================================================


============================================================
🔄 Round 246 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0933 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0932, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0932, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0932, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0932, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0932, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0933)

============================================================
📊 Round 246 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0002
   Val:   Loss=0.0933, RMSE=0.3054, R²=-0.0028
============================================================


📊 Round 246 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2606, R²: 0.0006

============================================================
🔄 Round 248 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 248 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=-0.0011
   Val:   Loss=0.0778, RMSE=0.2790, R²=0.0055
============================================================


📊 Round 248 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2606, R²: 0.0005

============================================================
🔄 Round 251 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 251 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0021
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0088
============================================================


📊 Round 251 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2606, R²: 0.0005

📊 Round 251 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2606, R²: 0.0005

============================================================
🔄 Round 254 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 254 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2812, R²=0.0009
   Val:   Loss=0.0906, RMSE=0.3010, R²=-0.0033
============================================================


============================================================
🔄 Round 256 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 256 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0039
   Val:   Loss=0.0869, RMSE=0.2949, R²=-0.0218
============================================================


============================================================
🔄 Round 257 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 257 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0033
   Val:   Loss=0.0806, RMSE=0.2840, R²=0.0092
============================================================


📊 Round 257 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2606, R²: 0.0003

============================================================
🔄 Round 259 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 259 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=-0.0000
   Val:   Loss=0.0926, RMSE=0.3043, R²=-0.0007
============================================================


============================================================
🔄 Round 260 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 260 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=-0.0002
   Val:   Loss=0.0847, RMSE=0.2911, R²=-0.0002
============================================================


============================================================
🔄 Round 267 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 267 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0009
   Val:   Loss=0.0771, RMSE=0.2776, R²=0.0041
============================================================


📊 Round 267 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2606, R²: 0.0004

📊 Round 267 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2606, R²: 0.0004

============================================================
🔄 Round 269 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 269 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2864, R²=0.0022
   Val:   Loss=0.0786, RMSE=0.2804, R²=-0.0172
============================================================


============================================================
🔄 Round 270 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 270 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=0.0003
   Val:   Loss=0.0814, RMSE=0.2853, R²=-0.0106
============================================================


============================================================
🔄 Round 272 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 272 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0036
   Val:   Loss=0.0811, RMSE=0.2847, R²=-0.0202
============================================================


📊 Round 272 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2606, R²: 0.0004

============================================================
🔄 Round 274 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 274 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=-0.0024
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0219
============================================================


📊 Round 274 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2606, R²: 0.0004

============================================================
🔄 Round 278 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 278 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=-0.0031
   Val:   Loss=0.0896, RMSE=0.2994, R²=0.0017
============================================================


============================================================
🔄 Round 279 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 279 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2829, R²=0.0006
   Val:   Loss=0.0866, RMSE=0.2943, R²=-0.0031
============================================================


📊 Round 279 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2606, R²: 0.0006

============================================================
🔄 Round 280 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 280 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=-0.0007
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0002
============================================================


============================================================
🔄 Round 281 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 281 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0017
   Val:   Loss=0.0754, RMSE=0.2746, R²=0.0040
============================================================


📊 Round 281 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2606, R²: 0.0006

============================================================
🔄 Round 283 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 283 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0010
   Val:   Loss=0.0847, RMSE=0.2911, R²=-0.0029
============================================================


📊 Round 283 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2606, R²: 0.0006

📊 Round 283 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0008

============================================================
🔄 Round 285 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 285 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0006
   Val:   Loss=0.0836, RMSE=0.2892, R²=0.0041
============================================================


📊 Round 285 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2606, R²: 0.0006

============================================================
🔄 Round 291 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 291 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0006
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0072
============================================================


============================================================
🔄 Round 292 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 292 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0013
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0171
============================================================


📊 Round 292 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0009

============================================================
🔄 Round 293 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 293 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0008
   Val:   Loss=0.0815, RMSE=0.2854, R²=-0.0009
============================================================


📊 Round 293 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0010

📊 Round 293 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0010

============================================================
🔄 Round 295 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 295 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0002
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0060
============================================================


📊 Round 295 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0010

📊 Round 295 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0010

============================================================
🔄 Round 297 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 297 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0005
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0003
============================================================


📊 Round 297 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0009

📊 Round 297 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0009

📊 Round 297 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0007

📊 Round 297 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0007

📊 Round 297 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0007

📊 Round 297 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0007

📊 Round 297 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0007

============================================================
🔄 Round 311 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 311 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0010
   Val:   Loss=0.0801, RMSE=0.2831, R²=-0.0032
============================================================


============================================================
🔄 Round 313 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 313 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0015
   Val:   Loss=0.0856, RMSE=0.2925, R²=-0.0048
============================================================


📊 Round 313 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0008

============================================================
🔄 Round 318 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0722 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0722, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0722)

============================================================
📊 Round 318 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0009
   Val:   Loss=0.0722, RMSE=0.2686, R²=0.0045
============================================================


📊 Round 318 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0008

📊 Round 318 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0008

📊 Round 318 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0008

📊 Round 318 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0007

📊 Round 318 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0009

📊 Round 318 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0009

============================================================
🔄 Round 332 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 332 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0001
   Val:   Loss=0.0842, RMSE=0.2901, R²=-0.0010
============================================================


============================================================
🔄 Round 333 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 333 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0035
   Val:   Loss=0.0832, RMSE=0.2884, R²=0.0033
============================================================


============================================================
🔄 Round 335 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0713 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0713, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0713, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0714, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0714, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0714, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0713)

============================================================
📊 Round 335 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0022
   Val:   Loss=0.0713, RMSE=0.2671, R²=-0.0078
============================================================


============================================================
🔄 Round 336 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 336 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0010
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0030
============================================================


============================================================
🔄 Round 337 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 337 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=0.0001
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0022
============================================================


📊 Round 337 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0011

============================================================
🔄 Round 338 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 338 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0023
   Val:   Loss=0.0791, RMSE=0.2813, R²=-0.0087
============================================================


📊 Round 338 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0011

============================================================
🔄 Round 341 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 341 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0010
   Val:   Loss=0.0762, RMSE=0.2760, R²=-0.0017
============================================================


📊 Round 341 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0010

============================================================
🔄 Round 342 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 342 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0002
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0111
============================================================


📊 Round 342 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0009

============================================================
🔄 Round 343 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 343 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0022
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0076
============================================================


============================================================
🔄 Round 344 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 344 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0001
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0062
============================================================


============================================================
🔄 Round 345 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 345 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0016
   Val:   Loss=0.0875, RMSE=0.2958, R²=-0.0121
============================================================


============================================================
🔄 Round 347 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 347 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0002
   Val:   Loss=0.0881, RMSE=0.2969, R²=-0.0021
============================================================


📊 Round 347 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0010

📊 Round 347 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0010

============================================================
🔄 Round 350 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 350 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0003
   Val:   Loss=0.0739, RMSE=0.2719, R²=-0.0037
============================================================


📊 Round 350 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0009

============================================================
🔄 Round 352 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 352 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=-0.0001
   Val:   Loss=0.0824, RMSE=0.2871, R²=0.0014
============================================================


============================================================
🔄 Round 354 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 354 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0029
   Val:   Loss=0.0870, RMSE=0.2950, R²=0.0091
============================================================


============================================================
🔄 Round 356 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 356 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0006
   Val:   Loss=0.0895, RMSE=0.2992, R²=-0.0005
============================================================


============================================================
🔄 Round 360 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 360 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0007
   Val:   Loss=0.0767, RMSE=0.2770, R²=0.0047
============================================================


📊 Round 360 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0008

📊 Round 360 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0008

📊 Round 360 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2606, R²: 0.0007

📊 Round 360 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2606, R²: 0.0005

============================================================
🔄 Round 365 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 365 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0004
   Val:   Loss=0.0829, RMSE=0.2880, R²=-0.0075
============================================================


📊 Round 365 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2606, R²: 0.0005

📊 Round 365 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2606, R²: 0.0005

============================================================
🔄 Round 368 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0685 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0685, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0685, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0685, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0686, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0686, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0685)

============================================================
📊 Round 368 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0010
   Val:   Loss=0.0685, RMSE=0.2618, R²=0.0002
============================================================


📊 Round 368 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2606, R²: 0.0005

============================================================
🔄 Round 369 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0938 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0939, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0939, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0939, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0939, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0940, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0938)

============================================================
📊 Round 369 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=-0.0026
   Val:   Loss=0.0938, RMSE=0.3063, R²=0.0034
============================================================


📊 Round 369 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2606, R²: 0.0006

📊 Round 369 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2606, R²: 0.0006

============================================================
🔄 Round 371 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 371 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=-0.0010
   Val:   Loss=0.0914, RMSE=0.3024, R²=-0.0040
============================================================


============================================================
🔄 Round 372 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 372 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0002
   Val:   Loss=0.0815, RMSE=0.2854, R²=-0.0016
============================================================


📊 Round 372 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2606, R²: 0.0004

📊 Round 372 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2606, R²: 0.0002

📊 Round 372 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2606, R²: 0.0003

📊 Round 372 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2606, R²: 0.0005

============================================================
🔄 Round 382 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 382 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0008
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0052
============================================================


📊 Round 382 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2606, R²: 0.0005

📊 Round 382 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2606, R²: 0.0005

============================================================
🔄 Round 384 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 384 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0023
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0024
============================================================


📊 Round 384 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2606, R²: 0.0003

============================================================
🔄 Round 386 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 386 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0028
   Val:   Loss=0.0789, RMSE=0.2809, R²=-0.0178
============================================================


============================================================
🔄 Round 388 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 388 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0003
   Val:   Loss=0.0795, RMSE=0.2819, R²=-0.0006
============================================================


📊 Round 388 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2606, R²: 0.0005

📊 Round 388 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2606, R²: 0.0006

📊 Round 388 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2606, R²: 0.0006

============================================================
🔄 Round 391 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 391 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0000
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0119
============================================================


============================================================
🔄 Round 395 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 395 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0005
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0031
============================================================


📊 Round 395 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2606, R²: 0.0004

============================================================
🔄 Round 396 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 396 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0031
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0000
============================================================


📊 Round 396 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2606, R²: 0.0006

============================================================
🔄 Round 399 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 399 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0013
   Val:   Loss=0.0781, RMSE=0.2794, R²=-0.0048
============================================================


📊 Round 399 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2606, R²: 0.0006

============================================================
🔄 Round 402 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 402 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0012
   Val:   Loss=0.0772, RMSE=0.2779, R²=-0.0025
============================================================


📊 Round 402 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2606, R²: 0.0007

============================================================
🔄 Round 403 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 403 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0008
   Val:   Loss=0.0831, RMSE=0.2884, R²=0.0023
============================================================


📊 Round 403 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2606, R²: 0.0007

📊 Round 403 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0008

============================================================
🔄 Round 408 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 408 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=-0.0003
   Val:   Loss=0.0778, RMSE=0.2789, R²=0.0016
============================================================


============================================================
🔄 Round 410 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 410 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2829, R²=0.0017
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0049
============================================================


📊 Round 410 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0009

📊 Round 410 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0008

============================================================
🔄 Round 412 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 412 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0002
   Val:   Loss=0.0757, RMSE=0.2751, R²=0.0006
============================================================


============================================================
🔄 Round 414 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 414 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0007
   Val:   Loss=0.0752, RMSE=0.2743, R²=-0.0017
============================================================


============================================================
🔄 Round 415 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 415 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0005
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0036
============================================================


📊 Round 415 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0008

📊 Round 415 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0007

📊 Round 415 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0007

📊 Round 415 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2606, R²: 0.0006

📊 Round 415 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2606, R²: 0.0007

============================================================
🔄 Round 424 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 424 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0004
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0028
============================================================


📊 Round 424 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2606, R²: 0.0007

📊 Round 424 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2606, R²: 0.0007

============================================================
🔄 Round 426 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 426 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0026
   Val:   Loss=0.0779, RMSE=0.2792, R²=-0.0250
============================================================


📊 Round 426 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0007

============================================================
🔄 Round 428 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 428 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=-0.0010
   Val:   Loss=0.0899, RMSE=0.2998, R²=0.0041
============================================================


📊 Round 428 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0007

📊 Round 428 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0008

============================================================
🔄 Round 430 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 430 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0009
   Val:   Loss=0.0772, RMSE=0.2778, R²=0.0006
============================================================


📊 Round 430 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0008

📊 Round 430 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0007

📊 Round 430 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0008

============================================================
🔄 Round 435 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 435 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0024
   Val:   Loss=0.0899, RMSE=0.2998, R²=-0.0076
============================================================


📊 Round 435 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0008

📊 Round 435 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0008

📊 Round 435 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0008

📊 Round 435 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0008

============================================================
🔄 Round 439 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 439 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0007
   Val:   Loss=0.0785, RMSE=0.2801, R²=-0.0005
============================================================


📊 Round 439 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0008

============================================================
🔄 Round 440 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 440 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0013
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0051
============================================================


============================================================
🔄 Round 441 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 441 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0025
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0099
============================================================


============================================================
🔄 Round 442 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 442 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0008
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0020
============================================================


============================================================
🔄 Round 446 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 446 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0012
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0124
============================================================


📊 Round 446 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2606, R²: 0.0006

============================================================
🔄 Round 450 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 450 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0015
   Val:   Loss=0.0782, RMSE=0.2797, R²=0.0070
============================================================


📊 Round 450 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2606, R²: 0.0006

📊 Round 450 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2606, R²: 0.0006

📊 Round 450 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2606, R²: 0.0006

============================================================
🔄 Round 454 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 454 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0042
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0037
============================================================


============================================================
🔄 Round 456 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 456 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0008
   Val:   Loss=0.0857, RMSE=0.2928, R²=0.0033
============================================================


📊 Round 456 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2606, R²: 0.0007

============================================================
🔄 Round 458 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0695 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0695, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0695, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0695, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0695, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0695, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0695)

============================================================
📊 Round 458 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0000
   Val:   Loss=0.0695, RMSE=0.2636, R²=-0.0029
============================================================


📊 Round 458 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2606, R²: 0.0007

============================================================
🔄 Round 460 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 460 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2819, R²=-0.0047
   Val:   Loss=0.0890, RMSE=0.2983, R²=-0.0257
============================================================


============================================================
🔄 Round 461 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 461 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0003
   Val:   Loss=0.0727, RMSE=0.2697, R²=-0.0014
============================================================


============================================================
🔄 Round 462 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 462 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0019
   Val:   Loss=0.0775, RMSE=0.2783, R²=0.0002
============================================================


📊 Round 462 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0007

============================================================
🔄 Round 464 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 464 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0000
   Val:   Loss=0.0783, RMSE=0.2798, R²=-0.0068
============================================================


📊 Round 464 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0009

📊 Round 464 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0008

============================================================
🔄 Round 469 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 469 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0009
   Val:   Loss=0.0798, RMSE=0.2824, R²=0.0047
============================================================


📊 Round 469 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0008

============================================================
🔄 Round 471 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 471 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0033
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0241
============================================================


📊 Round 471 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2606, R²: 0.0006

============================================================
🔄 Round 475 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0927, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 475 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=-0.0020
   Val:   Loss=0.0925, RMSE=0.3041, R²=-0.0047
============================================================


📊 Round 475 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2606, R²: 0.0006

📊 Round 475 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2606, R²: 0.0006

============================================================
🔄 Round 479 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 479 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0023
   Val:   Loss=0.0733, RMSE=0.2708, R²=-0.0119
============================================================


============================================================
🔄 Round 481 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 481 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0018
   Val:   Loss=0.0909, RMSE=0.3015, R²=-0.0272
============================================================


📊 Round 481 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0007

============================================================
🔄 Round 482 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 482 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=-0.0012
   Val:   Loss=0.0862, RMSE=0.2937, R²=-0.0032
============================================================


📊 Round 482 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0008

📊 Round 482 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0008

============================================================
🔄 Round 485 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 485 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0008
   Val:   Loss=0.0808, RMSE=0.2842, R²=0.0024
============================================================


============================================================
🔄 Round 487 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0719 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0719, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0719)

============================================================
📊 Round 487 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0012
   Val:   Loss=0.0719, RMSE=0.2681, R²=-0.0194
============================================================


============================================================
🔄 Round 488 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 488 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0021
   Val:   Loss=0.0849, RMSE=0.2913, R²=-0.0159
============================================================


📊 Round 488 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0008

============================================================
🔄 Round 489 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0956 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0956, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0956, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0957, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0957, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0958, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0956)

============================================================
📊 Round 489 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=-0.0012
   Val:   Loss=0.0956, RMSE=0.3092, R²=-0.0032
============================================================


============================================================
🔄 Round 490 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 490 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0017
   Val:   Loss=0.0854, RMSE=0.2922, R²=0.0075
============================================================


📊 Round 490 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0008

📊 Round 490 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0008

============================================================
🔄 Round 493 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 493 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0027
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0038
============================================================


📊 Round 493 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0008

============================================================
🔄 Round 494 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0992 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0992, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0992, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0992, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0992, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0992, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0992)

============================================================
📊 Round 494 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=0.0007
   Val:   Loss=0.0992, RMSE=0.3150, R²=-0.0127
============================================================


📊 Round 494 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2606, R²: 0.0007

📊 Round 494 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0007

📊 Round 494 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0008

============================================================
🔄 Round 499 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 499 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0001
   Val:   Loss=0.0843, RMSE=0.2904, R²=0.0007
============================================================


📊 Round 499 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0007

📊 Round 499 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0007

📊 Round 499 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0008

============================================================
🔄 Round 503 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 503 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=-0.0013
   Val:   Loss=0.0842, RMSE=0.2901, R²=-0.0055
============================================================


📊 Round 503 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0008

============================================================
🔄 Round 504 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 504 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0013
   Val:   Loss=0.0824, RMSE=0.2871, R²=0.0029
============================================================


📊 Round 504 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0007

📊 Round 504 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0007

📊 Round 504 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0008

============================================================
🔄 Round 510 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0943 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0943, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0943, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0943, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0943, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0943, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0943)

============================================================
📊 Round 510 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0018
   Val:   Loss=0.0943, RMSE=0.3070, R²=-0.0092
============================================================


📊 Round 510 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0008

📊 Round 510 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0008

============================================================
🔄 Round 513 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 513 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0001
   Val:   Loss=0.0787, RMSE=0.2805, R²=-0.0014
============================================================


📊 Round 513 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0008

📊 Round 513 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0008

============================================================
🔄 Round 515 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 515 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0010
   Val:   Loss=0.0769, RMSE=0.2773, R²=0.0057
============================================================


============================================================
🔄 Round 516 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 516 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0015
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0254
============================================================


============================================================
🔄 Round 517 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 517 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=0.0013
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0044
============================================================


============================================================
🔄 Round 518 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 518 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0011
   Val:   Loss=0.0861, RMSE=0.2935, R²=-0.0103
============================================================


📊 Round 518 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0009

============================================================
🔄 Round 520 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 520 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0012
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0031
============================================================


📊 Round 520 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0009

📊 Round 520 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0009

============================================================
🔄 Round 524 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0722 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0722, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0722)

============================================================
📊 Round 524 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0012
   Val:   Loss=0.0722, RMSE=0.2686, R²=-0.0050
============================================================


📊 Round 524 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0010

============================================================
🔄 Round 528 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 528 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0022
   Val:   Loss=0.0807, RMSE=0.2840, R²=-0.0070
============================================================


============================================================
🔄 Round 531 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 531 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0037
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0308
============================================================


📊 Round 531 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2606, R²: 0.0007

============================================================
🔄 Round 532 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 532 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0009
   Val:   Loss=0.0785, RMSE=0.2801, R²=0.0049
============================================================


============================================================
🔄 Round 535 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 535 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0005
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0077
============================================================


============================================================
🔄 Round 536 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 536 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2810, R²=-0.0008
   Val:   Loss=0.0911, RMSE=0.3018, R²=0.0024
============================================================


📊 Round 536 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2606, R²: 0.0006

============================================================
🔄 Round 537 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 537 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0002
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0041
============================================================


============================================================
🔄 Round 538 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 538 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0002
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0009
============================================================


============================================================
🔄 Round 539 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 539 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0007
   Val:   Loss=0.0798, RMSE=0.2825, R²=0.0034
============================================================


📊 Round 539 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0009

============================================================
🔄 Round 541 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 541 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0010
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0147
============================================================


============================================================
🔄 Round 544 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 544 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0007
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0135
============================================================


============================================================
🔄 Round 545 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 545 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2813, R²=0.0031
   Val:   Loss=0.0902, RMSE=0.3003, R²=-0.0142
============================================================


📊 Round 545 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2606, R²: 0.0006

============================================================
🔄 Round 547 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 547 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=-0.0001
   Val:   Loss=0.0782, RMSE=0.2796, R²=0.0007
============================================================


📊 Round 547 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0008

============================================================
🔄 Round 549 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 549 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0001
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0120
============================================================


📊 Round 549 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0008

📊 Round 549 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0008

============================================================
🔄 Round 552 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 552 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0003
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0022
============================================================


📊 Round 552 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0009

============================================================
🔄 Round 554 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0714 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0714, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0714, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0714, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0714, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0714, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0714)

============================================================
📊 Round 554 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0002
   Val:   Loss=0.0714, RMSE=0.2672, R²=0.0009
============================================================


📊 Round 554 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0009

============================================================
🔄 Round 556 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 556 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0017
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0070
============================================================


📊 Round 556 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0009

📊 Round 556 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0008

============================================================
🔄 Round 560 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 560 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=-0.0023
   Val:   Loss=0.0847, RMSE=0.2909, R²=-0.0077
============================================================


📊 Round 560 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0008

============================================================
🔄 Round 561 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 561 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=0.0013
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0073
============================================================


📊 Round 561 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0009

📊 Round 561 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0008

============================================================
🔄 Round 564 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 564 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=-0.0022
   Val:   Loss=0.0873, RMSE=0.2954, R²=-0.0050
============================================================


============================================================
🔄 Round 565 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 565 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2870, R²=0.0013
   Val:   Loss=0.0773, RMSE=0.2781, R²=-0.0042
============================================================


📊 Round 565 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0008

============================================================
🔄 Round 567 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 567 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0016
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0061
============================================================


============================================================
🔄 Round 568 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 568 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0005
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0050
============================================================


📊 Round 568 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0010

============================================================
🔄 Round 569 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0922, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0922, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0923, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 569 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0019
   Val:   Loss=0.0921, RMSE=0.3035, R²=-0.0366
============================================================


📊 Round 569 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0008

============================================================
🔄 Round 570 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 570 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0029
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0352
============================================================


📊 Round 570 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0008

============================================================
🔄 Round 571 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 571 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2836, R²=0.0005
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0027
============================================================


============================================================
🔄 Round 572 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 572 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2819, R²=0.0005
   Val:   Loss=0.0889, RMSE=0.2982, R²=-0.0025
============================================================


============================================================
🔄 Round 573 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 573 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0017
   Val:   Loss=0.0735, RMSE=0.2711, R²=-0.0059
============================================================


============================================================
🔄 Round 574 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 574 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0006
   Val:   Loss=0.0786, RMSE=0.2804, R²=-0.0016
============================================================


📊 Round 574 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0009

📊 Round 574 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0007

============================================================
🔄 Round 576 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 576 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=0.0001
   Val:   Loss=0.0781, RMSE=0.2795, R²=-0.0010
============================================================


📊 Round 576 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0007

📊 Round 576 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0009

============================================================
🔄 Round 579 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 579 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0016
   Val:   Loss=0.0812, RMSE=0.2849, R²=-0.0072
============================================================


============================================================
🔄 Round 580 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 580 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0019
   Val:   Loss=0.0739, RMSE=0.2718, R²=-0.0077
============================================================


============================================================
🔄 Round 581 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 581 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0007
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0043
============================================================


📊 Round 581 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0009

============================================================
🔄 Round 582 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 582 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0051
   Val:   Loss=0.0743, RMSE=0.2726, R²=-0.0009
============================================================


============================================================
🔄 Round 583 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 583 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0003
   Val:   Loss=0.0890, RMSE=0.2983, R²=0.0004
============================================================


📊 Round 583 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0011

📊 Round 583 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0011

============================================================
🔄 Round 587 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 587 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0010
   Val:   Loss=0.0831, RMSE=0.2883, R²=0.0055
============================================================


📊 Round 587 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0011

📊 Round 587 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0011

============================================================
🔄 Round 590 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 590 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0036
   Val:   Loss=0.0788, RMSE=0.2807, R²=0.0029
============================================================


============================================================
🔄 Round 591 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 591 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0011
   Val:   Loss=0.0737, RMSE=0.2715, R²=-0.0080
============================================================


============================================================
🔄 Round 592 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 592 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=-0.0020
   Val:   Loss=0.0793, RMSE=0.2817, R²=-0.0046
============================================================


📊 Round 592 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0011

============================================================
🔄 Round 593 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 593 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0018
   Val:   Loss=0.0740, RMSE=0.2721, R²=-0.0193
============================================================


============================================================
🔄 Round 596 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 596 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0006
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0046
============================================================


📊 Round 596 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0011

📊 Round 596 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0011

📊 Round 596 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0012

📊 Round 596 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0010

============================================================
🔄 Round 601 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 601 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=-0.0002
   Val:   Loss=0.0810, RMSE=0.2845, R²=0.0022
============================================================


📊 Round 601 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0010

============================================================
🔄 Round 604 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 604 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0009
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0045
============================================================


============================================================
🔄 Round 605 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 605 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0022
   Val:   Loss=0.0752, RMSE=0.2742, R²=0.0100
============================================================


📊 Round 605 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0010

📊 Round 605 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0010

============================================================
🔄 Round 607 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 607 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0003
   Val:   Loss=0.0787, RMSE=0.2805, R²=-0.0019
============================================================


📊 Round 607 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0011

============================================================
🔄 Round 610 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 610 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0001
   Val:   Loss=0.0762, RMSE=0.2761, R²=-0.0238
============================================================


📊 Round 610 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0010

📊 Round 610 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0010

📊 Round 610 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0008

📊 Round 610 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0009

============================================================
🔄 Round 619 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 619 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0003
   Val:   Loss=0.0776, RMSE=0.2786, R²=-0.0005
============================================================


📊 Round 619 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0010

📊 Round 619 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0010

📊 Round 619 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0010

============================================================
🔄 Round 623 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 623 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0004
   Val:   Loss=0.0833, RMSE=0.2887, R²=-0.0097
============================================================


============================================================
🔄 Round 628 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 628 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0007
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0152
============================================================


============================================================
🔄 Round 630 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 630 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0009
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0079
============================================================


📊 Round 630 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0011

============================================================
🔄 Round 633 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0695 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0695, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0695, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0695, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0695, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0695, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0695)

============================================================
📊 Round 633 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0009
   Val:   Loss=0.0695, RMSE=0.2636, R²=0.0044
============================================================


📊 Round 633 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0010

============================================================
🔄 Round 634 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 634 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0008
   Val:   Loss=0.0879, RMSE=0.2964, R²=-0.0112
============================================================


============================================================
🔄 Round 635 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 635 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0019
   Val:   Loss=0.0828, RMSE=0.2877, R²=0.0024
============================================================


📊 Round 635 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0010

📊 Round 635 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0010

============================================================
🔄 Round 638 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 638 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0014
   Val:   Loss=0.0789, RMSE=0.2810, R²=0.0012
============================================================


============================================================
🔄 Round 639 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0678 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0679, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0679, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0679, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0679, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0679, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0678)

============================================================
📊 Round 639 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0019
   Val:   Loss=0.0678, RMSE=0.2605, R²=-0.0102
============================================================


============================================================
🔄 Round 642 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 642 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=-0.0000
   Val:   Loss=0.0872, RMSE=0.2952, R²=0.0010
============================================================


📊 Round 642 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0010

============================================================
🔄 Round 646 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 646 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0015
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0034
============================================================


📊 Round 646 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0010

============================================================
🔄 Round 649 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 649 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0004
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0210
============================================================


📊 Round 649 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0010

📊 Round 649 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0012

============================================================
🔄 Round 654 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 654 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0034
   Val:   Loss=0.0877, RMSE=0.2962, R²=-0.0107
============================================================


📊 Round 654 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0010

============================================================
🔄 Round 660 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 660 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0040
   Val:   Loss=0.0727, RMSE=0.2695, R²=-0.0145
============================================================


============================================================
🔄 Round 661 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 661 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0011
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0023
============================================================


============================================================
🔄 Round 662 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 662 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0018
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0092
============================================================


📊 Round 662 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0009

============================================================
🔄 Round 663 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 663 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0006
   Val:   Loss=0.0774, RMSE=0.2783, R²=-0.0015
============================================================


📊 Round 663 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0009

============================================================
🔄 Round 664 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 664 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0000
   Val:   Loss=0.0810, RMSE=0.2847, R²=-0.0051
============================================================


📊 Round 664 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0008

============================================================
🔄 Round 666 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 666 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0001
   Val:   Loss=0.0889, RMSE=0.2981, R²=-0.0091
============================================================


📊 Round 666 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0009

📊 Round 666 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0009

============================================================
🔄 Round 670 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 670 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0005
   Val:   Loss=0.0773, RMSE=0.2780, R²=-0.0057
============================================================


📊 Round 670 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0009

============================================================
🔄 Round 671 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 671 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0007
   Val:   Loss=0.0769, RMSE=0.2772, R²=-0.0034
============================================================


============================================================
🔄 Round 672 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0688 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0688, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0688, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0688, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0688, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0687, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0688)

============================================================
📊 Round 672 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0014
   Val:   Loss=0.0688, RMSE=0.2622, R²=-0.0063
============================================================


============================================================
🔄 Round 673 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 673 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=0.0006
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0013
============================================================


============================================================
🔄 Round 674 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 674 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=-0.0006
   Val:   Loss=0.0905, RMSE=0.3008, R²=-0.0119
============================================================


📊 Round 674 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0010

============================================================
🔄 Round 675 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 675 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0012
   Val:   Loss=0.0800, RMSE=0.2829, R²=0.0066
============================================================


============================================================
🔄 Round 677 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 677 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0015
   Val:   Loss=0.0798, RMSE=0.2824, R²=-0.0082
============================================================


📊 Round 677 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0010

============================================================
🔄 Round 678 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 678 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0007
   Val:   Loss=0.0778, RMSE=0.2789, R²=0.0048
============================================================


📊 Round 678 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0010

============================================================
🔄 Round 679 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 679 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0010
   Val:   Loss=0.0720, RMSE=0.2683, R²=0.0014
============================================================


📊 Round 679 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0011

📊 Round 679 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0011

============================================================
🔄 Round 681 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 681 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0002
   Val:   Loss=0.0876, RMSE=0.2959, R²=-0.0141
============================================================


📊 Round 681 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0011

============================================================
🔄 Round 682 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 682 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0004
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0002
============================================================


📊 Round 682 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0011

============================================================
🔄 Round 684 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 684 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0002
   Val:   Loss=0.0775, RMSE=0.2783, R²=-0.0032
============================================================


📊 Round 684 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0010

📊 Round 684 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0010

============================================================
🔄 Round 687 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 687 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0005
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0004
============================================================


============================================================
🔄 Round 688 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 688 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0004
   Val:   Loss=0.0767, RMSE=0.2770, R²=-0.0045
============================================================


============================================================
🔄 Round 689 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 689 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0017
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0055
============================================================


📊 Round 689 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0012

============================================================
🔄 Round 691 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0714 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0714, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0714, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0714, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0714, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0713, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0714)

============================================================
📊 Round 691 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0011
   Val:   Loss=0.0714, RMSE=0.2671, R²=-0.0024
============================================================


📊 Round 691 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0011

============================================================
🔄 Round 694 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 694 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0014
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0030
============================================================


============================================================
🔄 Round 697 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 697 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=-0.0030
   Val:   Loss=0.0899, RMSE=0.2999, R²=-0.0049
============================================================


📊 Round 697 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0009

============================================================
🔄 Round 698 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 698 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0001
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0011
============================================================


============================================================
🔄 Round 699 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 699 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0008
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0031
============================================================


============================================================
🔄 Round 700 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 700 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0009
   Val:   Loss=0.0858, RMSE=0.2930, R²=0.0003
============================================================


============================================================
🔄 Round 701 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 701 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0003
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0004
============================================================


📊 Round 701 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0009

============================================================
🔄 Round 702 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 702 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=0.0006
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0173
============================================================


============================================================
🔄 Round 703 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 703 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0005
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0055
============================================================


📊 Round 703 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0009

============================================================
🔄 Round 704 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 704 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0001
   Val:   Loss=0.0776, RMSE=0.2786, R²=0.0007
============================================================


============================================================
🔄 Round 705 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0942 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0942, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0942, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0942, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0942, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0941, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0942)

============================================================
📊 Round 705 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2796, R²=0.0003
   Val:   Loss=0.0942, RMSE=0.3069, R²=-0.0055
============================================================


============================================================
🔄 Round 707 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 707 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0017
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0145
============================================================


============================================================
🔄 Round 709 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 709 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0004
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0022
============================================================


============================================================
🔄 Round 710 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 710 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0014
   Val:   Loss=0.0800, RMSE=0.2829, R²=-0.0128
============================================================


============================================================
🔄 Round 711 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 711 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=-0.0014
   Val:   Loss=0.0899, RMSE=0.2999, R²=-0.0023
============================================================


📊 Round 711 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0008

============================================================
🔄 Round 712 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 712 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=0.0020
   Val:   Loss=0.0894, RMSE=0.2990, R²=-0.0086
============================================================


============================================================
🔄 Round 714 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 714 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=-0.0005
   Val:   Loss=0.0901, RMSE=0.3001, R²=-0.0033
============================================================


============================================================
🔄 Round 715 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 715 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0012
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0048
============================================================


============================================================
🔄 Round 719 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 719 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0004
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0009
============================================================


📊 Round 719 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0008

📊 Round 719 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0008

============================================================
🔄 Round 721 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 721 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0015
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0117
============================================================


============================================================
🔄 Round 722 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 722 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=-0.0017
   Val:   Loss=0.0905, RMSE=0.3009, R²=-0.0030
============================================================


============================================================
🔄 Round 723 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 723 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0002
   Val:   Loss=0.0727, RMSE=0.2696, R²=-0.0007
============================================================


📊 Round 723 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0009

📊 Round 723 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0009

============================================================
🔄 Round 725 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 725 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0018
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0067
============================================================


📊 Round 725 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0009

============================================================
🔄 Round 726 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 726 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0010
   Val:   Loss=0.0820, RMSE=0.2863, R²=-0.0025
============================================================


📊 Round 726 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0009

📊 Round 726 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0009

📊 Round 726 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0009

============================================================
🔄 Round 730 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 730 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=0.0006
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0076
============================================================


============================================================
🔄 Round 731 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 731 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0013
   Val:   Loss=0.0759, RMSE=0.2756, R²=-0.0284
============================================================


============================================================
🔄 Round 734 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 734 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0008
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0011
============================================================


📊 Round 734 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0012

📊 Round 734 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0010

============================================================
🔄 Round 738 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 738 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=0.0032
   Val:   Loss=0.0761, RMSE=0.2759, R²=-0.0292
============================================================


============================================================
🔄 Round 739 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 739 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0012
   Val:   Loss=0.0857, RMSE=0.2927, R²=0.0029
============================================================


============================================================
🔄 Round 740 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 740 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0029
   Val:   Loss=0.0727, RMSE=0.2697, R²=-0.0347
============================================================


📊 Round 740 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0011

============================================================
🔄 Round 741 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 741 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0019
   Val:   Loss=0.0826, RMSE=0.2873, R²=-0.0060
============================================================


📊 Round 741 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0011

============================================================
🔄 Round 744 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0725, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 744 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0001
   Val:   Loss=0.0726, RMSE=0.2694, R²=0.0026
============================================================


📊 Round 744 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0011

============================================================
🔄 Round 746 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 746 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0023
   Val:   Loss=0.0791, RMSE=0.2812, R²=0.0023
============================================================


📊 Round 746 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0012

============================================================
🔄 Round 750 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 750 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0019
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0148
============================================================


============================================================
🔄 Round 751 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 751 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0010
   Val:   Loss=0.0774, RMSE=0.2781, R²=-0.0287
============================================================


📊 Round 751 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0011

📊 Round 751 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0010

============================================================
🔄 Round 756 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0670 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0670, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0670, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0670, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0670, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0671, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0670)

============================================================
📊 Round 756 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0002
   Val:   Loss=0.0670, RMSE=0.2589, R²=-0.0021
============================================================


📊 Round 756 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0010

📊 Round 756 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0008

============================================================
🔄 Round 759 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 759 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0010
   Val:   Loss=0.0785, RMSE=0.2802, R²=-0.0036
============================================================


📊 Round 759 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2606, R²: 0.0007

============================================================
🔄 Round 764 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 764 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=-0.0006
   Val:   Loss=0.0879, RMSE=0.2965, R²=0.0007
============================================================


📊 Round 764 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0007

============================================================
🔄 Round 765 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 765 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=0.0011
   Val:   Loss=0.0846, RMSE=0.2908, R²=-0.0044
============================================================


📊 Round 765 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2606, R²: 0.0007

============================================================
🔄 Round 770 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 770 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0016
   Val:   Loss=0.0813, RMSE=0.2852, R²=-0.0085
============================================================


📊 Round 770 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0009

📊 Round 770 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0008

📊 Round 770 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0009

============================================================
🔄 Round 774 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 774 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0024
   Val:   Loss=0.0740, RMSE=0.2721, R²=-0.0094
============================================================


============================================================
🔄 Round 775 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 775 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=-0.0007
   Val:   Loss=0.0873, RMSE=0.2954, R²=-0.0087
============================================================


📊 Round 775 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0010

============================================================
🔄 Round 778 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 778 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0014
   Val:   Loss=0.0724, RMSE=0.2691, R²=0.0083
============================================================


📊 Round 778 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0011

📊 Round 778 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0011

============================================================
🔄 Round 780 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 780 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0010
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0063
============================================================


📊 Round 780 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2606, R²: 0.0011

============================================================
🔄 Round 781 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 781 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0011
   Val:   Loss=0.0812, RMSE=0.2849, R²=-0.0091
============================================================


============================================================
🔄 Round 782 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 782 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0000
   Val:   Loss=0.0867, RMSE=0.2945, R²=0.0020
============================================================


============================================================
🔄 Round 785 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 785 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0004
   Val:   Loss=0.0765, RMSE=0.2767, R²=0.0007
============================================================


❌ Client client_5 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8692 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8692 {grpc_message:"Socket closed", grpc_status:14}"
>
