[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52e5b7c3-9077-4839-b445-55deb4f982fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b1e79bf-a269-42e2-9dd7-37d810ba99ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef64d2e0-2d30-413a-a6f2-f1e49b2d8e07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f64dcf7d-7a20-42c9-87f9-758f77499f22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99afe041-d23c-42b0-9af2-fec95de336fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 345cefae-eb6a-4ef8-9a16-704eca32a38f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a47afaa-189d-4eab-91dc-11f8f78d60a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f9d839b-49f3-4e30-bb61-74ec9aded2eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3feb2371-ad5c-4dd8-8448-88a473e330ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06b85281-bebd-4b0d-bdc1-fcd436b00386
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5eb2cb9-78f1-40d9-a354-e83fa18062d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67872fb6-e762-4e41-9890-793a15dbcef9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c631eb9c-9343-4927-8322-246d0f5e3571
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db9de4de-0542-43bc-acfd-4bec17c94893
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73d79f09-a635-4120-9a8e-ad05773ff5fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7634604-1dec-46ca-88a8-934958a8b27d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef0e7bcb-a7b8-4f0b-bc77-ac764639084e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd28e54e-c377-478d-8b2e-0a50f73e998d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f5b0370-58fb-44ab-95d5-9f6b774ea96f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 542a41e7-d6f3-473f-ad25-39de50793074
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58f8f851-0164-4f79-bbcf-802de7f033a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f297912-1dc0-4fdc-aaf0-a5be379a6db5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message acf35d80-a54c-4939-932d-dd152314cd77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0b8c5c1-5dbc-4255-81e5-5039e6734269
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23e0eaaa-4131-4c2b-a988-9bf0d9401f6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22c872d8-59f8-41fb-a35e-6227d53a158a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec6fe7a4-898f-41ac-8675-a8a2f551c67e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b071351-e6e7-4e7d-98cb-2e068d13422c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61c0479b-5ab1-408f-8707-fc4dc5a37930
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f950fd87-033f-49bd-a83b-05999468ab6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5964512-81af-4f78-881c-1734933dae7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5332d19d-4968-44f3-aa66-8d1ad1058391
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67036271-d828-4752-9132-ffd5dda9c328
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2701670-e9ee-4fc8-a97a-8a56d491a9b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f15f883d-b6ed-4abf-b252-f1c8bf5cc34b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f22ed83-3006-48cd-97dd-0798e1abb8fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19937bff-ccb4-4e0c-9a19-6de3debcbddd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4ca7abf-a6dc-4f98-8fb0-5187732c96fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f6c98d4-4c90-4693-b83f-750da8aa02db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1fd0d47-1e66-4144-aaec-a5b6a3815177
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f759713-d2aa-4de5-9d4d-71cb7c055c2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bcc5cea2-1816-4841-9496-a9671d2ca3ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f029ce0e-db39-4c82-b9d4-03febb91b997
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dca52709-1bd3-4cd5-b379-2b457c8fc51a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7416263f-a839-4cea-9884-2a0e3ddcff51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d581fe3b-d62e-474a-9a42-149b98635308
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09048875-ba17-435e-90fa-c9fd7a9b7523
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85011422-1367-460d-aca4-28bd3aba81b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 918fc0a4-044d-4312-9c58-2ce8c1083da6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e42b953f-ae60-481f-8b1a-4dd06f452fbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e530e18d-ec52-4970-85be-10092b679b28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 032db81b-8168-4f63-a5e4-9c37fb0e7e4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29deb36a-9335-4b29-a528-1b8510f80cc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9166ed8-2f01-4435-8eb4-af61ff635424
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb5ff030-3b34-43d6-98fd-a7bd56b3b218
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 109d7257-4f41-472d-aca2-46fa6b087666
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bbed30f0-5e3b-4c0c-b78a-ff48d4f65b20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 975ed4e8-b578-4673-8afc-17c435c93b35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3531d396-3425-4e27-80ef-b9d6e80014a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16770102-8fa6-4223-bba8-8f1f0bedc60c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5997c8f0-baf9-4eec-9010-e20d5c836d33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ecb2a83-e052-4b97-afec-272e89c2cea6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f20cecbe-a0ca-45c9-b493-e6871f182d55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89a247b8-baeb-4374-8c79-e0230808ba0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c729b87d-751e-4a12-a8af-bd8a3303cfaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48765e0c-8806-47e1-ba0d-d9c03b1c802e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b602b57-65a4-4f4b-8dc9-06381e714ffa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61a19c65-748c-4bea-a764-9ffcc21c8ef5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8038d9cf-ccd8-4295-8e4c-1a89d7126ec5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21258e66-8732-41c2-8dcf-4edbfd750973
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 564b55a0-84de-4f5c-a571-f07c8a13070d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac6856e0-92b5-4aa2-a68b-6c0dd8cb74bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b201677-a56d-4b53-9e3b-48f37b6e5451
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5328399-6323-4b0f-abde-ea506ce1612e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b347b206-a9d7-4e70-b0a7-c8893edb07d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9bee2092-8004-45f8-8b1e-9ad401d8b998
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cecfb5d2-0dee-4e5d-b2db-228b66049629
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f36852e7-f6a5-43a3-9ce4-08cac8154436
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5561b08-cc42-4d3e-82a6-38743d29fbd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 089a374f-db51-4cdd-a32d-40d938e7fd6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d75b33c6-a6d1-4edb-9526-c714761c255a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb8959ce-9656-49fc-9aee-4fc19227ec1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a87a9a9f-d1f3-47a6-821a-ffbeedd6ecae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 342a8515-3c47-4a59-9c2a-f2f8b502a33d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81e61e7b-13e9-4550-abdb-0efb1721c2f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e94cac3-966c-47da-9e7c-6de653277503
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60a55a85-9b11-4843-84d7-a462bbdf5114
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80808bcc-e1f2-4dc7-8d92-b7b19bc45df6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4aa34fa1-05d7-419d-b23c-86877d14f4d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b309d5f5-4e75-4222-a87e-6f302db58508
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4a8d230-eb47-4885-bd98-e1b816f91c56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 290ec144-23e6-4199-a465-75bd7491170e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0e53489-833b-4a68-b3df-f5aaba4799e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac2e43bc-cf98-4dc9-b0f2-7e63857de33b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d559afeb-2d13-455e-addf-3fe99acf8a91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9bacccd-c73e-43e9-b8da-0107b6654005
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4df7d144-36d4-4e9b-9c98-0300d1f6414b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7fd1766b-1fd6-42be-84f0-4ff2d03f3140
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c726b8c-f2b9-4a30-98ed-d6b70f0689e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c64ea096-3fe4-44ea-bb50-c133d567fdb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e85ba660-fae0-4635-bc6a-56559314f210
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ce74fdc-e54a-4e92-bf32-fc70e9230b5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ed1165d-1d28-4eff-90ca-e0f755b78b20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88ce90a9-a9bb-4be9-a6f9-357aff6f2ec6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1fd802ad-1c51-4316-a7a0-7f2db1932288
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 550a2920-3df1-447f-a4c9-402f3d775ef8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c163e01-59ff-4c1f-aaf0-02ff15c9514f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3847e2f-c902-477c-a153-7c561fcf509d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8716ef8b-0ae1-4fde-a4de-6926fb790dfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e7fcfc9-2bc7-473e-afe2-05b47b0c4162
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7ce1eb4-ac5c-45ae-840e-8dd18479984e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b3fe77b-80bc-4be5-b9ff-ebf56d32e9f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 708f316c-cdd1-4e64-9def-da6c27c7bb26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d34cc622-bf84-4753-951a-4b59c9130752
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b611d9ac-a471-4035-820c-01b42df8378c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c50cc6b-b8a7-4d92-a804-c678058ca01a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83b289f5-02c0-4c09-ad2d-e5947f5ea466
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce398a3a-40c7-414d-a94c-be8e08b49579
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64b8d9a6-8366-4a65-946f-74b8b7fb1241
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 426dc20e-d377-4b49-a930-8b0a2ff54c03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9944d90-ea63-46ee-b3cb-c193cba620f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cfd6fa18-ec63-4390-8908-7d192adfa33c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3c1b0af-dcf4-4a7e-ae4f-ad805ebb27f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22b0f79a-64b7-4bac-b920-7da74484a0ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54e90853-b5d9-4ed1-8ded-6ae5600729f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 570ab7bf-2027-4e26-8633-4a7d36880bae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d565bbb-abf3-45ca-8280-83f5ec78159a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce43f2d9-61da-4b35-8e8a-373cf51e1b7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15b3def2-3bb3-45dd-81c0-688f5415dd1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2535c19b-9834-40fe-8119-7ac5bfc6f3f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8981fa2a-fce1-41e3-a397-b6173603a679
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fab01080-e3fe-4696-86f9-d82771f63669
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d4b2696-ddbc-40f9-9127-0872bddba6a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 145f52b4-b415-42f6-a998-c7ebc8e5d146
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4eabdb12-072c-47f1-9664-0c49c146b850
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0c0de72-5d74-4017-9502-6da74ed7d650
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e3af3f6-de96-45af-ac64-c35914ee3fb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47c7f285-1497-4272-a655-334a9d8e03ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7dd79c23-49c7-4f71-b53f-f37d3a7037c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84fe6740-d39e-4d29-b203-ce6748e27ca9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7aad0fa1-98d5-40d9-82c6-b7a7b62027af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bac2faeb-8957-4ceb-aab7-e9c5d66f07eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce80b1ee-9f67-4f04-bb8a-e50beb82d5b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e855df8-7469-4058-9faa-97fe95df2dfc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd268631-b3a4-4300-bbff-e16f06406c8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae821175-3778-48c5-ad40-799928a3a592
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2389cfa-5a65-46b9-a642-122977165236
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1cb27d3-796e-4106-b721-11c92f78cd94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c786fd2d-9316-4959-be77-3791599678c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bfc9f82f-1d4f-4e6e-8af2-e5125d72eba9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8c3948d-56ff-4539-82ce-0abd16abf00a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16e402ab-de30-4991-880c-b926d6a48311
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc93a0a2-32e7-46f1-ae77-33f96f3acbe7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 575be00d-125b-4bb2-9d90-a02244143f64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 825692f7-2b00-4be3-9d48-e00c6442503f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d696789-a98a-4bf8-bbb7-abaf2edde073
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65f95b50-aef5-48ff-b43e-ec7aac1a9f11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7c6c53d-a77e-4ec6-93d0-0e7902535780
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fbb17785-4812-442a-a7f2-e715049c798f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f482f111-00c2-40a2-af49-40c016488c86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a277ee49-3f45-44ea-9af8-1a91ec444021
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7e0eac1-669e-457f-b850-dbad668eb796
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30d15d86-ca1a-4c0d-9138-d3a354edda4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83576625-fad6-4e6f-88ba-9dfbdbe8a258
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1fb8d37f-4cfa-402a-9d7b-6a7017a3f2f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ef441fc-5248-4e7e-8da5-5e4f99a09383
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 898d27c1-5a2a-44f3-b90b-5c0b1c884866
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab6c2599-a599-4611-a56b-eaeab040ef3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e4aee98-2d83-4bfa-93ad-4cb7519c4531
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a02f6779-86fc-4319-9978-c23b8df0cf3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7997ee06-c87b-4970-899d-fac1866cc261
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75a53cbd-d088-4620-b8e9-2645365e862d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1691e3ae-f95f-4c47-80ad-f9e2ccbb629b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6be46b12-6250-4472-82e7-2675838f8c28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39d77bda-9fd1-4c5f-9637-186962075bf4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54982caf-2329-4c04-8785-f2e2443f0f97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50b35eff-dfca-49d5-b1e3-7d7b45b1b379
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a23533b-fa21-4a87-912d-e0ed9bce996c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e32ea24-00dc-40d5-9fc0-1cf90a522bb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2220b1de-a9cf-4be4-a691-5e95b575dc1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b93598e3-4dcb-4029-bc0d-28b83a54a23b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 507a1ec4-0377-4ad6-b00f-7ef2cdc96578
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd0ce3b4-7ea3-4755-b1af-fb32e109f253
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e46002e-974d-482f-8ca1-b93d0d8c911c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a237d67-241a-4e5d-b1c7-9f10cd7d2522
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b18f3dc5-9601-41b7-aa28-b7e8065603cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc7a38e1-d908-43cc-9494-16f042ab7eb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5f13fc7-f240-4eaf-ac8b-625b4dcb7e13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83ef02ba-8de8-4106-bc1d-988711df3f02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c9c0a17-fd6c-431c-99dc-902ec6ed03ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fca5f666-290e-4d4b-a6b8-555143becca5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58c768ea-22a2-44a9-a0d8-51e347dc4a9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3330c093-03dd-44a9-86b9-6f9c8881b77c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36e7a26f-dd11-4eb2-bb4c-082db2cb8346
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7580de1-76e0-4471-86ef-f1861b8e853a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d40c7a1c-6ef8-4444-9f1c-192b60d71ae6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4797bc55-dde6-46f0-8057-3b07012bf9a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31cdc3bd-dea7-40a9-88e5-5387b8ac9709
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9c2df41-698d-4b75-a6a7-99b8aee20c68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 493d1032-0733-4b1c-af66-ccfc81535961
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57c64bf5-2280-4380-9a4b-41ccdef284c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3cebaecb-5775-4285-bee1-2fc866bf2a7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4ee0d07-9537-4de6-88f0-d62f57be6db4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a421b18a-ad8e-4669-b67a-56728fa38e1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50f8baaa-88eb-4f84-adad-c2a0ace9a515
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1592a980-ae4c-4f08-9329-47f7578499f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93c16d3a-4668-4567-8c24-d537187bbcda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39e10125-4cda-48db-bf72-420537907c7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cadfda72-3804-461b-8d3c-28192cf52530
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 212e8b6d-5a66-433b-bed5-d9a395bda63f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96f8264a-8a1a-4a92-ab14-7a04dc9d86e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82acf697-b269-4d11-ba86-bce2c2ed0635
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0d31cc1-a0aa-4075-8e03-78f9a127ec50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7814c4c8-f78a-4194-82d8-dc5d5ddb227b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b198235-e3d9-45bd-bcbf-18193d7c165f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c184d25-a92a-4743-9cfb-e3c9f7251e35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message efa15da0-dfeb-479e-8d68-358450a29b63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a1c2e19-3ce6-4332-bd00-c0debcf341dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8ae5323-f824-416c-93a2-ecb6e095e3a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0890c060-77a8-4598-aec8-00d8810b0694
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5f166e3-d7c4-40c5-b9dd-8f9253d67f71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86a4d897-3859-4f55-bf7e-dbec1819211e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ac72974-d871-4036-8795-f4cb01a36da8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6c922ab-97e3-400f-a8ba-a6cee1be75af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 051bdc32-63ab-4d03-9579-dece0648b4a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9068602b-471b-4a55-9a77-64f681639744
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4961983-ece6-4006-a852-787f47c57857
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fcdfdebb-40a6-48e9-9f15-c06a8cc65fa2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 280828a2-8faf-4da8-bc4f-3b8cc747936d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cfbf401f-ee86-4bce-9b97-287640c1c780
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22a979e1-c1f9-4085-8769-4c8e8cf071d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a40842fd-47f2-4fc0-8857-23fe57d55bc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd070084-2bac-4047-9101-0dc582700801
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9139c84-357e-41ce-b092-ff0b68d72ae3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d22b3770-9405-4c5c-a2e7-4e28eeefa4a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5980ebbc-000f-456a-a6e7-6fbf0d6b232d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd3833cb-3486-4210-a3f0-37e86d3458e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7001f226-5450-420b-b36e-0c122dfd9ed4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 523c90d3-2adc-4212-8c8c-e67e3160e769
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50d7f620-0fcd-4711-87c2-15468d6d7144
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 925fc675-797d-48f6-9f9a-79d6b79de6ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6e4766f-c2c1-4b7e-9a62-9ed116063cdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 764d017c-4f1e-4a4c-931b-b694dc692567
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce95e353-6bd1-4b24-9b7c-6cb78a7d0a44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09b99960-0b4d-480e-b207-613f2d0f2a8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75a3931a-25df-4cff-8c0b-dd668beb4a2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 238fd0ca-0226-4e54-96a7-14d64495f2f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65b50b69-f0e3-44cb-8273-d77991ceb1d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 263eb865-127e-4103-a3fc-7d44911a1596
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1759a25a-4e88-44b2-9d8d-35fb48a33f5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 772cf8f0-5afc-4b64-a986-bbd3e1adfb2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3a0a1e9-6a7d-4c0e-afbe-51becab939d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6fb809f-47e4-4875-8cb1-831a6d9f0409
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e15a0c2d-4d41-4dd2-ac9b-f7f6fe135860
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3cdabca-bf0d-4b97-a38a-08d70db2b769
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2507cc20-3725-4e85-9f77-3597817ac297
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5887e998-a4c2-49a7-a994-5b8dc45b10f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2278532c-eed8-43f1-89a2-ed360379a2c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ccf47a7-08f5-4b81-8e66-983c6da742ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ae005f6-e576-4492-8964-53901ccb6f7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68a91045-b910-4488-8cc5-de3618575712
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a97dc650-5384-42cd-85a2-a3e12549983d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f4c323e-5da5-4c51-8901-b14f484e77de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67fe5dd2-ded3-4d96-b90b-9e3ca946985c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55491582-0f94-4a6a-a6e9-24030b6059aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5fbca894-ee8c-40a3-84b9-e36c96af3326
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9137176-2070-45a2-941d-bffb83f87380
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15363f2e-b13e-41a1-8f61-2916c2e3f328
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10dabc3f-30f8-4a60-b31d-2997c4d460c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d804dd0-7db8-43e9-bef0-2b2f6f4e13b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3f11c9b-1f8a-4b61-bd94-d41ea7d83c97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4350ea4c-d03c-4a97-8427-18ca75e1a9c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02eb830c-0bdb-435d-816c-b702ed646f3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d23a107-5729-4acb-8752-f866cf21db6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74437b6e-2108-47e0-9a83-0db05062817a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41683d72-d879-4cb5-a971-b4456a779c98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ee5a053-91cb-44fe-8036-37519268b25e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc250d4e-0b78-4825-b4e7-31f6523187fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3cc8bcd5-9e63-4e31-ad40-ac0cb69dded0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ea5163a-da54-4e38-9897-7a3e2f192253
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0158ded-6a6b-492f-aca1-fce94ffbb52c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d630e82-12e5-4b74-9b9e-2f442c1eb4aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a780321c-2e82-47aa-b498-a858fb96e9fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 531adc14-ff0d-4260-9da2-640474510d5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2689c310-36fb-4bb5-ac62-fb6461f323c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91d85a66-b942-49d2-b87f-d2e93b6c6a40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81bc6173-4ffa-4928-940b-ff68717c5d77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d31a3ba-15ca-4ff4-86b6-b5b9666c32c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70019f29-b2d3-4645-9c36-f16b8c3b6277
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab65f610-c9f4-474e-9ff1-e3965a1bb9f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1ff7d6f-2e3d-4266-8cd2-6417eb4a1bc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b342e55-7ec7-4877-8ca1-f127f7c38dd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef6be96b-1833-4c45-b274-926d5d4b55b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d77f380a-0206-4d99-9bf3-800983e3c899
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5a8c059-b541-48ed-99c0-a31376e55316
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 988e0fca-0ee5-4e02-8764-c83c13c5e188
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ddc8ad14-3917-4f39-a327-c2d2f56d00d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa84e57e-f67d-4b40-9945-e988a1acfe3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ea4182c-a19d-40bd-b7fc-f9d9762c4671
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1fe3ff3b-73a2-4129-ba42-153caaa736f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cff1c5dc-2354-48d8-8be7-abbf5ae796dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f118b69-4d11-4347-8322-955c5952fb72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8fea0e0-5d1e-4942-9afd-05bff2b76ba5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac4bd770-8b73-450b-a84d-16008c43290b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df82086b-095e-47f2-bd8d-669429162c7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d51a77d-7958-4f7d-a97e-54cd78b91cc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34a72e65-45c1-4972-955d-550bc9d7a907
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e35e25a-dc1d-4be7-bd09-c4b28bef288d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4bfd6461-69c4-42b9-94fc-035ad1b4baa4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4bf18d00-384e-4e5a-8af0-2a3ef5af1027
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4607eaab-ac66-48ba-b8c7-801747850f92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e838cd69-9f7d-4d1f-8080-dd0835032e51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dbe0c14a-5d1a-4c6e-ab56-3f16bb02238d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8976a912-59da-453f-8183-d97372d4040b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb7ba8c8-d184-4423-8349-0b679a9a1359
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f9ca87f-b19e-429e-bdd1-fdf0394cbd1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c9bffd9-0de8-4623-8368-5ad197526096
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f4dbb62-50b9-411a-a08f-40a9c2ebd29f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a347f1e2-2823-45a5-a7cb-d38ec49a11fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f98f25cd-7e66-4a5b-b5f0-69045b201bd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69f236b9-b103-4dbd-ae35-a0a2c5acfabc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c197658-631b-4ad1-980e-83d08a95e17e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eafccbcd-77a2-4ef0-a8e8-17d251427143
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e954f586-b1d3-4a16-830a-1b6e4d691cf7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc8940bf-3b2f-401f-8628-bbb5d0c11ec2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message acb90763-188d-4bf6-a69f-2e5382547617
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9af442e5-d70a-4dd9-ad7f-c08876522eb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 968cd6b5-f151-418f-9e28-a93f4b234944
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41783baa-3ac7-4f6a-9160-0b1080f60690
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97c329a5-62ec-4cbf-ac76-ac8aa9683328
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5cf90722-570a-4723-a56f-a88f2504369a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c5b8183-3a22-488f-beac-a2ed4eafe8b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97372aa0-95a8-490d-bfc2-ecef925b590b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc92150e-7b9e-4ea5-84e7-de2fb3c99474
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2df5f83-9d71-49d6-8715-3df594899d65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9034023a-fc31-48c5-a606-2c699d5bf2d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7939cfba-77ef-4591-b167-d329fbe4ade0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb08d47b-191d-4a65-92f9-97451c5ef551
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5280f8f-d84a-41c2-8368-6449aa92c9be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73ca042f-5cd0-40ae-a11c-92d8acbcfdfe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message afe403fa-1faf-4abb-8c4a-6741304e0076
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12a8245a-d577-4ded-9adc-4426f6c18755
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a081f55-bc1a-4e3e-9db1-2d297a10afd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b121195b-b4f8-40d7-a1e4-0a0f2ba06611
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fca807d6-ef71-4750-a268-65429db4041e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7cbf45f0-41d1-4ca6-a920-889fb5e986bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dcaefc2e-4ce5-42df-b5d6-8441291d3308
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d4d4a09-a1c5-4212-9471-edeaceb7baba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1483cb1-5577-4a86-b6b7-706369c4dae7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d3b08c7-776d-440c-a11c-0fc4563bfbf7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 610fa1f9-8381-4969-a765-24f30ce4846e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message afce8a4d-e6cf-4aa6-a2a3-f4565b537487
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6920b7f8-546e-4bbb-b4a8-b0a792bdb412
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b84418f8-f09b-4c35-90ae-68745c55e393
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7f36eb5-7622-4f26-89b6-318002b2433a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c84fe39-af94-4012-8d42-5f716210a527
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ddcfc135-e551-4d0b-bed5-9f10c11d1c5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e24e2fe-988c-40db-b61c-c2acdef1c0e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48c469be-9db5-47c3-963e-bc79eac98455
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ddd9179-cd28-4140-90dd-6ab2c60a10a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81ef3560-8db4-4818-847d-55f5eb776a2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6570df57-f9ec-4199-aeba-01824b6b9722
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec777bb3-b9b5-4873-9258-69297a4997b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ec34954-0531-471d-b15e-d25ebb4723cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f8e4ba7-7620-4bce-b34d-3d11480d176f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1c9e415-e11a-44d8-a38c-2759ec5dc38e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4dde1180-cf8b-4b54-9825-cd383a5de40f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e01483e1-12d3-4689-967a-c5a1784c3cee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bbe019cd-569f-4815-8615-c25ae3b3c74b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2eacc0d7-87c3-436d-a4e2-6c62c41ece73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e64e4827-3aba-4eee-a9dd-43dc610735bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7a10d70-59cb-4ab6-b015-54a3ba2ef955
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26817dad-6155-42ea-8437-15c2f114608d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ce334ab-c22a-48ed-bb12-899bae9e4afc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8bd88e7c-3b76-42ae-bf92-b0cd544b8fed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2f72bb7-79f8-4beb-a517-a4329e539628
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba645e03-fc96-4a3e-aaac-6506cda0bb17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31e8ae2c-0c05-4c21-ae26-5ca09b855325
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 733b1cea-09a3-4677-b3b9-439e4f515f24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d5bbbeb-2463-4623-9818-5f3ba9b92264
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5363d40c-1480-4eaf-ba0a-36fa3bd884bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 868c59c4-1774-4220-a72c-12406636dec4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9bb51a4-30e3-484b-93c0-de2a1ef9c54e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50d3e677-6034-4e1b-aedf-8e230328b325
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d028bbf-8c98-4987-8a39-97313a6659da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84b62d14-8ad7-4980-924d-666e7b9b65ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e23527b-35f6-48f0-912d-43369bcb5542
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message caeb6c77-4cae-4180-a7e1-5304c045e64a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 326c845a-3c3b-49fc-8d4f-58d07286ebde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0992862-02cd-42bc-8c64-1f4fcff2c63e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee617fd0-e793-46a5-ba5d-68df372987bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6a66640-4e20-4704-b2e6-655d05e57d85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b059602-55db-4372-8731-7aac66859daa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d58d7203-f933-470b-8582-9988a9c75028
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c19357d3-09f6-4dec-ac72-806e4708bfaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42224b0d-9dc4-4bdb-b048-5641ae82cc26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8cc4dfd0-6f9c-4222-9d14-08afeeadd709
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94c9857d-0f05-493b-9ecb-06b34014351e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a0f8d7c-577b-4608-926e-9cd7e25b64c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33c615c2-da19-43ea-843e-67315152b412
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06ff649b-66a5-4f1d-872d-a14388848441
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cac3a8ed-1cad-4e17-b355-b2b3480d1c6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2fc08b5-0a94-4e4e-b66a-b5c7b3f1baa5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eafe874f-73ba-42ec-889d-d08217807691
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12f880f6-d9ad-4d03-9162-0430977ff168
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9cb66298-f1f6-4d01-8d84-9d7ed462f8d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01feeb2d-2ad4-4687-ae4d-5054680407c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c43d6fde-1122-4803-9008-b969a6f3ff04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e7bb06b-f9e4-4c7a-ba38-443644582f80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4abb06b-4021-41d2-b7e6-08dc89d98ec9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa073e9d-56e3-4d90-92fc-e66b4757a121
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba240247-6318-4f9c-848f-69265af04d1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7190cf1d-78e9-4ac9-8449-3e74c9c78605
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ebb929f-aa08-4677-8775-9a4942451c46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18eef7f8-a956-4800-a192-01876d9117a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da724f7a-7731-496b-8ccf-27cc59d04940
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6cbd1fd9-7277-4dde-8d4c-b7d4e6433309
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e9192c2-915a-410e-83cc-0a92b36bf299
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d07f3911-e24f-44b2-b188-3581fa96d8db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e777cdb-6b11-4147-bf1c-90216f435ed6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89d25182-81fa-4987-844a-2227dc963909
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e675f87d-e4bc-43d9-83d8-6a8597ec833b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ef8fd6a-4cb0-4dc6-acb6-4f7d48102f0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d28c251a-9851-4608-ad2f-a888e6795144
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0c9a5b1-9acf-452f-8d99-10d6eb9eab2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 777fb5c8-ecff-4549-a8fd-ca4f07d585f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2306e702-6dd2-425b-9d84-eef2e57c90ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cba71bf3-bc75-40f0-8a82-7327880cc2ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82cf9df2-2fd0-465b-b7b7-08c4acf37030
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72623c01-0224-4464-adc1-cc713c1b67b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37d5cac3-546b-4ad1-ad05-31012b8765ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b41285a-3316-4e27-bc89-9b2bd881a5f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b17f942-a0ac-4292-8f61-3665413efe83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef2d8963-5316-4ceb-aef0-d770ea167847
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b2f7591-df33-4bc3-86e9-f7d62b529682
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35f338f1-f041-446e-adef-ff69ca494bdd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d89c5c62-e048-4f90-a489-4fadd8cee06e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0c17ec5-6fc4-4f02-90cc-555c992e6a1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b51771f5-40a7-4440-8f7f-b2349c81fd88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d31dfab-bccc-4764-b67f-ea6a2befcc56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4455ae9-5d58-4345-aead-9ee60b8ff706
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9118e8c1-0d49-4ffa-b3f7-7f376fc98fc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab820f63-85f6-473c-8cc9-049119ec2416
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea3534a3-b5f5-41a0-b742-e50a51a3381e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cab1fa71-3148-45d9-b341-cf1729e51079
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58cb6510-21b8-4c53-aa5f-2a45bd77d585
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d5b743a-d809-42cc-969a-4bcdc24c05d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3be78797-4882-4356-abe9-204cd65c32ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7458dee0-7003-480f-b993-d57de4f68930
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a53d6b1-5379-493a-a2a0-830b688d3298
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67185a03-c4ed-46e2-b29f-081afb5f19f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 337fafb4-58cb-4564-9ed5-86b4a6b213e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f6430b0-1de2-417f-af06-12a3e5590837
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2246e86-f091-495c-b93e-8a0c7fc08599
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b50c15f1-89d0-4385-84f1-26e7de172f17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7304d823-fc3b-4718-8394-e95df4100d12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5fb023b8-20af-4385-af01-a47a53c4a11d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f59b9f69-f7d7-4f0f-9edf-d6ec17efc487
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ced86c71-1a48-4704-a4ae-350a49ece362
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb3c9037-11ec-4e5f-8ff1-64bc62d53cbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c50e583d-2247-4933-87d3-bb351ef12a4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f84e1e98-31e2-44ba-a711-f3a70667336a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fbfd6352-1362-4745-9a12-246842f4f0e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae3321ed-e45f-4225-938c-623e1e6c8825
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb849f1d-82c5-4a67-8c8b-bc6bd6427d32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a21faf7-a5ac-456d-89bf-414c5157e0e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19a8d481-38d1-4a36-8af6-14a18aa21b7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2bf1a5e8-3efc-4885-97aa-e3c23a105ec4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d315644a-b630-4e41-8a28-e945a147c86f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8c3bfa4-de55-4d6d-adcc-2a081ad3ffd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43e4d4e9-022b-48a1-953f-c73ecc153fe9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a88a896-e630-42f2-91fb-95cd800d9bf2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f63c88b-3408-4741-975f-2fbf6f94e49d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1cd1c78-c877-4e33-b9c6-01ab2d8477d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2aa74de-dac3-438c-ac7f-40e18b868516
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7bc3f574-defb-40ad-aa7a-7d40dda54c84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81a460b1-e4b7-488e-8edf-b839dcc06647
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ad63bb4-9107-44f5-8c1c-8ae3967ec30b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6974ebc6-b464-458a-96f1-a1bb27e0adda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4136158-db7d-4f05-a02c-bc7ce9f3312a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5fdde0e4-10bf-4389-97b6-2abc45399edc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c98612ce-c2e3-407d-a26c-6d5f431268ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe7b65a5-da84-4659-b7f8-27b3f5e955b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4de5b113-beaa-43fc-a9e3-6775c429c1da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 138919bc-492a-41fc-a18b-70f503db89a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14c9488c-e934-4173-8f68-9ea0dda9c39e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eabff09e-101c-47ad-a67e-2b72f378e124
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5359bba-b761-4b0f-b9e6-2efe60656ead
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e48b1d00-116b-42a9-9f5f-b139c354fe6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 054c4d5e-7108-4bb9-912a-55394f3136a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ccb596d9-19f5-4f39-bf2d-13785ba839ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f565c61-0420-4e07-aca2-389e59374018
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a5bf4c5-76a4-40e4-92c0-24ab7ea828a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5c9efaf-4736-4c76-9b05-f2804a9cb74a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9aec0bca-4fcf-4c8d-9893-6e92383c7e91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3e102dd-3233-4822-b464-805affb5c985
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36d04d06-17f3-42d8-a96e-90db7eeb221c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82b95bf7-cca9-4703-9cda-9f006c69157c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be2d5082-1b46-4a8c-b681-d8b0edb2cb92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ea85450-5dfb-4676-8ef1-2c3ad0ab2f17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43047316-b83c-4caa-b1d8-fda21e68663e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8582b3f5-4ee8-4da0-ac9d-35579b093ed2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dec44313-b091-44c1-8821-ac3af03eb40d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c4cf509-9b97-4acb-9a2a-335ef95573fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message badb3835-c282-4990-baf4-41de634202f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1eaa051d-79d2-4acb-a5ed-6f9aebe10ae3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dce258d9-2886-495a-9ed0-177fc519ecdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd42beb3-0176-4930-bd92-3d56b830fbf9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49eed8c7-8e49-427c-8d27-bc67c1bc0769
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56873ad7-da33-4220-bb8e-7640e215aacc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ca4a84a-cdfd-4008-892e-c470b77bfd5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec73f4be-bef2-4cd0-aedb-19ef9a75d8bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4436c45b-3208-4251-8f26-e43fd09dc7dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1f9f3ad-a59c-4773-9d3e-75c08175e02b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a416ca8-aa21-472c-a1f1-fee1b125cf9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67da1715-2037-4428-b249-0874584948d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c06c37f-6cbc-4501-bf0d-5e1c68420b74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0489234d-fab4-4b64-a7db-dc4ed9d7bb0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6694ec1-00f3-4be0-8852-a3b463e4aea6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df89c7bd-b6c2-4117-b206-8b1afe7d7dd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c00caee6-13b5-4bfb-b566-2f2f33cba9d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc2c809e-c51e-4522-bb1f-1840c5271faf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77ad7464-f8eb-4bb0-b38d-3195f698851c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 642c1ba1-a3e5-4011-aa73-3b9f2725eb44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8dbf3763-cd9b-44e0-a59a-95e160848ab0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df29b999-32e7-4cdc-bdb3-f529a6dd0ca2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8042eacd-51fc-426f-b5ff-7489ef1975f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9ff7eb3-b11f-4b72-8ded-9b5c64ab53bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8df50407-fd17-4a1f-af2c-d1be60bd0425
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91b39c86-1bb9-4228-865a-4461a7412a6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c657405a-529b-4ec3-be89-b8f9cd77c457
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9e700de-277a-426c-9a90-838badfb44c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b1cf78c-83d6-4d37-9e12-3a3ebb781e07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3b4c923-8920-4964-9d7a-22756be0cd7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a193cc08-7b78-41c1-a4d8-6390579a6be8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f968377-5457-4d8a-94bb-66aa8dada58a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00ff1431-14b8-480b-8f31-f4b94c3a5698
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 129b6444-05a1-4e72-a859-177995527f7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e128b0cb-9485-46e8-a28a-eb814e23225c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c7ad913-d52f-4826-8a0e-8edaf7e8e617
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1013afa0-6d5d-4187-ba4e-5b41583b76b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 524ad20a-feab-4bb9-83f6-5f6b91123897
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6dcafbf5-0cd5-4294-b80e-dd860046bfe2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89ac755f-4d41-420b-ba84-89e7b02dc78a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79c9dada-5eec-4094-bd7b-9b676fd1be02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7cd89df9-f420-4b92-9b15-6af777c4465e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0004d65-0a7f-4ba8-8a18-50f5edb850c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e41db906-eb02-42b9-8b4f-bb250db663a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8370831f-5218-45b1-baaa-07abb455bcf0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4c93171-cb43-439a-82b1-877802566b46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dff1bee5-70a9-488a-b9f6-b37bf5df6153
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 740b40bf-6011-46e4-af24-3161c9740f64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0e33e07-9149-4570-8026-233d6f2fd661
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8de3a80e-9d6c-496d-a578-d7a081d5e2be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 523c7eb1-6099-4444-9c5b-b73aa033bc57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a4daaae-14dc-4aa2-9095-7efb34b6f40d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65ab6391-0e6f-4cac-a2fb-dbe5284ce2d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f982a7f-3127-4911-9d9d-d4f3d62eab38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f30a7c63-f0a8-4627-a61c-9a1b2fe6c741
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e9c9380-470f-4597-87fb-2801df400dfa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc504818-4ad7-4fa0-a128-e685e22fafa3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8cdb79c9-b868-469f-ac66-6936f3864671
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ac9879e-af9b-4603-a9e6-88a1951ed844
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8faf51d1-4982-4efb-a99b-920cf1b30822
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13cb7aa4-4223-4401-ab82-ea227d327175
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d675173-5ac6-4cb4-b043-61abc79111d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2077c59b-196e-48ca-be6b-ccf966a96098
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9251e06-7c85-4baf-b90d-56e842612655
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 344d85d7-ce74-47e3-a36c-db39304c288a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7445603-e6a3-4482-818c-b7a241f4545d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3511a4e-a28f-4c53-9a9a-ec9b176e0dc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12f92dd0-d3dd-4a23-8b21-1c75e787b8d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6fa8196a-9ec9-4d69-8e90-a90efde8f4da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 001376d4-2633-4307-94d6-4d3fa9a71d80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0f40e56-138d-4cbd-b517-68080d287eb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 291bc56d-09d1-41cd-89df-60f8976a9b7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3819c50b-8941-49b8-ae80-33d679d7c083
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message accd0911-d7b3-4741-87b3-4bf72323c3ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 384b7b15-1577-4a97-ac68-dda704098118
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a984c525-a9f6-4cc8-b2e5-5411cf750ad4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b317d875-b95d-49cd-8b9c-ae6c1673aa21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b43f943-2760-43d8-a7ba-980cd9d318fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eaf7e87c-66aa-4bf3-a788-85e462a36783
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62475515-5d80-4123-a6cb-0f2c8186a069
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3b1ab56-019c-454d-8a47-d2f7aaa54b26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80a556cb-cf2d-48ea-93c3-4c8bd0e4ddf5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aafc0ec2-3c04-4758-b149-c1947a5df1ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 944e73cb-188f-4680-bd4e-35cafe523476
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df89553a-916a-4ff3-ba60-135dfad9a9f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0cc086fe-711c-4a36-ad84-41869e1d0eb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd1cd071-bc6e-4a2c-8f7c-3a4c3df6cf2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38e10fb3-121e-44e6-862d-cd6b2f2b8c95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7f047db-7aa3-45a6-8b9a-98aa5fc85508
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 368d0e98-a78f-4901-b1c0-551450d96181
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3c334c4-2ecf-485c-8184-67b491b61bb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d44298d8-f27d-462e-8641-4754a5d1f384
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5933347-3013-42c5-8bf4-7a01c2b38098
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1366b84a-d54b-4fcf-be8c-7933252cc3f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 863c41bd-b86b-412f-b880-5a4bde7be977
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dbc49524-7187-47e5-a31f-abc7fc484d9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9afb548f-dab6-4797-beb9-4a74f1c29e81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5334499-1013-4b03-9e33-41a53628a680
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ac61caa-a002-4758-b03f-3bfed1ab0439
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f397b75a-4db6-458a-b542-6ce8753f9502
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c54aec6-e83c-4748-8837-4a1e16eb4132
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a35010ed-3ab3-45de-b67f-efbf5f7cf15c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed8448f9-53ca-4de6-a1c0-d95b906e73c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1b408f9-8670-40f1-83cf-6edf7e5e3be8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 468ba08f-1e70-45cb-94f3-9c995b22459c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c523488f-c0bc-4694-a77b-b8e04f8dfe4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7256f19e-70c9-436c-8803-8172b9511e48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae68f437-fd9c-46a6-b3d9-2e0f71165b2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dbc88324-15fb-46b3-a3e6-50e3191fc320
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f17740ff-f69d-41a0-8c8c-57fa271cac57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 034e2941-25ae-44ea-ba68-2361cb348a30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be869ae0-b6c6-4a76-bd92-50a01028f710
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de155777-672a-46df-851d-5c07ec65fcbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6f193e0-a2b8-4fb6-bac4-cf7b8cdea078
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4bc2de65-925a-4bef-93ec-26a9082955d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4101bdc-d046-4300-8dbe-76fc4bc0d29f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22ce4c2c-46e4-413b-b1ef-5de84c7d386f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55a38dc2-6d80-4064-9f6b-fc9e0c05250c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2ff79f1-0e28-4db8-af25-6f0511a80bd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa211166-011d-4803-8a04-e6b1ad5ba6d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe93a5d4-f3bc-4696-b05b-2aa98ea523ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ecf819f3-f5f9-4501-b15b-98731fc1e2b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d307181-b886-4f01-b160-6bfa5c02777e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd7ff2c9-0b77-4150-a87f-ba5b3e59e189
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86fc6e7a-089f-4deb-ac22-01f15cef6420
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message deeb5496-24d9-4200-890c-5c04538f76b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b85b6b97-1da5-4cf9-92fd-b950ae9812af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7f53883-1f70-47ed-9232-b0327a6d88f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d25addc0-407b-450a-9ae8-769e03f62461
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f26bc120-ef70-45b1-9952-ab7ff50cfc2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12b62755-6c27-4086-bf81-dbfd57b1a49d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b9d6b0d-a84f-4c5a-ac31-24f58822da09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83f73bd5-084a-44bc-b14a-3d1ed3a638d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62007fa0-914d-403f-bf01-1a92f07234e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57fa579e-b628-422a-a3ea-32980b7ef4ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 661e30c6-0d8c-4991-b3cf-40b129a8c4b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ddd88142-f362-4a3c-ba9b-99b84621ca7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message edde1a9e-a5ed-4ac4-bd97-52f521e14b55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47d86ea5-39bd-4e7a-ac83-7673528ded76
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8692 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_6
Server: localhost:8692
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_6
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_6/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_6/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_6/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_6/test_labels.txt

📊 Raw data loaded:
   Train: X=(4759, 24), y=(4759,)
   Test:  X=(1190, 24), y=(1190,)

⚠️  Limiting training data: 4759 → 800 samples
⚠️  Limiting test data: 1190 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_6 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 2 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.3607, val=0.1615 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0975, val=0.0967 (↓), lr=0.001000
   ✓ Epoch   3/100: train=0.0862, val=0.0883 (↓), lr=0.001000
   • Epoch   4/100: train=0.0797, val=0.0886, patience=1/15, lr=0.001000
   • Epoch   5/100: train=0.0805, val=0.0882, patience=2/15, lr=0.001000
   • Epoch  11/100: train=0.0797, val=0.0879, patience=8/15, lr=0.001000
   • Epoch  21/100: train=0.0747, val=0.0874, patience=9/15, lr=0.001000
   • Epoch  31/100: train=0.0660, val=0.0857, patience=1/15, lr=0.001000
   • Epoch  41/100: train=0.0594, val=0.0874, patience=4/15, lr=0.001000
   📉 Epoch 43: LR reduced 0.001000 → 0.000500
   📉 Epoch 51: LR reduced 0.000500 → 0.000250
   • Epoch  51/100: train=0.0525, val=0.0894, patience=14/15, lr=0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 2 Summary - Client client_6
   Epochs: 52/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0613, RMSE=0.2476, R²=0.2337
   Val:   Loss=0.0851, RMSE=0.2916, R²=0.0304
============================================================


============================================================
🔄 Round 5 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.4278, val=0.3607 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.2791, val=0.1849 (↓), lr=0.000250
   ✓ Epoch   3/100: train=0.1068, val=0.0850 (↓), lr=0.000250
   ✓ Epoch   4/100: train=0.0843, val=0.0819 (↓), lr=0.000250
   • Epoch   5/100: train=0.0816, val=0.0820, patience=1/15, lr=0.000250
   • Epoch  11/100: train=0.0813, val=0.0819, patience=7/15, lr=0.000250
   📉 Epoch 12: LR reduced 0.000250 → 0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 5 Summary - Client client_6
   Epochs: 19/100 (early stopped)
   LR: 0.000250 → 0.000125 (1 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0017
   Val:   Loss=0.0819, RMSE=0.2861, R²=-0.0023
============================================================


📊 Round 5 Test Metrics:
   Loss: 0.4940, RMSE: 0.7028, MAE: 0.6447, R²: -5.3012

============================================================
🔄 Round 6 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000125 → 0.000063
   ✓ Epoch   1/100: train=0.4577, val=0.3937 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.3942, val=0.3574 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.3576, val=0.3226 (↓), lr=0.000063
   ✓ Epoch   4/100: train=0.3201, val=0.2837 (↓), lr=0.000063
   ✓ Epoch   5/100: train=0.2754, val=0.2358 (↓), lr=0.000063
   📉 Epoch 9: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0818, val=0.0835, patience=1/15, lr=0.000031
   📉 Epoch 17: LR reduced 0.000031 → 0.000016
   • Epoch  21/100: train=0.0808, val=0.0838, patience=11/15, lr=0.000016
   📉 Epoch 25: LR reduced 0.000016 → 0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 6 Summary - Client client_6
   Epochs: 25/100 (early stopped)
   LR: 0.000125 → 0.000008 (4 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0127
   Val:   Loss=0.0837, RMSE=0.2894, R²=-0.0049
============================================================


============================================================
🔄 Round 7 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.4767, val=0.4895 (↓), lr=0.000008
   ✓ Epoch   2/100: train=0.4701, val=0.4827 (↓), lr=0.000008
   ✓ Epoch   3/100: train=0.4636, val=0.4767 (↓), lr=0.000008
   ✓ Epoch   4/100: train=0.4579, val=0.4713 (↓), lr=0.000008
   ✓ Epoch   5/100: train=0.4527, val=0.4664 (↓), lr=0.000008
   📉 Epoch 8: LR reduced 0.000008 → 0.000004
   ✓ Epoch  11/100: train=0.4327, val=0.4478 (↓), lr=0.000004
   📉 Epoch 16: LR reduced 0.000004 → 0.000002
   ✓ Epoch  21/100: train=0.4195, val=0.4350 (↓), lr=0.000002
   📉 Epoch 24: LR reduced 0.000002 → 0.000001
   • Epoch  31/100: train=0.4144, val=0.4301, patience=1/15, lr=0.000001
   • Epoch  41/100: train=0.4108, val=0.4264, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.4074, val=0.4230, patience=1/15, lr=0.000001
   • Epoch  61/100: train=0.4041, val=0.4196, patience=1/15, lr=0.000001
   • Epoch  71/100: train=0.4008, val=0.4163, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.3976, val=0.4130, patience=1/15, lr=0.000001
   • Epoch  91/100: train=0.3944, val=0.4098, patience=1/15, lr=0.000001

============================================================
📊 Round 7 Summary - Client client_6
   Epochs: 100/100
   LR: 0.000008 → 0.000001 (3 reductions)
   Train: Loss=0.3912, RMSE=0.6254, R²=-3.8240
   Val:   Loss=0.4068, RMSE=0.6378, R²=-3.8735
============================================================


📊 Round 7 Test Metrics:
   Loss: 0.4814, RMSE: 0.6938, MAE: 0.6348, R²: -5.1403

============================================================
🔄 Round 9 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.4538, val=0.5180 (↓), lr=0.000001
   ✓ Epoch   2/100: train=0.4533, val=0.5175 (↓), lr=0.000001
   ✓ Epoch   3/100: train=0.4528, val=0.5170 (↓), lr=0.000001
   ✓ Epoch   4/100: train=0.4524, val=0.5165 (↓), lr=0.000001
   • Epoch   5/100: train=0.4519, val=0.5160, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.4493, val=0.5132, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.4455, val=0.5090, patience=1/15, lr=0.000001
   • Epoch  31/100: train=0.4420, val=0.5052, patience=1/15, lr=0.000001
   • Epoch  41/100: train=0.4386, val=0.5015, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.4352, val=0.4978, patience=1/15, lr=0.000001
   • Epoch  61/100: train=0.4319, val=0.4943, patience=1/15, lr=0.000001
   • Epoch  71/100: train=0.4287, val=0.4907, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.4254, val=0.4871, patience=1/15, lr=0.000001
   • Epoch  91/100: train=0.4221, val=0.4835, patience=1/15, lr=0.000001

============================================================
📊 Round 9 Summary - Client client_6
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.4188, RMSE=0.6471, R²=-4.1050
   Val:   Loss=0.4803, RMSE=0.6930, R²=-5.2050
============================================================


📊 Round 9 Test Metrics:
   Loss: 0.4635, RMSE: 0.6808, MAE: 0.6206, R²: -4.9120

📊 Round 9 Test Metrics:
   Loss: 0.4078, RMSE: 0.6386, MAE: 0.5739, R²: -4.2019

============================================================
🔄 Round 18 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.3072, val=0.2679 (↓), lr=0.000001
   ✓ Epoch   2/100: train=0.3061, val=0.2669 (↓), lr=0.000001
   ✓ Epoch   3/100: train=0.3050, val=0.2659 (↓), lr=0.000001
   ✓ Epoch   4/100: train=0.3039, val=0.2649 (↓), lr=0.000001
   ✓ Epoch   5/100: train=0.3029, val=0.2640 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.2973, val=0.2589 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.2890, val=0.2514 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.2814, val=0.2445 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.2740, val=0.2378 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.2668, val=0.2312 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.2597, val=0.2247 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.2526, val=0.2183 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.2456, val=0.2118 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.2385, val=0.2054 (↓), lr=0.000001

============================================================
📊 Round 18 Summary - Client client_6
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.2320, RMSE=0.4817, R²=-1.8185
   Val:   Loss=0.1996, RMSE=0.4468, R²=-1.5762
============================================================


============================================================
🔄 Round 19 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.2725, val=0.2724 (↓), lr=0.000001
   ✓ Epoch   2/100: train=0.2720, val=0.2718 (↓), lr=0.000001
   ✓ Epoch   3/100: train=0.2715, val=0.2713 (↓), lr=0.000001
   ✓ Epoch   4/100: train=0.2709, val=0.2708 (↓), lr=0.000001
   ✓ Epoch   5/100: train=0.2704, val=0.2703 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.2672, val=0.2671 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.2618, val=0.2616 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.2562, val=0.2559 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.2504, val=0.2500 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.2444, val=0.2440 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.2383, val=0.2379 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.2321, val=0.2316 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.2257, val=0.2252 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.2193, val=0.2188 (↓), lr=0.000001

============================================================
📊 Round 19 Summary - Client client_6
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.2131, RMSE=0.4616, R²=-1.6058
   Val:   Loss=0.2129, RMSE=0.4614, R²=-1.6337
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.2398, RMSE: 0.4897, MAE: 0.4105, R²: -2.0589

============================================================
🔄 Round 20 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.2333, val=0.2561 (↓), lr=0.000001
   ✓ Epoch   2/100: train=0.2327, val=0.2554 (↓), lr=0.000001
   ✓ Epoch   3/100: train=0.2321, val=0.2548 (↓), lr=0.000001
   ✓ Epoch   4/100: train=0.2315, val=0.2541 (↓), lr=0.000001
   ✓ Epoch   5/100: train=0.2309, val=0.2534 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.2273, val=0.2495 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.2212, val=0.2428 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.2149, val=0.2359 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.2086, val=0.2290 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.2022, val=0.2220 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.1958, val=0.2150 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.1894, val=0.2079 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.1830, val=0.2008 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.1767, val=0.1937 (↓), lr=0.000001

============================================================
📊 Round 20 Summary - Client client_6
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1697, RMSE=0.4119, R²=-1.0593
   Val:   Loss=0.1874, RMSE=0.4329, R²=-1.4261
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.2031, RMSE: 0.4506, MAE: 0.3723, R²: -1.5903

📊 Round 20 Test Metrics:
   Loss: 0.1412, RMSE: 0.3758, MAE: 0.3074, R²: -0.8011

============================================================
🔄 Round 23 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1396, val=0.1449 (↓), lr=0.000001
   ✓ Epoch   2/100: train=0.1390, val=0.1443 (↓), lr=0.000001
   ✓ Epoch   3/100: train=0.1384, val=0.1437 (↓), lr=0.000001
   ✓ Epoch   4/100: train=0.1379, val=0.1431 (↓), lr=0.000001
   ✓ Epoch   5/100: train=0.1373, val=0.1425 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.1340, val=0.1390 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.1286, val=0.1334 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.1235, val=0.1280 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.1187, val=0.1230 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.1143, val=0.1183 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.1101, val=0.1139 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.1063, val=0.1098 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.1028, val=0.1060 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.0996, val=0.1026 (↓), lr=0.000001

============================================================
📊 Round 23 Summary - Client client_6
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0969, RMSE=0.3112, R²=-0.1863
   Val:   Loss=0.0998, RMSE=0.3159, R²=-0.2288
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2431, R²: -0.0353

📊 Round 23 Test Metrics:
   Loss: 0.0803, RMSE: 0.2834, MAE: 0.2421, R²: -0.0244

📊 Round 23 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2416, R²: -0.0196

============================================================
🔄 Round 28 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 28 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2885, R²=-0.0149
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0016
============================================================


============================================================
🔄 Round 30 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 30 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0086
   Val:   Loss=0.0774, RMSE=0.2782, R²=0.0023
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0792, RMSE: 0.2813, MAE: 0.2407, R²: -0.0097

============================================================
🔄 Round 32 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 32 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0069
   Val:   Loss=0.0857, RMSE=0.2928, R²=-0.0045
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2405, R²: -0.0078

📊 Round 32 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2405, R²: -0.0076

📊 Round 32 Test Metrics:
   Loss: 0.0790, RMSE: 0.2810, MAE: 0.2405, R²: -0.0073

============================================================
🔄 Round 35 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 35 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0062
   Val:   Loss=0.0852, RMSE=0.2919, R²=0.0075
============================================================


============================================================
🔄 Round 38 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 38 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0003
   Val:   Loss=0.0862, RMSE=0.2937, R²=-0.0413
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2404, R²: -0.0067

============================================================
🔄 Round 39 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 39 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0045
   Val:   Loss=0.0774, RMSE=0.2782, R²=-0.0033
============================================================


============================================================
🔄 Round 40 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 40 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=-0.0082
   Val:   Loss=0.0766, RMSE=0.2767, R²=0.0144
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2404, R²: -0.0064

📊 Round 40 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2404, R²: -0.0061

============================================================
🔄 Round 46 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 46 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0018
   Val:   Loss=0.0837, RMSE=0.2892, R²=-0.0124
============================================================


============================================================
🔄 Round 48 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 48 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0005
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0051
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2402, R²: -0.0041

============================================================
🔄 Round 51 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 51 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0016
   Val:   Loss=0.0883, RMSE=0.2972, R²=0.0024
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2401, R²: -0.0037

📊 Round 51 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2401, R²: -0.0037

============================================================
🔄 Round 53 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 53 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0005
   Val:   Loss=0.0818, RMSE=0.2859, R²=-0.0041
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2401, R²: -0.0036

============================================================
🔄 Round 55 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 55 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=-0.0001
   Val:   Loss=0.0895, RMSE=0.2992, R²=-0.0003
============================================================


============================================================
🔄 Round 57 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 57 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0017
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0065
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2400, R²: -0.0025

============================================================
🔄 Round 59 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 59 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0017
   Val:   Loss=0.0832, RMSE=0.2885, R²=0.0051
============================================================


============================================================
🔄 Round 60 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0678 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0678, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0678, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0678, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0678, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0678, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0678)

============================================================
📊 Round 60 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0014
   Val:   Loss=0.0678, RMSE=0.2603, R²=0.0097
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2399, R²: -0.0021

📊 Round 60 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2399, R²: -0.0020

============================================================
🔄 Round 62 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 62 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0016
   Val:   Loss=0.0751, RMSE=0.2740, R²=-0.0062
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2399, R²: -0.0021

============================================================
🔄 Round 63 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 63 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0015
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0031
============================================================


============================================================
🔄 Round 66 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0930 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0930, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0930, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0930, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0930, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0930, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0930)

============================================================
📊 Round 66 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0020
   Val:   Loss=0.0930, RMSE=0.3049, R²=-0.0087
============================================================


============================================================
🔄 Round 67 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 67 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=0.0015
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0024
============================================================


============================================================
🔄 Round 69 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 69 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0008
   Val:   Loss=0.0741, RMSE=0.2723, R²=0.0060
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2399, R²: -0.0017

============================================================
🔄 Round 70 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 70 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0015
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0083
============================================================


============================================================
🔄 Round 71 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 71 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0002
   Val:   Loss=0.0832, RMSE=0.2884, R²=0.0026
============================================================


============================================================
🔄 Round 73 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 73 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0006
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0067
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2399, R²: -0.0017

============================================================
🔄 Round 74 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 74 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0009
   Val:   Loss=0.0761, RMSE=0.2759, R²=-0.0169
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2399, R²: -0.0016

============================================================
🔄 Round 75 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 75 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0025
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0110
============================================================


============================================================
🔄 Round 79 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 79 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0022
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.0074
============================================================


============================================================
🔄 Round 82 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 82 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0001
   Val:   Loss=0.0791, RMSE=0.2813, R²=-0.0633
============================================================


============================================================
🔄 Round 83 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 83 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0011
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0030
============================================================


============================================================
🔄 Round 84 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 84 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0025
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0151
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2399, R²: -0.0018

============================================================
🔄 Round 86 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 86 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0007
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0076
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2399, R²: -0.0018

============================================================
🔄 Round 88 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0700 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0700, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0700, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0700, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0700, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0700, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0700)

============================================================
📊 Round 88 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0009
   Val:   Loss=0.0700, RMSE=0.2646, R²=-0.0024
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0785, RMSE: 0.2803, MAE: 0.2399, R²: -0.0019

============================================================
🔄 Round 93 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0699 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0700, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0700, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0700, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0700, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0700, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0699)

============================================================
📊 Round 93 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0023
   Val:   Loss=0.0699, RMSE=0.2645, R²=-0.0139
============================================================


============================================================
🔄 Round 96 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 96 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2849, R²=0.0008
   Val:   Loss=0.0831, RMSE=0.2882, R²=-0.0012
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0785, RMSE: 0.2803, MAE: 0.2399, R²: -0.0018

============================================================
🔄 Round 97 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 97 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0003
   Val:   Loss=0.0786, RMSE=0.2804, R²=-0.0018
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2399, R²: -0.0018

============================================================
🔄 Round 98 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 98 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0027
   Val:   Loss=0.0863, RMSE=0.2937, R²=-0.0163
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2399, R²: -0.0021

============================================================
🔄 Round 99 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0716 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0716, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0716, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0716, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0716, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0716, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0716)

============================================================
📊 Round 99 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0024
   Val:   Loss=0.0716, RMSE=0.2675, R²=-0.0083
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2399, R²: -0.0021

============================================================
🔄 Round 101 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 101 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0010
   Val:   Loss=0.0846, RMSE=0.2908, R²=0.0054
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2400, R²: -0.0023

📊 Round 101 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2400, R²: -0.0025

📊 Round 101 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2400, R²: -0.0028

============================================================
🔄 Round 105 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 105 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=0.0020
   Val:   Loss=0.0908, RMSE=0.3014, R²=-0.0064
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2400, R²: -0.0028

📊 Round 105 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2400, R²: -0.0027

============================================================
🔄 Round 107 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 107 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=-0.0034
   Val:   Loss=0.0868, RMSE=0.2947, R²=-0.0096
============================================================


============================================================
🔄 Round 109 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 109 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0027
   Val:   Loss=0.0877, RMSE=0.2961, R²=-0.0088
============================================================


============================================================
🔄 Round 110 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 110 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0002
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0014
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2399, R²: -0.0020

============================================================
🔄 Round 113 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 113 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0010
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0036
============================================================


============================================================
🔄 Round 114 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 114 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0021
   Val:   Loss=0.0844, RMSE=0.2906, R²=0.0100
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2399, R²: -0.0020

📊 Round 114 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2399, R²: -0.0020

============================================================
🔄 Round 117 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 117 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0007
   Val:   Loss=0.0910, RMSE=0.3016, R²=-0.0085
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2399, R²: -0.0017

============================================================
🔄 Round 118 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 118 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0010
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0016
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2399, R²: -0.0016

============================================================
🔄 Round 120 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 120 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2843, R²=-0.0009
   Val:   Loss=0.0842, RMSE=0.2902, R²=0.0040
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2399, R²: -0.0017

📊 Round 120 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2399, R²: -0.0014

============================================================
🔄 Round 123 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 123 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0029
   Val:   Loss=0.0768, RMSE=0.2771, R²=-0.0111
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2399, R²: -0.0016

============================================================
🔄 Round 124 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 124 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0029
   Val:   Loss=0.0855, RMSE=0.2923, R²=-0.0204
============================================================


============================================================
🔄 Round 126 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0717 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0717, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0717, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0717, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0717, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0717, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0717)

============================================================
📊 Round 126 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0008
   Val:   Loss=0.0717, RMSE=0.2678, R²=0.0008
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2398, R²: -0.0013

📊 Round 126 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2398, R²: -0.0013

============================================================
🔄 Round 130 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 130 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0016
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0030
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2398, R²: -0.0011

============================================================
🔄 Round 131 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 131 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0027
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0138
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2398, R²: -0.0011

============================================================
🔄 Round 132 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 132 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=-0.0007
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.0032
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2398, R²: -0.0012

============================================================
🔄 Round 133 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0700 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0700, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0700, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0700, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0700, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0700, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0700)

============================================================
📊 Round 133 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0027
   Val:   Loss=0.0700, RMSE=0.2646, R²=-0.0082
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2398, R²: -0.0012

============================================================
🔄 Round 136 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 136 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0001
   Val:   Loss=0.0825, RMSE=0.2873, R²=-0.0007
============================================================


============================================================
🔄 Round 137 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 137 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0008
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0012
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2398, R²: -0.0012

📊 Round 137 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2398, R²: -0.0012

📊 Round 137 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2398, R²: -0.0012

📊 Round 137 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2398, R²: -0.0012

============================================================
🔄 Round 147 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 147 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=0.0001
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0034
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2398, R²: -0.0011

📊 Round 147 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2398, R²: -0.0013

============================================================
🔄 Round 150 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0922 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0922, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0922, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0923, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0922)

============================================================
📊 Round 150 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=0.0010
   Val:   Loss=0.0922, RMSE=0.3037, R²=-0.0045
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2398, R²: -0.0013

============================================================
🔄 Round 151 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 151 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0034
   Val:   Loss=0.0883, RMSE=0.2971, R²=-0.0136
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2398, R²: -0.0013

============================================================
🔄 Round 152 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 152 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0003
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0082
============================================================


============================================================
🔄 Round 153 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 153 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0010
   Val:   Loss=0.0838, RMSE=0.2894, R²=-0.0001
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2398, R²: -0.0013

📊 Round 153 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2398, R²: -0.0012

============================================================
🔄 Round 157 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 157 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2856, R²=0.0001
   Val:   Loss=0.0814, RMSE=0.2852, R²=0.0028
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2398, R²: -0.0014

📊 Round 157 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2399, R²: -0.0016

============================================================
🔄 Round 159 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 159 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0003
   Val:   Loss=0.0781, RMSE=0.2794, R²=-0.0073
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2399, R²: -0.0016

============================================================
🔄 Round 161 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 161 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=-0.0005
   Val:   Loss=0.0907, RMSE=0.3011, R²=0.0057
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2398, R²: -0.0014

============================================================
🔄 Round 162 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 162 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0007
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0221
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2399, R²: -0.0017

📊 Round 162 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2399, R²: -0.0015

📊 Round 162 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2398, R²: -0.0015

============================================================
🔄 Round 170 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 170 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0005
   Val:   Loss=0.0859, RMSE=0.2930, R²=0.0063
============================================================


============================================================
🔄 Round 172 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 172 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0019
   Val:   Loss=0.0789, RMSE=0.2810, R²=-0.0030
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2398, R²: -0.0013

📊 Round 172 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2398, R²: -0.0015

============================================================
🔄 Round 174 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 174 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0015
   Val:   Loss=0.0829, RMSE=0.2880, R²=0.0102
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2398, R²: -0.0015

============================================================
🔄 Round 178 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 178 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0019
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0093
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2398, R²: -0.0012

============================================================
🔄 Round 186 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 186 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0025
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0207
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2398, R²: -0.0013

📊 Round 186 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2398, R²: -0.0013

📊 Round 186 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2398, R²: -0.0011

📊 Round 186 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2398, R²: -0.0011

============================================================
🔄 Round 192 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 192 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=-0.0014
   Val:   Loss=0.0916, RMSE=0.3027, R²=-0.0011
============================================================


📊 Round 192 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2398, R²: -0.0011

============================================================
🔄 Round 193 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 193 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0003
   Val:   Loss=0.0814, RMSE=0.2852, R²=-0.0098
============================================================


📊 Round 193 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2398, R²: -0.0011

📊 Round 193 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2398, R²: -0.0011

============================================================
🔄 Round 195 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 195 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2863, R²=0.0017
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0134
============================================================


📊 Round 195 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2398, R²: -0.0013

============================================================
🔄 Round 197 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 197 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0001
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0009
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2398, R²: -0.0013

📊 Round 197 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2398, R²: -0.0012

============================================================
🔄 Round 201 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 201 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0009
   Val:   Loss=0.0734, RMSE=0.2710, R²=-0.0007
============================================================


📊 Round 201 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2398, R²: -0.0012

📊 Round 201 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2399, R²: -0.0016

============================================================
🔄 Round 205 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 205 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0009
   Val:   Loss=0.0891, RMSE=0.2986, R²=0.0009
============================================================


============================================================
🔄 Round 206 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0717 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0717, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0717, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0717, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0717, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0716, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0717)

============================================================
📊 Round 206 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0005
   Val:   Loss=0.0717, RMSE=0.2677, R²=0.0071
============================================================


============================================================
🔄 Round 209 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 209 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0005
   Val:   Loss=0.0777, RMSE=0.2787, R²=0.0014
============================================================


============================================================
🔄 Round 214 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 214 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0002
   Val:   Loss=0.0825, RMSE=0.2872, R²=0.0011
============================================================


📊 Round 214 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2399, R²: -0.0017

============================================================
🔄 Round 216 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 216 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0012
   Val:   Loss=0.0833, RMSE=0.2887, R²=-0.0028
============================================================


📊 Round 216 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2398, R²: -0.0015

📊 Round 216 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2399, R²: -0.0017

============================================================
🔄 Round 221 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 221 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0011
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0003
============================================================


📊 Round 221 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2399, R²: -0.0017

📊 Round 221 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2398, R²: -0.0014

============================================================
🔄 Round 225 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 225 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0009
   Val:   Loss=0.0783, RMSE=0.2799, R²=-0.0006
============================================================


============================================================
🔄 Round 226 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 226 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0007
   Val:   Loss=0.0866, RMSE=0.2943, R²=0.0002
============================================================


📊 Round 226 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2398, R²: -0.0015

📊 Round 226 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2398, R²: -0.0015

============================================================
🔄 Round 231 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 231 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0022
   Val:   Loss=0.0796, RMSE=0.2822, R²=-0.0045
============================================================


📊 Round 231 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2398, R²: -0.0012

============================================================
🔄 Round 233 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 233 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2849, R²=0.0007
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0006
============================================================


============================================================
🔄 Round 234 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 234 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0009
   Val:   Loss=0.0819, RMSE=0.2861, R²=0.0008
============================================================


============================================================
🔄 Round 235 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 235 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0010
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0013
============================================================


📊 Round 235 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2398, R²: -0.0011

📊 Round 235 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2398, R²: -0.0011

============================================================
🔄 Round 237 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 237 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0021
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0249
============================================================


============================================================
🔄 Round 238 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 238 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2813, R²=0.0011
   Val:   Loss=0.0909, RMSE=0.3015, R²=0.0000
============================================================


============================================================
🔄 Round 239 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 239 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0003
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0010
============================================================


📊 Round 239 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2398, R²: -0.0011

============================================================
🔄 Round 242 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 242 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=0.0013
   Val:   Loss=0.0769, RMSE=0.2774, R²=-0.0045
============================================================


============================================================
🔄 Round 246 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 246 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0001
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0119
============================================================


📊 Round 246 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2398, R²: -0.0009

============================================================
🔄 Round 247 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 247 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0000
   Val:   Loss=0.0762, RMSE=0.2760, R²=0.0050
============================================================


============================================================
🔄 Round 249 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 249 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2857, R²=0.0002
   Val:   Loss=0.0809, RMSE=0.2844, R²=-0.0003
============================================================


============================================================
🔄 Round 250 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 250 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0004
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0011
============================================================


📊 Round 250 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2398, R²: -0.0011

📊 Round 250 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2398, R²: -0.0011

============================================================
🔄 Round 253 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 253 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0003
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0035
============================================================


📊 Round 253 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2398, R²: -0.0012

📊 Round 253 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2398, R²: -0.0014

📊 Round 253 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2398, R²: -0.0014

============================================================
🔄 Round 259 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 259 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=-0.0009
   Val:   Loss=0.0892, RMSE=0.2987, R²=0.0061
============================================================


============================================================
🔄 Round 260 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 260 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0018
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0093
============================================================


============================================================
🔄 Round 261 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0962 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0962, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0962, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0962, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0962, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0962, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0962)

============================================================
📊 Round 261 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2790, R²=0.0021
   Val:   Loss=0.0962, RMSE=0.3101, R²=-0.0133
============================================================


============================================================
🔄 Round 263 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 263 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0002
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0058
============================================================


📊 Round 263 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2398, R²: -0.0011

============================================================
🔄 Round 264 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 264 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0000
   Val:   Loss=0.0771, RMSE=0.2776, R²=0.0056
============================================================


📊 Round 264 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2398, R²: -0.0013

📊 Round 264 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2398, R²: -0.0013

📊 Round 264 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2398, R²: -0.0013

📊 Round 264 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2398, R²: -0.0013

📊 Round 264 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2398, R²: -0.0014

============================================================
🔄 Round 270 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 270 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0011
   Val:   Loss=0.0785, RMSE=0.2801, R²=0.0024
============================================================


📊 Round 270 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2398, R²: -0.0014

============================================================
🔄 Round 273 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 273 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0013
   Val:   Loss=0.0882, RMSE=0.2970, R²=-0.0001
============================================================


📊 Round 273 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2398, R²: -0.0014

============================================================
🔄 Round 274 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 274 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0026
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0091
============================================================


📊 Round 274 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2398, R²: -0.0013

📊 Round 274 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2398, R²: -0.0013

============================================================
🔄 Round 277 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 277 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0046
   Val:   Loss=0.0858, RMSE=0.2929, R²=0.0052
============================================================


📊 Round 277 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2398, R²: -0.0010

============================================================
🔄 Round 282 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 282 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=0.0014
   Val:   Loss=0.0852, RMSE=0.2920, R²=-0.0016
============================================================


📊 Round 282 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2398, R²: -0.0010

📊 Round 282 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2398, R²: -0.0010

📊 Round 282 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2397, R²: -0.0008

📊 Round 282 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2398, R²: -0.0010

============================================================
🔄 Round 287 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0962 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0962, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0963, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0963, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0963, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0964, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0962)

============================================================
📊 Round 287 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=-0.0004
   Val:   Loss=0.0962, RMSE=0.3102, R²=-0.0037
============================================================


📊 Round 287 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2398, R²: -0.0010

📊 Round 287 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2397, R²: -0.0008

============================================================
🔄 Round 290 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 290 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0014
   Val:   Loss=0.0837, RMSE=0.2893, R²=0.0007
============================================================


📊 Round 290 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2397, R²: -0.0006

============================================================
🔄 Round 294 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 294 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0020
   Val:   Loss=0.0809, RMSE=0.2844, R²=-0.0030
============================================================


📊 Round 294 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2397, R²: -0.0006

📊 Round 294 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2397, R²: -0.0007

============================================================
🔄 Round 299 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 299 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2835, R²=0.0020
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0019
============================================================


============================================================
🔄 Round 304 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 304 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0019
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0025
============================================================


📊 Round 304 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2398, R²: -0.0009

============================================================
🔄 Round 305 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 305 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0017
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0032
============================================================


📊 Round 305 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2398, R²: -0.0010

📊 Round 305 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2398, R²: -0.0009

============================================================
🔄 Round 311 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 311 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0003
   Val:   Loss=0.0858, RMSE=0.2928, R²=0.0041
============================================================


📊 Round 311 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2398, R²: -0.0009

============================================================
🔄 Round 312 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 312 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0003
   Val:   Loss=0.0794, RMSE=0.2817, R²=0.0038
============================================================


📊 Round 312 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2398, R²: -0.0009

============================================================
🔄 Round 314 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 314 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0019
   Val:   Loss=0.0764, RMSE=0.2764, R²=-0.0257
============================================================


============================================================
🔄 Round 315 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 315 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0017
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0062
============================================================


📊 Round 315 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2398, R²: -0.0009

📊 Round 315 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2397, R²: -0.0009

📊 Round 315 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2397, R²: -0.0009

📊 Round 315 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2398, R²: -0.0010

📊 Round 315 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2398, R²: -0.0010

============================================================
🔄 Round 327 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 327 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0010
   Val:   Loss=0.0880, RMSE=0.2967, R²=-0.0008
============================================================


📊 Round 327 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2397, R²: -0.0008

============================================================
🔄 Round 331 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 331 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=0.0012
   Val:   Loss=0.0788, RMSE=0.2807, R²=0.0009
============================================================


📊 Round 331 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2397, R²: -0.0008

============================================================
🔄 Round 334 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 334 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0014
   Val:   Loss=0.0905, RMSE=0.3009, R²=-0.0013
============================================================


📊 Round 334 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2397, R²: -0.0006

============================================================
🔄 Round 336 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0681 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0681, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0681, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0681, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0682, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0682, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0681)

============================================================
📊 Round 336 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0023
   Val:   Loss=0.0681, RMSE=0.2610, R²=-0.0193
============================================================


📊 Round 336 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2397, R²: -0.0005

============================================================
🔄 Round 338 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0717 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0717, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0717, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0717, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0717, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0717, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0717)

============================================================
📊 Round 338 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0036
   Val:   Loss=0.0717, RMSE=0.2678, R²=-0.0131
============================================================


📊 Round 338 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2397, R²: -0.0005

============================================================
🔄 Round 339 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 339 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0004
   Val:   Loss=0.0846, RMSE=0.2909, R²=0.0008
============================================================


📊 Round 339 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2397, R²: -0.0006

============================================================
🔄 Round 341 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 341 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0003
   Val:   Loss=0.0866, RMSE=0.2943, R²=0.0048
============================================================


📊 Round 341 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2397, R²: -0.0006

📊 Round 341 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2397, R²: -0.0008

📊 Round 341 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2398, R²: -0.0011

============================================================
🔄 Round 346 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 346 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0046
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0251
============================================================


📊 Round 346 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2397, R²: -0.0009

📊 Round 346 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2397, R²: -0.0008

============================================================
🔄 Round 351 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0714 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0714, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0714, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0714, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0714, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0714, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0714)

============================================================
📊 Round 351 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0007
   Val:   Loss=0.0714, RMSE=0.2673, R²=0.0036
============================================================


📊 Round 351 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2397, R²: -0.0008

============================================================
🔄 Round 353 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 353 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0014
   Val:   Loss=0.0825, RMSE=0.2873, R²=-0.0012
============================================================


📊 Round 353 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2397, R²: -0.0008

============================================================
🔄 Round 355 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 355 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0015
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0066
============================================================


============================================================
🔄 Round 356 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0713 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0713, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0713, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0713, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0713, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0713, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0713)

============================================================
📊 Round 356 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0018
   Val:   Loss=0.0713, RMSE=0.2670, R²=-0.0045
============================================================


📊 Round 356 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2397, R²: -0.0008

============================================================
🔄 Round 358 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 358 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0025
   Val:   Loss=0.0803, RMSE=0.2833, R²=-0.0058
============================================================


============================================================
🔄 Round 359 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 359 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0019
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0056
============================================================


📊 Round 359 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2397, R²: -0.0008

============================================================
🔄 Round 361 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 361 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0008
   Val:   Loss=0.0805, RMSE=0.2838, R²=0.0016
============================================================


📊 Round 361 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2398, R²: -0.0010

📊 Round 361 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2398, R²: -0.0014

📊 Round 361 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2398, R²: -0.0015

📊 Round 361 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2398, R²: -0.0014

============================================================
🔄 Round 370 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 370 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0026
   Val:   Loss=0.0752, RMSE=0.2743, R²=-0.0141
============================================================


📊 Round 370 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2398, R²: -0.0013

============================================================
🔄 Round 371 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 371 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=0.0008
   Val:   Loss=0.0868, RMSE=0.2947, R²=0.0019
============================================================


📊 Round 371 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2398, R²: -0.0015

============================================================
🔄 Round 373 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 373 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0010
   Val:   Loss=0.0834, RMSE=0.2887, R²=0.0003
============================================================


============================================================
🔄 Round 374 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 374 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0019
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0197
============================================================


📊 Round 374 Test Metrics:
   Loss: 0.0785, RMSE: 0.2803, MAE: 0.2398, R²: -0.0019

📊 Round 374 Test Metrics:
   Loss: 0.0785, RMSE: 0.2803, MAE: 0.2398, R²: -0.0019

============================================================
🔄 Round 376 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 376 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=-0.0003
   Val:   Loss=0.0726, RMSE=0.2695, R²=-0.0121
============================================================


============================================================
🔄 Round 377 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 377 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0014
   Val:   Loss=0.0884, RMSE=0.2973, R²=-0.0032
============================================================


📊 Round 377 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2398, R²: -0.0018

============================================================
🔄 Round 378 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 378 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=0.0024
   Val:   Loss=0.0754, RMSE=0.2746, R²=-0.0065
============================================================


📊 Round 378 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2398, R²: -0.0017

============================================================
🔄 Round 379 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 379 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0021
   Val:   Loss=0.0792, RMSE=0.2815, R²=-0.0083
============================================================


📊 Round 379 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2398, R²: -0.0017

📊 Round 379 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2398, R²: -0.0015

============================================================
🔄 Round 383 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 383 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0022
   Val:   Loss=0.0772, RMSE=0.2778, R²=-0.0094
============================================================


📊 Round 383 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2398, R²: -0.0015

📊 Round 383 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2398, R²: -0.0017

============================================================
🔄 Round 386 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 386 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0005
   Val:   Loss=0.0754, RMSE=0.2746, R²=0.0019
============================================================


📊 Round 386 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2398, R²: -0.0016

============================================================
🔄 Round 390 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 390 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=-0.0007
   Val:   Loss=0.0832, RMSE=0.2884, R²=0.0071
============================================================


📊 Round 390 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2398, R²: -0.0013

============================================================
🔄 Round 391 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 391 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=-0.0024
   Val:   Loss=0.0899, RMSE=0.2998, R²=0.0038
============================================================


📊 Round 391 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2398, R²: -0.0015

============================================================
🔄 Round 395 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 395 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0015
   Val:   Loss=0.0858, RMSE=0.2928, R²=-0.0278
============================================================


============================================================
🔄 Round 398 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 398 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0001
   Val:   Loss=0.0791, RMSE=0.2812, R²=0.0051
============================================================


📊 Round 398 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2398, R²: -0.0014

============================================================
🔄 Round 400 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 400 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0006
   Val:   Loss=0.0733, RMSE=0.2708, R²=0.0025
============================================================


📊 Round 400 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2398, R²: -0.0011

============================================================
🔄 Round 406 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 406 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0000
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0140
============================================================


📊 Round 406 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2398, R²: -0.0010

============================================================
🔄 Round 408 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 408 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0027
   Val:   Loss=0.0823, RMSE=0.2870, R²=-0.0168
============================================================


============================================================
🔄 Round 409 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 409 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0010
   Val:   Loss=0.0912, RMSE=0.3020, R²=0.0013
============================================================


📊 Round 409 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2397, R²: -0.0010

============================================================
🔄 Round 411 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 411 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0012
   Val:   Loss=0.0750, RMSE=0.2738, R²=0.0106
============================================================


📊 Round 411 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2397, R²: -0.0010

============================================================
🔄 Round 412 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0702 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0702, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0702, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0702, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0703, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0703, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0702)

============================================================
📊 Round 412 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0013
   Val:   Loss=0.0702, RMSE=0.2650, R²=-0.0009
============================================================


📊 Round 412 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2398, R²: -0.0010

============================================================
🔄 Round 416 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 416 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0013
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0008
============================================================


📊 Round 416 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2398, R²: -0.0011

============================================================
🔄 Round 420 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 420 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0006
   Val:   Loss=0.0822, RMSE=0.2868, R²=0.0031
============================================================


============================================================
🔄 Round 421 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 421 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0001
   Val:   Loss=0.0800, RMSE=0.2829, R²=0.0060
============================================================


📊 Round 421 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2398, R²: -0.0012

📊 Round 421 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2398, R²: -0.0012

============================================================
🔄 Round 424 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 424 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0000
   Val:   Loss=0.0740, RMSE=0.2719, R²=-0.0020
============================================================


📊 Round 424 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2398, R²: -0.0012

============================================================
🔄 Round 425 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 425 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0019
   Val:   Loss=0.0762, RMSE=0.2761, R²=0.0049
============================================================


============================================================
🔄 Round 426 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 426 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0002
   Val:   Loss=0.0825, RMSE=0.2873, R²=-0.0087
============================================================


============================================================
🔄 Round 427 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 427 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=0.0021
   Val:   Loss=0.0821, RMSE=0.2864, R²=-0.0063
============================================================


📊 Round 427 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2398, R²: -0.0011

============================================================
🔄 Round 428 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 428 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0019
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0030
============================================================


============================================================
🔄 Round 429 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 429 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0008
   Val:   Loss=0.0832, RMSE=0.2885, R²=0.0003
============================================================


📊 Round 429 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2398, R²: -0.0010

📊 Round 429 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2398, R²: -0.0010

============================================================
🔄 Round 431 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 431 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0023
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0086
============================================================


📊 Round 431 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2397, R²: -0.0010

============================================================
🔄 Round 432 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 432 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0006
   Val:   Loss=0.0750, RMSE=0.2738, R²=-0.0003
============================================================


📊 Round 432 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2398, R²: -0.0010

============================================================
🔄 Round 433 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 433 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0031
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0125
============================================================


============================================================
🔄 Round 434 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 434 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0030
   Val:   Loss=0.0915, RMSE=0.3025, R²=-0.0062
============================================================


📊 Round 434 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2398, R²: -0.0010

============================================================
🔄 Round 436 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 436 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0013
   Val:   Loss=0.0795, RMSE=0.2819, R²=0.0009
============================================================


📊 Round 436 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2397, R²: -0.0010

📊 Round 436 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2397, R²: -0.0010

📊 Round 436 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2397, R²: -0.0009

============================================================
🔄 Round 440 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 440 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0018
   Val:   Loss=0.0842, RMSE=0.2901, R²=-0.0112
============================================================


📊 Round 440 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2397, R²: -0.0009

============================================================
🔄 Round 441 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 441 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0009
   Val:   Loss=0.0777, RMSE=0.2788, R²=0.0005
============================================================


📊 Round 441 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2398, R²: -0.0011

============================================================
🔄 Round 442 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 442 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0037
   Val:   Loss=0.0841, RMSE=0.2899, R²=-0.0107
============================================================


📊 Round 442 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2398, R²: -0.0011

📊 Round 442 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2398, R²: -0.0012

============================================================
🔄 Round 445 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 445 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0023
   Val:   Loss=0.0794, RMSE=0.2817, R²=-0.0065
============================================================


📊 Round 445 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2398, R²: -0.0013

📊 Round 445 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2398, R²: -0.0012

============================================================
🔄 Round 447 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 447 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0002
   Val:   Loss=0.0839, RMSE=0.2896, R²=0.0059
============================================================


📊 Round 447 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2398, R²: -0.0012

📊 Round 447 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2398, R²: -0.0012

============================================================
🔄 Round 449 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 449 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0035
   Val:   Loss=0.0857, RMSE=0.2928, R²=-0.0084
============================================================


============================================================
🔄 Round 450 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 450 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0015
   Val:   Loss=0.0869, RMSE=0.2948, R²=-0.0211
============================================================


📊 Round 450 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2398, R²: -0.0012

============================================================
🔄 Round 451 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 451 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0017
   Val:   Loss=0.0915, RMSE=0.3026, R²=-0.0412
============================================================


============================================================
🔄 Round 452 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 452 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0003
   Val:   Loss=0.0766, RMSE=0.2769, R²=0.0023
============================================================


📊 Round 452 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2398, R²: -0.0012

============================================================
🔄 Round 454 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 454 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0003
   Val:   Loss=0.0792, RMSE=0.2814, R²=0.0007
============================================================


============================================================
🔄 Round 456 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 456 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0010
   Val:   Loss=0.0806, RMSE=0.2838, R²=0.0011
============================================================


📊 Round 456 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2398, R²: -0.0011

📊 Round 456 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2398, R²: -0.0011

============================================================
🔄 Round 460 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 460 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0006
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0019
============================================================


============================================================
🔄 Round 461 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 461 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0020
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0023
============================================================


============================================================
🔄 Round 462 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 462 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0003
   Val:   Loss=0.0822, RMSE=0.2866, R²=0.0038
============================================================


============================================================
🔄 Round 463 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0690 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0690, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0690, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0690, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0690, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0690, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0690)

============================================================
📊 Round 463 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0010
   Val:   Loss=0.0690, RMSE=0.2628, R²=-0.0078
============================================================


📊 Round 463 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2398, R²: -0.0010

============================================================
🔄 Round 464 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 464 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0003
   Val:   Loss=0.0806, RMSE=0.2840, R²=-0.0009
============================================================


============================================================
🔄 Round 465 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 465 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0027
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0124
============================================================


📊 Round 465 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2397, R²: -0.0010

============================================================
🔄 Round 467 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 467 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0004
   Val:   Loss=0.0839, RMSE=0.2896, R²=-0.0202
============================================================


📊 Round 467 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2397, R²: -0.0009

============================================================
🔄 Round 469 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 469 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0025
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0056
============================================================


📊 Round 469 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2397, R²: -0.0009

============================================================
🔄 Round 473 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 473 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0005
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0244
============================================================


📊 Round 473 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2398, R²: -0.0010

============================================================
🔄 Round 475 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 475 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0004
   Val:   Loss=0.0762, RMSE=0.2761, R²=0.0002
============================================================


📊 Round 475 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2398, R²: -0.0012

============================================================
🔄 Round 477 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0938 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0938, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0938, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0938, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0938, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0938, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0938)

============================================================
📊 Round 477 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0015
   Val:   Loss=0.0938, RMSE=0.3063, R²=-0.0005
============================================================


📊 Round 477 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2398, R²: -0.0012

============================================================
🔄 Round 480 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 480 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0009
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0003
============================================================


📊 Round 480 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2398, R²: -0.0010

============================================================
🔄 Round 483 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0928 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0928, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0928, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0928, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0928, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0928, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0928)

============================================================
📊 Round 483 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=-0.0011
   Val:   Loss=0.0928, RMSE=0.3046, R²=0.0071
============================================================


============================================================
🔄 Round 484 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 484 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0016
   Val:   Loss=0.0786, RMSE=0.2803, R²=-0.0006
============================================================


📊 Round 484 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2398, R²: -0.0010

============================================================
🔄 Round 487 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 487 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0012
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0006
============================================================


============================================================
🔄 Round 489 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 489 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0015
   Val:   Loss=0.0902, RMSE=0.3003, R²=-0.0057
============================================================


📊 Round 489 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2397, R²: -0.0009

============================================================
🔄 Round 492 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 492 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0019
   Val:   Loss=0.0834, RMSE=0.2887, R²=-0.0021
============================================================


============================================================
🔄 Round 494 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 494 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=0.0010
   Val:   Loss=0.0771, RMSE=0.2777, R²=-0.0095
============================================================


============================================================
🔄 Round 495 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 495 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0010
   Val:   Loss=0.0877, RMSE=0.2962, R²=0.0020
============================================================


📊 Round 495 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2397, R²: -0.0009

============================================================
🔄 Round 503 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 503 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0005
   Val:   Loss=0.0817, RMSE=0.2859, R²=0.0027
============================================================


============================================================
🔄 Round 504 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 504 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0009
   Val:   Loss=0.0773, RMSE=0.2780, R²=0.0014
============================================================


📊 Round 504 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2398, R²: -0.0010

============================================================
🔄 Round 506 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 506 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0002
   Val:   Loss=0.0785, RMSE=0.2802, R²=-0.0011
============================================================


============================================================
🔄 Round 508 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 508 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0009
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0097
============================================================


📊 Round 508 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2397, R²: -0.0009

============================================================
🔄 Round 512 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0710 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0710, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0710, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0710, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0710, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0710, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0710)

============================================================
📊 Round 512 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0001
   Val:   Loss=0.0710, RMSE=0.2664, R²=0.0075
============================================================


📊 Round 512 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2397, R²: -0.0009

📊 Round 512 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2397, R²: -0.0009

============================================================
🔄 Round 514 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 514 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=0.0027
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0251
============================================================


============================================================
🔄 Round 516 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 516 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=0.0008
   Val:   Loss=0.0728, RMSE=0.2698, R²=0.0034
============================================================


📊 Round 516 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2397, R²: -0.0008

📊 Round 516 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2397, R²: -0.0008

============================================================
🔄 Round 518 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 518 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0014
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0026
============================================================


============================================================
🔄 Round 519 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 519 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0015
   Val:   Loss=0.0797, RMSE=0.2824, R²=0.0003
============================================================


📊 Round 519 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2397, R²: -0.0008

📊 Round 519 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2397, R²: -0.0008

============================================================
🔄 Round 523 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 523 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0000
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0007
============================================================


📊 Round 523 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2397, R²: -0.0006

============================================================
🔄 Round 532 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 532 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0003
   Val:   Loss=0.0822, RMSE=0.2867, R²=0.0048
============================================================


📊 Round 532 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2397, R²: -0.0009

============================================================
🔄 Round 535 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 535 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0010
   Val:   Loss=0.0799, RMSE=0.2826, R²=-0.0103
============================================================


============================================================
🔄 Round 536 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 536 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0018
   Val:   Loss=0.0820, RMSE=0.2863, R²=-0.0027
============================================================


📊 Round 536 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2398, R²: -0.0012

============================================================
🔄 Round 537 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 537 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=-0.0004
   Val:   Loss=0.0853, RMSE=0.2920, R²=0.0065
============================================================


📊 Round 537 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2398, R²: -0.0013

============================================================
🔄 Round 540 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 540 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0030
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0078
============================================================


📊 Round 540 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2397, R²: -0.0007

📊 Round 540 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2397, R²: -0.0007

📊 Round 540 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2397, R²: -0.0009

============================================================
🔄 Round 546 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 546 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2856, R²=0.0023
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0070
============================================================


📊 Round 546 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2398, R²: -0.0012

📊 Round 546 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2397, R²: -0.0009

============================================================
🔄 Round 548 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 548 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0000
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0007
============================================================


============================================================
🔄 Round 549 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 549 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2863, R²=0.0010
   Val:   Loss=0.0796, RMSE=0.2822, R²=0.0022
============================================================


📊 Round 549 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2397, R²: -0.0009

📊 Round 549 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2397, R²: -0.0009

============================================================
🔄 Round 553 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 553 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0010
   Val:   Loss=0.0745, RMSE=0.2729, R²=0.0091
============================================================


📊 Round 553 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2397, R²: -0.0007

============================================================
🔄 Round 554 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 554 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0032
   Val:   Loss=0.0744, RMSE=0.2728, R²=-0.0179
============================================================


📊 Round 554 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2397, R²: -0.0008

============================================================
🔄 Round 556 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 556 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0000
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0059
============================================================


📊 Round 556 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2397, R²: -0.0008

============================================================
🔄 Round 557 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 557 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0007
   Val:   Loss=0.0838, RMSE=0.2896, R²=-0.0032
============================================================


============================================================
🔄 Round 558 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 558 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0008
   Val:   Loss=0.0858, RMSE=0.2930, R²=0.0005
============================================================


📊 Round 558 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2397, R²: -0.0009

============================================================
🔄 Round 559 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 559 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0019
   Val:   Loss=0.0882, RMSE=0.2970, R²=-0.0046
============================================================


============================================================
🔄 Round 560 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 560 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0014
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0048
============================================================


📊 Round 560 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2397, R²: -0.0009

============================================================
🔄 Round 563 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 563 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0028
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0089
============================================================


📊 Round 563 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2397, R²: -0.0010

============================================================
🔄 Round 564 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 564 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0004
   Val:   Loss=0.0881, RMSE=0.2969, R²=0.0070
============================================================


============================================================
🔄 Round 565 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 565 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0025
   Val:   Loss=0.0861, RMSE=0.2935, R²=-0.0123
============================================================


============================================================
🔄 Round 567 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 567 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0007
   Val:   Loss=0.0843, RMSE=0.2904, R²=0.0022
============================================================


============================================================
🔄 Round 568 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 568 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0009
   Val:   Loss=0.0866, RMSE=0.2942, R²=0.0023
============================================================


============================================================
🔄 Round 569 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 569 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0002
   Val:   Loss=0.0735, RMSE=0.2711, R²=0.0037
============================================================


============================================================
🔄 Round 570 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 570 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0002
   Val:   Loss=0.0777, RMSE=0.2788, R²=-0.0163
============================================================


============================================================
🔄 Round 571 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 571 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0013
   Val:   Loss=0.0782, RMSE=0.2796, R²=-0.0004
============================================================


📊 Round 571 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2397, R²: -0.0008

============================================================
🔄 Round 572 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 572 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0004
   Val:   Loss=0.0822, RMSE=0.2866, R²=0.0046
============================================================


============================================================
🔄 Round 573 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 573 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0010
   Val:   Loss=0.0877, RMSE=0.2961, R²=-0.0063
============================================================


📊 Round 573 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2397, R²: -0.0008

📊 Round 573 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2397, R²: -0.0010

📊 Round 573 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2397, R²: -0.0010

📊 Round 573 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2397, R²: -0.0008

============================================================
🔄 Round 580 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 580 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0020
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0111
============================================================


📊 Round 580 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2397, R²: -0.0008

============================================================
🔄 Round 582 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 582 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2892, R²=-0.0006
   Val:   Loss=0.0727, RMSE=0.2696, R²=0.0081
============================================================


📊 Round 582 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2397, R²: -0.0007

📊 Round 582 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2397, R²: -0.0006

📊 Round 582 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2397, R²: -0.0006

============================================================
🔄 Round 585 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 585 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0006
   Val:   Loss=0.0875, RMSE=0.2959, R²=-0.0049
============================================================


📊 Round 585 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2397, R²: -0.0006

📊 Round 585 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2397, R²: -0.0006

============================================================
🔄 Round 587 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 587 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0017
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0005
============================================================


============================================================
🔄 Round 588 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 588 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0007
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0032
============================================================


📊 Round 588 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2397, R²: -0.0006

============================================================
🔄 Round 589 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 589 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0002
   Val:   Loss=0.0824, RMSE=0.2871, R²=0.0001
============================================================


📊 Round 589 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2397, R²: -0.0005

============================================================
🔄 Round 591 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 591 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=-0.0014
   Val:   Loss=0.0851, RMSE=0.2918, R²=0.0020
============================================================


============================================================
🔄 Round 592 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 592 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=0.0005
   Val:   Loss=0.0851, RMSE=0.2917, R²=0.0037
============================================================


📊 Round 592 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2397, R²: -0.0005

============================================================
🔄 Round 594 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 594 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0014
   Val:   Loss=0.0837, RMSE=0.2894, R²=-0.0039
============================================================


============================================================
🔄 Round 595 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 595 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0025
   Val:   Loss=0.0738, RMSE=0.2717, R²=-0.0118
============================================================


📊 Round 595 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2397, R²: -0.0005

============================================================
🔄 Round 597 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 597 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0029
   Val:   Loss=0.0846, RMSE=0.2908, R²=-0.0044
============================================================


📊 Round 597 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2397, R²: -0.0004

📊 Round 597 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2397, R²: -0.0006

============================================================
🔄 Round 603 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 603 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0044
   Val:   Loss=0.0822, RMSE=0.2868, R²=-0.0135
============================================================


📊 Round 603 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2397, R²: -0.0006

📊 Round 603 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2397, R²: -0.0006

📊 Round 603 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2397, R²: -0.0006

📊 Round 603 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2397, R²: -0.0006

============================================================
🔄 Round 609 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 609 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2842, R²=0.0028
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0298
============================================================


📊 Round 609 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2397, R²: -0.0007

============================================================
🔄 Round 613 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 613 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=0.0027
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0059
============================================================


============================================================
🔄 Round 614 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 614 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0007
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0014
============================================================


📊 Round 614 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2397, R²: -0.0010

============================================================
🔄 Round 616 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 616 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0007
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0033
============================================================


📊 Round 616 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2397, R²: -0.0008

📊 Round 616 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2397, R²: -0.0008

============================================================
🔄 Round 620 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 620 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0002
   Val:   Loss=0.0746, RMSE=0.2732, R²=0.0044
============================================================


📊 Round 620 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2397, R²: -0.0006

============================================================
🔄 Round 622 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 622 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0032
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0085
============================================================


📊 Round 622 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2397, R²: -0.0006

============================================================
🔄 Round 623 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 623 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0009
   Val:   Loss=0.0806, RMSE=0.2839, R²=0.0018
============================================================


============================================================
🔄 Round 624 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 624 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0019
   Val:   Loss=0.0786, RMSE=0.2804, R²=-0.0013
============================================================


============================================================
🔄 Round 625 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 625 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0022
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0177
============================================================


📊 Round 625 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2397, R²: -0.0006

============================================================
🔄 Round 628 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 628 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0008
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0032
============================================================


📊 Round 628 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2397, R²: -0.0007

============================================================
🔄 Round 629 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0922 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0922, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0922, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0922, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0922, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0922, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0922)

============================================================
📊 Round 629 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=-0.0003
   Val:   Loss=0.0922, RMSE=0.3036, R²=0.0037
============================================================


============================================================
🔄 Round 630 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 630 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0007
   Val:   Loss=0.0827, RMSE=0.2875, R²=0.0018
============================================================


📊 Round 630 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2397, R²: -0.0007

============================================================
🔄 Round 632 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 632 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0018
   Val:   Loss=0.0875, RMSE=0.2958, R²=-0.0097
============================================================


============================================================
🔄 Round 633 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 633 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0013
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0015
============================================================


📊 Round 633 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2397, R²: -0.0007

📊 Round 633 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2397, R²: -0.0007

============================================================
🔄 Round 640 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 640 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0011
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0211
============================================================


📊 Round 640 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2397, R²: -0.0006

📊 Round 640 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2397, R²: -0.0006

============================================================
🔄 Round 642 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 642 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0022
   Val:   Loss=0.0757, RMSE=0.2751, R²=-0.0146
============================================================


============================================================
🔄 Round 644 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 644 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0019
   Val:   Loss=0.0760, RMSE=0.2756, R²=-0.0034
============================================================


============================================================
🔄 Round 645 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0710 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0710, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0710, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0710, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0710, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0710, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0710)

============================================================
📊 Round 645 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0006
   Val:   Loss=0.0710, RMSE=0.2664, R²=0.0047
============================================================


📊 Round 645 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2397, R²: -0.0006

============================================================
🔄 Round 646 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 646 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0016
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0020
============================================================


📊 Round 646 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2397, R²: -0.0006

============================================================
🔄 Round 651 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 651 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0017
   Val:   Loss=0.0800, RMSE=0.2828, R²=-0.0015
============================================================


============================================================
🔄 Round 652 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 652 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0006
   Val:   Loss=0.0822, RMSE=0.2867, R²=0.0040
============================================================


============================================================
🔄 Round 654 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 654 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0018
   Val:   Loss=0.0818, RMSE=0.2861, R²=-0.0000
============================================================


📊 Round 654 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2397, R²: -0.0006

============================================================
🔄 Round 657 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 657 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0001
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0011
============================================================


============================================================
🔄 Round 658 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 658 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0028
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0055
============================================================


📊 Round 658 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2397, R²: -0.0006

============================================================
🔄 Round 659 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 659 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0017
   Val:   Loss=0.0896, RMSE=0.2993, R²=-0.0001
============================================================


============================================================
🔄 Round 660 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 660 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0012
   Val:   Loss=0.0748, RMSE=0.2735, R²=0.0017
============================================================


📊 Round 660 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2397, R²: -0.0006

============================================================
🔄 Round 661 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 661 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0001
   Val:   Loss=0.0778, RMSE=0.2789, R²=0.0044
============================================================


📊 Round 661 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2397, R²: -0.0008

📊 Round 661 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2397, R²: -0.0009

📊 Round 661 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2397, R²: -0.0010

============================================================
🔄 Round 666 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 666 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0040
   Val:   Loss=0.0853, RMSE=0.2920, R²=-0.0158
============================================================


============================================================
🔄 Round 667 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 667 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=-0.0000
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0027
============================================================


============================================================
🔄 Round 669 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 669 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0017
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0011
============================================================


📊 Round 669 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2397, R²: -0.0008

============================================================
🔄 Round 670 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 670 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0016
   Val:   Loss=0.0773, RMSE=0.2780, R²=-0.0084
============================================================


============================================================
🔄 Round 672 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 672 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0005
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0077
============================================================


📊 Round 672 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2397, R²: -0.0008

============================================================
🔄 Round 673 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 673 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0004
   Val:   Loss=0.0775, RMSE=0.2784, R²=0.0075
============================================================


============================================================
🔄 Round 675 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 675 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0000
   Val:   Loss=0.0803, RMSE=0.2833, R²=0.0070
============================================================


============================================================
🔄 Round 677 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 677 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0011
   Val:   Loss=0.0875, RMSE=0.2959, R²=0.0032
============================================================


============================================================
🔄 Round 679 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 679 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0013
   Val:   Loss=0.0752, RMSE=0.2743, R²=0.0017
============================================================


============================================================
🔄 Round 680 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 680 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0008
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0091
============================================================


📊 Round 680 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2397, R²: -0.0006

📊 Round 680 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2397, R²: -0.0006

📊 Round 680 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2397, R²: -0.0006

============================================================
🔄 Round 686 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 686 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0016
   Val:   Loss=0.0824, RMSE=0.2870, R²=0.0005
============================================================


📊 Round 686 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2397, R²: -0.0006

📊 Round 686 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2397, R²: -0.0004

============================================================
🔄 Round 690 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0722 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0722, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0722)

============================================================
📊 Round 690 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0006
   Val:   Loss=0.0722, RMSE=0.2688, R²=0.0083
============================================================


📊 Round 690 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2397, R²: -0.0004

============================================================
🔄 Round 691 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 691 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0006
   Val:   Loss=0.0837, RMSE=0.2893, R²=0.0023
============================================================


============================================================
🔄 Round 693 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 693 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0002
   Val:   Loss=0.0746, RMSE=0.2731, R²=0.0084
============================================================


📊 Round 693 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2397, R²: -0.0006

📊 Round 693 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2397, R²: -0.0006

============================================================
🔄 Round 697 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 697 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0017
   Val:   Loss=0.0774, RMSE=0.2781, R²=-0.0028
============================================================


📊 Round 697 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2397, R²: -0.0008

📊 Round 697 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2397, R²: -0.0009

============================================================
🔄 Round 701 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 701 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0024
   Val:   Loss=0.0762, RMSE=0.2761, R²=-0.0102
============================================================


📊 Round 701 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2397, R²: -0.0009

============================================================
🔄 Round 703 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 703 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0021
   Val:   Loss=0.0773, RMSE=0.2781, R²=-0.0085
============================================================


📊 Round 703 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2397, R²: -0.0009

============================================================
🔄 Round 705 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 705 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0025
   Val:   Loss=0.0777, RMSE=0.2787, R²=-0.0050
============================================================


📊 Round 705 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2397, R²: -0.0009

📊 Round 705 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2397, R²: -0.0009

📊 Round 705 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2397, R²: -0.0008

============================================================
🔄 Round 710 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 710 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=0.0020
   Val:   Loss=0.0851, RMSE=0.2918, R²=-0.0015
============================================================


📊 Round 710 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2397, R²: -0.0009

📊 Round 710 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2397, R²: -0.0009

📊 Round 710 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2397, R²: -0.0010

============================================================
🔄 Round 717 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 717 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0008
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0014
============================================================


📊 Round 717 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2398, R²: -0.0013

============================================================
🔄 Round 718 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 718 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0003
   Val:   Loss=0.0799, RMSE=0.2826, R²=0.0020
============================================================


📊 Round 718 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2397, R²: -0.0010

============================================================
🔄 Round 719 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 719 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0003
   Val:   Loss=0.0837, RMSE=0.2892, R²=-0.0032
============================================================


============================================================
🔄 Round 720 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 720 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0017
   Val:   Loss=0.0763, RMSE=0.2761, R²=-0.0052
============================================================


============================================================
🔄 Round 723 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 723 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0009
   Val:   Loss=0.0830, RMSE=0.2881, R²=0.0001
============================================================


📊 Round 723 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2397, R²: -0.0008

============================================================
🔄 Round 727 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 727 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0014
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0231
============================================================


============================================================
🔄 Round 728 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 728 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0000
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0051
============================================================


============================================================
🔄 Round 729 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 729 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0020
   Val:   Loss=0.0738, RMSE=0.2716, R²=-0.0033
============================================================


📊 Round 729 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2397, R²: -0.0008

📊 Round 729 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2397, R²: -0.0005

============================================================
🔄 Round 733 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 733 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0006
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0040
============================================================


📊 Round 733 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2397, R²: -0.0004

============================================================
🔄 Round 735 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 735 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0024
   Val:   Loss=0.0758, RMSE=0.2753, R²=-0.0052
============================================================


📊 Round 735 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2397, R²: -0.0004

📊 Round 735 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2397, R²: -0.0004

📊 Round 735 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2397, R²: -0.0006

📊 Round 735 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2397, R²: -0.0005

============================================================
🔄 Round 742 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 742 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2842, R²=0.0021
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0109
============================================================


📊 Round 742 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2397, R²: -0.0005

============================================================
🔄 Round 745 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0721, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0721, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 745 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0011
   Val:   Loss=0.0721, RMSE=0.2686, R²=0.0025
============================================================


============================================================
🔄 Round 746 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 746 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0022
   Val:   Loss=0.0888, RMSE=0.2980, R²=-0.0137
============================================================


============================================================
🔄 Round 747 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 747 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0010
   Val:   Loss=0.0807, RMSE=0.2841, R²=0.0005
============================================================


📊 Round 747 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2396, R²: -0.0002

============================================================
🔄 Round 749 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 749 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2822, R²=0.0004
   Val:   Loss=0.0887, RMSE=0.2979, R²=0.0018
============================================================


📊 Round 749 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2397, R²: -0.0002

============================================================
🔄 Round 751 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 751 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0004
   Val:   Loss=0.0839, RMSE=0.2896, R²=0.0018
============================================================


📊 Round 751 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2397, R²: -0.0004

============================================================
🔄 Round 752 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 752 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0022
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0132
============================================================


============================================================
🔄 Round 755 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 755 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0003
   Val:   Loss=0.0864, RMSE=0.2939, R²=0.0003
============================================================


============================================================
🔄 Round 758 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 758 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=-0.0012
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0088
============================================================


📊 Round 758 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2397, R²: -0.0010

============================================================
🔄 Round 759 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 759 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0005
   Val:   Loss=0.0758, RMSE=0.2753, R²=0.0033
============================================================


============================================================
🔄 Round 760 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 760 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0025
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0116
============================================================


📊 Round 760 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2398, R²: -0.0012

============================================================
🔄 Round 762 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 762 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=0.0009
   Val:   Loss=0.0769, RMSE=0.2773, R²=-0.0158
============================================================


📊 Round 762 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2398, R²: -0.0011

📊 Round 762 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2397, R²: -0.0010

📊 Round 762 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2398, R²: -0.0012

============================================================
🔄 Round 771 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 771 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0006
   Val:   Loss=0.0846, RMSE=0.2909, R²=0.0019
============================================================


============================================================
🔄 Round 772 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 772 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0019
   Val:   Loss=0.0801, RMSE=0.2831, R²=-0.0139
============================================================


📊 Round 772 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2397, R²: -0.0009

============================================================
🔄 Round 773 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 773 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=0.0017
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0009
============================================================


📊 Round 773 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2397, R²: -0.0007

============================================================
🔄 Round 775 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0717 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0718, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0718, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0718, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0720, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0717)

============================================================
📊 Round 775 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0030
   Val:   Loss=0.0717, RMSE=0.2678, R²=-0.0057
============================================================


📊 Round 775 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2397, R²: -0.0007

📊 Round 775 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2397, R²: -0.0005

============================================================
🔄 Round 781 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 781 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0020
   Val:   Loss=0.0809, RMSE=0.2844, R²=-0.0097
============================================================


============================================================
🔄 Round 783 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 783 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=-0.0009
   Val:   Loss=0.0853, RMSE=0.2920, R²=-0.0210
============================================================


============================================================
🔄 Round 784 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 784 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=0.0016
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0001
============================================================


❌ Client client_6 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8692 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8692 {grpc_status:14, grpc_message:"Socket closed"}"
>
