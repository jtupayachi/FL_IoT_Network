[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52be5856-5751-435a-97bb-c482573f1829
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb903910-2eec-40e6-8a20-0a8c29d1c971
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1fe6319-0038-44c4-adcf-3016f4de8859
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 203bffdc-0d88-4233-a598-439779397409
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8bc2115e-44b1-4958-bb50-fba7784d6757
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 453ff942-a2f4-43e6-97b7-3deae4dbe3da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 598e71da-a3f7-4784-bbe7-714bb54ba1c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ed8be7a-04f3-4a62-b964-9afabea8743e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 645ceb8b-425b-4091-b703-5b7f66d64f5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 311803bd-c885-4ef8-b1bb-9561dbd73da3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a40f396c-fca5-4fd0-8d8a-7f999c500c79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a0a8ae0-9ce5-4938-b6b5-1221cab5751c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c857d2b-f486-443c-a1d1-2c0caa8356a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d946696-cf45-4d8a-bd66-8b30a1450558
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d3e7073-2dfb-42d5-b2c1-1754307c9e18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 495dec29-485a-45d5-9905-04ea0019bf6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c23d0214-0698-4c8e-a8c2-8e975ee0b6e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32f74a0b-9047-4a19-a73a-b0d2a6d7c372
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a1e8408-8069-4e0e-84cb-590444eb7d15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e9a067b-b755-49e4-b6c1-9be593da4241
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa1e675f-aebc-42a4-90fe-66213e3a5ded
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee9e2b2c-be1f-4bc4-9bdc-c9b04016263f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ead539cd-4f17-4808-9152-66a510358ef8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43575e1f-5c38-4d73-9d61-1edc2579c39f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bebb8834-7426-4fa5-a23a-6e92fd9c5f43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 287c4468-ed78-40be-859c-26fd57f17222
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5d9463d-f4cf-47c2-9773-9516c9765dc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b0bc447-9ba9-466f-887a-94146092c8ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fcbca62d-2830-41de-ad76-72d36819f098
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cde6a699-b0b1-4087-97d8-cd798a4e5431
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22f80c39-17da-4839-8fbf-d24d19a1773e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7dbd9e36-4d44-403f-a161-2bffe46147c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b291852c-ded0-47d6-b343-52a6f8d43028
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f636783-4f95-4237-8c6e-e2d92015601c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24bde76c-dbde-4f47-ae57-02f1c5157492
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ddb90003-ae1d-4837-b80d-90b1f61ef499
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b8f29a5-2e17-47d3-a282-33ae7a3235a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1682214-116d-4eab-98e2-2f147a387549
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ec137f0-8a1b-4716-92fd-f20fc3d90e30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 375381df-1244-46b5-b7c3-71d05e9a29d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 413cc5fb-9ced-478d-884c-2c59df7b732d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ddab47e-db82-45e5-a9a0-7fec0b915f4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70316a78-4326-471e-be75-d676c70d8356
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ff1f8fd-293b-4458-b6af-a9bc4f9b6f89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8da237f-59ba-416d-b13e-dc961d85c4a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a69179c5-7d82-4ed6-8e24-6c0cf1e54846
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82eb1770-fe9d-4eb0-8518-b351e17bd8de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5abd0fe2-e2fe-4f3e-a686-9245f38b4731
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e3e8259-d8dd-4142-9934-f499248b1d1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28f32437-8c6a-4414-b09c-adbb16b8f153
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 770a43e5-a89d-4c7f-b823-078a3ed36949
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dcfa3b02-c087-4a66-b7ce-4526a8369260
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64336caa-d140-45cf-8b05-e07f00da3fe2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d55071f0-f1d5-4247-96b7-405c34abe2c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c9673d0-8033-485c-9042-c737988fce0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de37d1a0-d0df-4f46-ab3e-6419a4e94337
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d0ddd19-3e86-41ae-aa34-f68a743c735d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2dcafb5c-5ac5-436f-92e7-633cf0e94dfd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3e3e481-0bc6-43d3-9cdf-fb3ee260c9d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64a49fbe-4a9c-4c05-b6a7-54518dbe4ae3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c9cbb13-03f0-41db-bbdf-ff2059d6254c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d76e74a3-27d9-46a3-bee9-f12e0baa95d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98770412-98ac-46f8-8aba-85466b30c511
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4d57b96-3c20-4d2c-9ba7-11e60c8f2835
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f166b0e-e6c6-4883-a156-5c58144f2b32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93c9f767-4625-48ea-b25d-94e621f77084
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b28c38da-9061-43f9-994f-75a15f6eea1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5a80cdf-6b03-4d1c-8de4-a5650f53afe1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 297476ea-d565-42b8-a6d6-5f148c155dfc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9a31b45-ca63-4dfc-a9b8-d2b177a05e2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 222a9786-d7d0-4ff2-a20c-34f0b5c1dacf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6fd52afd-2402-48d8-926b-aa9f60a3981b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d7739aa-b04a-4ae5-95ec-6b66f097c5c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d85689b-b271-4591-80d4-f7bbe95bf0ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d114f0e1-5871-470e-aae0-6bc61500bb38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83952e99-6dc4-4672-98ed-0a31196bdee2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1e2a4fc-437f-487a-aa71-ba8d6d3dc882
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0a8c170-7b53-47da-a10b-185112610afc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 721df6e0-1807-4f70-92f0-b843111761e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 201092ea-038e-452a-9540-f89043880106
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 217ffd4c-210c-48b0-8ec8-3880dae658e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d80d8d5a-9a19-4bb1-b844-851fecb5ce24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 924a4520-3762-4159-b3b9-74d145d07480
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f747e444-de52-42d6-b45d-a68583353f2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8bec927-b674-4366-b56a-7eaa71be7a74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b272f9f9-7d66-4e41-b3ab-ab00f6eca7cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43e6a9bf-4c5f-4804-b1de-5b263f63e1f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e7538de-6530-473a-984d-af72f7db7e07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de598020-0813-48f6-8aa9-eab2dbcb124c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b61b05b6-2433-4862-bd49-e680b2d70ecf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d245e650-6747-4e50-a39c-1ceb07a7040c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 806e02a0-9fe4-4372-be1e-c4311cc7f3a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18066bc1-a9f0-48c7-b234-288e51e8a433
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73f80d0b-5176-4774-a90e-9110fa87ce40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a225437-cd0c-4593-befa-291014e85d0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 385de149-0023-4951-b0cd-3c35fef97b78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b21b8d49-3ad8-4362-8f7a-e50072f7b02b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bcc11ae6-e08b-492b-be24-b2e74466e535
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02a0504d-fd0a-4fbd-8e84-b4659bd7e7ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message daf41426-16e1-4d25-98bf-8caf0411abb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf386221-7465-4489-a8bf-75493c0f25a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a21ce18-b1e4-457c-ab7c-80d2c8e4cc46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e5a2c1d-707a-477e-aa01-76deaa86e69b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5f0dda4-8251-45c4-ac02-361e6f254378
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b83b1ca-e8a2-4520-8b53-d65525ace297
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 485e4cf6-ce24-4d40-b8c0-766aacdf8439
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff624274-813d-4ddc-bc66-b4eec89618eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59a05fa6-128e-45fa-b6cd-fb23b914aa65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message beac6d93-6a41-44db-86b6-070e98f935d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e69cd58-8386-4652-b25c-842bc279a6bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4050c90b-a206-4097-907e-0b6b5ec66e3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 873cd0bc-2820-4688-b6fb-c509cb7a4134
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b72c42b1-50db-448f-8d25-bc2c54795ce4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65b1c5ab-b4dc-4151-b0fb-dd2061b51f68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2fb12ab5-d97f-42ae-9612-dc1d438bee28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 896b95e3-0531-48d7-95b1-45f5ef6d67e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34617f01-7aca-4047-9aa7-b9fc817c3bbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc151f6d-8717-43d8-9c98-a4f6e17cd36f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9312e859-6237-4d0b-8c82-5bf3bec19935
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dcfac2fe-4055-4fcb-82d9-d6f127986b76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9bc584d1-9996-4556-9519-1d28e717588b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8455672a-041d-4da7-bcda-2eb7ac330a56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a54e97d1-807a-40a1-96b5-d71504dc7401
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f68cb06-00fd-47d8-b792-9deba411348e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5202b878-d5ca-488a-ae25-9c5e6d22e3f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5e2f0d0-edde-490d-8b13-9444031ff033
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74102e8f-4d28-4267-8d60-53df59ab14af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b61e8183-21bf-4dd5-87f8-10343d5093c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 031e027e-c212-45e2-a455-37b457962d80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f5f48da-dbdf-45e2-85a4-a5d54cee36cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e453b56e-ca2b-4865-a066-bdd3933cd42e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6c16bdf-7796-41db-94fe-51fd58d39028
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5bb57b7-7e4c-479f-8d4e-b53e4bb7de3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 212a22ea-e472-42c3-b83d-b0ff710b2831
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e6ebe82-524d-49de-823e-8253f076d2de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cfa3b335-15d2-46d1-a85c-c49f7482e663
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a5d445b-7f7d-4d61-bce4-414faf898d08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e906079-6d11-46e2-ad27-20dfe20f55ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8571c75b-65e7-4392-8941-8402159e1f8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9349fed-f30e-4004-a4b7-55859b56e4ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 825cf585-7cb7-4098-8394-98b22cf6de0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 888d9933-c606-4ec9-9ecc-a4eb32e3fdb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cce854a8-7721-4eca-b94a-63bb5f243dca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d77f0d53-82c5-487a-aa7a-55ce425c9adb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2335483-c7e9-4d26-912c-10b0bcc6a15d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0049698-ec77-4cbb-9bee-7f2310a38f21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66b87231-1898-4e13-a38c-439e47e06a37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b743665d-236d-433f-888e-db335fa5b704
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6fa9515-18d4-43f5-a1b7-035f7152384c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35d3c0eb-75b8-47e9-9832-592eff9ac411
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d0fc313-549d-4453-be56-ad78d7015b17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70b0a633-9e42-416b-b416-f3caf178e041
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df6aa8ea-a417-4a14-b73c-ad96d3320280
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70d861a0-c54a-4ff3-a747-f50c3b022742
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4dce7d61-5d29-4588-8e91-f228bdf593ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 527975fc-9131-404e-9ccf-78e9cf18c69b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd106c20-cf7a-4429-8422-56ba8094f0fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5dddfe7f-cd1f-42ce-a3c8-02ade41c0d6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c97d7ff9-8fa2-46a9-8cf9-f44081d383e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4560c513-7b91-4617-befb-8d5602a864d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3bc6be7-ca5b-4112-8763-41a81dc976ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dda13454-72ef-45db-84fd-bf7c92ee4a6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85325193-0e9c-4a22-b38d-9107ecc72fba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dae01e57-0774-45c5-ae86-c38809261232
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f479582a-181f-42d8-b6a3-54c8bdabe127
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1cee7d75-3a74-4fad-a9e0-7971484c2f2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fbdeee6e-80ec-4e47-9f67-af3eda7dcee3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 195987cf-4b56-4d17-be60-9a718bdcdcfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3efa579e-0ff4-420a-9424-f0fe048c45ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5359d8b4-184f-4257-8814-7fad6f5b056d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7710fe0f-9b72-4d6a-a99d-5c040e59cc42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f346926-f257-4274-afdf-27909d72d514
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07be508d-3508-4977-a853-2f8104478d23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5d19ce1-e72f-48d2-822b-9e8748ab1cfa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4adb4d54-6c91-4adc-a2b7-fa55c8691c43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b136d461-a623-45db-9fd6-3ba66dcb5f0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc654506-03f3-4c03-bf2b-fd149f75e0a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43c744d2-4877-46a1-b661-39e3be059762
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b203e1d4-db4c-471c-a1fc-da36f26bd177
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2784b1c4-cc69-4359-b347-f1d34366434e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 211fe6d2-3289-4c31-87eb-c222e9be39ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59efd7b0-0fb4-42b4-8a12-8248fad14c96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6828ccd-3c1c-4c90-a1d1-06f844a6394d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b61dc769-2edb-4261-a448-866bc00b221d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 219e39c6-15ca-45c2-8fc6-9b357c629120
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ee5a548-8df1-425a-ba48-3df803af6ba9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1b60404-2d84-4d79-b673-36242437b43d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f0cbaf3-e127-426e-9e05-a6d61ebfb8ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4239b5a-eef2-415b-ae55-1db1ec2b9b77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 948fab1f-0fe8-4995-bdf8-8adcfb592a05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61f22c61-3cb3-4996-bc15-0acc8dde145e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58dd12f6-88cd-451b-bc6d-c8ec9cb9eab5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 579bd107-06fb-43a7-ad57-4fad74fbba06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6aa849e3-4325-492f-81ad-1471e00ae8d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 246ec5e9-bec3-444f-8d2a-e2f2e7bd415d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 352db6bc-895a-4b6d-8a0a-abe4bb975600
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0a66917-624c-4694-a1f4-73682ee3fbef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a450fd27-b457-4a43-ab16-1ccd99c64c7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8619cd84-bfc8-4007-bc35-d5abaa6a54f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2f816c6-1b0f-4699-a61b-5407a87184c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d78e2a73-43ab-4dc2-95fd-95bda01de7c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64306842-9c60-4b78-a60d-4e0d071e59e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2875a677-42ea-492e-b6b9-6cf886baba88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45e47e12-da9e-4a39-bf95-db45dd8dd6b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0ca74a7-ef3e-4edd-8bbd-6b8f39af22ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b8817f9-7855-4af7-9574-b0ee222322f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c1fbe30-6773-43f1-8d56-50cc30793dd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e8865e5-8f0a-49ab-8b07-214d13234e43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8227ef0f-0567-4d17-a46d-82a2439714da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e073185-2ccd-4057-8aa8-5b1ba9770744
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b3c4311-a3ec-4a5b-9d13-2ff9c0a1685c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e0481e1-6933-4587-be39-7560a680c40c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52f73209-2d82-4fa4-950a-6117780703b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0be2c2c9-6ae4-40be-9170-6f6c4e0ea4d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 083cc37f-2164-4920-8e4c-b6ee60b3493a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66b9226b-eaf9-417a-98d0-1505d86f03ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee7f88d7-df16-4fa1-a5b6-d44ddf0c45e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e61ca370-c3aa-4be6-b395-59f3d38a7b81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65905c89-f0e7-4e01-ba33-b7ac20490af9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 960d737a-e4e2-4b81-8d35-5ff272a85133
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b85533c9-53fd-42db-b0ec-0cef73eaedae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49b436d5-72a5-4ed2-b5c8-c25c3ebef222
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39573b4c-77e5-4c25-acce-52d5c2f0e88f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 484ccdea-7082-4bbb-bb4b-e2450822d606
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06d32ae4-e1be-4110-8cd1-1945003b6ed5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 993574a2-75b8-4b32-b9c3-9c8d0829cfce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc64d3b2-fd62-4ff4-b98c-3a368d67c3c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d66d6029-c988-4fe9-b685-a5d83a0357bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 468dd41c-537a-4d40-a479-ba1ce6998885
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 787981a7-7bc4-4bf5-90da-e49e7daaa2f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dab28c2f-c87f-4495-8e3e-80da99dcbfcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6217d16-8c3c-4199-83c0-394cd6283c81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ec66273-0445-48ae-85a4-4b1c4a6341e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd4cbb15-6e78-4994-82da-4701010f3527
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8952266-50f4-4d40-b7e3-18123ceb9883
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe343841-0422-4fff-a6be-9a9838c6b186
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 784effeb-7c21-47f2-a0a0-28d4ee829fb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5918ed8-0e22-43a2-bf77-bbb9cb888c22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 117588cf-dec8-4010-9ffa-5612973f624c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9fe4ac8f-36b8-4dc3-94e0-00c6d90db1f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5ccda4e-02ea-4197-b732-a0cd981c1c77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f2bf67e-ca04-4dcd-8318-ea654d37dde8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dda0ad53-15dc-42d4-8b3f-7fec0cb2993f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3abcc2fc-5fba-4fdc-89eb-2fb1e7467141
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae1c477e-fddd-443d-b89b-0e582b326906
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41c8df65-53c0-4b19-8616-5c9ae1a3b65f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c63d0fc-7476-4c96-8ead-7f7677b5c402
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb3ce032-7c4f-48fd-be0d-37de83050f49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f11f7571-9798-43df-b585-59a88607eb04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e72d99a-87e6-46b5-ac7e-6b9b89ce7db5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f10261dc-ea95-4b06-a60a-0e67044e08d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 042b71d0-843f-4a29-8416-ff7e8cf2504a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b98fd2ab-dd9d-4b77-be50-c2f414fa553f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce14590f-c199-4300-ad47-ae6f4098d930
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5beea49c-3164-4073-8b82-192318aaa26f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e0c7e7c-e74b-45c0-a7f9-06667353b1bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b87d3b9d-d3ab-4329-bdaf-30a43cea73aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79c385f4-cffa-4371-986d-e581b8d83717
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14906ae2-dac8-4f75-9dc1-9e81bff9dda9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d17c8fb-c465-4c42-8298-1773ae45e145
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b57dfef2-6af3-4d87-9631-cae73c8ca1e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 937f4e5a-618d-4e09-bbe5-7ac249485958
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34ebb3a6-828c-4530-b4e6-df87a6d039c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c3ee19e-e1e0-4d04-bb0b-13fca01ff21f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message efb359d1-3935-43b5-8d19-5b01d4410b90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a82e244-7ba7-4f22-996a-a84a1421c3d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2573fcd-ba3a-4018-b126-c6166ad1aef2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e604d84-d7ee-4bab-9b6c-8e96c250f4ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7cce05b-6f77-4ce7-9ef4-8dc25b48900a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 974ca651-12f6-48cc-86f3-1adcbc5ef04c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c4c058c-37df-4937-be1c-f7074a0c2451
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62e636f2-d49d-4e50-a4b1-6d0db3400010
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da15f6a5-94e7-48bb-b327-ffef2a164113
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4e46d34-71b3-4663-8b8b-304429f8184f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4ee6a56-3ec1-48f9-b746-8ff1ff0d1919
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d187742-9719-462b-839e-259e1404a732
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 819ed802-9a39-475a-8151-7dfc9ba1854e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 306fb9a9-64b6-4edd-8528-9da1b1f97b2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bafce8ad-77ac-446c-9892-3d54423f61fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10a7e241-ce76-413a-8e0e-1c78b746c9bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ed8f5c3-c25e-4a5c-97d7-40daec915ad4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ce4e305-d389-4cef-b301-6ad569c7bb84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 014f0a14-a035-4e84-8b29-54c6adeeacdf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55eb5e8e-f8aa-484d-8948-465553b059c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60ea3c7a-4118-4069-9648-a5b054e41c98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 019fbddd-ea0e-4b57-a470-ae43b9207175
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 680d2cfe-084a-4936-9436-d1a9d0bfb409
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9fdd55b-30b3-40ec-b7ed-f91c5de3120d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a46fb33-282d-46cd-b5f6-bfcb48392db1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 571fa8d2-1c7b-4bdd-af58-c639704edaef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7bb4209-8c8e-42a0-9b5e-ccf48dd7d898
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a38de5c-2514-4cde-acfb-004cb23bd7a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a19b0960-2c52-4305-b768-3ee43aad41cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3049864f-19ee-462c-a1e6-86ec5fc5be44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7dd7ca86-a502-4719-9dd6-4a97339a418b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 744ce1ff-2999-4d1f-875a-5b974c81b298
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4bffe11e-26ec-4236-ad21-6a897fa9eb74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7636f7d-c5c2-46e0-99c4-cdd66dde7e30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac76bcab-58b2-4f5d-808b-ead7a6fb76ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 813456f2-b0d6-49e3-86a6-46bf6d49da02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de2d1b48-8061-427f-85bd-c09ea8bea28f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87031207-fb91-4338-a724-01fccac6637d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b26c70e-c0b9-4520-a210-c23b3c14687b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d693095-876e-4a47-9c68-5d1fcbc6f25b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5ad97c1-79ce-4e2e-a8d9-7fa140b6d668
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6744ab09-7e9a-4ce1-bc84-4df2e9b05d40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b23b2a72-0866-404f-9acb-6e74f9b5b42f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08b47dee-d54c-44f6-883f-4b3157289209
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc962116-96ca-4932-9765-731961bd09eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc993ed7-6cfe-446b-8515-3264a2ee1f2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 462ffca3-addc-48a4-ab02-dbf41b7eb493
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61123c7d-1aef-4dd7-be91-56a3a153c209
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d07ed0e6-ecfb-4d2a-9cca-36673dd3048a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57c5a225-c675-40b1-933d-6190ff973bb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cbeba508-f81f-4a0f-bb3d-3c6d47ae839b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17eeaeab-1f85-47da-a039-bf8abef2f140
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a440b4e-8c65-42b0-9870-197e9c4faea7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8e26679-e4f1-4979-964d-11eabed41eda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e38f1a5-82ff-4566-82c8-11c753a7d980
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9e13472-e01d-4356-89c9-f36f5e9d227f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1287726d-86d6-4598-be4a-08fca2980baa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51001c3d-d1c3-4d2c-b889-af034731fd71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e059d79-c927-4521-a2ab-d0a368decb3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9d1330c-a0bb-41f6-8f64-e509aae9cf47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9cd15372-f64b-4bf2-9198-613f58a0e985
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49156c0a-076e-432a-91f4-0626066ed2b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a54e039e-5c23-4f3c-9bc7-1b74d8cb8598
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15c0c174-ef59-440b-80d4-297658c54240
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9a280ab-da61-428e-8589-2bb12621f3f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f89ebb51-c9dd-4b40-abc2-19703279c2ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32cc021d-34ed-46ae-996c-5ff671fdc480
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 278c3baf-2973-46c9-8443-dce1411384fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c2e6622-900b-4de8-9ca1-00781634e6d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a954d42-5aa5-431e-8185-0219577fd2fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df773c6f-e833-4192-86b3-0d905d42725d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7095639c-2ac3-493b-97f4-18f43672eb2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63df497a-0020-4643-8b5c-4e04ea718352
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c686a9d8-7224-4a76-9ced-e1105fcd4647
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0cbc0ad1-6180-4280-a538-917c6f11e9ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f48cfe0-39ef-4ea2-9194-c5ce130df2d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 927f0782-2809-446c-ab65-987c3126dd0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f27b6494-f400-4461-8d1c-bffbb671ffe6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c3b8816-4215-48e4-a000-e77d116c5bb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae2ba09d-24a2-49aa-8995-8aa7eb7e83d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25e1c62b-a188-4a05-876f-3fcc572141af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53d80b47-f7b1-44fe-81f9-e2b0a4ca477e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ffc3ba12-9492-4b02-a080-8c58a6ad177b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1dfe5721-9cec-4e07-a8ac-c3ffb4a85fe6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3fd25b82-4b1c-491f-bec3-abbfb684d333
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 648f52b8-4476-4a75-8ef7-40a21ea1f119
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91fdb0bd-ed9b-4241-8b55-03a01c653aff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a05da65b-bdc5-4a07-9518-9ed382ee6e40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb699685-44b5-4bfb-a97b-c96859aae565
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5efb648f-682e-4316-960c-7fd2c9f52dcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5de28f6-d9ae-40e2-9cfc-fcc1b079ba3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe5e3e0b-69b6-46b6-9d55-57899942ed52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9dc14196-8cfc-41aa-8038-4e56b7e90a34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e10bb38a-be76-486c-81ea-54f4ab9f0b3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 039f7a03-81a0-48d6-8e00-ff574b944f38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8e58c5b-98d7-4400-a7df-59dc90b2d0a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5297508-130f-49aa-99e3-a5d8888f29ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a721c69-8a7f-4271-ac49-9461c1c41ace
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d3ac819-549c-47f9-8efe-a0f7eed540bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76fe73d9-1708-4b7a-b287-7b1daed94a84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f182f515-65d4-4afd-8b7d-f288f88dc307
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f58487a7-9e0e-4078-907c-7a73cd3ac912
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e5ddc41-cc0d-4242-bbd1-d129b6f84c4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a115a212-80c6-4f20-aadf-b5675ab51b8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54c9d485-488c-42df-bc88-c600a19b2089
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e139e73a-d3f2-49ed-8357-634ed877f40a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97e8c41f-23e6-493e-9f44-d90842bd10a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c82e2dbc-dfc3-4a7a-b0b2-0e237e91fed7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea8c4a3b-1e7f-4f41-ba99-d4652c8cdfd8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4d2e133-20fd-4a28-a331-340458d3f8d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da0faa96-db20-437e-b013-122656c72437
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e2fcc8a-f500-42f5-a8c5-1bf0e6f27e1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20f89f17-3d77-47bb-ad02-fc848342e897
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1dba0422-23a8-45c8-a0ed-5907ef1291c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7727cdf1-7224-4423-b16d-d13be97d17e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9dedb1a-b5ed-4ff1-8a92-1563bb21f114
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f25a36f4-457c-4a54-9569-d033d72f2c9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f738c9bc-5928-4976-a6d0-3863227172cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b8d555d-832a-424f-8413-9148f6e57033
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f1a60c5-8f4b-470c-8168-36d2f422c27b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d781968e-96e9-4d42-8901-91c52f609f2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9430dd94-c4aa-47ec-b560-04ffe7866d91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c36de7c8-e63c-4ec5-abb1-0bee795517cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec957e4a-2657-4dd0-9c97-dfbd0de2a08d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e319288-ed7b-4dd1-b476-b6dd9a57c5a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e88589e-1d4a-4cda-992f-97600870ab40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a111f82f-9ce1-414d-807d-c1dcfdf4c0e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0737eb8b-6858-46a0-88ac-e34134c37930
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25e531da-3d5d-4e68-ba3a-ca5e6eaad50b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88405505-85e2-4367-873f-afe4beec9558
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4720ad3a-94e9-4550-a7a1-2bc03a196123
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af7a9f17-1bf8-4db0-afec-eba0ec0659fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91aae40b-6671-49ec-81c3-27a24c9aaaca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b095e41d-1276-44a5-9fed-1e624a80aeae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5090f00d-cb54-46a4-a018-1c03479f92e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb1fd24f-ba90-45c4-b9ba-ffa77c238d68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 177ee3c3-0f2f-4022-8c92-ec281bf01428
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f854e439-d566-4179-9374-c9b277094508
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a64b30e-198c-4414-9579-a48e0f0dd466
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05212553-f0bc-4292-b302-6552fa1b114f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f9c8b2f-527a-474e-9dd8-487aea124d06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7170c2d0-6297-4b66-902a-ef9d0e0ed73c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d1f53c2-aca9-4f1d-ad04-9d479096110e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2bf28a44-9c65-4a0c-ab30-08be0a61a583
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a74fa06-4889-4bc2-b0f6-a0afaa80a94a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66ff9900-81d8-4834-81c1-0d321fb2c436
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 856813ed-b63e-4ec6-a364-357e067efbee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30ce4d17-0349-4f40-b45e-c6aded8fac46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43efaa91-75c8-4323-901f-cf188ef22622
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8be8fd36-db42-4fe9-94cd-43c9473328ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a45d122d-26f5-48e5-906d-10aa0fcd12e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4be0b5a3-f546-4748-a461-35421f9d85ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fccd344a-e445-4f4d-8e5a-2a97f4e1b9fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2acf49c0-6958-4a49-943a-5d91932ddacc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 154e436b-525f-4026-a682-b895b32d224c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a9d4194-82fe-4220-86ac-12e774e8552a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ce918a5-2b8a-4f52-b50b-275ec38d8757
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25e5de71-fbfb-4683-8041-d12ed9a1af63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76003d56-7aa5-4bc7-aa06-8b1cdd861c1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dbcb2de6-9180-418f-9a7b-5291d12cdabb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0f133bf-0edb-43a2-9e6b-25884879dce3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a14c0766-c88f-4d8f-8a4c-e0b863a41c24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d28d8510-3381-495b-a8d5-2533b0922117
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c07d934f-4a90-4e66-a9d6-47a06014e7c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b1b2a7b-f560-4a40-8a47-87e53129b877
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88254470-d41f-484b-9568-5f599cac1cfc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01704289-1020-439c-b91b-0e1135094d8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5574ef4-9207-41f7-a4fb-f2ae300267a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e002b87d-3cef-4259-8125-cebff334bf79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6dfad2bf-2496-4135-a111-9bdbe721bbc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc7ae490-cd46-426c-9d8c-b4d825ed180c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1315ea3-8582-40f1-82cb-014744f7a49a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b5ab5bf-8291-4c15-a308-3b0c1aba5fd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c81cb498-3fc3-4196-a076-293fd13c982d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae9cb846-f927-48dc-89ca-fdf6a5d3322c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b009734-da51-46bd-8e0c-a1c107a0ed09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b6d2d1c-bffb-4ef5-85e2-9f6ce18cf11d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37a7fd54-2dfe-4566-9889-fd86cd1abf4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4afd141b-a610-4736-81ce-c15035534066
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e295deb2-9d13-4763-9c7d-d8ed004d3080
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7e33f27-a6e0-4670-881c-4411b2b9b19e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6fc8f67-bdaf-4491-a1f4-ec968b727aff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8db4d60f-7557-4937-b70f-2fc494f0bb92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3029b1db-aea9-47fc-8e33-16ecae7f52de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 959b5056-010b-44ce-bb71-8a28b5d99c01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 112267f3-cfbb-446c-81f0-bd80e3e8b6b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 083f34d0-f334-434b-82d4-0c5bdb66bfe9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00abaed1-024e-465a-b920-9e2382b7afac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7747c7d-5283-454c-9585-e8a5e69ec904
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de9a14f2-c00e-44c7-8147-b8608b0f70bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed2b00ca-8e29-496e-b57e-2371472529d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a872549-d540-495b-89ca-e9ed387629a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed276eda-8d7e-440a-927a-b7b907b0b1fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e5efa94-3210-4501-bdb8-2e86c864bcaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message abb59ba4-c500-4234-8cb9-f1c493e0ab76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0f3bac0-fddf-4e1d-a457-6f1d3b6d08c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b253a08-cda8-473b-a2cd-1c87ba7cf73d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1fff5bf-a3d0-408f-9b26-03a94bbdf3fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55241000-0eaf-48bc-9763-5428bf11fcc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5f15851-4174-4392-b62b-bd8c22718a91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b18cafe-7d0d-4874-b8a6-2acb1e13e174
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7ae7e5f-e44b-4ae2-9a58-bf2e9d08841e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7bdccaeb-a070-4e70-9987-f4eadf798857
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00a17bf5-f31c-4da1-9d5a-ceeaca2a3ab4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59270ee7-efd3-438a-b0c4-00ac55a94986
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c474c14-4586-4586-88e6-d0921d2c7fa1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 443ed7c1-19ce-493b-8d7d-d2b598c0886d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e7c8fd0-46bb-486b-a14d-ccf4cad4248a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b678dd5c-db78-430b-8a9c-efb815924362
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc7c8ae0-9b7a-43b8-a6bd-354617422117
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 565ea66a-1aad-4f90-92ea-4d11b4c230f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75125402-035c-4fbf-94f5-cc3c9da61bbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f40779b1-2212-45d9-b86c-eb346d5c8e6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ca12016-066f-41e1-8d0c-bb3df2d7a8bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6cbf4ae-71e0-47ea-b0aa-9cd2d68a5697
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2501b446-4348-45d5-a158-86dab011e87c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a3cfb2d-3ae7-4799-8b96-49198b34f4ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c5f9fad-e1ae-47ea-ac9b-e2648139384d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 429ddf5d-2354-47c9-b782-64cfdb9ddcb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e267397-8744-4a36-8318-adc83ce008fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2cc2d66b-6d61-4c37-a8c5-eda0f8763508
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e351d25b-299d-40db-ae7a-5a27046306f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f4fb6bf-aad4-432f-bebf-906bd8411bd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 777fc65b-da7f-4421-bdb0-37ee36c629cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9fcd1cb1-4bc1-4983-8e59-49c18ae19e02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3cf94e0-ed66-473a-b117-f0c0811838ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2c5f308-4e7f-4e0f-a8f4-d45a40228855
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf46d16e-ea8e-4332-9795-4305d67fd1e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3d8621f-a3b9-441a-b58d-c8d0079c48ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e50affb0-58f4-4cf5-abd8-25add9813234
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 455f5105-6232-4727-8255-d951b5151eaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0624e56-9567-4e3f-8617-6c18c764991a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2cef097-d951-4d72-ba41-39fae184f1f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 256f989b-1ae7-4963-a509-f6bf5537b460
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7111435-dcea-4fce-9037-24a2fe3fac66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db569e5f-b709-43d3-b1e3-2ddc1bcf62b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b01f9e81-326f-4775-b763-7be67af15672
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0fe98a25-2a74-4c25-b895-b129ceeffddb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f35a386-25b9-48dd-b7dd-f7fbd58f5d32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 895a60ea-a1b0-4b35-b209-32cf8737307b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3daf48e4-5c34-49a2-a323-e791f7e90f88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71e8ca03-8d80-4692-9232-00753b8c9da1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2bb9ce7-4486-488c-8d5a-28780dfe47f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59fe003c-d8ee-4cf2-8108-fd7100aa7507
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 931d0952-e37f-42d7-a133-ec5b2d4c7910
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4ca9dc4-5e76-4bb1-a4da-c46497c7e390
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3ddb489-b87f-4ffb-b48f-a6cb9e53d0a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1dc02c1-eab3-41c7-9386-94d869ed3726
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53832f4d-55d2-4eaa-a288-d0967efa9a65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ef89c25-b4df-4dd4-96df-f57019d4fc31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7153f669-882b-418e-82b2-913bc84480e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8549d0d7-642e-4bb8-8229-c4cbfe7ed183
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ffa4020-8c51-41b9-a776-a56a24ec3781
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47e4f378-7730-4ae6-919f-bd4b422da66a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 218b67e1-e3b1-424e-8ea0-dedd9418d2bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4402b893-55e9-46ea-a152-a59380cc0268
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be1767e4-02e4-44b6-8ae8-1c0104ef0710
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc257daa-bf74-4f5c-8080-8e96d586b1a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message edfc8e7a-9822-4731-bc85-fa4b8bb6f6e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 833af3ab-c9cb-42ca-8eba-b8e017ec53bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68db4c6d-48fa-4d00-bf95-21ba2f1b5a74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e33f37a8-a13d-450b-956a-65d58d61dc87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a4ed178-d8f0-4bc5-8042-9442dd728e0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfd1f3d6-f9e7-4390-bb54-fde8b8183e78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7fe5508-763c-48ae-b8a6-bf3f880ec6c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a07b408-50ad-460d-9eae-1d6eb268fc9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eec5cda0-a591-4c1a-9464-5a095d362721
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4722e126-4acf-4c5a-94e6-82c0ef30aff7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71a3f3c2-5298-42bd-ae01-a8a570e27439
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2693ab9b-942f-4349-9aa8-53aab208029e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cdb36e65-f3c0-4124-85aa-4c43ccf1a787
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dbb1fb1c-68cf-474a-bd97-350cee5a4371
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4dd3dae-3b61-43bc-bfe2-f01493366d33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7935247-e3e6-4ae4-a360-fa7af12fa435
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3bba44d0-2985-4b48-b99e-29385ab5bb68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78e60b55-aedf-4f8d-9d9a-fd5161e08ca7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9222cc6e-3478-4785-ae6d-983984100c18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62416302-60da-47df-bb28-2fdeb30b8e07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7618a63-128b-443c-8967-484d7e53a365
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69227d54-067b-41c7-a801-e62fc0476410
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0d24d5d-6d85-47da-9861-c4d8a95b134d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c17c873b-3d4d-4e4a-8eda-c6225a8e3c89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message daa3fe0a-11b5-4395-8f0a-55160fb19ffc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20a5bc24-ee60-4b10-b032-e3ab22afc27a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6c8faaf-12a2-4f1f-bf48-8b9fd38c7acc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 863a4552-430e-497a-8b41-33c695701af5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d10dc0d8-948d-40ff-8c59-62843ff2cfa5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 103c41d9-c25f-485f-a03c-2dad3847580a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58a730cc-636b-412f-9b8d-b44d597142cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0e9d347-f644-4626-9ab3-b08a5d7ec624
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e557b3e8-9e48-4a80-a9bf-84e4e76c55c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9f01bb4-1715-4cde-a9fc-a90fa8f8eb5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f965362e-e4a6-4c44-b5f8-f491a80a7ae4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa30c33b-a95b-454d-858c-c57442e7bc6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 726c57bc-79e8-47be-8496-2c9f5a12b4cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b21a97d5-6c47-4976-82b5-030a51dedd12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9652ee1f-0480-4f10-aaa1-a9348118cedb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81d68d44-21af-4867-8761-52c7f4f57afd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab1c85d2-6b04-401f-8cdd-5bb670520c28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 297025de-c093-4c20-aae1-fc73dbcefd52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea2b12d2-bb22-4381-9853-ffef795a93f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ebc0e01f-5f1c-49e1-b0b9-f7dbc27bf577
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11f901a3-0fa0-4f6e-8ab6-af865795d76c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f5af253-bbe6-4841-8e5c-454a9d78b9cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b192b7d-ee5d-4662-8f7d-e5480cdc6c80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6849b8f0-282f-4b80-86e2-6ff3d705f086
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 745e0da1-3e44-4893-9302-09c97ac86c4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7bf06f3-d502-4a7b-a1f9-eb50c0f0186e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 846c8bd9-c3e9-4206-8550-4129a57b2904
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30e453f7-d71e-4703-a010-befc508ad920
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10ab4d91-7f03-483d-8b3c-c94d24cd03a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 656e1afd-9c06-4702-a62a-6cd1ee6b1a59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8858320-7414-4468-bced-05944f4fd9f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6ec60c6-eaa8-4c52-a497-08892d17248e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37cac2fd-df60-4e89-b263-b0dfeb5728ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84243b34-62d3-46b2-b765-a58029fb2d06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25092201-ce0d-4a82-b052-4e642b95a6a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb88aa0f-1d99-4227-9985-fdafbf76ceb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a572b240-4080-4b35-bf4c-f6cb663af1ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45f4db93-3f0e-4c0c-b3e0-6bba0989321b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce75c442-1283-40be-bc8b-ccdbbf2e59e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43a98b4b-79a6-4963-9acf-ff53d169f040
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5846fd3f-9089-4df1-b6c2-42e1ad5fcb1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb940cf7-3a4e-4922-bb4f-383209e79c87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37b9bf92-8c0c-4d21-a2dc-da5dac0b04e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message caaab7f7-fa6e-497d-b36b-0d04b06140d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02a9589c-e4b4-41be-844c-3cb3380081fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef879526-af56-4611-b841-a69043916b80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b41a024-ffa9-43bb-8285-0b73bec8a9ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58d7c715-1217-4264-b5cf-dfb804e615e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 056a5539-0196-407d-b791-3a568ce118a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66cbe636-7ab4-423a-b8b5-a19298713d00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ccee6e7-1cda-4cad-969f-6dc1e9f70ae0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72f436e8-2457-4158-980a-dcfc3f816947
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d55068a-183a-49e4-8bc7-4325490e4f02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a729de0-3fed-4a6e-8e98-f8999804cbca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11546381-8a0f-4d77-b466-fbeefd752342
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48ebd690-4bed-4e78-9731-3846a8dd6a47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5455ae96-2c89-45bf-8623-b55aae1c85b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e4b1171-5500-4271-8462-9719ab06363b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c39795e-845e-42d7-8d68-05d1918d50ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2864b3b5-988d-49df-a424-1984a00e99a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17f7832c-b763-4ed0-8d38-d67409d47db6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04fa662a-04b8-47f8-9113-c670e1beb2aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c745e6ea-9fb2-4226-aa36-fc8c762973a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20843c0e-123e-49d6-817a-682572b5e26f
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8692 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_7
Server: localhost:8692
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_7
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_7/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_7/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_7/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_7/test_labels.txt

📊 Raw data loaded:
   Train: X=(6192, 24), y=(6192,)
   Test:  X=(1549, 24), y=(1549,)

⚠️  Limiting training data: 6192 → 800 samples
⚠️  Limiting test data: 1549 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_7 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 1 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.3484, val=0.1626 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0908, val=0.0905 (↓), lr=0.001000
   ✓ Epoch   3/100: train=0.0862, val=0.0778 (↓), lr=0.001000
   • Epoch   4/100: train=0.0848, val=0.0779, patience=1/15, lr=0.001000
   • Epoch   5/100: train=0.0827, val=0.0781, patience=2/15, lr=0.001000
   • Epoch  11/100: train=0.0818, val=0.0770, patience=1/15, lr=0.001000
   • Epoch  21/100: train=0.0779, val=0.0761, patience=7/15, lr=0.001000
   • Epoch  31/100: train=0.0716, val=0.0749, patience=2/15, lr=0.001000
   📉 Epoch 40: LR reduced 0.001000 → 0.000500
   • Epoch  41/100: train=0.0635, val=0.0761, patience=9/15, lr=0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 1 Summary - Client client_7
   Epochs: 47/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0686, RMSE=0.2620, R²=0.1598
   Val:   Loss=0.0747, RMSE=0.2733, R²=0.0376
============================================================


📊 Round 1 Test Metrics:
   Loss: 0.5182, RMSE: 0.7198, MAE: 0.6603, R²: -5.2976

📊 Round 1 Test Metrics:
   Loss: 0.5062, RMSE: 0.7115, MAE: 0.6511, R²: -5.1520

============================================================
🔄 Round 5 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000500 → 0.000250
   ✓ Epoch   1/100: train=0.3836, val=0.2667 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.1893, val=0.0935 (↓), lr=0.000250
   ✓ Epoch   3/100: train=0.0895, val=0.0744 (↓), lr=0.000250
   • Epoch   4/100: train=0.0833, val=0.0741, patience=1/15, lr=0.000250
   ✓ Epoch   5/100: train=0.0837, val=0.0733 (↓), lr=0.000250
   • Epoch  11/100: train=0.0833, val=0.0732, patience=6/15, lr=0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 5 Summary - Client client_7
   Epochs: 20/100 (early stopped)
   LR: 0.000500 → 0.000250 (1 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0008
   Val:   Loss=0.0733, RMSE=0.2707, R²=-0.0047
============================================================


📊 Round 5 Test Metrics:
   Loss: 0.4993, RMSE: 0.7066, MAE: 0.6458, R²: -5.0678

📊 Round 5 Test Metrics:
   Loss: 0.4780, RMSE: 0.6914, MAE: 0.6291, R²: -4.8091

============================================================
🔄 Round 9 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.3923, val=0.3349 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.2409, val=0.1530 (↓), lr=0.000250
   ✓ Epoch   3/100: train=0.1008, val=0.0759 (↓), lr=0.000250
   • Epoch   4/100: train=0.0839, val=0.0759, patience=1/15, lr=0.000250
   • Epoch   5/100: train=0.0824, val=0.0769, patience=2/15, lr=0.000250
   📉 Epoch 6: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0823, val=0.0762, patience=8/15, lr=0.000125
   📉 Epoch 14: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 9 Summary - Client client_7
   Epochs: 18/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0084
   Val:   Loss=0.0759, RMSE=0.2755, R²=-0.0035
============================================================


============================================================
🔄 Round 11 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.4295, val=0.3547 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.3770, val=0.3077 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.3286, val=0.2640 (↓), lr=0.000063
   📉 Epoch 4: LR reduced 0.000063 → 0.000031
   ✓ Epoch   4/100: train=0.2772, val=0.2123 (↓), lr=0.000031
   ✓ Epoch   5/100: train=0.2307, val=0.1826 (↓), lr=0.000031
   ✓ Epoch  11/100: train=0.0902, val=0.0805 (↓), lr=0.000031
   📉 Epoch 12: LR reduced 0.000031 → 0.000016
   📉 Epoch 20: LR reduced 0.000016 → 0.000008
   • Epoch  21/100: train=0.0815, val=0.0807, patience=9/15, lr=0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 11 Summary - Client client_7
   Epochs: 27/100 (early stopped)
   LR: 0.000063 → 0.000008 (3 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0275
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0040
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.4493, RMSE: 0.6703, MAE: 0.6059, R²: -4.4608

============================================================
🔄 Round 13 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000008 → 0.000004
   ✓ Epoch   1/100: train=0.4220, val=0.3520 (↓), lr=0.000004
   ✓ Epoch   2/100: train=0.4172, val=0.3489 (↓), lr=0.000004
   ✓ Epoch   3/100: train=0.4137, val=0.3459 (↓), lr=0.000004
   ✓ Epoch   4/100: train=0.4105, val=0.3431 (↓), lr=0.000004
   ✓ Epoch   5/100: train=0.4076, val=0.3405 (↓), lr=0.000004
   📉 Epoch 9: LR reduced 0.000004 → 0.000002
   ✓ Epoch  11/100: train=0.3940, val=0.3291 (↓), lr=0.000002
   📉 Epoch 17: LR reduced 0.000002 → 0.000001
   ✓ Epoch  21/100: train=0.3851, val=0.3214 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.3802, val=0.3171 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.3757, val=0.3131 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.3714, val=0.3092 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.3673, val=0.3054 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.3631, val=0.3017 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.3590, val=0.2980 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.3549, val=0.2943 (↓), lr=0.000001

============================================================
📊 Round 13 Summary - Client client_7
   Epochs: 100/100
   LR: 0.000008 → 0.000001 (3 reductions)
   Train: Loss=0.3507, RMSE=0.5922, R²=-3.2562
   Val:   Loss=0.2909, RMSE=0.5394, R²=-2.9277
============================================================


============================================================
🔄 Round 14 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.3940, val=0.3892 (↓), lr=0.000001
   • Epoch   2/100: train=0.3935, val=0.3888, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.3931, val=0.3883 (↓), lr=0.000001
   • Epoch   4/100: train=0.3926, val=0.3879, patience=1/15, lr=0.000001
   ✓ Epoch   5/100: train=0.3922, val=0.3875 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.3897, val=0.3850 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.3857, val=0.3810 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.3817, val=0.3771 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.3778, val=0.3732 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.3739, val=0.3693 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.3700, val=0.3654 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.3661, val=0.3614 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.3621, val=0.3575 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.3581, val=0.3534 (↓), lr=0.000001

============================================================
📊 Round 14 Summary - Client client_7
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.3552, RMSE=0.5960, R²=-3.3552
   Val:   Loss=0.3498, RMSE=0.5914, R²=-3.3957
============================================================


============================================================
🔄 Round 15 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.3644, val=0.3811 (↓), lr=0.000001
   • Epoch   2/100: train=0.3640, val=0.3807, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.3636, val=0.3803 (↓), lr=0.000001
   • Epoch   4/100: train=0.3632, val=0.3799, patience=1/15, lr=0.000001
   ✓ Epoch   5/100: train=0.3628, val=0.3794 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.3603, val=0.3769 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.3561, val=0.3726 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.3520, val=0.3682 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.3478, val=0.3639 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.3435, val=0.3595 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.3392, val=0.3550 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.3348, val=0.3504 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.3303, val=0.3458 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.3258, val=0.3411 (↓), lr=0.000001

============================================================
📊 Round 15 Summary - Client client_7
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.3206, RMSE=0.5662, R²=-2.8995
   Val:   Loss=0.3368, RMSE=0.5803, R²=-3.3974
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.3593, RMSE: 0.5994, MAE: 0.5264, R²: -3.3669

============================================================
🔄 Round 16 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.3309, val=0.3869 (↓), lr=0.000001
   • Epoch   2/100: train=0.3305, val=0.3864, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.3300, val=0.3860 (↓), lr=0.000001
   • Epoch   4/100: train=0.3296, val=0.3855, patience=1/15, lr=0.000001
   ✓ Epoch   5/100: train=0.3292, val=0.3851 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.3267, val=0.3823 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.3225, val=0.3776 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.3182, val=0.3729 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.3138, val=0.3681 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.3093, val=0.3631 (↓), lr=0.000001
   • Epoch  61/100: train=0.3047, val=0.3581, patience=1/15, lr=0.000001
   ✓ Epoch  71/100: train=0.3001, val=0.3530 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.2954, val=0.3478 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.2905, val=0.3424 (↓), lr=0.000001

============================================================
📊 Round 16 Summary - Client client_7
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.2853, RMSE=0.5341, R²=-2.5796
   Val:   Loss=0.3375, RMSE=0.5810, R²=-2.9682
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.3305, RMSE: 0.5749, MAE: 0.4983, R²: -3.0172

============================================================
🔄 Round 17 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.3139, val=0.3103 (↓), lr=0.000001
   • Epoch   2/100: train=0.3134, val=0.3098, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.3129, val=0.3093 (↓), lr=0.000001
   • Epoch   4/100: train=0.3125, val=0.3088, patience=1/15, lr=0.000001
   ✓ Epoch   5/100: train=0.3120, val=0.3084 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.3091, val=0.3055 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.3043, val=0.3007 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.2994, val=0.2958 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.2944, val=0.2908 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.2893, val=0.2857 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.2840, val=0.2804 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.2786, val=0.2751 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.2731, val=0.2696 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.2674, val=0.2639 (↓), lr=0.000001

============================================================
📊 Round 17 Summary - Client client_7
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.2626, RMSE=0.5125, R²=-2.2398
   Val:   Loss=0.2588, RMSE=0.5087, R²=-2.1728
============================================================


============================================================
🔄 Round 19 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.2606, val=0.2980 (↓), lr=0.000001
   ✓ Epoch   2/100: train=0.2600, val=0.2974 (↓), lr=0.000001
   ✓ Epoch   3/100: train=0.2595, val=0.2967 (↓), lr=0.000001
   ✓ Epoch   4/100: train=0.2589, val=0.2961 (↓), lr=0.000001
   ✓ Epoch   5/100: train=0.2584, val=0.2955 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.2550, val=0.2918 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.2493, val=0.2854 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.2435, val=0.2789 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.2376, val=0.2723 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.2316, val=0.2655 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.2255, val=0.2587 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.2193, val=0.2517 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.2131, val=0.2446 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.2068, val=0.2375 (↓), lr=0.000001

============================================================
📊 Round 19 Summary - Client client_7
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.2000, RMSE=0.4472, R²=-1.4512
   Val:   Loss=0.2310, RMSE=0.4807, R²=-1.9749
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.2462, RMSE: 0.4962, MAE: 0.4142, R²: -1.9921

============================================================
🔄 Round 21 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1995, val=0.1929 (↓), lr=0.000001
   ✓ Epoch   2/100: train=0.1988, val=0.1922 (↓), lr=0.000001
   ✓ Epoch   3/100: train=0.1981, val=0.1915 (↓), lr=0.000001
   ✓ Epoch   4/100: train=0.1974, val=0.1908 (↓), lr=0.000001
   ✓ Epoch   5/100: train=0.1967, val=0.1902 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.1926, val=0.1861 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.1857, val=0.1794 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.1790, val=0.1729 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.1724, val=0.1664 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.1659, val=0.1601 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.1595, val=0.1539 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.1533, val=0.1479 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.1473, val=0.1421 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.1415, val=0.1365 (↓), lr=0.000001

============================================================
📊 Round 21 Summary - Client client_7
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1361, RMSE=0.3690, R²=-0.6787
   Val:   Loss=0.1316, RMSE=0.3628, R²=-0.6177
============================================================


============================================================
🔄 Round 23 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1404, val=0.1351 (↓), lr=0.000001
   ✓ Epoch   2/100: train=0.1398, val=0.1346 (↓), lr=0.000001
   ✓ Epoch   3/100: train=0.1393, val=0.1340 (↓), lr=0.000001
   ✓ Epoch   4/100: train=0.1387, val=0.1335 (↓), lr=0.000001
   ✓ Epoch   5/100: train=0.1382, val=0.1329 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.1349, val=0.1297 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.1297, val=0.1246 (↓), lr=0.000001
   • Epoch  31/100: train=0.1248, val=0.1197, patience=1/15, lr=0.000001
   • Epoch  41/100: train=0.1201, val=0.1151, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.1157, val=0.1108, patience=1/15, lr=0.000001
   • Epoch  61/100: train=0.1116, val=0.1067, patience=1/15, lr=0.000001
   • Epoch  71/100: train=0.1078, val=0.1030, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.1044, val=0.0996, patience=1/15, lr=0.000001
   • Epoch  91/100: train=0.1012, val=0.0965, patience=1/15, lr=0.000001

============================================================
📊 Round 23 Summary - Client client_7
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0986, RMSE=0.3139, R²=-0.2011
   Val:   Loss=0.0939, RMSE=0.3064, R²=-0.2110
============================================================


============================================================
🔄 Round 24 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1124, val=0.1164 (↓), lr=0.000001
   • Epoch   2/100: train=0.1119, val=0.1160, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.1115, val=0.1155 (↓), lr=0.000001
   • Epoch   4/100: train=0.1110, val=0.1151, patience=1/15, lr=0.000001
   ✓ Epoch   5/100: train=0.1105, val=0.1147 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.1078, val=0.1121 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.1037, val=0.1084 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.1001, val=0.1050 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.0968, val=0.1020 (↓), lr=0.000001
   • Epoch  51/100: train=0.0940, val=0.0995, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.0915, val=0.0972 (↓), lr=0.000001
   • Epoch  71/100: train=0.0893, val=0.0953, patience=1/15, lr=0.000001
   ✓ Epoch  81/100: train=0.0875, val=0.0937 (↓), lr=0.000001
   • Epoch  91/100: train=0.0859, val=0.0923, patience=2/15, lr=0.000001

============================================================
📊 Round 24 Summary - Client client_7
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0672
   Val:   Loss=0.0913, RMSE=0.3022, R²=-0.0487
============================================================


============================================================
🔄 Round 25 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0911, val=0.1021 (↓), lr=0.000001
   • Epoch   2/100: train=0.0909, val=0.1017, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.0907, val=0.1014 (↓), lr=0.000001
   • Epoch   4/100: train=0.0905, val=0.1010, patience=1/15, lr=0.000001
   ✓ Epoch   5/100: train=0.0903, val=0.1007 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.0891, val=0.0987 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.0874, val=0.0958 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.0861, val=0.0933 (↓), lr=0.000001
   • Epoch  41/100: train=0.0850, val=0.0912, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.0841, val=0.0894, patience=2/15, lr=0.000001
   • Epoch  61/100: train=0.0835, val=0.0879, patience=1/15, lr=0.000001
   • Epoch  71/100: train=0.0829, val=0.0866, patience=3/15, lr=0.000001
   • Epoch  81/100: train=0.0826, val=0.0855, patience=3/15, lr=0.000001
   • Epoch  91/100: train=0.0823, val=0.0846, patience=1/15, lr=0.000001

============================================================
📊 Round 25 Summary - Client client_7
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0106
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0960
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0862, RMSE: 0.2935, MAE: 0.2525, R²: -0.0471

============================================================
🔄 Round 26 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0858, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0819, val=0.0856, patience=7/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 26 Summary - Client client_7
   Epochs: 29/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0282
   Val:   Loss=0.0857, RMSE=0.2928, R²=0.0020
============================================================


============================================================
🔄 Round 28 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0966 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0966, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0965, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0965, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0964, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0961, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0789, val=0.0958, patience=9/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0961)

============================================================
📊 Round 28 Summary - Client client_7
   Epochs: 27/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=-0.0105
   Val:   Loss=0.0961, RMSE=0.3100, R²=-0.0345
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2505, R²: -0.0222

📊 Round 28 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2502, R²: -0.0189

============================================================
🔄 Round 31 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 31 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=-0.0127
   Val:   Loss=0.0866, RMSE=0.2942, R²=-0.0117
============================================================


============================================================
🔄 Round 32 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 32 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0081
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0364
============================================================


============================================================
🔄 Round 34 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 34 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=-0.0083
   Val:   Loss=0.0800, RMSE=0.2829, R²=-0.0276
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2500, R²: -0.0162

============================================================
🔄 Round 35 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 35 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0099
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0154
============================================================


============================================================
🔄 Round 36 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 36 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=-0.0170
   Val:   Loss=0.0895, RMSE=0.2992, R²=-0.0175
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2499, R²: -0.0157

📊 Round 36 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2499, R²: -0.0152

============================================================
🔄 Round 41 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 41 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=-0.0159
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0056
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2497, R²: -0.0137

============================================================
🔄 Round 46 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 46 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0065
   Val:   Loss=0.0851, RMSE=0.2918, R²=-0.0211
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0833, RMSE: 0.2887, MAE: 0.2497, R²: -0.0129

============================================================
🔄 Round 49 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 49 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0100
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0088
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2495, R²: -0.0116

📊 Round 49 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2495, R²: -0.0115

============================================================
🔄 Round 53 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 53 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2878, R²=-0.0096
   Val:   Loss=0.0778, RMSE=0.2790, R²=-0.0065
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2495, R²: -0.0114

📊 Round 53 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: -0.0109

============================================================
🔄 Round 55 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 55 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0099
   Val:   Loss=0.0839, RMSE=0.2896, R²=-0.0078
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0108

============================================================
🔄 Round 56 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 56 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0097
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0075
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: -0.0107

📊 Round 56 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2494, R²: -0.0100

📊 Round 56 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2493, R²: -0.0094

📊 Round 56 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2493, R²: -0.0093

============================================================
🔄 Round 63 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 63 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0071
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0111
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2493, R²: -0.0093

============================================================
🔄 Round 64 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 64 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0101
   Val:   Loss=0.0798, RMSE=0.2825, R²=0.0025
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2492, R²: -0.0088

============================================================
🔄 Round 67 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 67 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0083
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0042
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2492, R²: -0.0089

============================================================
🔄 Round 68 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 68 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0085
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0396
============================================================


============================================================
🔄 Round 69 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 69 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0101
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0016
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2492, R²: -0.0088

============================================================
🔄 Round 71 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 71 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=-0.0053
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0165
============================================================


============================================================
🔄 Round 74 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 74 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0069
   Val:   Loss=0.0802, RMSE=0.2833, R²=-0.0162
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2492, R²: -0.0087

============================================================
🔄 Round 75 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 75 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0087
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0155
============================================================


============================================================
🔄 Round 76 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 76 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0045
   Val:   Loss=0.0869, RMSE=0.2949, R²=-0.0183
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2492, R²: -0.0087

📊 Round 76 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2493, R²: -0.0089

============================================================
🔄 Round 81 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 81 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0066
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0133
============================================================


============================================================
🔄 Round 82 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 82 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0079
   Val:   Loss=0.0779, RMSE=0.2791, R²=-0.0050
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2493, R²: -0.0089

📊 Round 82 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2492, R²: -0.0086

============================================================
🔄 Round 87 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 87 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0085
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0021
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2493, R²: -0.0089

============================================================
🔄 Round 89 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 89 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0067
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0100
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2493, R²: -0.0090

📊 Round 89 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2493, R²: -0.0089

============================================================
🔄 Round 94 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 94 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0101
   Val:   Loss=0.0869, RMSE=0.2949, R²=-0.0184
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2493, R²: -0.0089

============================================================
🔄 Round 95 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 95 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0041
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0242
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2493, R²: -0.0089

============================================================
🔄 Round 97 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 97 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0065
   Val:   Loss=0.0793, RMSE=0.2817, R²=-0.0144
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2493, R²: -0.0089

📊 Round 97 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2493, R²: -0.0093

============================================================
🔄 Round 100 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 100 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0059
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0126
============================================================


============================================================
🔄 Round 101 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 101 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0058
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0138
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2493, R²: -0.0096

📊 Round 101 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2494, R²: -0.0102

============================================================
🔄 Round 107 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 107 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0093
   Val:   Loss=0.0744, RMSE=0.2727, R²=0.0009
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2494, R²: -0.0097

============================================================
🔄 Round 108 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 108 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0063
   Val:   Loss=0.0769, RMSE=0.2773, R²=-0.0142
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2494, R²: -0.0097

============================================================
🔄 Round 109 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 109 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0090
   Val:   Loss=0.0818, RMSE=0.2861, R²=-0.0228
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2493, R²: -0.0096

============================================================
🔄 Round 112 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 112 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0061
   Val:   Loss=0.0754, RMSE=0.2746, R²=-0.0123
============================================================


============================================================
🔄 Round 113 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 113 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=-0.0061
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0118
============================================================


============================================================
🔄 Round 114 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 114 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0053
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0374
============================================================


============================================================
🔄 Round 115 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 115 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0059
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.0191
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2493, R²: -0.0090

============================================================
🔄 Round 117 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 117 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0065
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0214
============================================================


============================================================
🔄 Round 119 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 119 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0061
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0491
============================================================


============================================================
🔄 Round 123 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 123 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0050
   Val:   Loss=0.0814, RMSE=0.2853, R²=-0.0232
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2492, R²: -0.0085

============================================================
🔄 Round 124 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 124 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0070
   Val:   Loss=0.0760, RMSE=0.2758, R²=-0.0075
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2492, R²: -0.0085

============================================================
🔄 Round 125 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0705 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0705, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0705, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0705, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0705, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0705, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0705)

============================================================
📊 Round 125 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0087
   Val:   Loss=0.0705, RMSE=0.2656, R²=0.0031
============================================================


============================================================
🔄 Round 126 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 126 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0099
   Val:   Loss=0.0768, RMSE=0.2770, R²=0.0058
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2492, R²: -0.0081

============================================================
🔄 Round 127 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 127 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0071
   Val:   Loss=0.0896, RMSE=0.2993, R²=-0.0138
============================================================


============================================================
🔄 Round 129 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 129 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=-0.0079
   Val:   Loss=0.0917, RMSE=0.3028, R²=-0.0103
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2492, R²: -0.0079

📊 Round 129 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2492, R²: -0.0077

============================================================
🔄 Round 132 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0924 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0924, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0924, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 132 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=-0.0053
   Val:   Loss=0.0924, RMSE=0.3040, R²=-0.0134
============================================================


============================================================
🔄 Round 135 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 135 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2896, R²=-0.0064
   Val:   Loss=0.0730, RMSE=0.2702, R²=-0.0169
============================================================


============================================================
🔄 Round 136 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 136 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0063
   Val:   Loss=0.0768, RMSE=0.2771, R²=-0.0078
============================================================


============================================================
🔄 Round 137 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 137 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=-0.0068
   Val:   Loss=0.0874, RMSE=0.2957, R²=-0.0205
============================================================


============================================================
🔄 Round 138 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 138 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0075
   Val:   Loss=0.0788, RMSE=0.2808, R²=-0.0027
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2492, R²: -0.0079

============================================================
🔄 Round 142 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 142 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0060
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0221
============================================================


============================================================
🔄 Round 143 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 143 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0088
   Val:   Loss=0.0831, RMSE=0.2883, R²=0.0029
============================================================


============================================================
🔄 Round 144 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 144 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0081
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0057
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2492, R²: -0.0077

📊 Round 144 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2492, R²: -0.0077

============================================================
🔄 Round 147 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 147 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0074
   Val:   Loss=0.0782, RMSE=0.2797, R²=-0.0068
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2492, R²: -0.0080

============================================================
🔄 Round 150 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 150 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0064
   Val:   Loss=0.0751, RMSE=0.2740, R²=-0.0106
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2492, R²: -0.0080

📊 Round 150 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2492, R²: -0.0080

📊 Round 150 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2492, R²: -0.0080

📊 Round 150 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2492, R²: -0.0079

📊 Round 150 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2492, R²: -0.0082

============================================================
🔄 Round 157 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 157 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0052
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0146
============================================================


============================================================
🔄 Round 159 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 159 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=-0.0046
   Val:   Loss=0.0797, RMSE=0.2824, R²=-0.0145
============================================================


============================================================
🔄 Round 160 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0704 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0705, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0705, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0705, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0705, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0706, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0704)

============================================================
📊 Round 160 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0079
   Val:   Loss=0.0704, RMSE=0.2654, R²=-0.0139
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2492, R²: -0.0083

============================================================
🔄 Round 163 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 163 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2877, R²=-0.0044
   Val:   Loss=0.0773, RMSE=0.2780, R²=-0.0137
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2493, R²: -0.0087

============================================================
🔄 Round 164 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 164 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0049
   Val:   Loss=0.0769, RMSE=0.2772, R²=-0.0141
============================================================


============================================================
🔄 Round 165 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 165 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0066
   Val:   Loss=0.0792, RMSE=0.2815, R²=-0.0107
============================================================


============================================================
🔄 Round 167 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 167 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0061
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0070
============================================================


============================================================
🔄 Round 169 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0723, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0723, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0723, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0723, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 169 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0047
   Val:   Loss=0.0723, RMSE=0.2689, R²=-0.0127
============================================================


============================================================
🔄 Round 170 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 170 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0057
   Val:   Loss=0.0814, RMSE=0.2854, R²=-0.0078
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2492, R²: -0.0078

📊 Round 170 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2492, R²: -0.0083

============================================================
🔄 Round 175 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 175 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0078
   Val:   Loss=0.0768, RMSE=0.2772, R²=-0.0210
============================================================


============================================================
🔄 Round 176 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 176 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0050
   Val:   Loss=0.0879, RMSE=0.2965, R²=-0.0330
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2492, R²: -0.0083

============================================================
🔄 Round 177 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 177 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0060
   Val:   Loss=0.0765, RMSE=0.2767, R²=-0.0058
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2492, R²: -0.0082

📊 Round 177 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2492, R²: -0.0081

📊 Round 177 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2492, R²: -0.0081

============================================================
🔄 Round 181 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 181 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0060
   Val:   Loss=0.0774, RMSE=0.2783, R²=-0.0075
============================================================


============================================================
🔄 Round 183 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 183 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=-0.0055
   Val:   Loss=0.0887, RMSE=0.2978, R²=-0.0076
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2492, R²: -0.0078

📊 Round 183 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2492, R²: -0.0078

============================================================
🔄 Round 186 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 186 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0050
   Val:   Loss=0.0787, RMSE=0.2805, R²=-0.0130
============================================================


============================================================
🔄 Round 187 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 187 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=-0.0043
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0129
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2492, R²: -0.0080

============================================================
🔄 Round 189 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 189 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2836, R²=-0.0063
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0042
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2492, R²: -0.0077

📊 Round 189 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2492, R²: -0.0077

============================================================
🔄 Round 193 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 193 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0060
   Val:   Loss=0.0790, RMSE=0.2810, R²=-0.0046
============================================================


📊 Round 193 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2492, R²: -0.0077

📊 Round 193 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2492, R²: -0.0079

📊 Round 193 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2492, R²: -0.0080

📊 Round 193 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2492, R²: -0.0080

============================================================
🔄 Round 202 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 202 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0060
   Val:   Loss=0.0756, RMSE=0.2750, R²=-0.0073
============================================================


📊 Round 202 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2492, R²: -0.0081

📊 Round 202 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2493, R²: -0.0084

📊 Round 202 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2492, R²: -0.0080

============================================================
🔄 Round 211 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 211 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0055
   Val:   Loss=0.0762, RMSE=0.2760, R²=-0.0122
============================================================


============================================================
🔄 Round 212 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 212 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=-0.0064
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0046
============================================================


============================================================
🔄 Round 214 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 214 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0059
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0053
============================================================


📊 Round 214 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2493, R²: -0.0085

============================================================
🔄 Round 215 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 215 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0072
   Val:   Loss=0.0883, RMSE=0.2971, R²=-0.0010
============================================================


============================================================
🔄 Round 218 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 218 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0065
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0076
============================================================


============================================================
🔄 Round 219 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 219 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=-0.0043
   Val:   Loss=0.0903, RMSE=0.3004, R²=-0.0154
============================================================


📊 Round 219 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2493, R²: -0.0086

📊 Round 219 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2493, R²: -0.0086

============================================================
🔄 Round 222 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 222 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=-0.0058
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0142
============================================================


📊 Round 222 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2492, R²: -0.0081

============================================================
🔄 Round 225 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 225 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0044
   Val:   Loss=0.0755, RMSE=0.2748, R²=-0.0228
============================================================


📊 Round 225 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2492, R²: -0.0080

============================================================
🔄 Round 227 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 227 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0055
   Val:   Loss=0.0792, RMSE=0.2815, R²=-0.0075
============================================================


📊 Round 227 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2493, R²: -0.0083

📊 Round 227 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2492, R²: -0.0078

📊 Round 227 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2492, R²: -0.0078

📊 Round 227 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2492, R²: -0.0077

============================================================
🔄 Round 235 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 235 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0058
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0158
============================================================


📊 Round 235 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2492, R²: -0.0076

📊 Round 235 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2492, R²: -0.0076

📊 Round 235 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2492, R²: -0.0076

============================================================
🔄 Round 241 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 241 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0047
   Val:   Loss=0.0800, RMSE=0.2828, R²=-0.0129
============================================================


============================================================
🔄 Round 242 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 242 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0090
   Val:   Loss=0.0810, RMSE=0.2845, R²=-0.0120
============================================================


============================================================
🔄 Round 243 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 243 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0085
   Val:   Loss=0.0826, RMSE=0.2874, R²=0.0071
============================================================


📊 Round 243 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2492, R²: -0.0076

============================================================
🔄 Round 244 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 244 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0046
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0079
============================================================


📊 Round 244 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2492, R²: -0.0076

============================================================
🔄 Round 245 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 245 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0041
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0139
============================================================


📊 Round 245 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2492, R²: -0.0074

============================================================
🔄 Round 246 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 246 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0039
   Val:   Loss=0.0789, RMSE=0.2809, R²=-0.0265
============================================================


📊 Round 246 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2492, R²: -0.0074

============================================================
🔄 Round 247 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 247 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0088
   Val:   Loss=0.0823, RMSE=0.2868, R²=0.0022
============================================================


📊 Round 247 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2492, R²: -0.0074

============================================================
🔄 Round 249 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 249 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0063
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0014
============================================================


📊 Round 249 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2492, R²: -0.0077

============================================================
🔄 Round 251 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 251 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0055
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0074
============================================================


📊 Round 251 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2492, R²: -0.0077

============================================================
🔄 Round 256 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 256 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0040
   Val:   Loss=0.0851, RMSE=0.2918, R²=-0.0327
============================================================


============================================================
🔄 Round 257 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 257 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0048
   Val:   Loss=0.0772, RMSE=0.2778, R²=-0.0071
============================================================


============================================================
🔄 Round 259 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 259 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=-0.0071
   Val:   Loss=0.0870, RMSE=0.2949, R²=-0.0142
============================================================


📊 Round 259 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2492, R²: -0.0081

============================================================
🔄 Round 260 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0715 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0715, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0715, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0715, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0715, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0715, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0715)

============================================================
📊 Round 260 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0063
   Val:   Loss=0.0715, RMSE=0.2674, R²=-0.0006
============================================================


📊 Round 260 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2492, R²: -0.0078

============================================================
🔄 Round 263 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 263 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0061
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0096
============================================================


============================================================
🔄 Round 265 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 265 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0057
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0034
============================================================


📊 Round 265 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2492, R²: -0.0080

============================================================
🔄 Round 266 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 266 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=-0.0046
   Val:   Loss=0.0872, RMSE=0.2954, R²=-0.0077
============================================================


📊 Round 266 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2492, R²: -0.0079

📊 Round 266 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2492, R²: -0.0080

============================================================
🔄 Round 272 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 272 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0061
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0221
============================================================


📊 Round 272 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2492, R²: -0.0080

📊 Round 272 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2492, R²: -0.0080

============================================================
🔄 Round 277 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 277 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0050
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0083
============================================================


📊 Round 277 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2492, R²: -0.0079

============================================================
🔄 Round 280 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 280 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0034
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0490
============================================================


📊 Round 280 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2492, R²: -0.0075

📊 Round 280 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2492, R²: -0.0075

============================================================
🔄 Round 283 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 283 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2892, R²=-0.0054
   Val:   Loss=0.0732, RMSE=0.2705, R²=-0.0059
============================================================


📊 Round 283 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2492, R²: -0.0074

============================================================
🔄 Round 284 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 284 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0034
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0149
============================================================


============================================================
🔄 Round 285 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 285 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0066
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0014
============================================================


============================================================
🔄 Round 287 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 287 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=-0.0059
   Val:   Loss=0.0909, RMSE=0.3014, R²=-0.0100
============================================================


============================================================
🔄 Round 288 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 288 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=-0.0012
   Val:   Loss=0.0898, RMSE=0.2996, R²=-0.0183
============================================================


📊 Round 288 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2491, R²: -0.0071

============================================================
🔄 Round 290 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 290 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0036
   Val:   Loss=0.0812, RMSE=0.2849, R²=-0.0170
============================================================


============================================================
🔄 Round 291 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 291 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0059
   Val:   Loss=0.0848, RMSE=0.2911, R²=-0.0007
============================================================


============================================================
🔄 Round 292 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 292 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0032
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0210
============================================================


============================================================
🔄 Round 293 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 293 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=-0.0049
   Val:   Loss=0.0774, RMSE=0.2783, R²=-0.0057
============================================================


============================================================
🔄 Round 294 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 294 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=-0.0048
   Val:   Loss=0.0906, RMSE=0.3009, R²=-0.0099
============================================================


============================================================
🔄 Round 296 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 296 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=-0.0045
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0088
============================================================


============================================================
🔄 Round 298 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 298 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0038
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0104
============================================================


📊 Round 298 Test Metrics:
   Loss: 0.0829, RMSE: 0.2878, MAE: 0.2491, R²: -0.0070

📊 Round 298 Test Metrics:
   Loss: 0.0829, RMSE: 0.2878, MAE: 0.2491, R²: -0.0070

============================================================
🔄 Round 300 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 300 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0037
   Val:   Loss=0.0815, RMSE=0.2854, R²=-0.0101
============================================================


📊 Round 300 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2491, R²: -0.0070

📊 Round 300 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2492, R²: -0.0074

============================================================
🔄 Round 302 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 302 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0050
   Val:   Loss=0.0763, RMSE=0.2762, R²=-0.0048
============================================================


📊 Round 302 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2492, R²: -0.0074

============================================================
🔄 Round 303 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 303 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0037
   Val:   Loss=0.0811, RMSE=0.2847, R²=-0.0176
============================================================


============================================================
🔄 Round 304 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 304 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=-0.0044
   Val:   Loss=0.0882, RMSE=0.2970, R²=-0.0061
============================================================


📊 Round 304 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2492, R²: -0.0074

============================================================
🔄 Round 305 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 305 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0060
   Val:   Loss=0.0743, RMSE=0.2725, R²=0.0010
============================================================


============================================================
🔄 Round 307 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 307 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0077
   Val:   Loss=0.0844, RMSE=0.2906, R²=0.0057
============================================================


============================================================
🔄 Round 308 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0683 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0683, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0683, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0683, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0683, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0683, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0683)

============================================================
📊 Round 308 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=-0.0029
   Val:   Loss=0.0683, RMSE=0.2613, R²=-0.0140
============================================================


============================================================
🔄 Round 312 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 312 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0059
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0007
============================================================


📊 Round 312 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2492, R²: -0.0073

📊 Round 312 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2492, R²: -0.0073

📊 Round 312 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2492, R²: -0.0073

============================================================
🔄 Round 317 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 317 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0043
   Val:   Loss=0.0848, RMSE=0.2913, R²=-0.0058
============================================================


📊 Round 317 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2492, R²: -0.0072

============================================================
🔄 Round 319 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0940 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0940, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0940, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0940, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0940, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0940, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0940)

============================================================
📊 Round 319 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2801, R²=-0.0046
   Val:   Loss=0.0940, RMSE=0.3066, R²=-0.0102
============================================================


============================================================
🔄 Round 321 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 321 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0049
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0056
============================================================


📊 Round 321 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2492, R²: -0.0074

============================================================
🔄 Round 324 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 324 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0074
   Val:   Loss=0.0880, RMSE=0.2966, R²=0.0052
============================================================


📊 Round 324 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2492, R²: -0.0074

============================================================
🔄 Round 327 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 327 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0030
   Val:   Loss=0.0800, RMSE=0.2828, R²=-0.0111
============================================================


📊 Round 327 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2492, R²: -0.0071

📊 Round 327 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2491, R²: -0.0070

📊 Round 327 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2492, R²: -0.0071

============================================================
🔄 Round 330 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 330 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0042
   Val:   Loss=0.0748, RMSE=0.2734, R²=-0.0080
============================================================


============================================================
🔄 Round 332 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 332 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0040
   Val:   Loss=0.0766, RMSE=0.2767, R²=-0.0069
============================================================


============================================================
🔄 Round 334 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 334 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=-0.0054
   Val:   Loss=0.0822, RMSE=0.2866, R²=-0.0014
============================================================


📊 Round 334 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2491, R²: -0.0069

📊 Round 334 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2491, R²: -0.0066

📊 Round 334 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2491, R²: -0.0067

📊 Round 334 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2492, R²: -0.0072

============================================================
🔄 Round 343 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 343 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0022
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0132
============================================================


============================================================
🔄 Round 345 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0695 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0695, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0695, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0695, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0695, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0695, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0695)

============================================================
📊 Round 345 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0034
   Val:   Loss=0.0695, RMSE=0.2637, R²=-0.0197
============================================================


📊 Round 345 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2492, R²: -0.0073

============================================================
🔄 Round 347 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 347 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=-0.0057
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0020
============================================================


============================================================
🔄 Round 348 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0720, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 348 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0052
   Val:   Loss=0.0720, RMSE=0.2683, R²=-0.0005
============================================================


📊 Round 348 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2492, R²: -0.0071

============================================================
🔄 Round 349 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 349 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0050
   Val:   Loss=0.0851, RMSE=0.2918, R²=-0.0076
============================================================


📊 Round 349 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2492, R²: -0.0072

📊 Round 349 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2492, R²: -0.0071

============================================================
🔄 Round 353 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0937 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0937, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0937, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0937, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0937, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0937, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0937)

============================================================
📊 Round 353 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=-0.0045
   Val:   Loss=0.0937, RMSE=0.3061, R²=-0.0058
============================================================


📊 Round 353 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2492, R²: -0.0072

============================================================
🔄 Round 357 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 357 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0076
   Val:   Loss=0.0852, RMSE=0.2919, R²=0.0003
============================================================


📊 Round 357 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2492, R²: -0.0072

📊 Round 357 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2492, R²: -0.0072

📊 Round 357 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2492, R²: -0.0074

📊 Round 357 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2493, R²: -0.0080

============================================================
🔄 Round 367 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 367 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=-0.0057
   Val:   Loss=0.0905, RMSE=0.3008, R²=-0.0074
============================================================


============================================================
🔄 Round 373 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 373 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=-0.0014
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0376
============================================================


============================================================
🔄 Round 374 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 374 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0047
   Val:   Loss=0.0781, RMSE=0.2794, R²=-0.0230
============================================================


📊 Round 374 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2493, R²: -0.0086

📊 Round 374 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2493, R²: -0.0085

📊 Round 374 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2493, R²: -0.0085

📊 Round 374 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2493, R²: -0.0085

============================================================
🔄 Round 378 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 378 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=-0.0065
   Val:   Loss=0.0838, RMSE=0.2895, R²=0.0030
============================================================


📊 Round 378 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2493, R²: -0.0084

============================================================
🔄 Round 379 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 379 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=-0.0052
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0016
============================================================


📊 Round 379 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2493, R²: -0.0082

📊 Round 379 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2493, R²: -0.0080

📊 Round 379 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2493, R²: -0.0080

📊 Round 379 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2493, R²: -0.0080

📊 Round 379 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2493, R²: -0.0082

============================================================
🔄 Round 389 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 389 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0044
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0056
============================================================


============================================================
🔄 Round 390 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0702 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0702, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0702, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0702, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0702, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0703, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0702)

============================================================
📊 Round 390 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0058
   Val:   Loss=0.0702, RMSE=0.2649, R²=-0.0024
============================================================


📊 Round 390 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2492, R²: -0.0077

📊 Round 390 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2493, R²: -0.0082

============================================================
🔄 Round 393 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 393 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0029
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0189
============================================================


============================================================
🔄 Round 394 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 394 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=-0.0052
   Val:   Loss=0.0737, RMSE=0.2715, R²=-0.0355
============================================================


📊 Round 394 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2493, R²: -0.0083

📊 Round 394 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2493, R²: -0.0079

============================================================
🔄 Round 398 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 398 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0038
   Val:   Loss=0.0757, RMSE=0.2752, R²=-0.0061
============================================================


============================================================
🔄 Round 401 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 401 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0051
   Val:   Loss=0.0866, RMSE=0.2943, R²=-0.0092
============================================================


📊 Round 401 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2493, R²: -0.0078

============================================================
🔄 Round 402 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 402 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0027
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0340
============================================================


📊 Round 402 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2492, R²: -0.0075

============================================================
🔄 Round 403 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 403 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0048
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0100
============================================================


📊 Round 403 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2492, R²: -0.0075

📊 Round 403 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2492, R²: -0.0075

============================================================
🔄 Round 405 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 405 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0036
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0118
============================================================


📊 Round 405 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2492, R²: -0.0073

📊 Round 405 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2492, R²: -0.0073

============================================================
🔄 Round 408 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 408 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0040
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0141
============================================================


============================================================
🔄 Round 409 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 409 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0058
   Val:   Loss=0.0803, RMSE=0.2833, R²=-0.0001
============================================================


============================================================
🔄 Round 410 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 410 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0063
   Val:   Loss=0.0774, RMSE=0.2782, R²=0.0064
============================================================


============================================================
🔄 Round 414 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 414 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=-0.0030
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0189
============================================================


============================================================
🔄 Round 415 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 415 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=-0.0033
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0066
============================================================


============================================================
🔄 Round 416 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 416 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=-0.0044
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0022
============================================================


📊 Round 416 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2492, R²: -0.0075

============================================================
🔄 Round 419 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 419 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0020
   Val:   Loss=0.0783, RMSE=0.2799, R²=-0.0131
============================================================


============================================================
🔄 Round 420 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 420 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0038
   Val:   Loss=0.0776, RMSE=0.2786, R²=-0.0048
============================================================


📊 Round 420 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2492, R²: -0.0075

📊 Round 420 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2492, R²: -0.0075

📊 Round 420 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2492, R²: -0.0075

============================================================
🔄 Round 424 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 424 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0041
   Val:   Loss=0.0754, RMSE=0.2745, R²=-0.0040
============================================================


📊 Round 424 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2492, R²: -0.0075

📊 Round 424 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2492, R²: -0.0074

============================================================
🔄 Round 427 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 427 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0064
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0084
============================================================


📊 Round 427 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2492, R²: -0.0074

============================================================
🔄 Round 429 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 429 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0044
   Val:   Loss=0.0795, RMSE=0.2819, R²=-0.0027
============================================================


============================================================
🔄 Round 430 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 430 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0039
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0052
============================================================


📊 Round 430 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2492, R²: -0.0072

📊 Round 430 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2492, R²: -0.0072

📊 Round 430 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2492, R²: -0.0073

============================================================
🔄 Round 434 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 434 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0038
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0097
============================================================


📊 Round 434 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2492, R²: -0.0072

============================================================
🔄 Round 437 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 437 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0046
   Val:   Loss=0.0823, RMSE=0.2870, R²=-0.0062
============================================================


============================================================
🔄 Round 439 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 439 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=-0.0031
   Val:   Loss=0.0814, RMSE=0.2854, R²=-0.0073
============================================================


============================================================
🔄 Round 445 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 445 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0041
   Val:   Loss=0.0749, RMSE=0.2737, R²=-0.0034
============================================================


============================================================
🔄 Round 446 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 446 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0030
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0081
============================================================


============================================================
🔄 Round 447 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 447 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0051
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0103
============================================================


============================================================
🔄 Round 449 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 449 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0050
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0106
============================================================


📊 Round 449 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2492, R²: -0.0075

📊 Round 449 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2492, R²: -0.0074

============================================================
🔄 Round 451 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 451 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0049
   Val:   Loss=0.0838, RMSE=0.2894, R²=-0.0072
============================================================


============================================================
🔄 Round 452 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 452 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0056
   Val:   Loss=0.0774, RMSE=0.2783, R²=0.0030
============================================================


============================================================
🔄 Round 453 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 453 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0048
   Val:   Loss=0.0836, RMSE=0.2892, R²=-0.0001
============================================================


============================================================
🔄 Round 456 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0706 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0706, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0706, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0706, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0706, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0706, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0706)

============================================================
📊 Round 456 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0047
   Val:   Loss=0.0706, RMSE=0.2657, R²=-0.0015
============================================================


📊 Round 456 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2492, R²: -0.0073

📊 Round 456 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2492, R²: -0.0072

============================================================
🔄 Round 461 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 461 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0047
   Val:   Loss=0.0739, RMSE=0.2718, R²=-0.0007
============================================================


📊 Round 461 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2492, R²: -0.0072

📊 Round 461 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2492, R²: -0.0072

📊 Round 461 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2492, R²: -0.0072

============================================================
🔄 Round 464 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 464 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0053
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0028
============================================================


============================================================
🔄 Round 466 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 466 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0050
   Val:   Loss=0.0832, RMSE=0.2885, R²=0.0014
============================================================


📊 Round 466 Test Metrics:
   Loss: 0.0829, RMSE: 0.2878, MAE: 0.2492, R²: -0.0069

============================================================
🔄 Round 470 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 470 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0026
   Val:   Loss=0.0782, RMSE=0.2797, R²=-0.0147
============================================================


📊 Round 470 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2492, R²: -0.0070

📊 Round 470 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2492, R²: -0.0071

============================================================
🔄 Round 472 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 472 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0027
   Val:   Loss=0.0848, RMSE=0.2913, R²=-0.0114
============================================================


📊 Round 472 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2492, R²: -0.0071

============================================================
🔄 Round 473 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 473 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0045
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0025
============================================================


============================================================
🔄 Round 474 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 474 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0051
   Val:   Loss=0.0748, RMSE=0.2735, R²=0.0012
============================================================


📊 Round 474 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2492, R²: -0.0074

📊 Round 474 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2492, R²: -0.0074

============================================================
🔄 Round 481 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0942 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0942, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0942, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0942, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0942, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0942, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0942)

============================================================
📊 Round 481 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=-0.0052
   Val:   Loss=0.0942, RMSE=0.3069, R²=0.0004
============================================================


📊 Round 481 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2492, R²: -0.0071

============================================================
🔄 Round 482 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 482 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0036
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0038
============================================================


📊 Round 482 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2492, R²: -0.0070

============================================================
🔄 Round 484 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 484 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0047
   Val:   Loss=0.0809, RMSE=0.2845, R²=0.0005
============================================================


📊 Round 484 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2492, R²: -0.0071

============================================================
🔄 Round 486 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 486 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0063
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.0061
============================================================


📊 Round 486 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2492, R²: -0.0070

📊 Round 486 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2492, R²: -0.0069

============================================================
🔄 Round 490 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 490 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0042
   Val:   Loss=0.0845, RMSE=0.2906, R²=-0.0107
============================================================


============================================================
🔄 Round 493 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 493 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0038
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0025
============================================================


📊 Round 493 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2492, R²: -0.0069

============================================================
🔄 Round 495 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 495 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=-0.0041
   Val:   Loss=0.0901, RMSE=0.3002, R²=-0.0028
============================================================


📊 Round 495 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2492, R²: -0.0071

============================================================
🔄 Round 498 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 498 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0031
   Val:   Loss=0.0806, RMSE=0.2840, R²=-0.0052
============================================================


📊 Round 498 Test Metrics:
   Loss: 0.0829, RMSE: 0.2878, MAE: 0.2492, R²: -0.0070

📊 Round 498 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2492, R²: -0.0070

============================================================
🔄 Round 502 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 502 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0052
   Val:   Loss=0.0765, RMSE=0.2766, R²=0.0037
============================================================


============================================================
🔄 Round 504 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 504 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2849, R²=-0.0016
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0111
============================================================


📊 Round 504 Test Metrics:
   Loss: 0.0829, RMSE: 0.2878, MAE: 0.2492, R²: -0.0070

============================================================
🔄 Round 506 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 506 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=-0.0043
   Val:   Loss=0.0877, RMSE=0.2961, R²=-0.0075
============================================================


============================================================
🔄 Round 507 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 507 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0037
   Val:   Loss=0.0772, RMSE=0.2778, R²=-0.0092
============================================================


📊 Round 507 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2492, R²: -0.0069

📊 Round 507 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2492, R²: -0.0069

📊 Round 507 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2492, R²: -0.0067

============================================================
🔄 Round 512 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 512 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0030
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0098
============================================================


============================================================
🔄 Round 514 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 514 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0056
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0029
============================================================


============================================================
🔄 Round 515 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 515 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0034
   Val:   Loss=0.0792, RMSE=0.2813, R²=-0.0049
============================================================


============================================================
🔄 Round 516 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 516 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0036
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0027
============================================================


📊 Round 516 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2492, R²: -0.0067

📊 Round 516 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2492, R²: -0.0067

📊 Round 516 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2492, R²: -0.0066

============================================================
🔄 Round 525 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 525 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0036
   Val:   Loss=0.0766, RMSE=0.2767, R²=-0.0148
============================================================


============================================================
🔄 Round 526 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 526 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0032
   Val:   Loss=0.0863, RMSE=0.2937, R²=-0.0045
============================================================


📊 Round 526 Test Metrics:
   Loss: 0.0829, RMSE: 0.2878, MAE: 0.2492, R²: -0.0069

============================================================
🔄 Round 534 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 534 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0021
   Val:   Loss=0.0854, RMSE=0.2923, R²=-0.0183
============================================================


📊 Round 534 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2492, R²: -0.0073

============================================================
🔄 Round 539 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 539 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0033
   Val:   Loss=0.0806, RMSE=0.2840, R²=-0.0238
============================================================


============================================================
🔄 Round 540 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 540 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=-0.0016
   Val:   Loss=0.0750, RMSE=0.2738, R²=-0.0227
============================================================


📊 Round 540 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2492, R²: -0.0066

============================================================
🔄 Round 542 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 542 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0030
   Val:   Loss=0.0784, RMSE=0.2799, R²=-0.0044
============================================================


📊 Round 542 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2492, R²: -0.0066

============================================================
🔄 Round 543 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0932 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0932, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0932, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0932, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0932, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0932, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0932)

============================================================
📊 Round 543 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=-0.0037
   Val:   Loss=0.0932, RMSE=0.3052, R²=-0.0028
============================================================


============================================================
🔄 Round 544 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 544 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0034
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0062
============================================================


📊 Round 544 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2492, R²: -0.0068

📊 Round 544 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2492, R²: -0.0069

============================================================
🔄 Round 546 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 546 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0020
   Val:   Loss=0.0747, RMSE=0.2734, R²=-0.0115
============================================================


============================================================
🔄 Round 547 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 547 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0034
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0030
============================================================


📊 Round 547 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2492, R²: -0.0069

============================================================
🔄 Round 550 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 550 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0043
   Val:   Loss=0.0835, RMSE=0.2889, R²=0.0006
============================================================


📊 Round 550 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2492, R²: -0.0069

============================================================
🔄 Round 551 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 551 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0045
   Val:   Loss=0.0869, RMSE=0.2948, R²=-0.0015
============================================================


📊 Round 551 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2492, R²: -0.0069

============================================================
🔄 Round 554 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 554 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=-0.0022
   Val:   Loss=0.0881, RMSE=0.2969, R²=-0.0094
============================================================


============================================================
🔄 Round 555 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 555 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0044
   Val:   Loss=0.0825, RMSE=0.2873, R²=0.0013
============================================================


📊 Round 555 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2492, R²: -0.0066

============================================================
🔄 Round 556 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 556 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0048
   Val:   Loss=0.0796, RMSE=0.2822, R²=0.0033
============================================================


📊 Round 556 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2492, R²: -0.0066

============================================================
🔄 Round 560 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 560 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0036
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0067
============================================================


📊 Round 560 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2492, R²: -0.0069

============================================================
🔄 Round 562 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 562 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2819, R²=-0.0049
   Val:   Loss=0.0893, RMSE=0.2989, R²=-0.0224
============================================================


============================================================
🔄 Round 564 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 564 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0015
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0102
============================================================


📊 Round 564 Test Metrics:
   Loss: 0.0829, RMSE: 0.2878, MAE: 0.2492, R²: -0.0069

============================================================
🔄 Round 566 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 566 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0004
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0213
============================================================


📊 Round 566 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2492, R²: -0.0069

============================================================
🔄 Round 567 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 567 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0042
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0053
============================================================


📊 Round 567 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2492, R²: -0.0068

============================================================
🔄 Round 569 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 569 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0022
   Val:   Loss=0.0847, RMSE=0.2909, R²=-0.0106
============================================================


📊 Round 569 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2492, R²: -0.0068

============================================================
🔄 Round 572 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 572 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0011
   Val:   Loss=0.0751, RMSE=0.2740, R²=-0.0154
============================================================


📊 Round 572 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2492, R²: -0.0067

📊 Round 572 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2492, R²: -0.0070

============================================================
🔄 Round 576 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 576 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0047
   Val:   Loss=0.0738, RMSE=0.2717, R²=-0.0096
============================================================


📊 Round 576 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2492, R²: -0.0067

============================================================
🔄 Round 578 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 578 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0030
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0047
============================================================


📊 Round 578 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2492, R²: -0.0067

============================================================
🔄 Round 581 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 581 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0048
   Val:   Loss=0.0749, RMSE=0.2737, R²=0.0045
============================================================


📊 Round 581 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2492, R²: -0.0066

============================================================
🔄 Round 582 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 582 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0019
   Val:   Loss=0.0741, RMSE=0.2721, R²=-0.0119
============================================================


📊 Round 582 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2491, R²: -0.0064

============================================================
🔄 Round 584 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 584 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0023
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0057
============================================================


📊 Round 584 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2491, R²: -0.0063

============================================================
🔄 Round 585 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0711 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0711, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0711, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0711, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0711, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0711, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0711)

============================================================
📊 Round 585 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0044
   Val:   Loss=0.0711, RMSE=0.2666, R²=0.0038
============================================================


============================================================
🔄 Round 587 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 587 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=-0.0008
   Val:   Loss=0.0892, RMSE=0.2986, R²=-0.0117
============================================================


📊 Round 587 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2491, R²: -0.0063

============================================================
🔄 Round 589 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 589 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=-0.0016
   Val:   Loss=0.0900, RMSE=0.2999, R²=-0.0100
============================================================


============================================================
🔄 Round 592 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 592 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0036
   Val:   Loss=0.0780, RMSE=0.2792, R²=-0.0102
============================================================


============================================================
🔄 Round 593 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 593 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0025
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0115
============================================================


============================================================
🔄 Round 595 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 595 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0001
   Val:   Loss=0.0805, RMSE=0.2838, R²=-0.0191
============================================================


📊 Round 595 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2491, R²: -0.0062

============================================================
🔄 Round 597 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 597 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0015
   Val:   Loss=0.0791, RMSE=0.2812, R²=-0.0119
============================================================


============================================================
🔄 Round 598 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 598 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0006
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0120
============================================================


============================================================
🔄 Round 599 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 599 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0041
   Val:   Loss=0.0798, RMSE=0.2825, R²=0.0022
============================================================


📊 Round 599 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2492, R²: -0.0064

============================================================
🔄 Round 603 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 603 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0040
   Val:   Loss=0.0734, RMSE=0.2710, R²=-0.0061
============================================================


📊 Round 603 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2492, R²: -0.0064

📊 Round 603 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2491, R²: -0.0063

============================================================
🔄 Round 607 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 607 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0045
   Val:   Loss=0.0761, RMSE=0.2758, R²=-0.0067
============================================================


📊 Round 607 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2492, R²: -0.0065

============================================================
🔄 Round 611 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 611 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0030
   Val:   Loss=0.0795, RMSE=0.2819, R²=-0.0072
============================================================


📊 Round 611 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2492, R²: -0.0066

============================================================
🔄 Round 612 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 612 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0033
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0331
============================================================


============================================================
🔄 Round 613 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 613 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0038
   Val:   Loss=0.0840, RMSE=0.2899, R²=-0.0023
============================================================


📊 Round 613 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2492, R²: -0.0065

============================================================
🔄 Round 615 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 615 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=-0.0038
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0031
============================================================


============================================================
🔄 Round 616 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 616 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0036
   Val:   Loss=0.0881, RMSE=0.2969, R²=-0.0009
============================================================


📊 Round 616 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2492, R²: -0.0067

============================================================
🔄 Round 619 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 619 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0043
   Val:   Loss=0.0755, RMSE=0.2747, R²=0.0035
============================================================


📊 Round 619 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2492, R²: -0.0064

============================================================
🔄 Round 621 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 621 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=-0.0029
   Val:   Loss=0.0887, RMSE=0.2977, R²=-0.0115
============================================================


📊 Round 621 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2492, R²: -0.0064

📊 Round 621 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2492, R²: -0.0065

📊 Round 621 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2492, R²: -0.0066

============================================================
🔄 Round 635 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 635 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=-0.0056
   Val:   Loss=0.0783, RMSE=0.2798, R²=-0.0197
============================================================


📊 Round 635 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2492, R²: -0.0066

============================================================
🔄 Round 637 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 637 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0022
   Val:   Loss=0.0782, RMSE=0.2797, R²=-0.0052
============================================================


📊 Round 637 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2492, R²: -0.0066

📊 Round 637 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2492, R²: -0.0064

============================================================
🔄 Round 639 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 639 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0009
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0122
============================================================


============================================================
🔄 Round 641 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 641 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0028
   Val:   Loss=0.0778, RMSE=0.2789, R²=-0.0023
============================================================


📊 Round 641 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2492, R²: -0.0064

============================================================
🔄 Round 643 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 643 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0030
   Val:   Loss=0.0760, RMSE=0.2757, R²=-0.0018
============================================================


📊 Round 643 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2492, R²: -0.0063

============================================================
🔄 Round 646 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0935 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0935, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0935, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0935, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0935, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0935, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0935)

============================================================
📊 Round 646 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2799, R²=-0.0015
   Val:   Loss=0.0935, RMSE=0.3057, R²=-0.0085
============================================================


📊 Round 646 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2492, R²: -0.0063

============================================================
🔄 Round 648 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 648 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0022
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0050
============================================================


📊 Round 648 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2492, R²: -0.0064

📊 Round 648 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2492, R²: -0.0064

📊 Round 648 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2492, R²: -0.0064

📊 Round 648 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2492, R²: -0.0064

============================================================
🔄 Round 652 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0706 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0706, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0706, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0706, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0706, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0706, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0706)

============================================================
📊 Round 652 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=-0.0033
   Val:   Loss=0.0706, RMSE=0.2657, R²=-0.0004
============================================================


📊 Round 652 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2491, R²: -0.0060

📊 Round 652 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2491, R²: -0.0060

📊 Round 652 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2491, R²: -0.0060

============================================================
🔄 Round 655 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 655 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0042
   Val:   Loss=0.0728, RMSE=0.2698, R²=0.0008
============================================================


📊 Round 655 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2492, R²: -0.0063

============================================================
🔄 Round 657 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 657 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0023
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0048
============================================================


============================================================
🔄 Round 658 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 658 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0028
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0056
============================================================


============================================================
🔄 Round 659 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 659 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0033
   Val:   Loss=0.0738, RMSE=0.2717, R²=-0.0071
============================================================


📊 Round 659 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2492, R²: -0.0063

============================================================
🔄 Round 661 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 661 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=-0.0047
   Val:   Loss=0.0899, RMSE=0.2999, R²=-0.0054
============================================================


📊 Round 661 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2492, R²: -0.0067

============================================================
🔄 Round 663 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 663 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0018
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0062
============================================================


============================================================
🔄 Round 664 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 664 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0050
   Val:   Loss=0.0812, RMSE=0.2849, R²=-0.0042
============================================================


============================================================
🔄 Round 666 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 666 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0021
   Val:   Loss=0.0790, RMSE=0.2810, R²=-0.0061
============================================================


📊 Round 666 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2492, R²: -0.0067

============================================================
🔄 Round 668 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 668 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0005
   Val:   Loss=0.0781, RMSE=0.2794, R²=-0.0119
============================================================


============================================================
🔄 Round 669 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 669 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=-0.0028
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0044
============================================================


📊 Round 669 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2492, R²: -0.0066

============================================================
🔄 Round 672 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 672 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0035
   Val:   Loss=0.0749, RMSE=0.2737, R²=-0.0019
============================================================


============================================================
🔄 Round 674 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 674 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0031
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0330
============================================================


📊 Round 674 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2492, R²: -0.0064

📊 Round 674 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2492, R²: -0.0062

============================================================
🔄 Round 680 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0683 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0683, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0683, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0683, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0683, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0683, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0683)

============================================================
📊 Round 680 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0029
   Val:   Loss=0.0683, RMSE=0.2614, R²=-0.0010
============================================================


📊 Round 680 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2492, R²: -0.0062

📊 Round 680 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2491, R²: -0.0062

📊 Round 680 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2491, R²: -0.0062

📊 Round 680 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2492, R²: -0.0062

📊 Round 680 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2491, R²: -0.0060

📊 Round 680 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2491, R²: -0.0060

============================================================
🔄 Round 692 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 692 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=-0.0016
   Val:   Loss=0.0826, RMSE=0.2873, R²=-0.0060
============================================================


============================================================
🔄 Round 693 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 693 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=-0.0037
   Val:   Loss=0.0878, RMSE=0.2964, R²=-0.0003
============================================================


📊 Round 693 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2492, R²: -0.0063

📊 Round 693 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2492, R²: -0.0066

============================================================
🔄 Round 697 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 697 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0043
   Val:   Loss=0.0837, RMSE=0.2892, R²=-0.0076
============================================================


📊 Round 697 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2492, R²: -0.0066

📊 Round 697 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2492, R²: -0.0066

============================================================
🔄 Round 703 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 703 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=-0.0048
   Val:   Loss=0.0795, RMSE=0.2819, R²=-0.0119
============================================================


📊 Round 703 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2492, R²: -0.0067

============================================================
🔄 Round 710 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 710 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0030
   Val:   Loss=0.0749, RMSE=0.2736, R²=-0.0018
============================================================


📊 Round 710 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2492, R²: -0.0070

📊 Round 710 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2492, R²: -0.0067

============================================================
🔄 Round 713 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 713 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0041
   Val:   Loss=0.0777, RMSE=0.2788, R²=0.0026
============================================================


📊 Round 713 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2492, R²: -0.0066

📊 Round 713 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2492, R²: -0.0067

============================================================
🔄 Round 715 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 715 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0002
   Val:   Loss=0.0787, RMSE=0.2805, R²=-0.0144
============================================================


📊 Round 715 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2492, R²: -0.0069

============================================================
🔄 Round 716 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 716 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0023
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0244
============================================================


📊 Round 716 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2493, R²: -0.0072

📊 Round 716 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2492, R²: -0.0068

📊 Round 716 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2492, R²: -0.0068

============================================================
🔄 Round 720 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 720 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0018
   Val:   Loss=0.0776, RMSE=0.2786, R²=-0.0055
============================================================


============================================================
🔄 Round 721 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 721 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0027
   Val:   Loss=0.0789, RMSE=0.2809, R²=-0.0088
============================================================


============================================================
🔄 Round 724 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 724 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0013
   Val:   Loss=0.0805, RMSE=0.2838, R²=-0.0074
============================================================


============================================================
🔄 Round 727 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 727 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2871, R²=-0.0021
   Val:   Loss=0.0770, RMSE=0.2775, R²=-0.0071
============================================================


📊 Round 727 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2492, R²: -0.0065

📊 Round 727 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2492, R²: -0.0065

============================================================
🔄 Round 730 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 730 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2878, R²=-0.0039
   Val:   Loss=0.0753, RMSE=0.2745, R²=0.0011
============================================================


============================================================
🔄 Round 732 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 732 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0036
   Val:   Loss=0.0729, RMSE=0.2699, R²=0.0023
============================================================


============================================================
🔄 Round 733 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 733 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0015
   Val:   Loss=0.0879, RMSE=0.2965, R²=-0.0059
============================================================


📊 Round 733 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2492, R²: -0.0062

============================================================
🔄 Round 739 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 739 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=-0.0025
   Val:   Loss=0.0765, RMSE=0.2766, R²=-0.0019
============================================================


📊 Round 739 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2492, R²: -0.0062

📊 Round 739 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2492, R²: -0.0062

============================================================
🔄 Round 742 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 742 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0027
   Val:   Loss=0.0866, RMSE=0.2943, R²=-0.0180
============================================================


📊 Round 742 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2491, R²: -0.0061

============================================================
🔄 Round 747 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 747 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0021
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.0038
============================================================


============================================================
🔄 Round 748 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 748 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0030
   Val:   Loss=0.0820, RMSE=0.2863, R²=-0.0071
============================================================


============================================================
🔄 Round 750 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 750 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0009
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0078
============================================================


📊 Round 750 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2491, R²: -0.0060

📊 Round 750 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2491, R²: -0.0061

📊 Round 750 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2492, R²: -0.0063

============================================================
🔄 Round 754 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 754 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0015
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0176
============================================================


📊 Round 754 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2492, R²: -0.0064

📊 Round 754 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2492, R²: -0.0064

📊 Round 754 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2492, R²: -0.0068

📊 Round 754 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2492, R²: -0.0067

============================================================
🔄 Round 760 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0933 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0933, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0933, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0933, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0933, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0933, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0933)

============================================================
📊 Round 760 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=-0.0005
   Val:   Loss=0.0933, RMSE=0.3054, R²=-0.0270
============================================================


📊 Round 760 Test Metrics:
   Loss: 0.0829, RMSE: 0.2878, MAE: 0.2492, R²: -0.0070

============================================================
🔄 Round 764 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 764 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0061
   Val:   Loss=0.0819, RMSE=0.2863, R²=-0.0346
============================================================


📊 Round 764 Test Metrics:
   Loss: 0.0829, RMSE: 0.2878, MAE: 0.2492, R²: -0.0069

============================================================
🔄 Round 765 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 765 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0010
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0078
============================================================


============================================================
🔄 Round 766 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 766 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2819, R²=-0.0035
   Val:   Loss=0.0890, RMSE=0.2983, R²=-0.0113
============================================================


📊 Round 766 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2493, R²: -0.0070

============================================================
🔄 Round 769 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 769 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0009
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0089
============================================================


============================================================
🔄 Round 770 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 770 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0014
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0080
============================================================


============================================================
🔄 Round 771 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 771 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0024
   Val:   Loss=0.0841, RMSE=0.2899, R²=-0.0106
============================================================


============================================================
🔄 Round 773 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 773 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0023
   Val:   Loss=0.0760, RMSE=0.2757, R²=-0.0046
============================================================


📊 Round 773 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2492, R²: -0.0063

============================================================
🔄 Round 775 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 775 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0044
   Val:   Loss=0.0788, RMSE=0.2807, R²=0.0068
============================================================


============================================================
🔄 Round 776 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 776 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0000
   Val:   Loss=0.0870, RMSE=0.2949, R²=-0.0110
============================================================


============================================================
🔄 Round 777 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 777 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0036
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0035
============================================================


============================================================
🔄 Round 779 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 779 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0028
   Val:   Loss=0.0801, RMSE=0.2831, R²=0.0002
============================================================


============================================================
🔄 Round 780 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 780 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0045
   Val:   Loss=0.0865, RMSE=0.2942, R²=0.0067
============================================================


📊 Round 780 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2491, R²: -0.0060

============================================================
🔄 Round 782 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 782 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0038
   Val:   Loss=0.0784, RMSE=0.2801, R²=0.0042
============================================================


📊 Round 782 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2491, R²: -0.0059

📊 Round 782 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2492, R²: -0.0063

============================================================
🔄 Round 785 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 785 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0017
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0106
============================================================


❌ Client client_7 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8692 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8692 {grpc_message:"Socket closed", grpc_status:14}"
>
