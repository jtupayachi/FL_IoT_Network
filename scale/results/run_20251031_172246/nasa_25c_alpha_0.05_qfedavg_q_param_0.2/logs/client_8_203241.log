[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 462c5f2a-7a8a-4f3f-bf19-f64337346681
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2555daf-f48a-4f10-8c29-a7ec6557a9b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4dab9fdc-007b-4239-a2dd-158a0dd35ef9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7e766da-dd02-4dd1-bcc3-0bf0371e98b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4fffcbd-2bf5-438a-96aa-7886ca4845ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c2987b1-fe6a-4ad2-a8d9-e84d1b27d2c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93804d04-33c2-438c-88e2-e2d1db99413c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8bc8957-0f25-4fb4-8c2f-e6cf98e45930
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8912a345-1296-457b-8b13-b9049bc3ec19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6fd7862-dc97-4268-8a94-d7bfc90856ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14f2cc30-3c74-4b6f-9ebe-5278afd13740
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4fc08f30-6c66-453e-838a-2fd2204e4146
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 518e233b-25d7-4a32-bde5-46c48464b25f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4235ce33-6955-4367-9532-16e3ccd8d819
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 660f5192-1384-4193-909d-50897042d78c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f403013-315d-43b2-8efd-3a032573c399
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77a66743-d6ac-44be-aa31-3d89d66154af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f71eaf61-aba5-44e5-81d9-a300b3f26b0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab56ac20-641b-45f4-9626-21c13f3a411c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b99822ea-da44-48e0-9a49-5c631aa7738b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f24be94f-27de-470a-bba2-777dea8da1a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64fb8426-b60d-42e5-b107-e57b6a28c721
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 350c7cb7-a984-4ee2-b838-34bb9e9e385e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 099f8018-28e0-445e-ae75-f730e56a1e7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1c7e1a0-7ac4-46cb-8edb-0b58051ec966
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18a83cca-2da2-4428-890d-b3cd5a7c395a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca5e8a28-76df-493b-975d-a6a6cd5491e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56eee8c0-d712-4420-a970-07712a540473
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6ac4092-49b9-48c4-a300-b37ae8059686
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e21713c-b571-43b6-8e2e-1f64bd95d950
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98208990-7387-4ad0-b137-90926dd32611
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95dcbde2-b778-4777-90dd-6adac014ece6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d56dacd1-bb35-4c5e-8509-2a72a598b006
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15959928-3363-413f-aedf-a4bb50ea224f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13ccec90-5c62-4ca5-b2b6-6418279a33b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 347500f5-0b56-4a3f-97e9-983db7914163
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba789a93-d429-476e-9913-a4f09f5a486b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a89833ab-c35c-4f6a-b704-77b6f347506b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7421b523-ff49-4a1c-8946-bea0b5f0544b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2fde00a-bc61-44d1-aafa-3260f7f18f1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb3730e8-0dbd-4906-b236-db1d62c0b6cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43246fd4-8848-41bc-8324-cf336e3aaa83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1259a2c9-91d1-4d3e-97ee-8f310a6dc457
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04f77ba5-711f-4392-adda-e423ff0c96c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f40f90b4-1ded-441f-af59-97f02feccaf0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3061cd65-01d6-4244-85f3-11f3a7cec58e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7935246a-30c1-42b1-ab30-cb7417f96be9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message efd8e6cc-deb1-4c2d-b881-96d4a5816010
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d72896f-d451-4478-8890-98bf1bbc36a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21d8f001-e53b-4375-9460-38c82ff93150
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cbfb5a9f-fb03-4a22-8245-1a9f817683fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81646988-66a6-4d6c-9786-986d3e7db0c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ef3f2fc-6c2d-435a-bf88-af4bae06c9e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7a02a94-328a-42c0-9fd7-983265167e22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aca1ccb3-e1f9-47b7-bf7b-ab6610285554
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1215ea54-7c9a-44d3-b0ee-4e57c5035241
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37c23387-454a-49bb-b31b-f7c2fb8ad267
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ef69c28-6e27-4942-afa9-ad4876a8b0e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd201966-b8d7-4bb5-af83-15447c377450
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8cc7c2a-79f0-4f01-86f2-8573da630b70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fec50fcb-edef-4603-8bde-3d8fe063c06c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ee037cd-bf5a-47ea-8889-3428cbc191d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22b03da3-3703-41a6-9e9c-ffc4626f1c30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d8c25a3-47c4-4e5c-ab94-e99e79853804
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d0b5675-ce7f-4d60-a9b0-dc16584519bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a400f018-2d4f-4764-a381-c9a6aafb819a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 776fda6a-f10e-4336-b201-8df3126e73ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 634b9520-ae81-4c1a-942f-6df6a418dce5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cff51a93-3c77-404e-85e4-aa396633a078
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0db5b764-dc2c-45aa-abbc-bdea83b30328
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f31a674f-deac-47f8-b290-e2849cd29d79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1bfdd1ae-9691-4916-ae9d-9b0f9e41ff1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6dc30f5-dc35-4a3d-96a4-2ab16d0a6134
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce502705-19ff-49ab-b233-a329afc0d235
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message abae4749-bef6-4e91-8bdc-64f2e5449f55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f93c77e-e83a-4af0-b1b1-fc6b784368ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32752353-f629-418e-93d0-4efb288501f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76c828a7-27f2-451c-80b0-c5f2c9f5cbea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8029f4c-8954-43ae-9aac-1788e09761a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3079bb36-c5b6-4d28-8a5c-8a24e868900e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 671594a5-03d2-454b-a928-cff2039af0e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e11ea4b-8b0e-4adb-8781-d5e0832ffcc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e7b6241-fdc5-4aa6-8847-5f8fa734c0cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b294ee9f-12eb-426f-a36e-a66e5be2bbcd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc7f69cf-edc7-486a-b27b-c44532fce856
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e72bd620-7234-4bee-b32d-e2e184a13f79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d52e8ed7-1c3d-484f-94e2-0e6de29d2ab7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3197a54-e74d-42b7-89f9-ed0723e363b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ebebbff6-c51c-4501-a21b-0f3b270b5c9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4ad5a70-5b3d-4bf7-8be7-7ab667d7771d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d49c09d0-5b7e-464c-86f1-c8df33ef8cfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18780d26-edcf-4a0f-a611-f59f6bbcee3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92f30d5a-6c8c-42f6-900b-a9e18b5b8907
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a12b264c-3f9f-4a38-9445-dc3cc0dc440d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef83edf1-8251-4dfb-9e22-9cc4da923f68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ddf786e-70eb-473f-a757-5db815da69f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd582841-ec34-4d52-bd70-1888bd45fb83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4cc78ff-4099-4cbf-9a8c-061cb681f4e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1fb278c-d0c3-4ddf-a8f4-7231ad0d7157
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37ef696a-9bc4-4bd5-8db4-864cf16433e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5a23b8f-3fcb-422d-9d05-203e9b2429a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee56339c-115b-46a8-8de6-31024244e235
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ba5ecbe-b6c8-4356-b81f-12e713bda942
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa57662d-e342-41d2-a194-ef99e093bb6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4eacf8b6-e456-4762-8b4b-4957972aab83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d86bda4a-83e1-4c77-9180-c03f832cef31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c01138e-1509-4e3d-9f1f-d429af51c1f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11c38bab-148e-40de-8dcb-c1ec6ebcc546
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52bccfc6-3e2a-4a47-a170-ad4fc5bb01f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28e6a464-7ac9-4ee0-9cbe-8caa38edfd93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07bbf758-1985-4bee-808a-bc3ab646c35a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b55d4963-1b12-4260-9966-b978790aa1e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 210362a2-2160-43d3-9c1f-173608baca01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63944dd3-9d9a-4b7d-a876-6e250d3da971
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6934db4f-aca4-40c2-9cba-37b174bac0c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b922288-e40f-4254-b448-3a44a558608e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c25b7f20-b192-4d32-9d77-6443711ce5ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68d731e7-a6b0-4493-877c-60a0234acfe0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 394d9f9d-fc1c-4b07-81b7-1b6af6d4292e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 851ed3d7-827c-4b33-ad13-161efaa526aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80a86fb7-11be-4c0e-af18-0cc7855226a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9fa98e0-aebf-4459-9fc3-9dd2b87d8080
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81d89508-c352-4d01-af0f-a6d69ff0cc7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d951bac8-b5e1-4d1b-bfcf-43dcf052275f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3271e88-75e2-4166-94bd-af0b3b30d19b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a678ffb-25fe-439c-9cb0-50436bb79a0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 895362e4-e7b4-44a8-9f4f-09ff1c2c626f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca3c2f50-c30a-4c75-a5c7-71e8952faa24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 390c7bad-a8e1-4e6c-9914-e8e5e3c440d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e48b266d-2be9-4bba-853b-5a125ba43a04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37617aba-deed-4469-befc-711e4a52dea5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b29835f1-3664-447a-accc-137230ceec8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4fb257a-2cce-40e9-8c54-4091e7251c13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 900bcc5c-077d-4511-8ce3-7324747af5c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1776f148-d751-440d-85f9-17a57a5fe1c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b130b954-990b-44cc-9a7e-83f392fee149
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ecc566cf-eb40-41aa-872a-c733a9ba1011
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df7844ec-5d2b-439c-9c2a-c6b199bdbe96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 200325a6-64c5-424f-9276-d286171bee2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1260cb2a-7ce6-4768-83c5-4b9d82293a50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48d17a05-f8e1-48cb-a5ff-dec5b921b52a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2457954b-ce97-4bf3-833f-3c590d2808e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c114478b-2afb-4226-82b5-1d4df6d56209
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7cd866e-5101-4af5-8639-2d9ed9dc0566
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 589662f9-892b-48ae-9869-c49c48bb9187
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7cb6751-ddc8-47de-a12c-5c274d2d1ad1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d5c0f34-2824-409a-8e87-99bf70ad6883
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb5a2015-05c6-4c90-8449-22cb5c82610b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30d3075b-fc59-4dac-9f69-f5cf42b702d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f93375c-5882-4180-92a1-32d283c61560
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b77e79f-59d5-4170-8c5e-0e9ef71ae5bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0befbf1-e321-4212-8e5b-bceabc40aa34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b73819ec-ba81-4e3f-98f7-87f6fadb9515
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 844b52bb-7db7-43de-95d2-8fbeb2b821fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c6c54bd-be5e-4204-bccd-68adbf1d3431
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e76eebe4-2859-45e8-a7b2-3b7be6d9eda5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9dbc1000-e2b5-48d3-a4ec-b2baa903ee82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f410e78-52b3-4390-b1c2-55186b16536d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b27e8671-0763-43c3-a471-4f343f53b533
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8b2ffc3-26dd-470e-9f9c-749cf696c0a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e671e24-1763-4c9d-8be8-0c9c0f79a738
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32bfe499-0d62-4f23-828a-4bd25aa2c763
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9e47c7b-5b9a-434f-90cf-d55e21928a1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 931632ff-4fdf-46fa-8bd0-0ba08a540121
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 155e3037-9506-44e7-be10-7f869b1f7ef0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44eff2d3-9fdf-42bc-9950-a82f72f646ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27ad81ed-8df7-4218-a555-eaf29f9dcd51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 317214d8-5ae9-4f44-945b-65b847e22185
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10654cf8-068f-4b91-bffd-2082d49aa612
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 922e7a9c-c344-42bc-a3ef-a4ec2b61d2ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dbb36c9e-29b3-47f6-ac9d-ced39acacde4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25fe2da5-60c8-4596-ad5d-dbe4e4f0c095
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f1ad4a8-ae7c-4ad3-8505-dde1ee2ac7f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4cec7514-e3c3-4afa-8e89-b37d83b06811
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6d67320-baf2-46cc-819c-475d205a4db8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5bc4cda3-112b-4e39-9ef1-d93b7f694cd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3dce42ae-2c4e-4a28-a3de-ba00825b2254
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3bcdf499-fa7a-431e-9965-16f99fc0fa90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e0c22ba-986c-435f-97e1-e9a603ee93f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de9835c7-c83a-4894-b235-40bef6bf2fb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3d5c4cd-5c37-4307-8937-f7b31c0353f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 453f0648-207f-4b1a-87cd-7631236def43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 559b19dd-78f6-4cca-a642-4b1901343b3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76b77692-53e2-40e6-bfb0-323e53402aa5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5781348d-5c48-4015-9c62-b4d5a3137d8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2ebe560-1985-46d4-be7c-0afe57fa22fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46d649b4-c6de-4342-a065-b9d079c8e4f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 120f70c2-f89d-4d07-8ba2-bdaa1af46236
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0533c9dc-b914-4f40-8500-fa7e4f9c8152
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f024a27c-fd88-4d76-95d7-98d81e910f0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f40eeea-43ce-4814-8157-9b0987b082e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc5f6415-8703-4010-9d06-f091d010b8d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8b02c3c-1cb4-40cb-906b-0772aa533a3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ecca1f9-abe3-43f2-81e5-e30871cfa825
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c85c1339-c768-4974-a01c-c4db4ec7be2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a78a05e1-ffce-461c-9d11-8ff6949790da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b091ea24-7b4a-4663-9d93-d64e08e0e42c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e5e141d-b714-4d3d-94a8-ab4610a8283d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd1ee813-4252-4496-b49d-e0ebac689c55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a3d7f63-e21e-4082-b7f3-bb854834068e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46293688-3996-4f76-945f-f691398a6be7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4910ff8-c00f-46c1-8395-41f865114a9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c9732fa-c604-4c9c-98f2-91db8c6dfc40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2043aa77-4e1a-493c-965a-079b9e2eed29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64845aaa-7d20-4235-8cab-e4ac32b51269
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01dc5962-2965-4e7d-b0f2-a7fa7aadb619
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21d376ac-78c9-4802-b452-ce8508167130
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99a67690-4f41-47a1-9515-89dab9e21868
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f20b254-caae-4f5e-a652-4b8b3dc8e446
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6df16803-46cb-4065-b244-276b8a0ac8b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ec7718d-dfd7-444d-bf65-e47a39006705
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message adec83d7-cec3-4d35-87ec-6dec201ba40f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fbb299a6-7e2a-4107-ac64-3331a7ed39e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d90143e7-4ab8-4471-885c-bd02fae72679
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 137ca242-12e6-4148-bf76-57add107a375
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7583c4f-869e-449e-95f8-4b8847566f04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38194d90-fdb5-4b83-942d-b000c3a453f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 542ba05a-f061-46d2-8596-eea1a9baa55b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bdfa7f2c-834b-45e4-bbc3-b682a3f8eba0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e5fa6d9-bc67-49a1-9fac-35f7d48278a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee147193-679d-4fad-a2f3-7b8bb8ca1c99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3f21f66-b6eb-4b01-8887-9b7e9f44197a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea1e5d1d-4a15-4f24-bb8e-b08a4d7fe891
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57c825dd-a94c-44ca-b5b4-182357a124a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3797e113-86e1-4eab-8276-96213c61cce1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30c362cb-8cf6-447e-8c0a-02be0bd0a1a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d109cfe7-7f26-4656-8474-402355420f89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d85d1ef-4584-4424-b2e4-dfe50ee03bd8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97bc8df0-47cc-4836-b1f0-7f6b44f16ea1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8645763-c7ca-466c-8a45-0df7b3836bb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9741fa1e-f8b1-48b1-9be8-b9e514cab94d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7839fb4-1475-4436-994b-36002c4e3e4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86ed474d-bdd0-4732-a128-98537391ce29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42314708-1671-47b4-b62d-790b0bae6fcd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f8ecfd7-afa1-4213-833b-5043350f04fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7dca8f1e-74a6-4da3-977c-5abde75630cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e3170d4-3cc0-4452-ad54-567ac9bf6c65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8eeb5d52-e208-4b52-99ce-a9faf36f2dda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b1f4d0f-95ec-4777-968e-f077639e8329
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a54ee01f-b721-4892-8eff-b93387303e49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f1874d8-26bd-409c-a469-0c65cb4050d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8afb5f44-26e4-441c-bef3-f700104b0483
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3a9da26-1313-457c-b758-6e6658de9583
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 077c50ec-3c9a-4b5a-8b01-e3532ee0506a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f15f92df-8761-41ed-bc38-26781fe20a95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07d72f71-508f-486a-9f84-18bfb5126708
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6bd4e747-f84c-44b7-859e-95c8ea797123
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 098a0a64-9fed-4b81-8cc6-c4adacf0e4de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6568c60c-5e5b-426e-8b5f-3d045ef6eeb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c1fc650-2f6f-4598-a319-2d436df7fb8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89811d2a-7f83-43ac-a1d9-c6d4b14d3f69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b5aec9d-19fb-4ed2-a6f9-ee9b4f4d6a1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f6e534d-ab59-41b9-9a45-565d7b096daa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 859a00c8-9c7d-46dd-b2df-be0a5841fc3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4194eb20-c810-4d7f-b1e1-fb27e13a5d25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bbd0b879-04a9-4cad-8d9e-f16dd39931e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95c03820-5525-4e8a-920a-2d553bca32f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6fbd612-2329-476a-b2a3-0d964c88be73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a774cac-0250-4ca2-a37c-350a4c29eef4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89cd95c0-42b3-48fd-9b1c-59df1edc7122
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8eb7cd14-adc8-43d9-8854-342a101e2e73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7123c7bc-bff6-4d80-81f0-27ff62f27f74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eaebd574-ef26-459e-bdd1-416ba728609f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ff0e98a-2496-49e8-96a7-fb6e8ab7629b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 447e0fe3-7aa9-4cac-b0af-31e406cf9d05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02a836f4-84ec-4305-a38c-15c93c06bd9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6b660a0-5b88-4fba-afd0-b6983be2a703
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 154abdf8-0db9-498d-8d9a-eef3f536f445
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff63d2af-0e6d-4670-83de-8582ba64c82c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0c7c986-adc3-4140-9ff7-706cdd5c7ef2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da4a9a76-4cb4-4938-b8c1-210a4fb63246
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7aa0713e-21d5-4f02-bae8-970b4a3325ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cac822fc-ad1d-4b73-8292-305850a79fbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d262f84-4bd9-472e-bbce-e687acc1b46c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28d1e460-62f1-428b-a744-3ed3eace1ede
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c519ebc-e4de-4b99-9877-1e4286ba67ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0b03b94-1dc8-4921-bcff-f8acf060c08a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32a05b7f-8d88-43ad-86cd-78080b4ce626
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b00d2a3-2be2-49e7-9c3b-791d4181812b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message faad4071-df90-4e26-aba3-d011a5c23301
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91257374-a2af-4b4d-853a-2c33b16fdba5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4579d4e8-e4e1-4901-b7aa-895de480c656
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7466107d-ba07-4b65-aa8b-5e956d401b13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3c04cfc-e484-4d40-96a9-ea8932d2b4fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f14faf5f-1a1f-45ac-b7af-8813dd8cd994
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 332e6dcf-6915-489a-9b5b-534796e889d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5cd34ef-356a-441d-8b07-a527e27b6d40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d0469c7-85cf-4e30-a94f-93b2aa8fba4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd5e0a44-e26f-42ef-a9e2-e1a8de9e43a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c9f1952-fb59-47d2-9b80-ceb0fd9e2e4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18353acd-2237-4f5e-9959-adfbf1ca6a91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62d5feb5-8f65-49a3-ab4d-b4cb1bc836f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 235aaacf-2c7e-4128-ace2-60566443314a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19846481-fce2-4d10-ab7d-49721b8d71cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08a0971e-4583-4304-8007-12ff19fa7176
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ba14236-164f-4d04-89af-921b504037c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6fc4ca5-3d91-4920-83c6-11f1fcfca4ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92f2c5bf-acf4-413b-9d53-a9c2b5436c41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59fd8be9-532a-48a2-992a-d2db153876a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fbdd23d0-2b88-4263-94fd-1ff4e555e497
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bafbb0aa-c05b-413c-94a2-677453ead3e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a517017d-4bfd-4acf-ace4-24afb2a0334f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ed0ba69-f5f1-4597-a37b-ad3d221bae72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac35e383-050e-4bac-a118-de15d3871219
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bbd38bc0-1562-4af9-8434-221133c89fe1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a862f25c-e4f0-4276-b0f6-a250bff676c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message badc44a5-fa8b-4f7a-806e-45a33161b47b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 402b44a1-c9bd-43d9-8e8f-09c4629114e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b26bebf-6da1-45e7-bdfd-d036ad09ea34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f6404fb-96e6-451c-975c-1cd746eaa6d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98730134-4dc9-4ac0-980c-e018bbe6c2e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3188b3ce-7d14-41f4-8e5d-bd9cfc134e62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7aebfbab-ef53-45f4-a239-583708ffd0df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47da106d-1bba-4ff6-aa77-d6e248211cd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47ac5a64-5b6d-4828-9a65-cfa5a2608980
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88a5c1d0-d19b-48f3-9010-94487dcb28dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59ea9d4f-28a0-4b2e-a36d-80b5feb1771c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a8e9fce-19ab-4ebf-80e0-5635fb335114
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28bf3f03-8b7d-4d96-afb9-917ee6a09cdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7019d1b5-70f7-4cdd-94d8-0f3ada2494a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33787068-ef1d-43b8-bd3c-6539ea2c5723
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cfe8e040-c9b0-4d2f-91c2-aba755b700a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2faf542a-114c-4a1c-92fe-51c7884af2c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8bb242e-c96c-44a4-b00c-9a96d2e1bbf3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ccf076ea-9c69-4941-8d6e-a9fa0faaabfc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f822b035-aecc-45ca-9dc3-df8b61265b52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1dd8d25c-d4a1-4a22-b789-163fe57f2a6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd8fab24-269c-41c1-bdf7-a9daeb97a032
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 912b51a8-85bb-4084-98f2-23efdc8be5e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0aec3704-aa24-4de0-911e-0f40466358cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64b5bddf-c119-4773-8d0e-daf7f8d96838
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a67b1a8-047a-44c2-9221-16fc0bc6fa42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ff53323-986c-49d6-9b5c-7f588fa1259e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b05886f-7d17-4f95-85c3-5464fd69be25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c3c7ba1-51ff-4592-afde-f234d8e83f9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ded9fe1e-86f4-4c2d-97b4-97eb3cf967a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2115bd4b-87a5-4e34-9e87-b28b567346cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d653b17-d1c0-46ba-b42b-d7b28356efdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2d8249e-a144-4c5d-af31-44b7afc556a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4785b3f-bb1b-467e-aaa8-a1f5870ae53b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2940914a-7b73-4fe0-9e21-09c87ad3c962
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d1fda46-468d-41e5-9dc6-5fe97227a64f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 663ac5bd-f894-4036-ba83-472dfdab8164
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a4e757f-4156-42cb-ab20-e02d7e8a1c57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e93509a3-e725-4d3c-8a5e-124126eb999a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48e260c5-832e-403f-a6ae-09df05f26230
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8bfbe352-c5e3-41c0-8a55-33caa5e69124
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54074219-6de1-4d27-8966-caea274ec7b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea6ffded-98c2-4ea2-b10d-e171fe61182c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d89bc3c3-da0d-4750-ad1a-03cd6ec63b40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f55e9369-f351-49b4-b1ea-1f86b34ac380
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 547637d5-2cce-4cf1-bc9a-b575b950154f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a4bd3d1-841b-4676-bc31-dd5ca063f8e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64180de8-e335-4218-a99d-e9b7df9c8131
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4a414b7-567d-4bcf-9d19-56ae481a3def
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8abd8588-747d-4732-b869-b3be7e0f2845
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message beabcbc0-862f-4ce4-9bbb-48d7a7cd7de8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 115dd80c-7dde-455c-b6d2-7223a5fd57f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27ca8e29-d09e-4576-b149-480474d916fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 158f8be5-f7a9-4bd9-b313-22565c143e7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 547b5cc8-1b4b-4e50-8815-afb5a9e57b3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 131ac50a-7791-4ce3-af91-a73ca922dc25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 675bd845-8bc1-41c4-adb0-f522b2b42436
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31155cf9-fcbd-45a2-b04b-318a46daefe3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8eb352a3-f6e1-4fc2-9ba3-17d659d31d06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cbf79890-343f-40ef-aa8b-605dcb4391c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a2f6871-a92d-4aad-a211-a13e0ab6bbc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b27fcf17-db30-41d2-88aa-f8a42f99a226
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 916870f2-a769-40bd-a313-65032d7bf308
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94ea3bc6-db7e-4032-8302-f2f9920fbcd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9dd4d4d6-3b47-4331-8fa1-bc50c909a0da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f19ced20-c2ff-47e6-ad3b-e27503f53d84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b55b16ec-922d-4b0c-9d74-808b2f920d47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bff5d5d1-f732-4c83-b8b0-1d22ce161994
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ecf9f5eb-73b6-49e8-8fd5-f92386573248
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54d0e38f-5e92-4715-9e51-883b2ce679fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa17444f-a984-4b29-b81d-1becf640b4e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df285448-1d96-45ba-8ca9-c15264107b1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aff6e226-7926-4d06-9d78-18c3f500c457
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66f1c02a-7bd1-464e-add6-4352ecc379d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2bf536c8-4080-47a4-9d8e-4a84e2cbc51b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80b2ad12-3f12-4a85-8625-e33fe7a9d8ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54846c88-bf17-4d5f-8bdb-788089cd6360
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3aef639-41e7-43a9-9887-df93a40991f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1af3ceac-fc17-422b-ae94-283676323980
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a211d94-704d-489b-ae55-7d0d9c0f70e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0edf7658-fba6-4b3c-bd42-8690b52fce99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64949e22-7195-4e06-a380-50dff96d2200
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4bea1f49-9b23-4a3c-8a61-dafc62e37c0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42f59566-99ce-488c-88f1-dd27406b055f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4009b1b3-3688-4860-b051-982cbb3fb95f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1706ce1-eb91-4e0d-80c4-9d2a5092b111
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3705b9e3-6b9e-4ea0-a7b8-15bc7c636ae9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 733b142e-e5b9-4a4b-a413-4125fc9030a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6c220e8-6d8b-4270-b36e-91b5091d2973
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e64be83a-261d-4df2-80ea-0b561c801b7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message daaf37fd-21bf-4f84-a4a5-a1a9e4847a51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 859fcf82-d496-4df4-9f75-55c03e74cae2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73fb45a3-dda6-47d6-bc3d-a91bdc684e5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fdd5c635-447c-414c-9f1c-2034f0aed8dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e6bb2fd-8720-4aef-88fa-7a223cc9439a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b66abb0-c9fc-46b1-a8fa-eedcc35f1307
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8178b90-f8af-4476-b27b-5d6166cc8cc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8aa52a3-20ad-4d17-9153-9c812536d1ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c14f2d88-c996-47a2-9c42-73b430fbf583
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb5451cc-5424-4e8b-a6be-f21dcfbda0ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8ef44a9-4403-45eb-a651-1bf7815f7112
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ce88620-9348-43bc-bd7b-add59f09872c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e148f422-4f70-42ac-84c3-755539c5a9d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af342798-0f4f-4c2b-95f2-05a3055eef52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99bdbf40-5c98-4dd8-a835-b02aa93b028d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f1155e6-8c1a-4048-b5ad-9069457a185a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70a24c08-37ec-4322-88f3-7550aa659dd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eeb6d771-09ae-4a3d-8e07-05bcbba7bdd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec4fa1e6-964c-4578-b0b5-65731c3bd510
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8d87faf-e327-493b-8638-11641493fc89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 510b0b6e-360c-4eb8-a605-c819e5bab073
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62bfdf0f-f3c4-4943-a11d-3f9a55dcf974
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16327fb8-7a17-4b89-b418-5c256c29e6d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca2d1cfa-bcd0-48ab-8a62-0b5232959e3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa6d7a38-720f-4668-8362-e171af21f154
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66dc603b-02d3-4524-9fb6-bea4db340b21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df8ab97f-c7c1-4dd1-923b-49598f02aa2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ffff42c-bc1d-422c-8b66-f70b582706d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37d9c15c-2845-4fdb-b6c1-8ad111e72dd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6be40c97-f1d0-4160-bf54-fb8ce8531491
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cabaf049-da6d-4143-95bf-9ee394343258
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c64d9f54-820e-458d-a0bf-b3c7ef68b0c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f36f13df-dfd1-4d5f-bf95-b8f6de1e3cac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee98378c-3739-4ef5-b3d8-cdef4b2f68c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 135fc385-b60f-4657-a2d7-da59b725bbc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5fc4344-fe53-4ec4-98a9-4b02653824b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message afbad72f-f401-49db-bdfc-67ac22ac1ef1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59dd9ea3-e2a9-4928-9583-1ab9bc4fdde1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20452823-3a08-42d6-9919-a6bc6d9d552d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e39cf7e6-d71e-44c1-9dd1-22ffc1aff77b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb2cc9df-018a-4af3-9b3c-584bad00d434
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 421031df-34c2-4dc9-872a-eb89488d8ef4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f390bb8-5b57-4e93-a7d7-3e3992e4f0a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5c16f35-4733-4f67-a76f-eecbfbdb1942
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92809c01-e039-4810-8c3a-23a5b6d60a44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a456a315-db15-43ac-a925-3758d0d5cc91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 057f3d82-569b-4af5-bfae-4d16c7c34c89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e617143d-f12e-44af-b6b3-8fb438cf5d49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e513424a-1870-4a35-924a-d25e61c2b6ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a10f9b1b-461e-41d4-82eb-9f40ec94d927
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9514ab8-bb23-49a2-80b7-dc32cb07e557
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5603827-d00b-4065-ab45-a9051be153a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1e6bf59-b994-437b-925f-9a6ede3e7774
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2652963a-bdaf-41d4-93e2-37a35824bfc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62c25107-30aa-4d14-9ea4-f0b06408ee65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c453698a-9685-40fc-a000-03190ed27947
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 860f14df-3da2-4062-9dc5-c1e8f061022d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd393631-655d-4282-90e6-b9f1f1743b28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5328b7f-7acd-4871-84aa-fe88529f0dc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b40ef74f-2f5c-4739-91e0-48ba65274841
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 297db87e-2f41-45ed-9b03-a35ec9f27678
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1ef39e5-0696-4fca-a6f4-2061703d22f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6176e99-2fd5-4294-9c1d-1cd12ab461e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 886c69b6-db9d-4341-960c-09212ba95964
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9875dcbd-51f3-4c55-87fb-09b3b06303de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1671dd69-43a4-48e4-aee1-bb487405a537
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10278c9e-4b80-4413-be29-83bf0bc2d9bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d85d9299-f575-460d-92b5-7859a010db27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7871c577-eb6a-4ccd-a8ad-a3c022607ba7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c198f919-c337-423e-8a8e-43a6ea149e11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a628562f-6181-4b22-926a-8d9ed8e61117
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5033426d-5670-4a27-b974-8e76844d28c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43289cc6-4075-4bda-bd14-616c8082cc24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47067383-fb2d-4c5f-bb58-9ecfb46e8c27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7572496-766b-4f5f-b96b-fed7f75e5fa9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5da46f1-e4e5-467f-8f71-3e85b37158f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76eee417-8143-498b-911c-2043032db3a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80200301-6b92-4c90-8d6b-abb889bd1247
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f84d0e80-5d91-484f-a30a-52709c02eb5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2385d268-7ca5-482c-80c4-b5882a4aba9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5461b70-8fe6-43c8-a684-fb0d2a8c6963
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a97708d1-0036-4af2-96ae-f059d4de3443
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da7824d0-581f-4777-9d99-d78185c5b995
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a3a0f7e-931f-48da-b523-cf3b475d8918
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4fb0670-9cb6-401b-bb1d-4df5097f09be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9a51c08-3cd2-477e-b617-32f6594d9ade
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15e71d98-b24a-49e0-8fec-840600cb1ee4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c37773d2-5930-488c-b1d9-49ba80635cbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ba47c2f-9d13-4e69-bfc5-f81595afd6e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6af99d24-7897-4082-a2b3-f52fe103eca1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9c1e93b-e7e0-4eac-a555-4d38fa0609d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6038cb5c-4a74-40fe-864f-19f02e1fae2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1657efe-1061-456b-96f4-2be6db57c0d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c0ecfc9-5395-4aea-9e27-ddac445230df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b13e6dcd-8aa1-4c25-a38f-29c74d08b067
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa41820b-7a1c-4459-b906-ffb834d9d3b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5bbb927d-a274-43f0-b189-43759e464612
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 231f3c98-952c-4a54-92a8-88e1050fdeb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e27d05f-05ff-4085-abc8-59be6746bb3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 037204b6-1e50-401f-b41f-daf42e551ed2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc8761f2-affc-46ea-bc64-6983b84fb4a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d1ce506-9e75-4d9a-8e8e-29d04d609c36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a404a6b-a2c0-49ff-8653-16e3677d5448
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7bc049b-ba1a-46da-8166-8b41b7c1afcb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7f282e2-cf42-4872-bf4d-b2119678e264
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 474c9578-d707-427a-8322-41fa7a1fce40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20800e90-1afb-4b6c-a82f-c1bc11e9b5ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f12b7ab-cf9a-4ca9-9a80-da02f47b5ba7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 936040db-3fb4-4c5c-b76c-9620ad65ea3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dac06c62-ee0f-47c1-bd47-5da6b4e896da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9152af9b-2218-409e-9a3f-17a0cc9a4603
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 219b71ec-f964-4bf4-a1c5-38d56ae729ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13dc6a18-8fe1-4a90-9bb1-4a45a370caae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06002a4f-91a5-4238-a624-9b3c4d9b4848
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 754f8fdb-ffbe-4e16-a550-8ea77aa477f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50c59b65-f0a2-4d22-a1eb-9a9e267abec9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a004c36-c285-40be-af89-60b7a88f02df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad8f99b9-c6e0-43c7-84e4-20ef716fb6f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba63dc2e-6d6f-4892-b97f-8555fcacfb26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cec426e0-ccb9-4d74-97fe-74ff628cff0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d88e7ba-65b4-4c3e-980f-e5e35ec7f000
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d76bbae6-1278-479d-a2e9-ac750849e0c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d67f7c5b-c8e5-4e9c-ac26-6a752459ec55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22a6a5c6-f26a-4acb-93bf-5f0ae4546d81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52c16cae-e62e-4ec3-aba9-bc3fd791ccab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77cb66cc-29dc-4f56-b539-ef1ae2f010ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35b5553f-9b20-415e-8aa1-a75eae90c6bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4dd3282-6d71-47af-a556-07dc10e691a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a46444b-15d3-422f-8e38-500f614b987b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d619fc78-db71-4197-a005-ae12592c6a1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f40031c-09fb-4d73-a8d0-a1a9e0114ac1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 758fa0fb-6c48-46b6-88ee-4a71944c5656
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6b44ed4-fa64-4b6c-8c6d-f9a36c2aab9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60b98611-1504-411f-96eb-2378782de486
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e090e35-bd6c-44b5-8990-21bf2b504909
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0c80da2-d394-48d9-ae75-a60e5187d647
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85450709-3d57-436e-8e5e-c768a53e7528
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d89c970f-39de-429c-b31f-cf2f11d646e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4121b846-7b76-4d7e-ab1b-b4e206d9b9d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e3041a0-030c-4871-b1f7-5322489f7018
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c6c23f3-094f-4bde-83d3-0c48ce7ba2c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0132bf3c-340c-41b3-b22d-4d6f42f7d8b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23197423-12cf-442c-923f-6b238f603a0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6d6eeaa-535c-4aeb-be19-bd9cd46e9178
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d98fced7-bd02-4f85-b4ef-43980b979b27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad7d5afd-90a3-4e04-906a-b01474e5c338
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64aea551-8a21-43a6-ab12-9bdd76518967
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7324469-b343-469f-8572-5a60c10fc602
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31c28ca7-0ed2-4d88-9dcd-d04cef9e0117
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01edad32-de02-47e5-8912-55e6b6489afe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90269ed7-9538-47a6-9275-57c8dd91edc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75946dfc-a915-47d8-afd9-ca01edd3c4de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c0a6567-5541-4454-88b9-8f4820d7ed25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b88c37d7-4eb6-43cb-887c-ff3316634992
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a1be4eb-6f89-46f0-97e5-705c01c434ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b88515ba-e773-4098-961e-a4dd49ba838a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ffc65e6f-9d99-47cd-81af-d44288f718e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab52c2ea-a4cd-4537-bbed-416b112eae7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7647c26-1fcc-423b-abc0-cd133ff26310
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9fa7684-1c5d-4644-a984-01a926fb1f7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8acd5af6-ade6-4fa6-bd5b-426d0b2ba43c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66fb1406-33d5-4484-bbe8-f05d7f9122db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f66935d-477e-459c-91dd-212d49a5effd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ded4031-4093-42d3-81b2-79b20f7d57f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f9f1e47-8548-4ca3-b558-05ac1aebd30b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4adbafff-4feb-4e97-abbe-101c7ee19377
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02daee1b-2e8f-4dbe-af22-4a61eac66d03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15e85de3-734a-4775-96ad-aac51f49ba88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b66b417-a8bb-40ff-b3d9-ff0e83996387
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b974c930-7296-4384-bec2-092544eaceda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ed822f5-daac-4624-aae6-c7f886d6f299
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 769bcc86-3733-4583-acb9-00f2fa4e9799
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e47352d-e5b4-41de-83a4-19fac6e818e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a890648f-b4e2-442d-998a-743f67b097ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d4b1ab3-c706-41af-9323-9e1b7876bd0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 729c5831-b4ee-4648-818b-c334055d4d87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d002d45-0ed7-41ef-8483-4441c711045a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e6fdb46-43a1-4d9b-b225-89debb7be264
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8db086e7-cfa8-4c69-9c1f-dbb110266a91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f63caee-cda4-4357-b9b8-476c1e4cb02b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4955e6dc-8bfe-45c4-ac79-67d219b4f986
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a82f49b-e035-439b-95ba-85adab41217c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74c32a3a-41ee-4a9f-aa3e-bf4d1dc2e563
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eaa3105f-2d3c-4a02-b8e7-3a10f8c97569
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70dfb6b0-e4dc-49f4-9f7e-7c3418473910
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 326b6269-d2a2-45f4-9f93-ac59c5bded44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a8672ab-0322-4f3b-baae-c4ce49f0d6fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be684139-e5a5-4dff-ac15-0788fb890043
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be6069b1-5927-4439-bd3c-e48666a69379
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48ed2db1-8b75-46af-9a28-9d14529276d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d8ce7dc-14f2-4abe-bbda-ff583c28d557
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e629665-34ed-4c52-9098-1f99e80099ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message daa67637-db72-4250-9c06-f7a55fc333b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cede2e05-7091-4080-914a-7e2681e0c5ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6132f6e7-ca22-4297-a129-06ada613cf0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5bc53686-dbb7-4ae1-a05e-6ebbc97472c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d34fcde2-dc71-40b5-ac8e-ae3cf9f5f756
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7383d5a-641e-4cdc-9d91-d6318debe0e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f751fbd2-38fd-4627-a086-085d1d47b736
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10eb0f65-48a4-443e-b7d6-5d78c1dfd03d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4eebd067-7052-4486-bfa8-f2b22a2adfc1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 031fef9e-c2ed-4eb2-9294-29df53b78535
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9becd437-4624-482c-958f-de1a21be2faa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46e5ccf4-d178-4fe1-bc23-1d7e21939f03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e62321d6-12e0-466b-8dbe-4d1aa0a53e4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b05c1048-4bab-4fad-83cf-66e32139030e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 911bcf48-acbd-4f4f-be89-831cd1b59d7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7967cf0c-05a1-42b6-a14d-9f6b31f6ef31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3764076-9c5f-41e8-8c81-4b7424159289
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2669e453-e559-4e59-8e6a-5f6b83f006f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d368e45a-dc85-49d1-86d5-f4f7081fcf18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0172f0c-a61b-4be4-b52f-5eda73c3d40e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9eabbc6-0c4b-4a73-bec4-9d7c7ea6502e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c03d3e33-b831-4c74-a064-a9c899f98066
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ecdd1b4f-ef0e-4685-8098-ab34e3cccdbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2098d9b1-4402-4b1d-be52-8781a093cbe7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11c6284b-678a-49a9-ad12-145b4956f272
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 850f0260-f484-4337-924c-5fa044209314
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6e5476a-3fd4-4ecb-8dde-f089d32c0b40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df94bc0f-8e11-4546-823a-a1c383e21ada
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d118ca22-2674-47d0-9fa2-220b7f210aa3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42fcb314-69ff-4ee7-b884-f72e45a884c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6ada5ea-20f3-45da-a6de-e2b62fa753c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3cf25272-c2c3-43ba-874b-53ed5c711f11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bbed7b52-4a79-4252-a7fb-e4c8415d9755
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08e27d9b-76df-461f-a9b7-343c38e97aee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 209e9d0b-4df5-4b75-8996-8fb9921f2f23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a83e6dfb-e9b7-49f5-8e76-5851a378935c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8cb51e4-eb57-4d84-bd68-b403a9cb861a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07ae7463-0a65-4131-ad59-1e7e615e31f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 030b96fa-6ecf-4ab3-afcb-f9becb3bc28d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ad22887-c3d3-43b6-8abe-3ef581091748
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22fafbfc-a6d6-4cec-8a04-3e8f78bc6d3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c913991a-f204-4abc-8616-f794596d69cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2b28e82-3b1c-4e43-9e3e-b1c6abe7e165
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37358db1-9def-4dfa-893d-f8de119b3693
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7986876a-990d-4fd3-b43e-f65917596e0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e47b2fa1-1d07-4e7c-b792-955b0bf34532
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65064be4-676e-4b68-9c75-db68b18f3871
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1be169fd-1f13-41bf-9272-6c3efcef46f9
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8692 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_8
Server: localhost:8692
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_8
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_8/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_8/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_8/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_8/test_labels.txt

📊 Raw data loaded:
   Train: X=(5265, 24), y=(5265,)
   Test:  X=(1317, 24), y=(1317,)

⚠️  Limiting training data: 5265 → 800 samples
⚠️  Limiting test data: 1317 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_8 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 2 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.3492, val=0.1411 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0938, val=0.0827 (↓), lr=0.001000
   • Epoch   3/100: train=0.0844, val=0.0831, patience=1/15, lr=0.001000
   ✓ Epoch   4/100: train=0.0845, val=0.0814 (↓), lr=0.001000
   • Epoch   5/100: train=0.0834, val=0.0817, patience=1/15, lr=0.001000
   📉 Epoch 10: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0832, val=0.0818, patience=7/15, lr=0.000500
   📉 Epoch 18: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 2 Summary - Client client_8
   Epochs: 19/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0019
   Val:   Loss=0.0814, RMSE=0.2854, R²=-0.0036
============================================================


📊 Round 2 Test Metrics:
   Loss: 0.4985, RMSE: 0.7060, MAE: 0.6443, R²: -4.9768

============================================================
🔄 Round 3 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.4387, val=0.3978 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.3379, val=0.2973 (↓), lr=0.000250
   ✓ Epoch   3/100: train=0.2105, val=0.1215 (↓), lr=0.000250
   ✓ Epoch   4/100: train=0.0904, val=0.0831 (↓), lr=0.000250
   ✓ Epoch   5/100: train=0.0848, val=0.0823 (↓), lr=0.000250
   • Epoch  11/100: train=0.0834, val=0.0810, patience=5/15, lr=0.000250
   📉 Epoch 12: LR reduced 0.000250 → 0.000125
   📉 Epoch 20: LR reduced 0.000125 → 0.000063
   • Epoch  21/100: train=0.0832, val=0.0811, patience=15/15, lr=0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 3 Summary - Client client_8
   Epochs: 21/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0024
   Val:   Loss=0.0809, RMSE=0.2845, R²=-0.0058
============================================================


📊 Round 3 Test Metrics:
   Loss: 0.4884, RMSE: 0.6988, MAE: 0.6364, R²: -4.8554

============================================================
🔄 Round 5 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.4698, val=0.4331 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.4288, val=0.3968 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.3955, val=0.3672 (↓), lr=0.000063
   ✓ Epoch   4/100: train=0.3663, val=0.3391 (↓), lr=0.000063
   ✓ Epoch   5/100: train=0.3374, val=0.3105 (↓), lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   ✓ Epoch  11/100: train=0.1488, val=0.1327 (↓), lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016
   • Epoch  21/100: train=0.0822, val=0.0860, patience=2/15, lr=0.000016
   📉 Epoch 23: LR reduced 0.000016 → 0.000008
   📉 Epoch 31: LR reduced 0.000008 → 0.000004
   • Epoch  31/100: train=0.0818, val=0.0862, patience=12/15, lr=0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 5 Summary - Client client_8
   Epochs: 34/100 (early stopped)
   LR: 0.000063 → 0.000004 (4 reductions)
   Train: Loss=0.0827, RMSE=0.2877, R²=-0.0057
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0058
============================================================


📊 Round 5 Test Metrics:
   Loss: 0.4815, RMSE: 0.6939, MAE: 0.6310, R²: -4.7735

============================================================
🔄 Round 6 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.4764, val=0.4723 (↓), lr=0.000004
   ✓ Epoch   2/100: train=0.4734, val=0.4691 (↓), lr=0.000004
   ✓ Epoch   3/100: train=0.4703, val=0.4662 (↓), lr=0.000004
   ✓ Epoch   4/100: train=0.4675, val=0.4636 (↓), lr=0.000004
   📉 Epoch 5: LR reduced 0.000004 → 0.000002
   ✓ Epoch   5/100: train=0.4650, val=0.4612 (↓), lr=0.000002
   ✓ Epoch  11/100: train=0.4581, val=0.4551 (↓), lr=0.000002
   📉 Epoch 13: LR reduced 0.000002 → 0.000001
   ✓ Epoch  21/100: train=0.4527, val=0.4500 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.4490, val=0.4463 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.4455, val=0.4429 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.4423, val=0.4397 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.4391, val=0.4366 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.4360, val=0.4335 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.4330, val=0.4305 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.4300, val=0.4275 (↓), lr=0.000001

============================================================
📊 Round 6 Summary - Client client_8
   Epochs: 100/100
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.4257, RMSE=0.6525, R²=-4.1975
   Val:   Loss=0.4248, RMSE=0.6517, R²=-3.8728
============================================================


============================================================
🔄 Round 7 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.4644, val=0.4861 (↓), lr=0.000001
   • Epoch   2/100: train=0.4640, val=0.4856, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.4636, val=0.4852 (↓), lr=0.000001
   • Epoch   4/100: train=0.4632, val=0.4848, patience=1/15, lr=0.000001
   ✓ Epoch   5/100: train=0.4628, val=0.4844 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.4605, val=0.4821 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.4569, val=0.4784 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.4536, val=0.4750 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.4503, val=0.4717 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.4471, val=0.4684 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.4439, val=0.4651 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.4408, val=0.4619 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.4376, val=0.4586 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.4345, val=0.4554 (↓), lr=0.000001

============================================================
📊 Round 7 Summary - Client client_8
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.4323, RMSE=0.6575, R²=-4.2608
   Val:   Loss=0.4525, RMSE=0.6727, R²=-4.2624
============================================================


📊 Round 7 Test Metrics:
   Loss: 0.4692, RMSE: 0.6850, MAE: 0.6212, R²: -4.6258

============================================================
🔄 Round 9 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.4497, val=0.4779 (↓), lr=0.000001
   • Epoch   2/100: train=0.4493, val=0.4775, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.4489, val=0.4772 (↓), lr=0.000001
   • Epoch   4/100: train=0.4486, val=0.4768, patience=1/15, lr=0.000001
   ✓ Epoch   5/100: train=0.4482, val=0.4764 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.4460, val=0.4742 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.4425, val=0.4705 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.4390, val=0.4670 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.4355, val=0.4635 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.4321, val=0.4599 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.4286, val=0.4564 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.4252, val=0.4528 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.4217, val=0.4492 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.4182, val=0.4456 (↓), lr=0.000001

============================================================
📊 Round 9 Summary - Client client_8
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.4140, RMSE=0.6434, R²=-4.0805
   Val:   Loss=0.4423, RMSE=0.6651, R²=-3.9884
============================================================


============================================================
🔄 Round 11 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.4429, val=0.4037 (↓), lr=0.000001
   • Epoch   2/100: train=0.4425, val=0.4034, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.4422, val=0.4030 (↓), lr=0.000001
   • Epoch   4/100: train=0.4418, val=0.4026, patience=1/15, lr=0.000001
   ✓ Epoch   5/100: train=0.4414, val=0.4023 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.4391, val=0.4001 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.4354, val=0.3965 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.4317, val=0.3930 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.4280, val=0.3894 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.4242, val=0.3859 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.4205, val=0.3823 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.4167, val=0.3787 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.4129, val=0.3750 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.4091, val=0.3713 (↓), lr=0.000001

============================================================
📊 Round 11 Summary - Client client_8
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.4058, RMSE=0.6371, R²=-3.7652
   Val:   Loss=0.3680, RMSE=0.6066, R²=-3.9930
============================================================


============================================================
🔄 Round 13 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.4110, val=0.4050 (↓), lr=0.000001
   • Epoch   2/100: train=0.4106, val=0.4046, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.4102, val=0.4042 (↓), lr=0.000001
   • Epoch   4/100: train=0.4098, val=0.4039, patience=1/15, lr=0.000001
   ✓ Epoch   5/100: train=0.4094, val=0.4035 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.4072, val=0.4012 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.4033, val=0.3973 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.3995, val=0.3934 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.3956, val=0.3894 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.3916, val=0.3854 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.3876, val=0.3813 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.3835, val=0.3772 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.3794, val=0.3731 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.3753, val=0.3689 (↓), lr=0.000001

============================================================
📊 Round 13 Summary - Client client_8
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.3696, RMSE=0.6080, R²=-3.3195
   Val:   Loss=0.3650, RMSE=0.6041, R²=-4.0342
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.3446, RMSE: 0.5871, MAE: 0.5110, R²: -3.1322

============================================================
🔄 Round 17 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.3068, val=0.3299 (↓), lr=0.000001
   ✓ Epoch   2/100: train=0.3061, val=0.3292 (↓), lr=0.000001
   ✓ Epoch   3/100: train=0.3055, val=0.3285 (↓), lr=0.000001
   ✓ Epoch   4/100: train=0.3049, val=0.3279 (↓), lr=0.000001
   ✓ Epoch   5/100: train=0.3042, val=0.3272 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.3005, val=0.3233 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.2946, val=0.3171 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.2889, val=0.3111 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.2832, val=0.3051 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.2775, val=0.2990 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.2717, val=0.2929 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.2659, val=0.2867 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.2599, val=0.2804 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.2539, val=0.2740 (↓), lr=0.000001

============================================================
📊 Round 17 Summary - Client client_8
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.2480, RMSE=0.4980, R²=-2.0089
   Val:   Loss=0.2682, RMSE=0.5179, R²=-2.1657
============================================================


============================================================
🔄 Round 18 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.2985, val=0.2624 (↓), lr=0.000001
   • Epoch   2/100: train=0.2980, val=0.2620, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.2975, val=0.2616 (↓), lr=0.000001
   • Epoch   4/100: train=0.2970, val=0.2611, patience=1/15, lr=0.000001
   ✓ Epoch   5/100: train=0.2965, val=0.2607 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.2936, val=0.2581 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.2886, val=0.2536 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.2834, val=0.2490 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.2781, val=0.2442 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.2726, val=0.2394 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.2670, val=0.2343 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.2611, val=0.2292 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.2552, val=0.2239 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.2491, val=0.2185 (↓), lr=0.000001

============================================================
📊 Round 18 Summary - Client client_8
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.2436, RMSE=0.4936, R²=-1.9859
   Val:   Loss=0.2136, RMSE=0.4621, R²=-1.4633
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.2698, RMSE: 0.5194, MAE: 0.4350, R²: -2.2343

📊 Round 18 Test Metrics:
   Loss: 0.2348, RMSE: 0.4846, MAE: 0.3998, R²: -1.8156

============================================================
🔄 Round 20 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.2306, val=0.2312 (↓), lr=0.000001
   ✓ Epoch   2/100: train=0.2300, val=0.2305 (↓), lr=0.000001
   ✓ Epoch   3/100: train=0.2293, val=0.2299 (↓), lr=0.000001
   ✓ Epoch   4/100: train=0.2287, val=0.2292 (↓), lr=0.000001
   ✓ Epoch   5/100: train=0.2280, val=0.2286 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.2241, val=0.2247 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.2176, val=0.2183 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.2110, val=0.2117 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.2044, val=0.2052 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.1978, val=0.1987 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.1913, val=0.1922 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.1847, val=0.1857 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.1782, val=0.1793 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.1718, val=0.1730 (↓), lr=0.000001

============================================================
📊 Round 20 Summary - Client client_8
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1654, RMSE=0.4067, R²=-1.0031
   Val:   Loss=0.1674, RMSE=0.4091, R²=-0.9781
============================================================


============================================================
🔄 Round 22 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1667, val=0.1651 (↓), lr=0.000001
   ✓ Epoch   2/100: train=0.1661, val=0.1645 (↓), lr=0.000001
   ✓ Epoch   3/100: train=0.1655, val=0.1638 (↓), lr=0.000001
   ✓ Epoch   4/100: train=0.1649, val=0.1632 (↓), lr=0.000001
   ✓ Epoch   5/100: train=0.1643, val=0.1626 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.1607, val=0.1588 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.1548, val=0.1526 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.1490, val=0.1465 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.1434, val=0.1406 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.1380, val=0.1349 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.1329, val=0.1294 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.1279, val=0.1241 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.1232, val=0.1191 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.1188, val=0.1144 (↓), lr=0.000001

============================================================
📊 Round 22 Summary - Client client_8
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1150, RMSE=0.3391, R²=-0.3547
   Val:   Loss=0.1104, RMSE=0.3322, R²=-0.4684
============================================================


============================================================
🔄 Round 23 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1403, val=0.1261 (↓), lr=0.000001
   ✓ Epoch   2/100: train=0.1398, val=0.1255 (↓), lr=0.000001
   ✓ Epoch   3/100: train=0.1392, val=0.1250 (↓), lr=0.000001
   ✓ Epoch   4/100: train=0.1386, val=0.1244 (↓), lr=0.000001
   ✓ Epoch   5/100: train=0.1380, val=0.1238 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.1346, val=0.1206 (↓), lr=0.000001
   • Epoch  21/100: train=0.1292, val=0.1154, patience=1/15, lr=0.000001
   • Epoch  31/100: train=0.1241, val=0.1106, patience=1/15, lr=0.000001
   • Epoch  41/100: train=0.1195, val=0.1062, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.1151, val=0.1021, patience=1/15, lr=0.000001
   • Epoch  61/100: train=0.1112, val=0.0984, patience=1/15, lr=0.000001
   • Epoch  71/100: train=0.1075, val=0.0950, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.1042, val=0.0919, patience=1/15, lr=0.000001
   • Epoch  91/100: train=0.1012, val=0.0892, patience=1/15, lr=0.000001

============================================================
📊 Round 23 Summary - Client client_8
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0986, RMSE=0.3139, R²=-0.1602
   Val:   Loss=0.0869, RMSE=0.2949, R²=-0.1599
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.1148, RMSE: 0.3388, MAE: 0.2798, R²: -0.3761

============================================================
🔄 Round 25 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0956, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0954, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0952, val=0.0830, patience=2/15, lr=0.000001
   ✓ Epoch   4/100: train=0.0950, val=0.0829 (↓), lr=0.000001
   • Epoch   5/100: train=0.0948, val=0.0827, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.0937, val=0.0817, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.0920, val=0.0802, patience=3/15, lr=0.000001
   ✓ Epoch  31/100: train=0.0906, val=0.0789 (↓), lr=0.000001
   • Epoch  41/100: train=0.0894, val=0.0779, patience=5/15, lr=0.000001
   • Epoch  51/100: train=0.0884, val=0.0770, patience=3/15, lr=0.000001
   • Epoch  61/100: train=0.0876, val=0.0764, patience=6/15, lr=0.000001
   • Epoch  71/100: train=0.0869, val=0.0758, patience=8/15, lr=0.000001
   • Epoch  81/100: train=0.0864, val=0.0754, patience=7/15, lr=0.000001
   • Epoch  91/100: train=0.0860, val=0.0752, patience=2/15, lr=0.000001

============================================================
📊 Round 25 Summary - Client client_8
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0094
   Val:   Loss=0.0750, RMSE=0.2738, R²=0.0054
============================================================


============================================================
🔄 Round 26 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0784, patience=1/15, lr=0.000001
   ✓ Epoch  21/100: train=0.0850, val=0.0779 (↓), lr=0.000001
   • Epoch  31/100: train=0.0848, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 26 Summary - Client client_8
   Epochs: 36/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0049
   Val:   Loss=0.0779, RMSE=0.2791, R²=-0.0262
============================================================


============================================================
🔄 Round 27 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 27 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0074
   Val:   Loss=0.0862, RMSE=0.2935, R²=-0.0140
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0845, RMSE: 0.2908, MAE: 0.2512, R²: -0.0137

============================================================
🔄 Round 29 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 29 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0053
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0033
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2510, R²: -0.0116

📊 Round 29 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2510, R²: -0.0099

============================================================
🔄 Round 32 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 32 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=0.0007
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0089
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2510, R²: -0.0089

📊 Round 32 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2510, R²: -0.0087

📊 Round 32 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2510, R²: -0.0086

============================================================
🔄 Round 37 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 37 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0027
   Val:   Loss=0.0794, RMSE=0.2818, R²=0.0049
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2510, R²: -0.0084

============================================================
🔄 Round 38 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 38 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0022
   Val:   Loss=0.0849, RMSE=0.2913, R²=0.0046
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2510, R²: -0.0082

============================================================
🔄 Round 41 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 41 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0024
   Val:   Loss=0.0772, RMSE=0.2778, R²=-0.0007
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2510, R²: -0.0080

📊 Round 41 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2510, R²: -0.0075

📊 Round 41 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2510, R²: -0.0074

============================================================
🔄 Round 48 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 48 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0004
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0046
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2511, R²: -0.0072

============================================================
🔄 Round 50 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 50 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=-0.0010
   Val:   Loss=0.0905, RMSE=0.3008, R²=-0.0084
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2511, R²: -0.0071

📊 Round 50 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2511, R²: -0.0071

============================================================
🔄 Round 52 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 52 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0007
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0038
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2511, R²: -0.0070

📊 Round 52 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2511, R²: -0.0069

============================================================
🔄 Round 55 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 55 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0019
   Val:   Loss=0.0806, RMSE=0.2840, R²=0.0011
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2511, R²: -0.0069

============================================================
🔄 Round 56 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 56 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0003
   Val:   Loss=0.0815, RMSE=0.2856, R²=-0.0021
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2511, R²: -0.0067

📊 Round 56 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2511, R²: -0.0067

============================================================
🔄 Round 59 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 59 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2863, R²=-0.0012
   Val:   Loss=0.0870, RMSE=0.2950, R²=0.0002
============================================================


============================================================
🔄 Round 61 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 61 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0019
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0086
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0840, RMSE: 0.2897, MAE: 0.2512, R²: -0.0066

📊 Round 61 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2512, R²: -0.0066

📊 Round 61 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2512, R²: -0.0065

============================================================
🔄 Round 67 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 67 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0025
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0105
============================================================


============================================================
🔄 Round 68 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 68 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0012
   Val:   Loss=0.0868, RMSE=0.2946, R²=0.0037
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2512, R²: -0.0065

============================================================
🔄 Round 69 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 69 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=-0.0009
   Val:   Loss=0.0891, RMSE=0.2984, R²=0.0029
============================================================


============================================================
🔄 Round 76 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 76 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0015
   Val:   Loss=0.0790, RMSE=0.2810, R²=0.0052
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2512, R²: -0.0065

============================================================
🔄 Round 77 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 77 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2878, R²=-0.0005
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0008
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2512, R²: -0.0065

📊 Round 77 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2512, R²: -0.0065

📊 Round 77 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2512, R²: -0.0065

📊 Round 77 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2512, R²: -0.0064

============================================================
🔄 Round 82 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 82 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0002
   Val:   Loss=0.0897, RMSE=0.2995, R²=0.0004
============================================================


============================================================
🔄 Round 84 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 84 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0004
   Val:   Loss=0.0748, RMSE=0.2735, R²=-0.0056
============================================================


============================================================
🔄 Round 85 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 85 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0028
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0150
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2512, R²: -0.0064

📊 Round 85 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2512, R²: -0.0064

============================================================
🔄 Round 88 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 88 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0003
   Val:   Loss=0.0728, RMSE=0.2697, R²=-0.0025
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2512, R²: -0.0064

📊 Round 88 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2512, R²: -0.0064

📊 Round 88 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2512, R²: -0.0063

============================================================
🔄 Round 93 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0938 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0938, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0938, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0938, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0938, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0938, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0938)

============================================================
📊 Round 93 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0012
   Val:   Loss=0.0938, RMSE=0.3062, R²=-0.0056
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2512, R²: -0.0063

============================================================
🔄 Round 94 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 94 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0016
   Val:   Loss=0.0776, RMSE=0.2785, R²=0.0061
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2512, R²: -0.0063

============================================================
🔄 Round 95 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 95 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0015
   Val:   Loss=0.0840, RMSE=0.2899, R²=-0.0224
============================================================


============================================================
🔄 Round 96 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 96 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0012
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0110
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2512, R²: -0.0063

============================================================
🔄 Round 97 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 97 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0014
   Val:   Loss=0.0908, RMSE=0.3014, R²=0.0023
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2511, R²: -0.0063

📊 Round 97 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2511, R²: -0.0063

============================================================
🔄 Round 103 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0927, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0927, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0929, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 103 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=-0.0006
   Val:   Loss=0.0926, RMSE=0.3042, R²=-0.0285
============================================================


============================================================
🔄 Round 104 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 104 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0011
   Val:   Loss=0.0816, RMSE=0.2857, R²=0.0012
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2511, R²: -0.0064

============================================================
🔄 Round 106 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 106 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2863, R²=-0.0026
   Val:   Loss=0.0870, RMSE=0.2950, R²=0.0099
============================================================


============================================================
🔄 Round 109 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 109 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0001
   Val:   Loss=0.0801, RMSE=0.2831, R²=-0.0000
============================================================


============================================================
🔄 Round 110 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 110 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0019
   Val:   Loss=0.0820, RMSE=0.2863, R²=-0.0077
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2511, R²: -0.0062

============================================================
🔄 Round 111 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 111 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0017
   Val:   Loss=0.0890, RMSE=0.2983, R²=-0.0069
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2511, R²: -0.0062

============================================================
🔄 Round 113 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 113 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0003
   Val:   Loss=0.0903, RMSE=0.3006, R²=0.0008
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2511, R²: -0.0062

📊 Round 113 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2511, R²: -0.0061

============================================================
🔄 Round 121 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 121 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0021
   Val:   Loss=0.0827, RMSE=0.2875, R²=-0.0294
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2512, R²: -0.0061

📊 Round 121 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2511, R²: -0.0060

📊 Round 121 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2511, R²: -0.0060

📊 Round 121 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2511, R²: -0.0060

📊 Round 121 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2512, R²: -0.0060

============================================================
🔄 Round 128 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 128 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0003
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0027
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2512, R²: -0.0060

============================================================
🔄 Round 130 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 130 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0014
   Val:   Loss=0.0807, RMSE=0.2841, R²=0.0037
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2512, R²: -0.0060

📊 Round 130 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2512, R²: -0.0059

============================================================
🔄 Round 134 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 134 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0059
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0068
============================================================


============================================================
🔄 Round 135 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 135 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0014
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.0068
============================================================


============================================================
🔄 Round 136 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 136 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0015
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0048
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2512, R²: -0.0059

============================================================
🔄 Round 137 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 137 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0017
   Val:   Loss=0.0845, RMSE=0.2908, R²=0.0030
============================================================


============================================================
🔄 Round 138 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 138 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0022
   Val:   Loss=0.0746, RMSE=0.2732, R²=0.0053
============================================================


============================================================
🔄 Round 139 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 139 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=-0.0009
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0023
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2512, R²: -0.0059

📊 Round 139 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2512, R²: -0.0059

📊 Round 139 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2512, R²: -0.0059

============================================================
🔄 Round 145 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 145 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0011
   Val:   Loss=0.0887, RMSE=0.2978, R²=-0.0273
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2512, R²: -0.0059

============================================================
🔄 Round 149 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 149 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0007
   Val:   Loss=0.0827, RMSE=0.2875, R²=0.0008
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2511, R²: -0.0058

============================================================
🔄 Round 153 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0961 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0961, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0961, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0961, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0961, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0961, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0961)

============================================================
📊 Round 153 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0001
   Val:   Loss=0.0961, RMSE=0.3100, R²=-0.0023
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2511, R²: -0.0058

============================================================
🔄 Round 154 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 154 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0017
   Val:   Loss=0.0840, RMSE=0.2899, R²=-0.0032
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2511, R²: -0.0058

📊 Round 154 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2512, R²: -0.0058

📊 Round 154 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2511, R²: -0.0058

📊 Round 154 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2511, R²: -0.0058

📊 Round 154 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2511, R²: -0.0057

============================================================
🔄 Round 159 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 159 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0011
   Val:   Loss=0.0846, RMSE=0.2908, R²=-0.0079
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2511, R²: -0.0057

📊 Round 159 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2511, R²: -0.0057

============================================================
🔄 Round 163 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 163 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0003
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0263
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2511, R²: -0.0057

============================================================
🔄 Round 166 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0711 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0711, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0712, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0712, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0712, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0713, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0711)

============================================================
📊 Round 166 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0006
   Val:   Loss=0.0711, RMSE=0.2667, R²=-0.0255
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2511, R²: -0.0056

📊 Round 166 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2511, R²: -0.0056

============================================================
🔄 Round 170 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 170 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2871, R²=0.0006
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0093
============================================================


============================================================
🔄 Round 171 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 171 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0015
   Val:   Loss=0.0812, RMSE=0.2849, R²=0.0042
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2511, R²: -0.0056

============================================================
🔄 Round 174 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 174 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0002
   Val:   Loss=0.0885, RMSE=0.2975, R²=-0.0274
============================================================


============================================================
🔄 Round 175 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 175 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0016
   Val:   Loss=0.0884, RMSE=0.2973, R²=-0.0106
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2511, R²: -0.0056

📊 Round 175 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2511, R²: -0.0055

============================================================
🔄 Round 181 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 181 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0017
   Val:   Loss=0.0745, RMSE=0.2730, R²=0.0028
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2511, R²: -0.0055

============================================================
🔄 Round 182 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 182 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0002
   Val:   Loss=0.0823, RMSE=0.2868, R²=-0.0021
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2511, R²: -0.0055

============================================================
🔄 Round 186 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 186 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0000
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0051
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2511, R²: -0.0055

📊 Round 186 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2511, R²: -0.0055

📊 Round 186 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2511, R²: -0.0055

📊 Round 186 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2511, R²: -0.0055

📊 Round 186 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2511, R²: -0.0055

============================================================
🔄 Round 191 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 191 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=0.0008
   Val:   Loss=0.0761, RMSE=0.2758, R²=-0.0066
============================================================


============================================================
🔄 Round 192 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 192 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0004
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0007
============================================================


============================================================
🔄 Round 193 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 193 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0003
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0083
============================================================


============================================================
🔄 Round 194 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 194 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0036
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0326
============================================================


============================================================
🔄 Round 196 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 196 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0007
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0083
============================================================


📊 Round 196 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2511, R²: -0.0054

📊 Round 196 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2511, R²: -0.0054

📊 Round 196 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2511, R²: -0.0054

📊 Round 196 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2511, R²: -0.0054

📊 Round 196 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2511, R²: -0.0054

============================================================
🔄 Round 203 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 203 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0001
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0142
============================================================


📊 Round 203 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2511, R²: -0.0054

============================================================
🔄 Round 207 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 207 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0024
   Val:   Loss=0.0811, RMSE=0.2849, R²=-0.0138
============================================================


📊 Round 207 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2511, R²: -0.0054

📊 Round 207 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2511, R²: -0.0054

============================================================
🔄 Round 209 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 209 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0009
   Val:   Loss=0.0846, RMSE=0.2908, R²=-0.0081
============================================================


📊 Round 209 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2511, R²: -0.0054

============================================================
🔄 Round 211 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 211 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0004
   Val:   Loss=0.0906, RMSE=0.3010, R²=-0.0031
============================================================


📊 Round 211 Test Metrics:
   Loss: 0.0838, RMSE: 0.2896, MAE: 0.2511, R²: -0.0053

============================================================
🔄 Round 212 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 212 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0006
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0049
============================================================


📊 Round 212 Test Metrics:
   Loss: 0.0838, RMSE: 0.2896, MAE: 0.2511, R²: -0.0053

============================================================
🔄 Round 215 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 215 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0006
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0213
============================================================


📊 Round 215 Test Metrics:
   Loss: 0.0838, RMSE: 0.2896, MAE: 0.2511, R²: -0.0053

============================================================
🔄 Round 216 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 216 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0003
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0030
============================================================


📊 Round 216 Test Metrics:
   Loss: 0.0838, RMSE: 0.2896, MAE: 0.2511, R²: -0.0053

📊 Round 216 Test Metrics:
   Loss: 0.0838, RMSE: 0.2896, MAE: 0.2511, R²: -0.0053

============================================================
🔄 Round 220 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 220 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0028
   Val:   Loss=0.0902, RMSE=0.3003, R²=0.0021
============================================================


📊 Round 220 Test Metrics:
   Loss: 0.0838, RMSE: 0.2896, MAE: 0.2510, R²: -0.0053

📊 Round 220 Test Metrics:
   Loss: 0.0838, RMSE: 0.2896, MAE: 0.2510, R²: -0.0053

============================================================
🔄 Round 223 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 223 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0008
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0052
============================================================


📊 Round 223 Test Metrics:
   Loss: 0.0838, RMSE: 0.2896, MAE: 0.2510, R²: -0.0053

============================================================
🔄 Round 226 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 226 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0011
   Val:   Loss=0.0777, RMSE=0.2788, R²=-0.0021
============================================================


============================================================
🔄 Round 229 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 229 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0009
   Val:   Loss=0.0840, RMSE=0.2899, R²=-0.0012
============================================================


📊 Round 229 Test Metrics:
   Loss: 0.0838, RMSE: 0.2896, MAE: 0.2511, R²: -0.0052

📊 Round 229 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2511, R²: -0.0052

============================================================
🔄 Round 231 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 231 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0005
   Val:   Loss=0.0872, RMSE=0.2952, R²=-0.0001
============================================================


📊 Round 231 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2511, R²: -0.0052

============================================================
🔄 Round 233 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 233 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0005
   Val:   Loss=0.0851, RMSE=0.2918, R²=-0.0098
============================================================


📊 Round 233 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2511, R²: -0.0052

============================================================
🔄 Round 235 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 235 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0013
   Val:   Loss=0.0910, RMSE=0.3016, R²=-0.0106
============================================================


============================================================
🔄 Round 237 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 237 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0017
   Val:   Loss=0.0770, RMSE=0.2774, R²=0.0043
============================================================


📊 Round 237 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2511, R²: -0.0051

📊 Round 237 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2511, R²: -0.0052

📊 Round 237 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2511, R²: -0.0051

============================================================
🔄 Round 248 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 248 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0019
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0114
============================================================


📊 Round 248 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2511, R²: -0.0051

📊 Round 248 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2511, R²: -0.0051

============================================================
🔄 Round 253 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 253 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0012
   Val:   Loss=0.0747, RMSE=0.2733, R²=-0.0078
============================================================


📊 Round 253 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2511, R²: -0.0051

📊 Round 253 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2511, R²: -0.0051

============================================================
🔄 Round 257 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0971 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0971, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0971, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0971, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0972, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0972, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0971)

============================================================
📊 Round 257 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=-0.0007
   Val:   Loss=0.0971, RMSE=0.3116, R²=-0.0085
============================================================


============================================================
🔄 Round 258 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 258 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0016
   Val:   Loss=0.0888, RMSE=0.2979, R²=-0.0087
============================================================


============================================================
🔄 Round 259 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 259 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0008
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.0016
============================================================


📊 Round 259 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2510, R²: -0.0051

📊 Round 259 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2511, R²: -0.0051

📊 Round 259 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2511, R²: -0.0051

============================================================
🔄 Round 262 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 262 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0002
   Val:   Loss=0.0834, RMSE=0.2887, R²=-0.0113
============================================================


============================================================
🔄 Round 263 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 263 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0004
   Val:   Loss=0.0790, RMSE=0.2810, R²=-0.0012
============================================================


📊 Round 263 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2510, R²: -0.0050

============================================================
🔄 Round 269 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 269 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0008
   Val:   Loss=0.0813, RMSE=0.2852, R²=-0.0016
============================================================


📊 Round 269 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2510, R²: -0.0050

============================================================
🔄 Round 272 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 272 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0008
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0026
============================================================


📊 Round 272 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2510, R²: -0.0050

============================================================
🔄 Round 273 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 273 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0001
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0090
============================================================


📊 Round 273 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2510, R²: -0.0050

============================================================
🔄 Round 274 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 274 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0001
   Val:   Loss=0.0839, RMSE=0.2896, R²=-0.0021
============================================================


📊 Round 274 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2510, R²: -0.0050

============================================================
🔄 Round 276 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 276 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0002
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0028
============================================================


📊 Round 276 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2510, R²: -0.0049

📊 Round 276 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2510, R²: -0.0049

============================================================
🔄 Round 281 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 281 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0008
   Val:   Loss=0.0919, RMSE=0.3032, R²=0.0005
============================================================


📊 Round 281 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2511, R²: -0.0049

📊 Round 281 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2511, R²: -0.0049

============================================================
🔄 Round 284 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 284 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=-0.0011
   Val:   Loss=0.0801, RMSE=0.2830, R²=0.0004
============================================================


📊 Round 284 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2511, R²: -0.0049

============================================================
🔄 Round 287 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 287 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=-0.0006
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0280
============================================================


============================================================
🔄 Round 288 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 288 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=-0.0010
   Val:   Loss=0.0896, RMSE=0.2994, R²=-0.0003
============================================================


📊 Round 288 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2511, R²: -0.0049

============================================================
🔄 Round 291 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 291 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0030
   Val:   Loss=0.0788, RMSE=0.2807, R²=0.0081
============================================================


📊 Round 291 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2511, R²: -0.0049

============================================================
🔄 Round 293 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 293 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0020
   Val:   Loss=0.0824, RMSE=0.2871, R²=0.0039
============================================================


📊 Round 293 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2511, R²: -0.0049

============================================================
🔄 Round 295 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 295 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0008
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0018
============================================================


📊 Round 295 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2511, R²: -0.0048

============================================================
🔄 Round 298 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 298 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=-0.0018
   Val:   Loss=0.0830, RMSE=0.2880, R²=-0.0113
============================================================


📊 Round 298 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2511, R²: -0.0048

============================================================
🔄 Round 299 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 299 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0006
   Val:   Loss=0.0803, RMSE=0.2833, R²=-0.0157
============================================================


📊 Round 299 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2511, R²: -0.0048

📊 Round 299 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2511, R²: -0.0048

============================================================
🔄 Round 301 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 301 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0022
   Val:   Loss=0.0754, RMSE=0.2745, R²=0.0009
============================================================


📊 Round 301 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2511, R²: -0.0048

============================================================
🔄 Round 304 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 304 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0001
   Val:   Loss=0.0822, RMSE=0.2868, R²=-0.0290
============================================================


📊 Round 304 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2511, R²: -0.0048

============================================================
🔄 Round 307 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 307 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2915, R²=-0.0018
   Val:   Loss=0.0753, RMSE=0.2744, R²=-0.0246
============================================================


============================================================
🔄 Round 308 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 308 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0004
   Val:   Loss=0.0809, RMSE=0.2845, R²=-0.0069
============================================================


📊 Round 308 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2510, R²: -0.0047

============================================================
🔄 Round 309 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 309 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0019
   Val:   Loss=0.0743, RMSE=0.2726, R²=0.0051
============================================================


📊 Round 309 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2511, R²: -0.0047

============================================================
🔄 Round 310 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 310 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0005
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.0009
============================================================


============================================================
🔄 Round 312 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 312 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0028
   Val:   Loss=0.0849, RMSE=0.2914, R²=0.0059
============================================================


📊 Round 312 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2511, R²: -0.0047

📊 Round 312 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2511, R²: -0.0047

============================================================
🔄 Round 314 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 314 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0019
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0030
============================================================


📊 Round 314 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2511, R²: -0.0047

============================================================
🔄 Round 316 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 316 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0006
   Val:   Loss=0.0890, RMSE=0.2984, R²=-0.0014
============================================================


📊 Round 316 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2511, R²: -0.0047

📊 Round 316 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2511, R²: -0.0047

📊 Round 316 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2511, R²: -0.0047

📊 Round 316 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2511, R²: -0.0047

============================================================
🔄 Round 320 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 320 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0027
   Val:   Loss=0.0754, RMSE=0.2745, R²=-0.0170
============================================================


📊 Round 320 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2510, R²: -0.0047

============================================================
🔄 Round 325 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 325 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0032
   Val:   Loss=0.0805, RMSE=0.2838, R²=0.0012
============================================================


============================================================
🔄 Round 326 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 326 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0011
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0009
============================================================


📊 Round 326 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2511, R²: -0.0047

============================================================
🔄 Round 328 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 328 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0005
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.0086
============================================================


📊 Round 328 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2511, R²: -0.0047

📊 Round 328 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2511, R²: -0.0046

📊 Round 328 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2511, R²: -0.0046

============================================================
🔄 Round 334 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 334 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0002
   Val:   Loss=0.0894, RMSE=0.2989, R²=-0.0245
============================================================


📊 Round 334 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2511, R²: -0.0046

============================================================
🔄 Round 335 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 335 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2856, R²=0.0005
   Val:   Loss=0.0890, RMSE=0.2983, R²=-0.0185
============================================================


============================================================
🔄 Round 336 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 336 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0012
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0001
============================================================


============================================================
🔄 Round 337 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 337 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0003
   Val:   Loss=0.0797, RMSE=0.2824, R²=-0.0033
============================================================


============================================================
🔄 Round 338 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 338 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0021
   Val:   Loss=0.0873, RMSE=0.2955, R²=0.0026
============================================================


============================================================
🔄 Round 339 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 339 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0003
   Val:   Loss=0.0857, RMSE=0.2928, R²=-0.0069
============================================================


📊 Round 339 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2511, R²: -0.0047

============================================================
🔄 Round 340 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 340 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0057
   Val:   Loss=0.0908, RMSE=0.3014, R²=-0.0110
============================================================


📊 Round 340 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2511, R²: -0.0046

📊 Round 340 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2510, R²: -0.0046

============================================================
🔄 Round 344 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 344 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0012
   Val:   Loss=0.0914, RMSE=0.3024, R²=-0.0105
============================================================


📊 Round 344 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2510, R²: -0.0046

============================================================
🔄 Round 346 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 346 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0035
   Val:   Loss=0.0791, RMSE=0.2812, R²=-0.0109
============================================================


📊 Round 346 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2510, R²: -0.0046

📊 Round 346 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2511, R²: -0.0046

📊 Round 346 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2510, R²: -0.0045

============================================================
🔄 Round 351 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 351 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0013
   Val:   Loss=0.0826, RMSE=0.2873, R²=0.0018
============================================================


📊 Round 351 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2510, R²: -0.0045

📊 Round 351 Test Metrics:
   Loss: 0.0838, RMSE: 0.2894, MAE: 0.2510, R²: -0.0045

📊 Round 351 Test Metrics:
   Loss: 0.0838, RMSE: 0.2894, MAE: 0.2510, R²: -0.0045

📊 Round 351 Test Metrics:
   Loss: 0.0838, RMSE: 0.2894, MAE: 0.2510, R²: -0.0045

📊 Round 351 Test Metrics:
   Loss: 0.0838, RMSE: 0.2894, MAE: 0.2510, R²: -0.0045

============================================================
🔄 Round 365 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 365 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0000
   Val:   Loss=0.0772, RMSE=0.2778, R²=-0.0075
============================================================


📊 Round 365 Test Metrics:
   Loss: 0.0838, RMSE: 0.2894, MAE: 0.2510, R²: -0.0044

============================================================
🔄 Round 367 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 367 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0009
   Val:   Loss=0.0822, RMSE=0.2868, R²=-0.0066
============================================================


📊 Round 367 Test Metrics:
   Loss: 0.0838, RMSE: 0.2894, MAE: 0.2510, R²: -0.0044

📊 Round 367 Test Metrics:
   Loss: 0.0838, RMSE: 0.2894, MAE: 0.2510, R²: -0.0044

📊 Round 367 Test Metrics:
   Loss: 0.0838, RMSE: 0.2894, MAE: 0.2510, R²: -0.0044

📊 Round 367 Test Metrics:
   Loss: 0.0838, RMSE: 0.2894, MAE: 0.2510, R²: -0.0044

📊 Round 367 Test Metrics:
   Loss: 0.0838, RMSE: 0.2894, MAE: 0.2510, R²: -0.0044

============================================================
🔄 Round 374 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 374 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0013
   Val:   Loss=0.0799, RMSE=0.2826, R²=-0.0170
============================================================


📊 Round 374 Test Metrics:
   Loss: 0.0838, RMSE: 0.2894, MAE: 0.2509, R²: -0.0045

============================================================
🔄 Round 375 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 375 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0010
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0059
============================================================


============================================================
🔄 Round 378 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 378 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0003
   Val:   Loss=0.0875, RMSE=0.2958, R²=-0.0069
============================================================


📊 Round 378 Test Metrics:
   Loss: 0.0838, RMSE: 0.2894, MAE: 0.2509, R²: -0.0044

============================================================
🔄 Round 379 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 379 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0006
   Val:   Loss=0.0851, RMSE=0.2918, R²=-0.0292
============================================================


📊 Round 379 Test Metrics:
   Loss: 0.0838, RMSE: 0.2894, MAE: 0.2510, R²: -0.0044

📊 Round 379 Test Metrics:
   Loss: 0.0838, RMSE: 0.2894, MAE: 0.2510, R²: -0.0044

📊 Round 379 Test Metrics:
   Loss: 0.0838, RMSE: 0.2894, MAE: 0.2509, R²: -0.0044

============================================================
🔄 Round 386 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 386 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0018
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0105
============================================================


============================================================
🔄 Round 387 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 387 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0011
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0001
============================================================


📊 Round 387 Test Metrics:
   Loss: 0.0838, RMSE: 0.2894, MAE: 0.2509, R²: -0.0044

📊 Round 387 Test Metrics:
   Loss: 0.0838, RMSE: 0.2894, MAE: 0.2509, R²: -0.0043

============================================================
🔄 Round 390 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 390 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=0.0016
   Val:   Loss=0.0772, RMSE=0.2778, R²=-0.0113
============================================================


============================================================
🔄 Round 391 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 391 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0027
   Val:   Loss=0.0833, RMSE=0.2886, R²=0.0065
============================================================


============================================================
🔄 Round 392 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 392 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=-0.0006
   Val:   Loss=0.0848, RMSE=0.2913, R²=-0.0008
============================================================


📊 Round 392 Test Metrics:
   Loss: 0.0838, RMSE: 0.2894, MAE: 0.2509, R²: -0.0043

📊 Round 392 Test Metrics:
   Loss: 0.0838, RMSE: 0.2894, MAE: 0.2509, R²: -0.0043

📊 Round 392 Test Metrics:
   Loss: 0.0838, RMSE: 0.2894, MAE: 0.2509, R²: -0.0043

📊 Round 392 Test Metrics:
   Loss: 0.0838, RMSE: 0.2894, MAE: 0.2509, R²: -0.0043

============================================================
🔄 Round 396 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 396 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0011
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0055
============================================================


============================================================
🔄 Round 397 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 397 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0004
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0170
============================================================


============================================================
🔄 Round 400 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 400 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0003
   Val:   Loss=0.0767, RMSE=0.2769, R²=-0.0133
============================================================


📊 Round 400 Test Metrics:
   Loss: 0.0838, RMSE: 0.2894, MAE: 0.2509, R²: -0.0042

📊 Round 400 Test Metrics:
   Loss: 0.0838, RMSE: 0.2894, MAE: 0.2509, R²: -0.0042

============================================================
🔄 Round 402 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 402 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0007
   Val:   Loss=0.0855, RMSE=0.2923, R²=-0.0087
============================================================


📊 Round 402 Test Metrics:
   Loss: 0.0838, RMSE: 0.2894, MAE: 0.2510, R²: -0.0042

============================================================
🔄 Round 404 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 404 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0006
   Val:   Loss=0.0767, RMSE=0.2769, R²=-0.0084
============================================================


📊 Round 404 Test Metrics:
   Loss: 0.0838, RMSE: 0.2894, MAE: 0.2510, R²: -0.0042

============================================================
🔄 Round 407 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 407 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0019
   Val:   Loss=0.0846, RMSE=0.2909, R²=0.0028
============================================================


📊 Round 407 Test Metrics:
   Loss: 0.0838, RMSE: 0.2894, MAE: 0.2510, R²: -0.0042

📊 Round 407 Test Metrics:
   Loss: 0.0838, RMSE: 0.2894, MAE: 0.2510, R²: -0.0042

============================================================
🔄 Round 410 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 410 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0007
   Val:   Loss=0.0755, RMSE=0.2748, R²=-0.0069
============================================================


============================================================
🔄 Round 411 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 411 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0005
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0097
============================================================


============================================================
🔄 Round 413 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 413 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0001
   Val:   Loss=0.0920, RMSE=0.3033, R²=-0.0096
============================================================


📊 Round 413 Test Metrics:
   Loss: 0.0838, RMSE: 0.2894, MAE: 0.2510, R²: -0.0042

============================================================
🔄 Round 414 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0923, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 414 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0003
   Val:   Loss=0.0923, RMSE=0.3038, R²=-0.0048
============================================================


📊 Round 414 Test Metrics:
   Loss: 0.0838, RMSE: 0.2894, MAE: 0.2510, R²: -0.0042

============================================================
🔄 Round 418 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0721, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0721, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 418 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0008
   Val:   Loss=0.0720, RMSE=0.2684, R²=-0.0081
============================================================


📊 Round 418 Test Metrics:
   Loss: 0.0837, RMSE: 0.2894, MAE: 0.2510, R²: -0.0041

============================================================
🔄 Round 419 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0924, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0924, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 419 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0017
   Val:   Loss=0.0923, RMSE=0.3039, R²=-0.0098
============================================================


📊 Round 419 Test Metrics:
   Loss: 0.0837, RMSE: 0.2894, MAE: 0.2510, R²: -0.0041

============================================================
🔄 Round 420 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 420 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0002
   Val:   Loss=0.0874, RMSE=0.2957, R²=-0.0058
============================================================


============================================================
🔄 Round 421 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 421 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=-0.0011
   Val:   Loss=0.0745, RMSE=0.2729, R²=-0.0072
============================================================


📊 Round 421 Test Metrics:
   Loss: 0.0837, RMSE: 0.2894, MAE: 0.2510, R²: -0.0041

============================================================
🔄 Round 425 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0943 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0943, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0943, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0943, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0943, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0944, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0943)

============================================================
📊 Round 425 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0033
   Val:   Loss=0.0943, RMSE=0.3071, R²=0.0023
============================================================


📊 Round 425 Test Metrics:
   Loss: 0.0837, RMSE: 0.2894, MAE: 0.2510, R²: -0.0041

============================================================
🔄 Round 427 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 427 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0013
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0028
============================================================


📊 Round 427 Test Metrics:
   Loss: 0.0837, RMSE: 0.2894, MAE: 0.2510, R²: -0.0041

📊 Round 427 Test Metrics:
   Loss: 0.0837, RMSE: 0.2894, MAE: 0.2510, R²: -0.0041

📊 Round 427 Test Metrics:
   Loss: 0.0837, RMSE: 0.2894, MAE: 0.2510, R²: -0.0041

============================================================
🔄 Round 434 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0716 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0716, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0716, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0717, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0717, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0719, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0716)

============================================================
📊 Round 434 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0026
   Val:   Loss=0.0716, RMSE=0.2675, R²=-0.0226
============================================================


📊 Round 434 Test Metrics:
   Loss: 0.0837, RMSE: 0.2894, MAE: 0.2510, R²: -0.0041

============================================================
🔄 Round 436 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0949 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0949, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0949, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0949, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0949, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0949, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0949)

============================================================
📊 Round 436 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0012
   Val:   Loss=0.0949, RMSE=0.3080, R²=-0.0017
============================================================


📊 Round 436 Test Metrics:
   Loss: 0.0837, RMSE: 0.2894, MAE: 0.2510, R²: -0.0041

============================================================
🔄 Round 437 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 437 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0028
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0067
============================================================


📊 Round 437 Test Metrics:
   Loss: 0.0837, RMSE: 0.2894, MAE: 0.2510, R²: -0.0041

============================================================
🔄 Round 438 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 438 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0004
   Val:   Loss=0.0765, RMSE=0.2766, R²=-0.0059
============================================================


📊 Round 438 Test Metrics:
   Loss: 0.0837, RMSE: 0.2894, MAE: 0.2510, R²: -0.0041

============================================================
🔄 Round 440 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 440 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0000
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0052
============================================================


📊 Round 440 Test Metrics:
   Loss: 0.0837, RMSE: 0.2894, MAE: 0.2510, R²: -0.0041

============================================================
🔄 Round 444 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 444 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0006
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0094
============================================================


📊 Round 444 Test Metrics:
   Loss: 0.0837, RMSE: 0.2894, MAE: 0.2509, R²: -0.0040

============================================================
🔄 Round 446 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 446 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=0.0001
   Val:   Loss=0.0805, RMSE=0.2838, R²=-0.0117
============================================================


📊 Round 446 Test Metrics:
   Loss: 0.0837, RMSE: 0.2894, MAE: 0.2509, R²: -0.0040

============================================================
🔄 Round 447 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 447 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2920, R²=-0.0019
   Val:   Loss=0.0741, RMSE=0.2722, R²=0.0031
============================================================


📊 Round 447 Test Metrics:
   Loss: 0.0837, RMSE: 0.2894, MAE: 0.2509, R²: -0.0040

============================================================
🔄 Round 448 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 448 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0010
   Val:   Loss=0.0888, RMSE=0.2980, R²=-0.0240
============================================================


📊 Round 448 Test Metrics:
   Loss: 0.0837, RMSE: 0.2894, MAE: 0.2509, R²: -0.0040

============================================================
🔄 Round 450 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0715 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0715, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0715, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0715, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0715, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0715, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0715)

============================================================
📊 Round 450 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0006
   Val:   Loss=0.0715, RMSE=0.2675, R²=-0.0007
============================================================


📊 Round 450 Test Metrics:
   Loss: 0.0837, RMSE: 0.2894, MAE: 0.2509, R²: -0.0040

============================================================
🔄 Round 452 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 452 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0008
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0049
============================================================


📊 Round 452 Test Metrics:
   Loss: 0.0837, RMSE: 0.2894, MAE: 0.2509, R²: -0.0040

📊 Round 452 Test Metrics:
   Loss: 0.0837, RMSE: 0.2894, MAE: 0.2510, R²: -0.0040

============================================================
🔄 Round 455 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 455 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=0.0006
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0054
============================================================


📊 Round 455 Test Metrics:
   Loss: 0.0837, RMSE: 0.2894, MAE: 0.2510, R²: -0.0040

============================================================
🔄 Round 459 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 459 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0010
   Val:   Loss=0.0912, RMSE=0.3020, R²=-0.0107
============================================================


============================================================
🔄 Round 460 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 460 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=0.0006
   Val:   Loss=0.0865, RMSE=0.2940, R²=-0.0077
============================================================


============================================================
🔄 Round 461 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 461 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0003
   Val:   Loss=0.0871, RMSE=0.2952, R²=-0.0062
============================================================


📊 Round 461 Test Metrics:
   Loss: 0.0837, RMSE: 0.2894, MAE: 0.2510, R²: -0.0040

============================================================
🔄 Round 464 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0699 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0699, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0699, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0699, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0698, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0698, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0699)

============================================================
📊 Round 464 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0006
   Val:   Loss=0.0699, RMSE=0.2643, R²=-0.0029
============================================================


============================================================
🔄 Round 465 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 465 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0027
   Val:   Loss=0.0905, RMSE=0.3008, R²=-0.0101
============================================================


============================================================
🔄 Round 466 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 466 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0007
   Val:   Loss=0.0790, RMSE=0.2810, R²=-0.0021
============================================================


📊 Round 466 Test Metrics:
   Loss: 0.0837, RMSE: 0.2894, MAE: 0.2510, R²: -0.0040

============================================================
🔄 Round 472 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 472 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0030
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0052
============================================================


============================================================
🔄 Round 473 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 473 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0012
   Val:   Loss=0.0829, RMSE=0.2878, R²=0.0003
============================================================


📊 Round 473 Test Metrics:
   Loss: 0.0837, RMSE: 0.2894, MAE: 0.2509, R²: -0.0039

============================================================
🔄 Round 475 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 475 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0012
   Val:   Loss=0.0852, RMSE=0.2918, R²=-0.0089
============================================================


📊 Round 475 Test Metrics:
   Loss: 0.0837, RMSE: 0.2894, MAE: 0.2509, R²: -0.0039

📊 Round 475 Test Metrics:
   Loss: 0.0837, RMSE: 0.2894, MAE: 0.2509, R²: -0.0039

📊 Round 475 Test Metrics:
   Loss: 0.0837, RMSE: 0.2894, MAE: 0.2509, R²: -0.0039

============================================================
🔄 Round 479 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0703 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0703, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0703, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0703, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0703, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0703, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0703)

============================================================
📊 Round 479 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0016
   Val:   Loss=0.0703, RMSE=0.2651, R²=0.0040
============================================================


============================================================
🔄 Round 481 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 481 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0007
   Val:   Loss=0.0830, RMSE=0.2882, R²=-0.0036
============================================================


📊 Round 481 Test Metrics:
   Loss: 0.0837, RMSE: 0.2894, MAE: 0.2510, R²: -0.0039

============================================================
🔄 Round 483 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 483 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0011
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0083
============================================================


📊 Round 483 Test Metrics:
   Loss: 0.0837, RMSE: 0.2894, MAE: 0.2510, R²: -0.0039

============================================================
🔄 Round 485 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 485 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0012
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0001
============================================================


============================================================
🔄 Round 486 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 486 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=-0.0008
   Val:   Loss=0.0830, RMSE=0.2880, R²=-0.0029
============================================================


============================================================
🔄 Round 487 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 487 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0004
   Val:   Loss=0.0778, RMSE=0.2790, R²=-0.0098
============================================================


📊 Round 487 Test Metrics:
   Loss: 0.0837, RMSE: 0.2894, MAE: 0.2510, R²: -0.0039

📊 Round 487 Test Metrics:
   Loss: 0.0837, RMSE: 0.2894, MAE: 0.2510, R²: -0.0039

============================================================
🔄 Round 493 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 493 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0022
   Val:   Loss=0.0854, RMSE=0.2923, R²=-0.0114
============================================================


📊 Round 493 Test Metrics:
   Loss: 0.0837, RMSE: 0.2894, MAE: 0.2510, R²: -0.0038

📊 Round 493 Test Metrics:
   Loss: 0.0837, RMSE: 0.2894, MAE: 0.2510, R²: -0.0038

============================================================
🔄 Round 496 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 496 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=-0.0002
   Val:   Loss=0.0802, RMSE=0.2831, R²=-0.0098
============================================================


📊 Round 496 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2509, R²: -0.0038

📊 Round 496 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2510, R²: -0.0038

============================================================
🔄 Round 499 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 499 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=-0.0048
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0231
============================================================


📊 Round 499 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2510, R²: -0.0038

📊 Round 499 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2509, R²: -0.0038

============================================================
🔄 Round 501 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 501 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0019
   Val:   Loss=0.0795, RMSE=0.2820, R²=0.0027
============================================================


📊 Round 501 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2510, R²: -0.0038

============================================================
🔄 Round 502 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0687 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0687, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0687, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0687, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0687, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0687, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0687)

============================================================
📊 Round 502 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0012
   Val:   Loss=0.0687, RMSE=0.2621, R²=-0.0015
============================================================


📊 Round 502 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2510, R²: -0.0038

============================================================
🔄 Round 504 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 504 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0008
   Val:   Loss=0.0885, RMSE=0.2976, R²=-0.0119
============================================================


============================================================
🔄 Round 505 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 505 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0004
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0117
============================================================


📊 Round 505 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2509, R²: -0.0038

📊 Round 505 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2510, R²: -0.0038

============================================================
🔄 Round 507 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 507 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0015
   Val:   Loss=0.0822, RMSE=0.2867, R²=0.0021
============================================================


📊 Round 507 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2510, R²: -0.0038

============================================================
🔄 Round 509 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 509 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0010
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0174
============================================================


============================================================
🔄 Round 510 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 510 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0010
   Val:   Loss=0.0859, RMSE=0.2930, R²=-0.0003
============================================================


============================================================
🔄 Round 511 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 511 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0008
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0083
============================================================


📊 Round 511 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2510, R²: -0.0038

============================================================
🔄 Round 513 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 513 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0003
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0029
============================================================


📊 Round 513 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2510, R²: -0.0038

📊 Round 513 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2510, R²: -0.0038

📊 Round 513 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2510, R²: -0.0038

============================================================
🔄 Round 518 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 518 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0021
   Val:   Loss=0.0783, RMSE=0.2799, R²=0.0037
============================================================


📊 Round 518 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2510, R²: -0.0038

📊 Round 518 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2510, R²: -0.0038

============================================================
🔄 Round 523 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 523 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0005
   Val:   Loss=0.0771, RMSE=0.2776, R²=-0.0166
============================================================


============================================================
🔄 Round 524 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 524 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2911, R²=-0.0002
   Val:   Loss=0.0762, RMSE=0.2760, R²=-0.0127
============================================================


📊 Round 524 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2510, R²: -0.0038

============================================================
🔄 Round 528 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 528 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0009
   Val:   Loss=0.0733, RMSE=0.2708, R²=-0.0032
============================================================


📊 Round 528 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2510, R²: -0.0037

============================================================
🔄 Round 530 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 530 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0003
   Val:   Loss=0.0794, RMSE=0.2817, R²=-0.0171
============================================================


📊 Round 530 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2510, R²: -0.0037

============================================================
🔄 Round 531 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0933 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0933, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0933, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0932, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0932, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0932, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0933)

============================================================
📊 Round 531 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0009
   Val:   Loss=0.0933, RMSE=0.3054, R²=-0.0007
============================================================


============================================================
🔄 Round 533 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 533 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0010
   Val:   Loss=0.0852, RMSE=0.2919, R²=0.0002
============================================================


============================================================
🔄 Round 534 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 534 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0024
   Val:   Loss=0.0791, RMSE=0.2812, R²=-0.0268
============================================================


📊 Round 534 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2509, R²: -0.0037

📊 Round 534 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2509, R²: -0.0037

============================================================
🔄 Round 538 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 538 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0008
   Val:   Loss=0.0853, RMSE=0.2920, R²=-0.0018
============================================================


📊 Round 538 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2509, R²: -0.0037

============================================================
🔄 Round 541 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 541 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0004
   Val:   Loss=0.0833, RMSE=0.2887, R²=-0.0030
============================================================


📊 Round 541 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2510, R²: -0.0037

============================================================
🔄 Round 542 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0934 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0934, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0934, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0934, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0934, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0934, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0934)

============================================================
📊 Round 542 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0015
   Val:   Loss=0.0934, RMSE=0.3056, R²=-0.0154
============================================================


============================================================
🔄 Round 543 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 543 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0005
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0151
============================================================


📊 Round 543 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2510, R²: -0.0037

============================================================
🔄 Round 544 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 544 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0024
   Val:   Loss=0.0863, RMSE=0.2938, R²=0.0029
============================================================


📊 Round 544 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2509, R²: -0.0037

📊 Round 544 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2509, R²: -0.0037

📊 Round 544 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2509, R²: -0.0036

============================================================
🔄 Round 548 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 548 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0028
   Val:   Loss=0.0875, RMSE=0.2957, R²=-0.0068
============================================================


📊 Round 548 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2509, R²: -0.0036

📊 Round 548 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2509, R²: -0.0036

📊 Round 548 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2509, R²: -0.0036

============================================================
🔄 Round 552 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 552 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0018
   Val:   Loss=0.0869, RMSE=0.2948, R²=-0.0105
============================================================


📊 Round 552 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2509, R²: -0.0036

============================================================
🔄 Round 559 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 559 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0018
   Val:   Loss=0.0859, RMSE=0.2930, R²=-0.0205
============================================================


📊 Round 559 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2509, R²: -0.0036

============================================================
🔄 Round 560 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 560 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0010
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0222
============================================================


============================================================
🔄 Round 561 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 561 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0010
   Val:   Loss=0.0785, RMSE=0.2802, R²=-0.0100
============================================================


📊 Round 561 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2509, R²: -0.0036

📊 Round 561 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2510, R²: -0.0036

📊 Round 561 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2509, R²: -0.0036

📊 Round 561 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2509, R²: -0.0036

============================================================
🔄 Round 569 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 569 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0021
   Val:   Loss=0.0770, RMSE=0.2775, R²=0.0041
============================================================


============================================================
🔄 Round 573 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 573 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0010
   Val:   Loss=0.0890, RMSE=0.2983, R²=-0.0006
============================================================


📊 Round 573 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2509, R²: -0.0036

📊 Round 573 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2509, R²: -0.0035

============================================================
🔄 Round 579 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 579 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0011
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0005
============================================================


============================================================
🔄 Round 580 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 580 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0029
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0055
============================================================


============================================================
🔄 Round 582 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 582 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0010
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0007
============================================================


📊 Round 582 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2509, R²: -0.0035

============================================================
🔄 Round 583 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 583 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0002
   Val:   Loss=0.0885, RMSE=0.2976, R²=-0.0186
============================================================


============================================================
🔄 Round 584 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 584 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0011
   Val:   Loss=0.0774, RMSE=0.2782, R²=-0.0049
============================================================


============================================================
🔄 Round 585 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 585 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0011
   Val:   Loss=0.0815, RMSE=0.2854, R²=-0.0246
============================================================


📊 Round 585 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2510, R²: -0.0035

📊 Round 585 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2510, R²: -0.0035

============================================================
🔄 Round 589 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 589 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2849, R²=0.0003
   Val:   Loss=0.0907, RMSE=0.3011, R²=-0.0128
============================================================


📊 Round 589 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2510, R²: -0.0035

============================================================
🔄 Round 590 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 590 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2904, R²=0.0001
   Val:   Loss=0.0779, RMSE=0.2790, R²=-0.0156
============================================================


============================================================
🔄 Round 591 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 591 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0013
   Val:   Loss=0.0754, RMSE=0.2746, R²=-0.0077
============================================================


============================================================
🔄 Round 592 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 592 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2878, R²=-0.0017
   Val:   Loss=0.0839, RMSE=0.2896, R²=0.0012
============================================================


============================================================
🔄 Round 594 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0929 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0929, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0929, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0929, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0929, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0929, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0929)

============================================================
📊 Round 594 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0009
   Val:   Loss=0.0929, RMSE=0.3048, R²=-0.0026
============================================================


============================================================
🔄 Round 595 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 595 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0024
   Val:   Loss=0.0788, RMSE=0.2807, R²=0.0024
============================================================


📊 Round 595 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2510, R²: -0.0035

📊 Round 595 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2510, R²: -0.0035

============================================================
🔄 Round 598 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 598 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=-0.0013
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0023
============================================================


📊 Round 598 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2510, R²: -0.0035

============================================================
🔄 Round 599 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 599 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2915, R²=-0.0044
   Val:   Loss=0.0755, RMSE=0.2748, R²=-0.0003
============================================================


📊 Round 599 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2509, R²: -0.0035

============================================================
🔄 Round 600 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 600 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0011
   Val:   Loss=0.0791, RMSE=0.2813, R²=-0.0054
============================================================


============================================================
🔄 Round 601 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 601 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0012
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0053
============================================================


============================================================
🔄 Round 602 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 602 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0012
   Val:   Loss=0.0797, RMSE=0.2822, R²=-0.0145
============================================================


============================================================
🔄 Round 603 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 603 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0016
   Val:   Loss=0.0819, RMSE=0.2863, R²=0.0012
============================================================


============================================================
🔄 Round 604 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 604 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0001
   Val:   Loss=0.0877, RMSE=0.2961, R²=-0.0047
============================================================


📊 Round 604 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2510, R²: -0.0035

📊 Round 604 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2510, R²: -0.0035

============================================================
🔄 Round 608 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 608 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0009
   Val:   Loss=0.0909, RMSE=0.3015, R²=-0.0015
============================================================


📊 Round 608 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2510, R²: -0.0035

============================================================
🔄 Round 610 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 610 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=0.0003
   Val:   Loss=0.0802, RMSE=0.2833, R²=-0.0084
============================================================


============================================================
🔄 Round 611 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 611 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=-0.0026
   Val:   Loss=0.0911, RMSE=0.3019, R²=0.0025
============================================================


============================================================
🔄 Round 615 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 615 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0020
   Val:   Loss=0.0856, RMSE=0.2926, R²=0.0021
============================================================


============================================================
🔄 Round 616 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 616 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0008
   Val:   Loss=0.0899, RMSE=0.2999, R²=-0.0013
============================================================


📊 Round 616 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2509, R²: -0.0034

============================================================
🔄 Round 618 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 618 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0021
   Val:   Loss=0.0844, RMSE=0.2906, R²=-0.0127
============================================================


📊 Round 618 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2509, R²: -0.0034

============================================================
🔄 Round 621 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 621 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0017
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0089
============================================================


============================================================
🔄 Round 622 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 622 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0015
   Val:   Loss=0.0795, RMSE=0.2819, R²=-0.0019
============================================================


📊 Round 622 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2509, R²: -0.0034

📊 Round 622 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2509, R²: -0.0034

📊 Round 622 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2509, R²: -0.0034

============================================================
🔄 Round 627 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 627 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0006
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0046
============================================================


📊 Round 627 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2509, R²: -0.0034

============================================================
🔄 Round 632 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 632 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0036
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.0229
============================================================


📊 Round 632 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2509, R²: -0.0034

============================================================
🔄 Round 635 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 635 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0034
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0226
============================================================


📊 Round 635 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2509, R²: -0.0034

📊 Round 635 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2509, R²: -0.0034

============================================================
🔄 Round 640 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 640 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0005
   Val:   Loss=0.0919, RMSE=0.3032, R²=-0.0094
============================================================


============================================================
🔄 Round 642 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 642 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0001
   Val:   Loss=0.0775, RMSE=0.2784, R²=-0.0071
============================================================


📊 Round 642 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2509, R²: -0.0034

============================================================
🔄 Round 644 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 644 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0020
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0142
============================================================


📊 Round 644 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2509, R²: -0.0034

============================================================
🔄 Round 647 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0922 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0922, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0923, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0922)

============================================================
📊 Round 647 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0030
   Val:   Loss=0.0922, RMSE=0.3037, R²=-0.0011
============================================================


============================================================
🔄 Round 651 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 651 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0026
   Val:   Loss=0.0901, RMSE=0.3001, R²=0.0031
============================================================


📊 Round 651 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2510, R²: -0.0033

📊 Round 651 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2510, R²: -0.0033

============================================================
🔄 Round 656 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 656 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0014
   Val:   Loss=0.0786, RMSE=0.2804, R²=-0.0046
============================================================


📊 Round 656 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2509, R²: -0.0033

📊 Round 656 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2509, R²: -0.0033

============================================================
🔄 Round 659 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 659 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0023
   Val:   Loss=0.0838, RMSE=0.2895, R²=0.0013
============================================================


📊 Round 659 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2509, R²: -0.0033

📊 Round 659 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2509, R²: -0.0033

============================================================
🔄 Round 665 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 665 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0033
   Val:   Loss=0.0808, RMSE=0.2842, R²=0.0019
============================================================


============================================================
🔄 Round 666 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 666 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=-0.0012
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0015
============================================================


============================================================
🔄 Round 667 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 667 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0032
   Val:   Loss=0.0834, RMSE=0.2887, R²=0.0079
============================================================


============================================================
🔄 Round 668 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 668 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0018
   Val:   Loss=0.0764, RMSE=0.2764, R²=-0.0103
============================================================


📊 Round 668 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2509, R²: -0.0033

📊 Round 668 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2509, R²: -0.0033

📊 Round 668 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2509, R²: -0.0032

📊 Round 668 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2509, R²: -0.0032

============================================================
🔄 Round 677 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 677 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0033
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0057
============================================================


============================================================
🔄 Round 681 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 681 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0029
   Val:   Loss=0.0761, RMSE=0.2759, R²=0.0051
============================================================


============================================================
🔄 Round 682 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 682 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2915, R²=-0.0006
   Val:   Loss=0.0755, RMSE=0.2748, R²=-0.0080
============================================================


📊 Round 682 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2509, R²: -0.0032

============================================================
🔄 Round 683 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 683 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0004
   Val:   Loss=0.0900, RMSE=0.3000, R²=-0.0113
============================================================


📊 Round 683 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2509, R²: -0.0032

📊 Round 683 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2509, R²: -0.0032

============================================================
🔄 Round 686 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 686 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0009
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0091
============================================================


📊 Round 686 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2509, R²: -0.0032

📊 Round 686 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2509, R²: -0.0032

📊 Round 686 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2509, R²: -0.0032

============================================================
🔄 Round 695 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 695 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0004
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0079
============================================================


============================================================
🔄 Round 696 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 696 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0012
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0005
============================================================


📊 Round 696 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2509, R²: -0.0032

============================================================
🔄 Round 699 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 699 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0022
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0037
============================================================


📊 Round 699 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2509, R²: -0.0032

📊 Round 699 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2509, R²: -0.0032

============================================================
🔄 Round 701 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 701 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0019
   Val:   Loss=0.0855, RMSE=0.2925, R²=-0.0065
============================================================


============================================================
🔄 Round 704 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 704 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0008
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0023
============================================================


============================================================
🔄 Round 706 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 706 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=-0.0019
   Val:   Loss=0.0882, RMSE=0.2970, R²=0.0008
============================================================


============================================================
🔄 Round 707 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 707 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0016
   Val:   Loss=0.0858, RMSE=0.2929, R²=0.0008
============================================================


============================================================
🔄 Round 708 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 708 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0008
   Val:   Loss=0.0870, RMSE=0.2949, R²=-0.0108
============================================================


============================================================
🔄 Round 709 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 709 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0008
   Val:   Loss=0.0839, RMSE=0.2896, R²=-0.0060
============================================================


============================================================
🔄 Round 711 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 711 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0001
   Val:   Loss=0.0786, RMSE=0.2803, R²=-0.0087
============================================================


📊 Round 711 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2509, R²: -0.0031

📊 Round 711 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2509, R²: -0.0031

📊 Round 711 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2509, R²: -0.0031

📊 Round 711 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2509, R²: -0.0031

============================================================
🔄 Round 717 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 717 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0003
   Val:   Loss=0.0788, RMSE=0.2806, R²=-0.0085
============================================================


📊 Round 717 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2509, R²: -0.0031

============================================================
🔄 Round 719 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 719 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0015
   Val:   Loss=0.0763, RMSE=0.2762, R²=-0.0007
============================================================


📊 Round 719 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2509, R²: -0.0031

📊 Round 719 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2509, R²: -0.0031

📊 Round 719 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2509, R²: -0.0031

============================================================
🔄 Round 724 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 724 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0015
   Val:   Loss=0.0777, RMSE=0.2787, R²=-0.0272
============================================================


============================================================
🔄 Round 725 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 725 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0004
   Val:   Loss=0.0776, RMSE=0.2786, R²=-0.0128
============================================================


📊 Round 725 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2509, R²: -0.0031

📊 Round 725 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2509, R²: -0.0031

============================================================
🔄 Round 730 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 730 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0013
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0008
============================================================


📊 Round 730 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2509, R²: -0.0031

📊 Round 730 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2509, R²: -0.0031

============================================================
🔄 Round 732 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 732 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0002
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0064
============================================================


📊 Round 732 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2509, R²: -0.0031

📊 Round 732 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2509, R²: -0.0031

📊 Round 732 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2509, R²: -0.0030

============================================================
🔄 Round 738 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 738 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0013
   Val:   Loss=0.0900, RMSE=0.2999, R²=-0.0143
============================================================


============================================================
🔄 Round 739 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0922 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0922, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0922, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0922, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0922, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0923, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0922)

============================================================
📊 Round 739 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0006
   Val:   Loss=0.0922, RMSE=0.3037, R²=-0.0124
============================================================


============================================================
🔄 Round 740 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 740 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0067
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0604
============================================================


============================================================
🔄 Round 741 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 741 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0022
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0337
============================================================


📊 Round 741 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2509, R²: -0.0030

============================================================
🔄 Round 744 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 744 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0008
   Val:   Loss=0.0789, RMSE=0.2808, R²=-0.0031
============================================================


============================================================
🔄 Round 745 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 745 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0023
   Val:   Loss=0.0891, RMSE=0.2985, R²=0.0027
============================================================


============================================================
🔄 Round 747 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0944 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0944, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0944, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0944, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0944, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0944, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0944)

============================================================
📊 Round 747 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0025
   Val:   Loss=0.0944, RMSE=0.3072, R²=0.0027
============================================================


📊 Round 747 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2509, R²: -0.0030

============================================================
🔄 Round 752 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 752 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=-0.0019
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0029
============================================================


============================================================
🔄 Round 755 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 755 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0015
   Val:   Loss=0.0879, RMSE=0.2964, R²=-0.0010
============================================================


📊 Round 755 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2509, R²: -0.0030

============================================================
🔄 Round 757 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 757 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0008
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0027
============================================================


📊 Round 757 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2509, R²: -0.0030

============================================================
🔄 Round 759 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 759 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0005
   Val:   Loss=0.0762, RMSE=0.2760, R²=-0.0056
============================================================


📊 Round 759 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2508, R²: -0.0030

============================================================
🔄 Round 762 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0952 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0952, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0952, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0952, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0952, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0952, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0952)

============================================================
📊 Round 762 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0005
   Val:   Loss=0.0952, RMSE=0.3086, R²=-0.0031
============================================================


📊 Round 762 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2508, R²: -0.0030

============================================================
🔄 Round 763 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 763 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0014
   Val:   Loss=0.0844, RMSE=0.2904, R²=-0.0409
============================================================


📊 Round 763 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2508, R²: -0.0030

📊 Round 763 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2508, R²: -0.0030

============================================================
🔄 Round 767 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 767 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0027
   Val:   Loss=0.0872, RMSE=0.2952, R²=-0.0141
============================================================


📊 Round 767 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2508, R²: -0.0030

============================================================
🔄 Round 769 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 769 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=-0.0005
   Val:   Loss=0.0910, RMSE=0.3017, R²=-0.0084
============================================================


📊 Round 769 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2508, R²: -0.0030

📊 Round 769 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2509, R²: -0.0029

📊 Round 769 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2509, R²: -0.0029

============================================================
🔄 Round 773 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 773 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0008
   Val:   Loss=0.0866, RMSE=0.2943, R²=-0.0030
============================================================


📊 Round 773 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2509, R²: -0.0029

============================================================
🔄 Round 776 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 776 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0019
   Val:   Loss=0.0749, RMSE=0.2737, R²=0.0003
============================================================


============================================================
🔄 Round 777 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 777 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0006
   Val:   Loss=0.0856, RMSE=0.2927, R²=-0.0065
============================================================


📊 Round 777 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2509, R²: -0.0029

📊 Round 777 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2509, R²: -0.0029

============================================================
🔄 Round 780 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 780 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0009
   Val:   Loss=0.0817, RMSE=0.2859, R²=-0.0029
============================================================


📊 Round 780 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2509, R²: -0.0029

📊 Round 780 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2509, R²: -0.0029

============================================================
🔄 Round 782 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 782 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0030
   Val:   Loss=0.0751, RMSE=0.2740, R²=0.0064
============================================================


📊 Round 782 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2509, R²: -0.0029

📊 Round 782 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2509, R²: -0.0029

❌ Client client_8 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8692 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8692 {grpc_status:14, grpc_message:"Socket closed"}"
>
