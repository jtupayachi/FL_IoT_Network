[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e982a4c-796b-44ba-8753-96ff9bbbc666
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3798757-7a1c-4da4-b060-b8c9731d3631
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 104fd1c9-e05a-4dde-b917-7638cfacb955
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b5f0ecd-8a1a-42e7-92f5-7317699fb8a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2da3d583-1d16-4d9c-8250-4b057936df05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31518643-0bf7-40c8-b739-fd41c40ea612
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d7dd3c8-a81d-401c-bf9f-daee8ae17d3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc47f081-93aa-4da3-93fd-b86ea0172654
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d4fa84f-bd42-41f4-8034-9e8f2a1ee548
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4e47743-8795-4f93-90ff-777ff57835b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22887c89-481e-425b-a231-8923684feffe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c02555a0-2484-4c96-b3a7-9b7597db8be1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c412437-93cc-486b-bdaa-166598afecb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af44bc56-1149-4f77-b083-6c10b1c16bef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ec6ba77-9de7-4833-a4ff-a5a7f0b312f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d9df049-dfef-4ec0-84c4-2a5c780cc8b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4109729a-d09e-4b01-8467-1c62451a7607
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ab6b58c-2501-439b-9504-834570ec7efc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba14037c-538c-4b46-b81b-1d33cae228f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec55248f-a9de-41d6-ae52-b4deb5fddcb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0141b6aa-2c17-442c-9db5-8eef083b9f31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2bc6edf2-4e37-4b3b-a5af-a0f00a0e95c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87f5fe93-0008-4093-a8e4-5d6155ae23ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a873eccf-f3fb-49c5-a16f-7cd0b9da1e0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c22f640-6022-423f-bdb5-e68a65980f8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62a6ef80-9904-4018-a652-aa59093c675f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 240633c5-a9ec-4556-b0e2-d7e6dba1ea4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message daba0458-5a54-44ac-94d5-60079b328c83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9cfa66d2-48de-4730-91e8-d8a8fc3b1247
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41ecb3d6-2288-4e06-98f1-e87489eb9ee7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c5af28f-b407-4b54-b8d6-40e09bbf111b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f65b43f-798f-4940-bcc1-dc2c004efe5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f9acf1f-d3b7-421e-aad2-f0afd4275a1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c8a0e66-7b21-4e63-91b9-f28bbb6a7660
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ff13a58-53c5-4c2d-8fda-fb66a4d78dcb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce81a58e-0b20-4a79-ae49-1eb3ea9c51e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 207bf273-8778-476f-93c3-9125cd9bc474
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5443d8d6-89df-4a62-9cd8-cd02ea87ef33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88289040-f7b5-404f-8651-baae2132d30f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 578342e1-4eb6-468b-be85-c702b6ecd0f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 094f224c-5fb5-401c-b345-31cff2e9d35f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a485a1b-7b34-4885-adf3-721088558e14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17f3eb33-75c0-49ba-b22c-efa8ba364e08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfd7dba3-7008-4dd1-ae49-fb08d7f497f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17d61b66-c7b9-42d9-b96d-f066b39e7c5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb62cdad-ce51-455d-9f36-2f917fdcaf74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3433f1da-6283-4dc1-85d3-6773aa43b090
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b47becfd-ff72-4190-8e69-166ac4275367
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aecd1877-dcf4-445d-9fed-b58758bd62ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2fc9d46a-cdcf-44ef-b6f8-7776808e2921
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 565a183c-d9c6-41b4-a8b3-7d5fab368a1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 137be568-478a-4610-86b1-037d19214fa2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad35c218-5aca-4fd4-82ce-06ce63793a81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac2c3f30-258a-4d84-86e5-b6e7f850c168
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42dc03d1-2f92-48d1-ae06-274a67278377
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95441f36-1dce-443e-bfe4-5cfa80fc5dcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6e80992-ba78-46d3-a1d9-e61c3a2dd5e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30986f64-a89e-4eaa-a2d8-7d31685755f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34c62847-9d93-4f1b-aecc-c5ce56bb2464
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88da7dfd-0dae-4a69-a582-99d85158e186
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37a95703-1018-4b5c-8e2b-278d411ee0aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41036b2f-f13b-4765-9763-8009ae4b8994
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b32d9ab-26fb-4d62-a472-01d3607d49cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9fc3cc5b-9167-4d10-8e54-8816d8044081
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e5eb7c9-af39-4b21-9bc2-7a9a8b41c414
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f881e155-1e4c-4205-886b-7ce66bd0a2c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f5a9b77-7951-4d7a-9924-74ee228f222a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 478a9ad2-c86f-4031-9f5b-5d004aa1f479
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15ace88a-c247-4c9d-8fbe-8c7d8470759e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e323f9c3-ffe3-4064-8611-2a9e9774d159
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37e79227-1e8c-44ca-a47f-2569da9623b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da005f4c-18d0-41a0-8d7b-40fd47229e5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb35b98d-69d0-4e84-8519-669a3ce3206b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44920162-4537-4089-b02c-e2618919fa63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ac5967a-dfe1-487a-a193-e8ec194ef424
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e483fcba-8b8e-4e8a-b833-23587edcdadc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be8613c2-2a65-40ed-9349-d6040e6dc6dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89c5dcab-ac08-4b5c-84ea-f2c25ef96613
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4eed413-851a-459f-876b-977dbb295224
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1278ba62-ff39-4526-91e8-baaac96c929c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 618c9b41-d5a8-4db1-8ada-ac45bb3c101b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0191d45e-02ec-4748-9231-01e4748bf3ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 730a652d-f44c-4bfb-b49f-4593f6145bb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5ecc6f5-357c-4112-adab-04a62db1520f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8be742d0-cb5b-4d31-aaa9-6181fadc05a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a499023-d666-4841-9bf8-0f237f03bb01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3ee0bb9-92e4-4ce1-9cbc-edbe466e21ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a54175c-bde6-484e-835e-78e7179fd96d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 832790ef-3518-45e1-bb10-07eaf235e8e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de1180af-4f80-4dcb-873f-326c773f9815
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a56baab-f3a2-489d-8194-7ae68af28b2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bbeacc8a-be95-417e-aeaf-24cb191bed2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3cae225d-6f70-4d10-9778-3b96d1fd226e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ded459e0-0122-4db9-9bcb-9444f191ab88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4866ea9-5df4-48ef-8773-114dc6ce452e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 824ab8af-ba87-4720-bd7d-a3f7f1679378
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68828bae-dfc2-48ab-a28a-ad522c70ae59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 904e8800-5d73-4f07-89ca-8ae2f6fddb35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c5c7997-1f6f-4c2e-b133-3abc20a6f008
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0970760f-4962-4f3c-aa52-dca1e4b5e5bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2eb8af7d-b974-4729-b6f6-9424fd67f161
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76300e6e-e99c-44aa-b5bc-702034e3d045
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6af38f0d-3252-4f66-8e85-696b4726b049
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f3c720e-55c6-484a-a463-88e5e2ee7648
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b5ed70a-036f-4d19-9b1f-31cc41df0422
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message daed4351-3255-4a95-9ea7-d8d01a1454d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad360073-3d70-445a-b87c-6cbd3ca301ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a87e383-8c2b-4ad1-aeba-06523bf869c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f51257e5-d765-446e-85b9-56ef54bd6ae8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf6d92df-0fe1-4f13-a1df-46e9aee62b6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1f09eca-5c30-4e98-a64c-933b5033257c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82450935-e3c1-4671-9d18-4c2888e7b956
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09363fb1-c155-4360-9f16-a07446fb8a60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c9e3375-f9a0-4b9b-9d5a-a51736b9c48d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98260477-efd1-437c-902b-acfa426eb190
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48406d76-46c3-4b1f-baec-e650c87a35b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd553be0-f94f-45e2-8959-13e4702fa3e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e393f743-9418-4ca6-a2d4-4a7708190294
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc8d8052-ba88-4332-91ba-7afc0cde9f14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc3f032e-64c7-49a5-9c63-5efbbbdeeaf4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee4e5853-0ec0-401f-b408-6e03a6f0e4a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4339fd94-d756-4211-b5b7-65d56a56df9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c61126fd-4e39-48d4-aee2-e98b26894d1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bbd24425-3e43-43be-a867-c4a4cdaeaa72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 756b1ae9-c1e7-4a66-8106-be0aa1f3fe4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14a851c4-033e-4017-87f0-9656f367c762
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a04da8c2-0c4b-4e92-a9e5-5f72cffa2643
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 436436a9-b3f2-4b53-9ba7-33d173cdbffa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0ccc8a7-802b-40c3-99d2-405b4ee67cb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f450f462-e697-4d0f-bf23-84d8a35588f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5fd5ded-c63e-4f7a-b205-2eb010c61292
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13f9fb33-3035-475c-8aa5-d764018140f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96b20a0d-46a7-4512-bf19-b589ff8749ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8272eb2-d460-4510-aba6-166c666621b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bac31d5b-d5dd-4b2e-a615-0e1057dce74f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ce5e493-9ae9-47fc-8193-a05398fdbbf7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40613364-ccba-459e-a23d-7312774b499f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66b36001-b291-4053-b4e2-9a4c486a628c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8d94f9e-41aa-4aa7-bd3e-0edea7f8c4aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96793f66-1595-43a6-b61b-9a2aefc00e1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21bc854d-00e3-44c9-996e-ee88e459bcb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 921269f6-8803-49ce-a8c3-48f7819966b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e12461b5-3388-4b7a-81c6-25718152966f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e92efa18-4977-4a50-9e84-6029ab6135ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message faed9720-582e-4ae3-93a7-2039912b3941
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a01c891d-501a-4152-9be4-b8d85dfcdec1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5515b9f5-d516-4fb1-bb8b-129c18f7b6d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c19be8b-6dac-4467-8b11-8407882f041f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e3407fe-f2e8-4f1a-98ab-9302776242f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 573eda47-b474-4b1e-ba33-d8735c6f636a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f91da38-fd84-4ab2-9c86-a164a1a3dc46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9abd9040-b8c7-4345-9c98-91b021b05de1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f874d10-8514-4a79-80ca-af18ca6e703b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d265249-47fa-4c0d-beee-3b8a3286caa1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5994b0dc-fbf7-493a-a7b9-8698d2f76f2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1227a4e-7a8f-4fc9-a5fe-9232f128303f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f99d0333-175c-46f4-9112-e1765e6dd1d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96cdfad3-2868-4204-8a05-fdd1c9f2c454
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 409d8522-f4ab-472c-9787-9c40517e0484
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04752ad0-0052-43b3-926d-299812fe48f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0391c09-6d0e-4148-8b06-7ac3b7662366
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15789882-80d1-4196-898a-85dc7af831a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9fcaf242-e9d4-41f4-965c-f065c4d6a84c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce99a5c9-0c82-44ed-a27d-f0b924f14dae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55e579f4-e9e2-41c7-9c3c-f2794dd453b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0eee22f8-9a0d-4a15-9b2c-9e284258ba01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c376e807-18de-4203-bc35-08300257213a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b29120d5-704d-4eda-94ff-580e86127e0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af376351-723d-4d63-8d8a-d92e463cd284
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41c7b865-a144-46b0-95ab-ac8cc94d4638
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3579bc2f-b67e-4de1-bf34-e9df71f50b68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8ed7e41-6bcb-4705-8b3e-a118e93e1d6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 172878d0-686e-463e-896a-a66d99af77b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c4cebe4-37c3-4c18-810f-6db831eb064d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04a14990-63e8-4b0b-90ae-97f1bf6c321c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15d09ba5-d4e7-4e82-8e60-a1b683789a09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33fee0a1-6f9e-4ba5-921f-06020effce92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6754ed9d-9813-4b79-8822-ad24ab077a34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7efb2e5-341b-4de8-996f-bb74e9f6a9fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aaf688ce-5c99-4269-a68f-fbbca83e10cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 170e5b90-f785-4978-a9c2-35633a8daf23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ce291d9-1543-41d8-8c27-3f0ca509154d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ae6deba-32bb-4134-b46d-6b3c6005d340
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd5bfc41-5e7a-43e5-b6cf-9bb532e3bc29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99233136-383a-4098-9ee8-50731729a7eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bbf0b515-1161-4302-9e6e-7d8afe697212
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c139fce-ae91-4960-90bc-a5b11cbdfe05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c69fb3fd-1f7d-405d-9d76-7d3a5e2533d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 113ca24b-6bed-43f5-b15e-85df9d27bbda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42065644-c801-48b5-951a-81e6e63c5a39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 715618bd-34f2-4809-a55a-c1f5fdde737d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0369ab13-d0de-49d0-9064-d0e4c2b9459b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d2cac21-a4e4-4eb8-a9cc-026eb75c5f5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15162b95-30d6-4e69-8a54-01b2c741894a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9573f24-84ac-4f04-b87f-9b60b0d68096
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ceba29d7-08f2-4cbb-abdc-9336895b7cff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ca42d98-60ad-4f98-9dc5-5d6b66808597
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd6f48cd-18b7-4a81-a2b5-a21204e94bf8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message beff4779-795e-44b5-a2d3-c43b689601f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a7ec4c5-49ee-427e-89b3-ac72d6f2111a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d24aad41-77de-4f45-bb5a-25e73821de11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1fc2bf0d-a8cf-45a0-82a6-2cae1dcac353
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9e47c77-ed24-4ab1-8a2c-4dfbf204fb63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35ecea87-b8bf-4b9a-890a-d837a943aa89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 037817b5-b2be-4ac0-b108-84fcaf6374ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ae1a16d-3aae-4a7a-89fb-82d6fa147c29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7054c479-0b70-4e9e-888a-0148205d9586
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c868094-a66a-4743-a2a1-7f72bb0c630f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1be86be9-ec14-4d9d-80fc-043a2472cb80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 565fe4d5-a554-43d5-8b2a-a32e466363ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49d7657d-ad88-4fc2-8224-8c7ad320b2c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80d2c047-50cf-4b0e-bc0c-fbe69c869439
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1936fd00-a505-4841-b140-982af1fb2b62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd67fdf5-1375-4876-b9bb-4dbe9cb1b9eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f767d314-ded8-405f-b7ac-143670b80b07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1435ef12-a79c-418b-9cd9-55fed4ba97a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ef1abd8-9b6d-45a5-9581-7067b64d2fcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6afb21e-654a-417e-91c1-0517c09fe808
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89e9b1e4-2056-48ef-95e3-fca48f113311
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4440a41b-d90e-4179-80df-b3af0447210b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54d7fc79-2b67-4919-b9f0-9600f9c26a19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e6027b3-40f2-44ac-aa3b-09c6413b4a4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8b9a3bf-b9d6-402e-b6da-1266123e9915
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06518319-ab37-4f39-a841-6ec3ff4cf53a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1329b76-72ec-49c5-99cb-0df2f90dd699
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15cbfb73-4c32-44ec-980f-92b68f25777f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b76826d3-f1ea-43f6-b36b-d281f59857ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b092dad3-6c7c-4215-b183-93b618771a99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6bddf59f-3701-4905-bdf2-41dcfa92cf46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message decd05f1-7958-4ad3-8e99-8894d4f94f12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9759a41d-10c7-47b5-a8cd-8270e2280165
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27575c09-097c-45c6-9f4c-b124882d4226
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 205a1879-3aae-40ac-a079-0c3de9f0c714
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e55dad6-bc7d-4050-8958-601f30d2b91b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16d03bcb-0453-4179-b9a5-79422b385ef7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 957d5981-bd34-41e0-91f7-a70fe50794ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc785520-e71f-4a60-ae16-c155ea977b57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8f81cf6-83cc-48ba-9639-8a9a775c2ee0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f72f9ce-5045-4cc1-87ed-41ea283cc3bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b916cdf-575b-48cd-8148-7d8c3c24eb39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54424aed-071c-4c80-807f-1a55dbff3947
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be8cf930-a43c-4b4a-bf7a-5e0855af1d57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2cd7c8a9-8261-4329-bd66-4db94e847b60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ef5bb67-0429-485d-8f8f-2395e163844a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9fc56dbc-da68-4e11-bf28-81cd8140144f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ebdd0838-2782-47b7-a9b7-ceb2339fad2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ada88a7-af45-490d-8084-05f14b5bbf2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 378664e1-13b9-4101-8e06-f482239fbdcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5b5ca2c-ca56-4c2d-a027-7711982ac709
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e796ccfc-29de-4a4a-bd31-864842fbbc6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message edbf7502-e343-4fed-95de-ca93427c1bfe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03ca71f1-6e8a-4159-a723-01d9da1ccb0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e5e7784-95af-48b3-854e-29cc3493938f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cffe46d0-aad7-4121-86ca-db65e61dc507
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b17b2cb-5281-4cc8-8bfa-97c0be4959ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83e5ae59-e15b-4ee3-9aa8-a83b04f3694e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8cd9274-cc4b-454d-ba75-22d3e274f392
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9bf7263a-f976-4b15-9d2a-d2dc01716d72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e148506c-c367-45ff-81aa-f8d0041b5122
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6a9b881-cec1-4335-a982-bfa0af51ce59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91320f82-365e-46b1-84e9-a667e75aca69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dded5ca1-8f98-4d26-89a7-4fc4c667e58b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec1298a4-dcf7-456a-abe2-0ca512f6f9bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed28ef27-1858-4cef-a163-18534e3d6e08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 145ccf95-e05f-4508-9e1a-71f6a4523385
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6abb5f7d-0e20-4a9f-a1ff-712001aa7c66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6eb4bdbe-e3c1-4d22-9c46-298ea8b3823f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd482d96-e104-41b0-b0b3-df30342a7111
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message daa22538-ad0b-418c-99fa-c609f0db9fed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf7f6354-7d06-4736-becb-67189be18374
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72325a2e-a236-4ddc-a925-c685d6f38cef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3765384-8bd1-4d53-a06a-05e72905562c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 348c05ba-fb54-453d-98ea-3d5432b0faf5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4a32435-76ee-45ca-9121-b379020ff42f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b066f6f-0715-4670-8cf2-1ea193feae43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0c304ba-1c99-405c-a077-4a68beb87092
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61a6d44e-7630-405a-a3ad-078cd00fc323
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5682ac1b-7cb2-4c04-be3b-279fdd3425ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76e72a09-bba4-462c-9397-971d3f0ccc6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 748e1705-e0b4-4daf-b524-76d71b3b4e5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d52aa03d-c81f-44dd-8669-75b5fd49240e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 953adace-2f9a-4f5b-ab92-010c3097ec74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2a312b2-449f-4161-b74c-09edd44d0222
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c457c4e-4b30-409c-97d9-d78281be3324
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88b59da7-cd73-46b7-8049-395272ddd3b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9af3b890-f298-4781-9d02-4c7f390d249d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b889324f-b991-4934-8b06-b9b49ba98453
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 528c0650-b887-4546-af61-de2d9a57754d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8711dd20-fdaa-4859-972a-674b008fcae8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3f9b3a6-75bb-419e-89b9-3577bef3a4f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2a33f6f-7f40-4d4d-a7fe-413e554f4b04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 159bac5f-17e4-4406-89c5-4e06da75152a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 584781f0-0eaa-4526-ae46-b11108808c5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b39a827-71af-4d04-a6bd-e81785f55a6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9129f0a0-39d9-413a-9f13-595a182fefa6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2e3726c-7407-470e-a6f4-4560650835ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5a48c70-dddf-4dac-b02f-d0d8a0a10611
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1cd8ed54-9569-402b-b38c-252fe405bdbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea8c29ed-2b4b-4a61-8259-75f42baf0a57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a582903-4e70-41da-a24f-a12cee19d663
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea6ef921-5008-4deb-a03f-519e726c7336
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3243d84c-d883-4074-b2a3-52a1b6fb6b68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97cf267b-6bb5-45fb-88fe-fce0f2a35848
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b747385e-f0e5-47f2-81a3-5ddb6cac80a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24221b2e-6fb5-43e0-8191-d5b0cf788d63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47ec3165-63f7-4942-8d0e-f9f1ffe1c18b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58922364-e5d2-4546-be9b-dbc3c98bc844
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9071e7d3-b3a4-43f3-850f-a5dbc6ef6c4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a9d2d93-34ab-4834-95ac-c932f59d1cd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc17f76b-847f-472d-9d9d-2034dfee203e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e9f85dc-5b73-47da-93b7-54b7ff96ef41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc5a6923-eff2-4a9a-86fe-1f0300c73464
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f4e80a6-3f16-4e5e-a780-de7720d49b67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ba702ae-4885-473a-a4b4-529487f2a7ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2db58b38-ac4a-4aab-a81d-909ca93e5f13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0b79fef-ea6a-417e-9332-1d3eb8a44aa0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2fac997a-069f-4173-9c51-09450b9f906c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4e95c6e-595b-4d3b-ad64-56b6e158a35e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 852cafd7-9b09-46ab-928e-d5d31f096b39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f46d3073-a26f-4012-ab5a-98df3305df14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 271c7233-61ce-4c8c-91b6-d01808671b6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ecd756c-81fd-4e7e-8ea9-7021472d97c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71e11d11-42ac-4941-8ba2-289e1326c66d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0c5091c-9825-413e-8c47-3f5455f01467
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6d813ae-0959-40c7-b00c-396a9ef8f2aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6087bf04-4ff3-4444-ac30-7bf0180574fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64251ddd-ef5a-4602-8c9e-81df7322ed8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed83ed05-5f06-4b0b-9095-da8b37253c29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78d45654-ed92-4246-b9e1-f30e3aa68e69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cfa9a4ed-bf9f-4f3b-a59a-ebd62ca355f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b542cb77-5f44-45c8-ae40-1f24937f708f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4455dbc4-d17c-40b4-92b2-74e49cf05176
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6311e3f1-bc67-4bf2-b9a8-aae4d953e2bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d720b0b7-d18d-40a6-9ab7-051d01a96d1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c13d518-a2ce-48ea-a662-26fde33482b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 659b9f31-ee15-4bf3-867a-152af1167320
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a161e6c5-dade-4b0e-b7ee-11747e16f4ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3c63e98-8fa4-447b-b144-d5028be0169c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ceba8dee-140e-4abd-a7b8-719b8b62caa0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b26433af-5494-4b80-8289-a6a98548d7d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0277fe1-4933-4dba-8363-25c35e9ae0f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00afdaba-0f79-477a-8d05-7a1cd929c5a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ecd8b8b8-07ad-40d1-805e-0e97712c25cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7f707bf-aa1e-475b-ac34-e910e52ae4a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9437d01f-5b5a-443a-9191-d5636b180334
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ee186a6-44f5-48b0-aac4-83274affc38c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f870894-168d-4f8d-a82e-379953533238
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1f84e32-adcd-4566-8fca-c1c4f4a4a60c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9bb82c6e-f793-4cb6-9f23-4abfb51c4eec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91f2cdda-f1b6-4ea7-b4c8-01cb0677b194
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf192d28-a43f-42e7-9b99-38c85b612d95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bcc4fe72-eb57-4386-baf0-8feb724ae29a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea12f3f7-6a1e-48ee-864c-7f0e26221d57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c07c4ec2-55dd-442f-b88c-88436cf8e3aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91328549-771c-4b18-bd34-c79335e34f5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d67a97f-ff4b-46b7-9f31-dc33fdd3dc76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43964b9d-3c83-4769-abc2-79ea9000f7f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87fc6e63-5d42-4d03-aa87-752efb64c1f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24f270b3-4809-4a6d-ba22-1ee17a190a84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03684111-2242-4661-81a9-4cf3b02c85f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29c287c0-2e13-4fb9-9245-f95830e8515d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac4f74c7-4f75-4f4e-b115-e9480dbda3c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d740396d-3b2a-4924-bd7f-61b9d16b3eb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7503766e-a8b8-400c-b8c6-ce3f55aaa50a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ff131fa-ca86-4362-9240-11191a68ac04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fcaa4838-e3fb-457c-966a-c3fddbb00ffc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d3f5167-30fd-468d-af4f-49375ee3bf6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19a3a083-6271-485d-9556-ef76885c9268
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20ad1b18-5630-4f75-855a-9c3860cee297
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f704618-0688-4f5f-97b6-056492b29687
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ecc5cd28-b0dd-4a0f-953d-c122f1b87515
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6719fdda-9cf8-486e-9f77-4eba88c39e9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae666b59-69a8-44ce-873d-fe41e1f31e20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20323b7a-036a-42b6-bb40-ec8aa122eec2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 947b3390-cf2e-4150-94da-23e419938384
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74d76096-a0a5-4062-8e67-fbdd9729527e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d4c1866-c107-4384-b09e-ef2ef42c1ee3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6111f62-3961-41cf-b280-03e820e1e72a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1a6400e-9f9b-44da-b295-2fe5f680ca0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce6c17c1-7538-4b8f-a6a8-07c37a110475
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15ec979e-3884-4f0f-b865-d36a894f8c25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ea786bc-c71b-4c5e-b2f3-2f1e0df5b198
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76d1482b-bc8c-4777-8738-a333e36c54c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a566dcb-e3f1-4a5e-87b6-e15bfa79ea95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 521149d4-f470-4458-aaea-6cb677013ade
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f9e1bac-9d42-4f4d-87e4-1b7a7f152340
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8113060-1667-4d24-a6e2-6548a8c61518
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ef6888b-4fe3-43c9-80a7-873a7e60958c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message abc4a2d1-f6ee-414e-975a-36fe3a72a84f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b57c27f-1e44-4870-a1f5-071f90358113
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 443e059f-3865-41d1-a758-06287967e1ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62277a50-e878-464e-9111-6c4257964b18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12c90a86-c217-44d8-9393-ee72a20f50e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49757d60-af2f-4a74-8f7c-34d3d963425c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef1d778e-d0c2-476e-8397-4c800f4162e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12179bef-6478-4cce-989f-63042b410b27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b71c7de-2293-466e-afd4-670ce7ef5790
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 185affa0-fe2a-4eff-b7ff-e3327bba4815
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2df8c1ef-a423-44da-aebd-1e5631b60098
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a45fe99-7986-4828-90cf-4273bece48a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9dd9605b-27b8-4032-9ebc-25db4ea876a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d68e8f7-6829-40fd-8c47-3193bccbf3df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2355bca0-a475-47f3-9722-aae865e50bbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89d4822f-d073-4a81-9871-d710f43a6363
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4e5bb67-3483-4e07-8ed5-a67802f016ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 674deb6f-a906-4399-b46f-86574e4821ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8bdf957b-855d-455b-9e5f-f4669cf0946c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba3d5f73-bf36-48cb-936e-8b07f6366929
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98cc1021-fc26-4e3b-b95a-e6f110dea6f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16b8d236-dc3b-4dfd-9fcc-0cae91910a94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8cde518f-b603-45ef-bf39-5ecd9fde5f99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f916838-2b1a-4cfd-aa48-8d885003d751
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 833dae53-6efe-45d0-a78a-fa9e50beda43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48602a82-4af7-4c2d-9e58-4dea51902853
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5000bccf-46e7-4c75-8a56-09bc93c65b77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6a03dfd-5815-4365-8dca-bcf906442193
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b8efca7-e74c-4080-88d7-514f00bfd3d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4fa54972-be96-4ec4-923c-0e3a9b460d98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d01d762-d3b1-4eba-8f8f-eeffb61b6200
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd9cf5cc-3bdb-4fd4-b6e9-310f10135536
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0152037f-04ce-47de-89f9-78b66555d884
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36a286b8-c513-4cd3-8b66-0a06cda20fce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29198cca-80bc-4f3f-89e0-b4b6c3b8db34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc0a663b-f5a3-4d8e-9718-121f2cbabc4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26c7be01-2313-4b64-9dbb-c50474a0ddcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fca5cc77-f049-4436-acb3-ad24d9e224bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61b3762b-c6db-4f1b-9e8a-d01a348f9551
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9e54d34-5d54-4fb5-a972-a1564b1a0f7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2d93e4b-2a69-4fb5-9402-58d8431fd14a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a73e2240-7794-4653-8722-4890c38faf93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd70dc62-9cb7-4421-9f91-b19e6b416972
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b58a16d6-3522-4dd1-9761-f3bfd7ba4dc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bda3509a-66ce-4737-b4b4-bc3df12ccd4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8aa297c5-7c32-469e-a24f-9a79dc32650c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75002431-c73e-49b3-a130-e662fc7e8fc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c118183-fa68-4db4-b5d9-1bf058b4d945
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be033180-a395-439e-892d-197dcf6c8c43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2873883f-8a77-457c-a1f7-34b939808c50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c54dfd4e-d309-4f53-8def-5bc594915987
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22ab1380-c8d0-4387-8f9a-f7bc16306325
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cfff1ac7-d109-471b-8ad1-ab5ccc4ae68d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48023ed2-9d69-4059-b1e1-6fbd3372c4b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd4ae8f9-ced4-4b5c-8426-8412c23593ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da319791-e3fe-4fc2-b9a9-e98c7b800830
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4ce36fe-398f-4081-a2a8-3baf39e11d49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a790916-0247-4161-bb56-8a6584d6b62e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 365c3a11-6b7d-4218-b328-48071ea780c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df72b500-8d83-4379-905a-3479e5a7272d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9c62540-bff4-4b67-ae19-4b6fcdfe8b58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2302e7fb-6779-4aca-8c37-710e0d53dc4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b861af57-5f49-46b9-9451-340680101d87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d813ed0-ef78-43e6-82a4-ee12e1b4f7b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc6b6b21-9eb5-4ef6-9b9c-15ba7d3b52b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 375a13cf-608a-4f1f-8103-109a6718b43b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9fb090f5-fa34-49bf-abbd-47b655e4333f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ddbdba0c-1de6-4f75-8842-43e0909b29bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f845740-d6d5-427b-b513-ece3a7ae570c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae0da6c4-9948-4b15-ba6e-ff3bfc6a8310
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6521e8cb-beb3-49bc-b228-91ff3e4f6038
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 500b70c5-d27d-4788-b920-7e3601f9d448
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d02f64c-053c-414f-83d8-978418033c83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a090bf0-c6c5-4520-9822-1973634ec8f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b07b90bd-6a1f-4132-9ce3-cbd7e83407b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df175781-b703-4600-b06c-fc47d7b4e6ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42e5413b-e092-4325-910e-105c32dfb37b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9456ed5-1b17-4037-93bd-6fb215589462
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0a1d032-c2da-4896-a7fd-24c7ddf3deae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10a3371b-253e-4596-8c16-f4727bd07288
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf84b477-da1c-4d7e-b423-50d5128c2612
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8e297bc-0f26-44fe-80d8-f21c3af65efb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e68fd42-d5ee-49e0-a0dd-5bc22b6294c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 761c0a3c-49a1-4b38-a030-2fb72c653712
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 034fb4fa-0550-40e9-b331-cc652a4b006d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed28c25a-b4b1-49b3-9ccd-2a686259eb6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f276104-334c-4b10-80de-f1701dba1592
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b33aba7-ea19-43da-8049-ead94fe4f2d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c27c36e-37de-4dae-b918-c2c145c5e07a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 235a736b-8fe2-41e8-8cf8-e5830a9a2b90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e236cc7-4f94-45bc-865e-83a3309e8d3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10742fa4-4bc6-4d39-9f97-6211d64e2ad2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f685ae5-88e4-4d1c-93d7-6575615da37c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20420ec0-e648-4963-a8c6-b2cccd079e35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08b281b2-89fe-4fd1-9937-17855543737c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ae56de3-2e9c-42f6-8fb0-1e9379e8d76e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 339988e9-4125-499d-901e-2c84d3e07815
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41f407d3-49f0-4935-afc2-10fc771808b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e668a88b-732c-467e-a6a2-d6618c663319
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66ea174f-c423-47cd-bd6f-b9dd28ce583d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 964a02fe-4341-43de-9ca7-cf67f5c1ff94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd19c41e-3b8b-43aa-a3b0-01e59c1c284d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b246987-690d-4d1a-80a7-7bb1579d5a4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 306214d8-703c-4a44-98ec-ca90e7562b95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c6adb10-1570-46a8-8a53-744773f03a24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16d3da77-497c-473e-a907-8d38698554a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fba6a682-cb84-450e-8a01-a3455b22114d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14736bf0-611d-4a52-8760-5ea0f9a660f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82945621-7a26-40d7-ada3-27bebe120e2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eed89709-642d-42ea-a54e-9c4b57ea5fc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d15bb33-7288-4d95-af46-024c73c1682b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message efb3173e-25f3-4935-826d-4f257c2bb5d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab5e4cf6-5d15-4b2f-808a-70b1d0f891e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6050ce87-3594-40c1-abcd-de1edc437302
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9aecc053-6cd3-4136-9091-ee50535cb3c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e8b7ce6-a358-4920-8bb7-81053b892c8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 379287ce-02b9-45df-9e69-ccaca562d71a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 490718ba-15c4-4966-97fd-06226c6d4d18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb8c62e9-96d0-4851-a587-5b6cc98738e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35411ede-49f4-4f7f-b981-6525655d212b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48818c4e-8f2c-4a71-83d1-d8204618ee16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c3a4201-415e-434d-9211-66a9688df089
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d20bbf7b-f269-482b-ad86-6912ffe69b8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3faebeb8-68c5-46b3-a02e-01710e696d3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c1693fe-69dd-430e-a1ac-78decd97352d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5c0a1ba-40b8-45af-b8ae-2f0ee666f72f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ffd046ef-fdb5-473f-b14a-1df0b48344e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8fc36b18-2505-44c2-bf64-508c6ea40534
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 810af2c5-02cd-4165-9e6a-d7b0bb6c3e9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56501895-d5c8-48ac-a1f0-4f4095bb440b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3588da77-29c8-43ec-ac2a-971d0150c45d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7af6f88e-7ddd-4212-9dee-1323d83a6810
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7088248e-34fb-4269-89b7-dff0298b3f85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19403675-41f5-4bf1-8006-d98dedc24ecd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 204d9909-df2a-4c52-ab2e-aee02f377bba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6d5cd07-5955-485b-846a-6ff6500585d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a439e275-e918-4737-9a65-b666c37688b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5bf958a-9ef5-44ce-be04-b0eab0689b02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6497f303-beb0-4be5-8be9-b13a47dcb3c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2c80923-2ec1-448f-92fe-d5ee3de3e8d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e6d0106-1c12-452e-a3a1-5e84e4c8a39c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 479c4309-1f5b-4452-9e99-3d71dab1692c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8087ca8-dced-4e83-9ec4-37c43852c131
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43b3363d-4ca9-4799-a60e-585fe31c2c5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81621f6f-61d1-4461-a47d-cf8e9e8f7879
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8159926e-6678-4b56-a19c-dc66c0588d8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 325f5cbe-3064-464d-a5bf-48850df7dd81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50d31d5b-1809-4bcf-bcb2-db53d562186c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eacd14f6-a959-463d-be87-1db41e549bac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b86a2be6-05a7-477f-b559-539e07ea2a77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ec5bf75-f869-4e6d-9d8a-d2be5e34c152
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80b8710f-5005-4cd4-a784-2507521b570e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16f876de-6d4f-4145-bd25-8f057ea5e00b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed2bf464-ca46-48e3-bf02-124110761cac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9ecc1c8-42e1-4b07-bc17-4dc17abd602d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34df8e1b-498c-48c1-a436-7ca40d8c50f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5710bbfc-5910-49d0-82dd-b87d2657f459
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7a45472-92bb-4c2b-824d-ab0312571900
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf956023-4869-4db7-bd23-e2594bde1054
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64d3acee-7a6d-4a1c-9d66-cd87005d5019
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02838034-0c4c-4bfe-8534-832a8f0489bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ffbc6ac-b5e3-404a-9d8e-f8c8c340a4fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cfa95140-4a4f-45b3-93c7-b61fcef6878b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fbb12093-af32-48b9-8f44-73c91755b713
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d258360d-564b-45da-ba4d-fcb920945868
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e683803b-2218-4780-86e5-70749797578c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bcb898cc-ed41-4648-a391-67e08c36e45f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6aa97eef-1ab3-4cd3-87aa-9dbc9f49c709
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60eb76f1-39a3-4907-8f83-8ea14c356e6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a8c4c2d-4235-4e5d-a12a-471791c9fc7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8933708-db49-4a6b-bfa1-3ec98fbb0552
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b6b695b-a7fb-4557-ae71-d6bc22c56eed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a52c492d-04a9-4ee8-9b9f-ff571668872b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f345ff8-d2d9-4ec3-ae65-e4809562c535
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3fe654e5-1b27-49f4-9eb2-980c009587fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42d60ad8-3eeb-44f2-91da-db10c4b6957a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd4a4304-c3cd-4102-92f7-2e64d20320fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13a8b3c0-2327-4d06-83f8-d3a528cb6e9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48bbaca3-d26d-43b2-8ed6-bd1da2ae49d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ccc3984-e117-41d9-bc16-502fbd05a07f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7170ee19-2c84-423f-8800-60abd56782d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef1ecad1-b4c5-4617-ab19-1f2e0460a68f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3c4e294-f3f6-4cb2-af4d-4fdd3351d611
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 271b104c-e567-4cb0-8dea-3246058e9628
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc08d298-d0a1-41ee-8da1-2295ab55addb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4903e158-0fd7-4106-a6ee-efa39ad1cc34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b94200c-afb5-410a-aac2-145a5450cddb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 793d1d3a-a715-4a27-b238-ceb59c7ffce4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d274c358-94ea-4f1f-b1a1-3218c74b723d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a321b854-dc8d-427c-b216-bbf68f58f5cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48e163e4-ef49-4b7f-82ec-2080220e8446
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe25d973-9b21-4777-abf1-3c92888c7f12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2ac9350-e352-4df1-979b-d22857cd62ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3465af4-c5f7-417e-9838-bdf588aef447
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0140c552-e414-473b-86a7-e20ae8245dfc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9403c253-b654-4b7a-9618-32129b6aaa72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dcce6766-3e3a-46f2-bc9b-4d1ef0f5f35b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 886a06c8-7671-4023-ba28-2f8812ec1351
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f121a32-14e3-4156-87b8-5af75165d241
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 278206ca-ed39-4a59-86e7-085835227c64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89f168de-e414-4ce9-9c53-220c02f87976
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57fe6cbd-01c7-4eb6-9268-6fb45efb7a95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb9c2dde-7a58-43a6-9590-624bcb92b0f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3056a48d-17e2-4662-8023-7e7e9efbbf00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 698a50c1-353b-49f4-8818-382620476fe4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24a49925-d817-4c89-9bef-768280d946ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ece5a99-a596-43b7-b908-000de3dcef70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d95ebd8a-e905-48bc-8114-e9db830833e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07f76c70-1d17-4edc-a827-c58fbfe92d19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ffc4499-387b-4fcd-af6b-59cab878824f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e2eb76e-b1d5-4bc1-a058-93dad722fe15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5831ff3d-fc99-4b36-ae1e-63a6b253e626
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fab81887-d6dc-4aae-a0ab-de0843918d1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e229e8a-bda9-414f-9b03-d790105d492c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c185cf4-d0b7-4d36-be21-7edf8977e44d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cef12c44-4433-4dfb-b929-c11ada6b2a8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c01f7be0-4a44-4544-a297-9297a3d5a11b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 563614ea-6ae9-4063-87e8-0dbc97627a53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 354477d3-385b-491d-81c3-db907d985584
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af0be2b8-e6b0-4c5b-a905-85617a91d1f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91fccaba-6780-4f0e-b0c0-a1072e017cfe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 200d709e-4ab4-4f40-888d-c0793389d775
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f451e6f-83ac-4902-aca9-93e59c83252a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20f95d90-f42d-4b4d-b1ad-43daab9d8a71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 242c0bc3-e547-432d-a073-655886791c42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 855c96bc-2553-4279-8eb0-4d7cde58be96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ed67298-1131-41bb-b285-6ab8c4c01fe9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55f85e13-f762-4d70-a2fc-aec123158bf6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35d99b82-5816-44e1-b700-2d2e055e6ed9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8377c5e4-6e2e-49d3-b3b3-99447e1cc1d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98fe47e0-0c6c-4741-9825-3c9ee1fc8b2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc28ae9c-b97e-4d46-99e7-651f53651380
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cdd4b18d-2952-40c0-8917-3214bf1f6e67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87f8b826-a4f5-4a38-ab96-af1bb680445e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65dd10e3-0f6b-4d35-8248-7a5b005ef4ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 717f2547-2115-4182-9ef1-0bdd05c90585
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35601bcb-7c8e-478f-b597-5f3f0c6d7c15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 590e10b9-f7d6-4f8f-8c28-fb6e7761e077
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5aa4876-389a-4ab7-a321-5846a14c1e4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09b4e364-4889-49a2-a9ac-c32fb2a922b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d2952db-b7b7-4078-be04-4043b8425cd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54ec458d-c42a-48c1-b87e-68f98f441846
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b6e983a-8556-48ae-9abd-6af7070a979a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eef48d29-cf2d-440f-8729-1a695b35095c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e87c7a6-0716-441c-8483-4f59403444a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d78d828c-d561-4bc3-82f8-1bcd5c4bb734
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3dc6ad2c-603a-4f09-b2db-1a4a13adbd04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb198554-de65-481e-8d52-3796807598a2
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8692 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_9
Server: localhost:8692
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_9
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_9/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_9/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_9/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_9/test_labels.txt

📊 Raw data loaded:
   Train: X=(5643, 24), y=(5643,)
   Test:  X=(1411, 24), y=(1411,)

⚠️  Limiting training data: 5643 → 800 samples
⚠️  Limiting test data: 1411 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_9 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 2 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.3441, val=0.1404 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0954, val=0.0889 (↓), lr=0.001000
   ✓ Epoch   3/100: train=0.0846, val=0.0817 (↓), lr=0.001000
   ✓ Epoch   4/100: train=0.0809, val=0.0811 (↓), lr=0.001000
   • Epoch   5/100: train=0.0806, val=0.0812, patience=1/15, lr=0.001000
   📉 Epoch 10: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0799, val=0.0814, patience=7/15, lr=0.000500
   📉 Epoch 18: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 2 Summary - Client client_9
   Epochs: 19/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0045
   Val:   Loss=0.0811, RMSE=0.2849, R²=0.0001
============================================================


📊 Round 2 Test Metrics:
   Loss: 0.5019, RMSE: 0.7085, MAE: 0.6485, R²: -5.1694

============================================================
🔄 Round 3 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.4313, val=0.3806 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.3374, val=0.2933 (↓), lr=0.000250
   ✓ Epoch   3/100: train=0.2262, val=0.1493 (↓), lr=0.000250
   ✓ Epoch   4/100: train=0.0946, val=0.0973 (↓), lr=0.000250
   ✓ Epoch   5/100: train=0.0803, val=0.0907 (↓), lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0783, val=0.0910, patience=6/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 3 Summary - Client client_9
   Epochs: 20/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=0.0008
   Val:   Loss=0.0907, RMSE=0.3012, R²=-0.0019
============================================================


📊 Round 3 Test Metrics:
   Loss: 0.4952, RMSE: 0.7037, MAE: 0.6433, R²: -5.0867

📊 Round 3 Test Metrics:
   Loss: 0.4789, RMSE: 0.6920, MAE: 0.6305, R²: -4.8858

📊 Round 3 Test Metrics:
   Loss: 0.4359, RMSE: 0.6602, MAE: 0.5954, R²: -4.3571

📊 Round 3 Test Metrics:
   Loss: 0.4171, RMSE: 0.6458, MAE: 0.5794, R²: -4.1261

📊 Round 3 Test Metrics:
   Loss: 0.3472, RMSE: 0.5893, MAE: 0.5157, R²: -3.2677

============================================================
🔄 Round 17 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.2828, val=0.2528 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.2085, val=0.1679 (↓), lr=0.000063
   📉 Epoch 3: LR reduced 0.000063 → 0.000031
   ✓ Epoch   3/100: train=0.1272, val=0.1032 (↓), lr=0.000031
   ✓ Epoch   4/100: train=0.0897, val=0.0914 (↓), lr=0.000031
   ✓ Epoch   5/100: train=0.0820, val=0.0879 (↓), lr=0.000031
   📉 Epoch 11: LR reduced 0.000031 → 0.000016
   • Epoch  11/100: train=0.0793, val=0.0872, patience=5/15, lr=0.000016
   📉 Epoch 19: LR reduced 0.000016 → 0.000008
   • Epoch  21/100: train=0.0792, val=0.0873, patience=15/15, lr=0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 17 Summary - Client client_9
   Epochs: 21/100 (early stopped)
   LR: 0.000063 → 0.000008 (3 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=-0.0041
   Val:   Loss=0.0872, RMSE=0.2953, R²=0.0038
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.2363, RMSE: 0.4861, MAE: 0.4022, R²: -1.9045

📊 Round 17 Test Metrics:
   Loss: 0.2007, RMSE: 0.4480, MAE: 0.3660, R²: -1.4671

============================================================
🔄 Round 21 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1902, val=0.1691 (↓), lr=0.000008
   ✓ Epoch   2/100: train=0.1787, val=0.1572 (↓), lr=0.000008
   ✓ Epoch   3/100: train=0.1665, val=0.1462 (↓), lr=0.000008
   ✓ Epoch   4/100: train=0.1555, val=0.1363 (↓), lr=0.000008
   ✓ Epoch   5/100: train=0.1455, val=0.1274 (↓), lr=0.000008
   📉 Epoch 6: LR reduced 0.000008 → 0.000004
   ✓ Epoch  11/100: train=0.1175, val=0.1045 (↓), lr=0.000004
   📉 Epoch 14: LR reduced 0.000004 → 0.000002
   ✓ Epoch  21/100: train=0.1026, val=0.0918 (↓), lr=0.000002
   📉 Epoch 22: LR reduced 0.000002 → 0.000001
   • Epoch  31/100: train=0.0983, val=0.0881, patience=1/15, lr=0.000001
   • Epoch  41/100: train=0.0951, val=0.0854, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.0926, val=0.0832, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.0904, val=0.0814 (↓), lr=0.000001
   • Epoch  71/100: train=0.0886, val=0.0800, patience=2/15, lr=0.000001
   • Epoch  81/100: train=0.0872, val=0.0788, patience=3/15, lr=0.000001
   • Epoch  91/100: train=0.0860, val=0.0779, patience=2/15, lr=0.000001

============================================================
📊 Round 21 Summary - Client client_9
   Epochs: 100/100
   LR: 0.000008 → 0.000001 (3 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0360
   Val:   Loss=0.0773, RMSE=0.2779, R²=-0.0216
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.1714, RMSE: 0.4140, MAE: 0.3352, R²: -1.1062

📊 Round 21 Test Metrics:
   Loss: 0.1411, RMSE: 0.3756, MAE: 0.3034, R²: -0.7337

📊 Round 21 Test Metrics:
   Loss: 0.1144, RMSE: 0.3383, MAE: 0.2761, R²: -0.4066

============================================================
🔄 Round 25 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0910, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0907, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0904, val=0.0873, patience=2/15, lr=0.000001
   ✓ Epoch   4/100: train=0.0901, val=0.0871 (↓), lr=0.000001
   • Epoch   5/100: train=0.0899, val=0.0869, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0858, patience=1/15, lr=0.000001
   ✓ Epoch  21/100: train=0.0863, val=0.0843 (↓), lr=0.000001
   • Epoch  31/100: train=0.0847, val=0.0833, patience=5/15, lr=0.000001
   • Epoch  41/100: train=0.0836, val=0.0826, patience=2/15, lr=0.000001
   • Epoch  51/100: train=0.0827, val=0.0821, patience=2/15, lr=0.000001
   • Epoch  61/100: train=0.0821, val=0.0818, patience=12/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 25 Summary - Client client_9
   Epochs: 64/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0291
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0096
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2483, R²: -0.0285

📊 Round 25 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2477, R²: -0.0148

============================================================
🔄 Round 28 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 28 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0028
   Val:   Loss=0.0839, RMSE=0.2896, R²=-0.0258
============================================================


============================================================
🔄 Round 29 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 29 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0019
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.0215
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2474, R²: -0.0088

📊 Round 29 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2474, R²: -0.0064

============================================================
🔄 Round 31 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0725, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 31 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0047
   Val:   Loss=0.0724, RMSE=0.2690, R²=-0.0108
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2473, R²: -0.0047

📊 Round 31 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2473, R²: -0.0042

📊 Round 31 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2473, R²: -0.0041

============================================================
🔄 Round 38 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 38 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=-0.0039
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0012
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2473, R²: -0.0040

============================================================
🔄 Round 39 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 39 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0004
   Val:   Loss=0.0866, RMSE=0.2943, R²=-0.0155
============================================================


============================================================
🔄 Round 40 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 40 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0031
   Val:   Loss=0.0796, RMSE=0.2822, R²=-0.0059
============================================================


============================================================
🔄 Round 41 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 41 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0014
   Val:   Loss=0.0853, RMSE=0.2920, R²=-0.0230
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2473, R²: -0.0036

============================================================
🔄 Round 42 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 42 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0042
   Val:   Loss=0.0791, RMSE=0.2813, R²=0.0005
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2473, R²: -0.0035

============================================================
🔄 Round 43 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 43 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=-0.0031
   Val:   Loss=0.0912, RMSE=0.3020, R²=-0.0288
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2473, R²: -0.0029

📊 Round 43 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2473, R²: -0.0025

📊 Round 43 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2473, R²: -0.0024

📊 Round 43 Test Metrics:
   Loss: 0.0815, RMSE: 0.2856, MAE: 0.2473, R²: -0.0023

📊 Round 43 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2473, R²: -0.0020

============================================================
🔄 Round 50 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 50 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=-0.0024
   Val:   Loss=0.0904, RMSE=0.3006, R²=-0.0150
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2473, R²: -0.0019

============================================================
🔄 Round 55 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 55 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=-0.0051
   Val:   Loss=0.0846, RMSE=0.2909, R²=0.0050
============================================================


============================================================
🔄 Round 58 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 58 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0032
   Val:   Loss=0.0786, RMSE=0.2804, R²=-0.0066
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2473, R²: -0.0008

📊 Round 58 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2473, R²: -0.0006

📊 Round 58 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2473, R²: -0.0005

============================================================
🔄 Round 61 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0725, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0725, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 61 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0001
   Val:   Loss=0.0725, RMSE=0.2693, R²=-0.0185
============================================================


============================================================
🔄 Round 62 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 62 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0046
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0066
============================================================


============================================================
🔄 Round 63 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 63 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0039
   Val:   Loss=0.0826, RMSE=0.2873, R²=-0.0315
============================================================


============================================================
🔄 Round 64 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 64 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=-0.0010
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0112
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2474, R²: -0.0003

============================================================
🔄 Round 66 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 66 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2808, R²=-0.0057
   Val:   Loss=0.0901, RMSE=0.3002, R²=-0.0077
============================================================


============================================================
🔄 Round 67 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 67 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0030
   Val:   Loss=0.0743, RMSE=0.2726, R²=-0.0173
============================================================


============================================================
🔄 Round 70 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 70 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0037
   Val:   Loss=0.0736, RMSE=0.2713, R²=-0.0156
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2474, R²: -0.0003

📊 Round 70 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2474, R²: -0.0003

📊 Round 70 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2474, R²: -0.0003

📊 Round 70 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2474, R²: -0.0004

============================================================
🔄 Round 79 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0967 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0967, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0967, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0967, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0967, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0967, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0967)

============================================================
📊 Round 79 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=-0.0027
   Val:   Loss=0.0967, RMSE=0.3109, R²=-0.0053
============================================================


============================================================
🔄 Round 80 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 80 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0029
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0145
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2474, R²: -0.0004

📊 Round 80 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2474, R²: -0.0004

📊 Round 80 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2474, R²: -0.0004

============================================================
🔄 Round 85 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 85 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=-0.0006
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0169
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2474, R²: -0.0002

📊 Round 85 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2474, R²: -0.0004

============================================================
🔄 Round 88 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 88 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0006
   Val:   Loss=0.0764, RMSE=0.2764, R²=-0.0210
============================================================


============================================================
🔄 Round 89 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 89 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=-0.0039
   Val:   Loss=0.0768, RMSE=0.2772, R²=-0.0007
============================================================


============================================================
🔄 Round 90 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 90 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0051
   Val:   Loss=0.0821, RMSE=0.2864, R²=0.0054
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2474, R²: -0.0004

============================================================
🔄 Round 92 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 92 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0044
   Val:   Loss=0.0737, RMSE=0.2715, R²=-0.0191
============================================================


============================================================
🔄 Round 93 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 93 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0029
   Val:   Loss=0.0786, RMSE=0.2804, R²=-0.0054
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2474, R²: -0.0004

📊 Round 93 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2474, R²: -0.0004

============================================================
🔄 Round 96 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 96 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=-0.0012
   Val:   Loss=0.0882, RMSE=0.2969, R²=-0.0366
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2474, R²: -0.0004

============================================================
🔄 Round 98 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 98 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0041
   Val:   Loss=0.0790, RMSE=0.2810, R²=-0.0001
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2474, R²: -0.0006

============================================================
🔄 Round 99 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 99 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0069
   Val:   Loss=0.0728, RMSE=0.2699, R²=0.0025
============================================================


============================================================
🔄 Round 100 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 100 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2822, R²=-0.0030
   Val:   Loss=0.0867, RMSE=0.2945, R²=-0.0023
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2474, R²: -0.0007

============================================================
🔄 Round 101 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 101 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0022
   Val:   Loss=0.0745, RMSE=0.2730, R²=-0.0082
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2473, R²: -0.0011

📊 Round 101 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2474, R²: -0.0008

============================================================
🔄 Round 109 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 109 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=-0.0060
   Val:   Loss=0.0863, RMSE=0.2938, R²=0.0088
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2474, R²: -0.0006

============================================================
🔄 Round 112 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 112 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2799, R²=-0.0046
   Val:   Loss=0.0919, RMSE=0.3031, R²=-0.0035
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2474, R²: -0.0005

📊 Round 112 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2474, R²: -0.0005

============================================================
🔄 Round 116 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 116 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0017
   Val:   Loss=0.0822, RMSE=0.2868, R²=-0.0097
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2474, R²: -0.0005

📊 Round 116 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2474, R²: -0.0003

📊 Round 116 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2474, R²: -0.0003

============================================================
🔄 Round 119 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 119 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=-0.0053
   Val:   Loss=0.0886, RMSE=0.2976, R²=0.0036
============================================================


============================================================
🔄 Round 120 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 120 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=-0.0031
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0050
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2474, R²: -0.0003

📊 Round 120 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2474, R²: -0.0002

============================================================
🔄 Round 122 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 122 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0003
   Val:   Loss=0.0838, RMSE=0.2894, R²=-0.0261
============================================================


============================================================
🔄 Round 123 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0715 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0715, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0715, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0715, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0715, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0714, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0715)

============================================================
📊 Round 123 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0007
   Val:   Loss=0.0715, RMSE=0.2674, R²=-0.0137
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2474, R²: -0.0003

📊 Round 123 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2474, R²: -0.0003

📊 Round 123 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2474, R²: -0.0001

============================================================
🔄 Round 129 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 129 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0008
   Val:   Loss=0.0800, RMSE=0.2828, R²=-0.0151
============================================================


============================================================
🔄 Round 130 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 130 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0050
   Val:   Loss=0.0783, RMSE=0.2798, R²=-0.0029
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0814, RMSE: 0.2852, MAE: 0.2474, R²: -0.0000

============================================================
🔄 Round 132 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 132 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0056
   Val:   Loss=0.0761, RMSE=0.2759, R²=0.0012
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2474, R²: -0.0001

============================================================
🔄 Round 133 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0685 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0685, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0685, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0685, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0685, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0685, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0685)

============================================================
📊 Round 133 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0024
   Val:   Loss=0.0685, RMSE=0.2617, R²=-0.0155
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2474, R²: -0.0001

📊 Round 133 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2474, R²: -0.0001

============================================================
🔄 Round 135 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 135 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0039
   Val:   Loss=0.0823, RMSE=0.2868, R²=-0.0144
============================================================


============================================================
🔄 Round 136 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0710 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0710, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0710, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0709, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0709, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0709, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0710)

============================================================
📊 Round 136 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0026
   Val:   Loss=0.0710, RMSE=0.2664, R²=-0.0095
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2474, R²: -0.0002

📊 Round 136 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2474, R²: -0.0002

============================================================
🔄 Round 138 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 138 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0026
   Val:   Loss=0.0821, RMSE=0.2866, R²=-0.0048
============================================================


============================================================
🔄 Round 139 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 139 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0042
   Val:   Loss=0.0726, RMSE=0.2695, R²=0.0017
============================================================


============================================================
🔄 Round 140 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 140 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0011
   Val:   Loss=0.0801, RMSE=0.2831, R²=-0.0257
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2474, R²: -0.0001

============================================================
🔄 Round 143 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 143 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0007
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0153
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2474, R²: -0.0001

============================================================
🔄 Round 144 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 144 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=-0.0017
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0102
============================================================


============================================================
🔄 Round 146 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 146 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0060
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.0044
============================================================


============================================================
🔄 Round 147 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 147 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0053
   Val:   Loss=0.0816, RMSE=0.2856, R²=-0.0134
============================================================


============================================================
🔄 Round 150 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 150 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0053
   Val:   Loss=0.0825, RMSE=0.2872, R²=0.0043
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2474, R²: -0.0002

============================================================
🔄 Round 151 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 151 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0043
   Val:   Loss=0.0734, RMSE=0.2709, R²=-0.0042
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2474, R²: -0.0002

📊 Round 151 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2474, R²: -0.0002

📊 Round 151 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2474, R²: -0.0004

============================================================
🔄 Round 160 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 160 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2842, R²=-0.0056
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0070
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2474, R²: -0.0004

📊 Round 160 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2474, R²: -0.0002

============================================================
🔄 Round 164 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 164 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=-0.0005
   Val:   Loss=0.0893, RMSE=0.2989, R²=-0.0107
============================================================


============================================================
🔄 Round 166 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 166 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=-0.0031
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0065
============================================================


============================================================
🔄 Round 167 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 167 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=-0.0042
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0029
============================================================


============================================================
🔄 Round 168 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 168 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0027
   Val:   Loss=0.0845, RMSE=0.2906, R²=-0.0236
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2474, R²: -0.0002

============================================================
🔄 Round 169 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 169 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0029
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0062
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2474, R²: -0.0001

============================================================
🔄 Round 171 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 171 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0038
   Val:   Loss=0.0755, RMSE=0.2748, R²=-0.0081
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2474, R²: -0.0002

============================================================
🔄 Round 172 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 172 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0011
   Val:   Loss=0.0814, RMSE=0.2853, R²=-0.0132
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2474, R²: -0.0004

📊 Round 172 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2474, R²: -0.0003

📊 Round 172 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2474, R²: -0.0003

============================================================
🔄 Round 179 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 179 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=0.0000
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0140
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2474, R²: -0.0003

============================================================
🔄 Round 181 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 181 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0002
   Val:   Loss=0.0806, RMSE=0.2838, R²=-0.0126
============================================================


============================================================
🔄 Round 182 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 182 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0036
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0200
============================================================


============================================================
🔄 Round 183 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 183 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=-0.0015
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0085
============================================================


============================================================
🔄 Round 185 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 185 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0048
   Val:   Loss=0.0786, RMSE=0.2803, R²=0.0035
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2474, R²: -0.0002

============================================================
🔄 Round 188 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 188 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=-0.0040
   Val:   Loss=0.0869, RMSE=0.2947, R²=-0.0127
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2474, R²: -0.0002

============================================================
🔄 Round 192 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 192 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0060
   Val:   Loss=0.0755, RMSE=0.2748, R²=0.0038
============================================================


📊 Round 192 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2475, R²: -0.0001

============================================================
🔄 Round 193 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 193 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0040
   Val:   Loss=0.0849, RMSE=0.2914, R²=0.0015
============================================================


============================================================
🔄 Round 195 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 195 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0009
   Val:   Loss=0.0862, RMSE=0.2937, R²=-0.0160
============================================================


📊 Round 195 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2474, R²: -0.0002

============================================================
🔄 Round 198 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 198 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0080
   Val:   Loss=0.0827, RMSE=0.2875, R²=-0.0253
============================================================


📊 Round 198 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2475, R²: -0.0002

============================================================
🔄 Round 199 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0705 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0705, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0705, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0705, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0705, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0705, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0705)

============================================================
📊 Round 199 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0037
   Val:   Loss=0.0705, RMSE=0.2655, R²=-0.0189
============================================================


============================================================
🔄 Round 200 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 200 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0033
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0005
============================================================


============================================================
🔄 Round 204 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 204 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=-0.0006
   Val:   Loss=0.0873, RMSE=0.2954, R²=-0.0102
============================================================


============================================================
🔄 Round 206 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 206 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0051
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0025
============================================================


============================================================
🔄 Round 207 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 207 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=-0.0069
   Val:   Loss=0.0779, RMSE=0.2791, R²=0.0011
============================================================


📊 Round 207 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2475, R²: -0.0003

============================================================
🔄 Round 210 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 210 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0021
   Val:   Loss=0.0769, RMSE=0.2773, R²=-0.0073
============================================================


============================================================
🔄 Round 211 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0721, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0721, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 211 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0051
   Val:   Loss=0.0720, RMSE=0.2684, R²=-0.0006
============================================================


============================================================
🔄 Round 213 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 213 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0042
   Val:   Loss=0.0729, RMSE=0.2700, R²=0.0044
============================================================


📊 Round 213 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2474, R²: -0.0005

============================================================
🔄 Round 217 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 217 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0001
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0147
============================================================


============================================================
🔄 Round 218 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 218 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0038
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0031
============================================================


📊 Round 218 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2474, R²: -0.0005

============================================================
🔄 Round 219 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 219 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=-0.0059
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0077
============================================================


📊 Round 219 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2474, R²: -0.0006

============================================================
🔄 Round 223 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 223 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=-0.0034
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0207
============================================================


============================================================
🔄 Round 224 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 224 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=-0.0033
   Val:   Loss=0.0899, RMSE=0.2998, R²=-0.0022
============================================================


============================================================
🔄 Round 225 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 225 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0039
   Val:   Loss=0.0863, RMSE=0.2938, R²=0.0009
============================================================


📊 Round 225 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2475, R²: -0.0003

============================================================
🔄 Round 226 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 226 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=-0.0022
   Val:   Loss=0.0809, RMSE=0.2844, R²=-0.0032
============================================================


📊 Round 226 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2475, R²: -0.0003

============================================================
🔄 Round 227 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 227 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0034
   Val:   Loss=0.0807, RMSE=0.2840, R²=-0.0030
============================================================


📊 Round 227 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2475, R²: -0.0004

📊 Round 227 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2475, R²: -0.0004

============================================================
🔄 Round 231 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 231 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0051
   Val:   Loss=0.0743, RMSE=0.2727, R²=-0.0023
============================================================


📊 Round 231 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2475, R²: -0.0003

============================================================
🔄 Round 234 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 234 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0065
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0055
============================================================


============================================================
🔄 Round 235 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 235 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0011
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0116
============================================================


============================================================
🔄 Round 236 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 236 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=-0.0033
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0022
============================================================


📊 Round 236 Test Metrics:
   Loss: 0.0814, RMSE: 0.2852, MAE: 0.2475, R²: -0.0001

============================================================
🔄 Round 239 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 239 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0033
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0005
============================================================


📊 Round 239 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2475, R²: -0.0002

============================================================
🔄 Round 240 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 240 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0030
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0021
============================================================


📊 Round 240 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2475, R²: -0.0002

============================================================
🔄 Round 245 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 245 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0003
   Val:   Loss=0.0786, RMSE=0.2803, R²=-0.0247
============================================================


============================================================
🔄 Round 248 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 248 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=-0.0011
   Val:   Loss=0.0831, RMSE=0.2882, R²=-0.0092
============================================================


📊 Round 248 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2475, R²: -0.0003

📊 Round 248 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2475, R²: -0.0002

📊 Round 248 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2475, R²: -0.0002

============================================================
🔄 Round 252 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 252 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0017
   Val:   Loss=0.0770, RMSE=0.2776, R²=-0.0209
============================================================


📊 Round 252 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2475, R²: -0.0002

============================================================
🔄 Round 254 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 254 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=-0.0009
   Val:   Loss=0.0846, RMSE=0.2908, R²=-0.0119
============================================================


📊 Round 254 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2475, R²: -0.0002

📊 Round 254 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2475, R²: -0.0002

============================================================
🔄 Round 256 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 256 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0017
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0059
============================================================


============================================================
🔄 Round 257 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 257 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0008
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0088
============================================================


📊 Round 257 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2475, R²: -0.0004

============================================================
🔄 Round 258 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 258 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=-0.0035
   Val:   Loss=0.0826, RMSE=0.2874, R²=0.0023
============================================================


📊 Round 258 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2475, R²: -0.0004

📊 Round 258 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2475, R²: -0.0003

============================================================
🔄 Round 262 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 262 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0008
   Val:   Loss=0.0772, RMSE=0.2778, R²=-0.0345
============================================================


📊 Round 262 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2475, R²: -0.0002

📊 Round 262 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2475, R²: -0.0004

📊 Round 262 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2475, R²: -0.0004

📊 Round 262 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2475, R²: -0.0004

============================================================
🔄 Round 269 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 269 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0032
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0000
============================================================


📊 Round 269 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2475, R²: -0.0004

============================================================
🔄 Round 272 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 272 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0002
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0198
============================================================


============================================================
🔄 Round 273 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 273 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0046
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0019
============================================================


📊 Round 273 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2475, R²: -0.0004

============================================================
🔄 Round 275 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 275 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=-0.0052
   Val:   Loss=0.0886, RMSE=0.2977, R²=-0.0104
============================================================


📊 Round 275 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2475, R²: -0.0003

📊 Round 275 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2475, R²: -0.0002

📊 Round 275 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2475, R²: -0.0002

============================================================
🔄 Round 284 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 284 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0027
   Val:   Loss=0.0743, RMSE=0.2727, R²=-0.0015
============================================================


============================================================
🔄 Round 286 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 286 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=-0.0004
   Val:   Loss=0.0893, RMSE=0.2988, R²=-0.0102
============================================================


📊 Round 286 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2475, R²: -0.0002

📊 Round 286 Test Metrics:
   Loss: 0.0814, RMSE: 0.2852, MAE: 0.2475, R²: -0.0001

============================================================
🔄 Round 289 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 289 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=-0.0048
   Val:   Loss=0.0830, RMSE=0.2881, R²=0.0031
============================================================


📊 Round 289 Test Metrics:
   Loss: 0.0814, RMSE: 0.2852, MAE: 0.2475, R²: -0.0001

============================================================
🔄 Round 291 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 291 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0013
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0146
============================================================


============================================================
🔄 Round 293 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 293 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=-0.0035
   Val:   Loss=0.0751, RMSE=0.2740, R²=0.0001
============================================================


📊 Round 293 Test Metrics:
   Loss: 0.0814, RMSE: 0.2852, MAE: 0.2475, R²: 0.0001

📊 Round 293 Test Metrics:
   Loss: 0.0814, RMSE: 0.2852, MAE: 0.2475, R²: 0.0001

📊 Round 293 Test Metrics:
   Loss: 0.0814, RMSE: 0.2852, MAE: 0.2475, R²: -0.0000

============================================================
🔄 Round 302 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 302 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0006
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0162
============================================================


📊 Round 302 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2475, R²: -0.0002

📊 Round 302 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2475, R²: -0.0002

============================================================
🔄 Round 306 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 306 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0012
   Val:   Loss=0.0763, RMSE=0.2763, R²=-0.0123
============================================================


============================================================
🔄 Round 307 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 307 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0018
   Val:   Loss=0.0757, RMSE=0.2751, R²=-0.0053
============================================================


📊 Round 307 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2475, R²: -0.0002

📊 Round 307 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2475, R²: -0.0002

📊 Round 307 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2475, R²: -0.0002

📊 Round 307 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2475, R²: -0.0002

============================================================
🔄 Round 317 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0951 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0951, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0951, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0951, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0951, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0952, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0951)

============================================================
📊 Round 317 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=-0.0020
   Val:   Loss=0.0951, RMSE=0.3084, R²=-0.0121
============================================================


============================================================
🔄 Round 321 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 321 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=-0.0019
   Val:   Loss=0.0798, RMSE=0.2824, R²=-0.0146
============================================================


📊 Round 321 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2475, R²: -0.0003

📊 Round 321 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2475, R²: -0.0003

📊 Round 321 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2475, R²: -0.0004

============================================================
🔄 Round 326 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 326 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2849, R²=-0.0026
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0005
============================================================


📊 Round 326 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2475, R²: -0.0003

============================================================
🔄 Round 328 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 328 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0033
   Val:   Loss=0.0818, RMSE=0.2859, R²=-0.0004
============================================================


============================================================
🔄 Round 329 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 329 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0049
   Val:   Loss=0.0825, RMSE=0.2873, R²=0.0016
============================================================


📊 Round 329 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2475, R²: -0.0001

============================================================
🔄 Round 335 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 335 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0031
   Val:   Loss=0.0785, RMSE=0.2802, R²=-0.0135
============================================================


📊 Round 335 Test Metrics:
   Loss: 0.0814, RMSE: 0.2852, MAE: 0.2476, R²: 0.0000

============================================================
🔄 Round 336 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 336 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0005
   Val:   Loss=0.0737, RMSE=0.2715, R²=-0.0673
============================================================


📊 Round 336 Test Metrics:
   Loss: 0.0814, RMSE: 0.2852, MAE: 0.2476, R²: -0.0000

============================================================
🔄 Round 337 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 337 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=-0.0033
   Val:   Loss=0.0875, RMSE=0.2958, R²=-0.0061
============================================================


📊 Round 337 Test Metrics:
   Loss: 0.0814, RMSE: 0.2852, MAE: 0.2476, R²: -0.0000

📊 Round 337 Test Metrics:
   Loss: 0.0814, RMSE: 0.2852, MAE: 0.2476, R²: 0.0000

============================================================
🔄 Round 339 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 339 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=-0.0013
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0082
============================================================


============================================================
🔄 Round 340 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 340 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0026
   Val:   Loss=0.0762, RMSE=0.2761, R²=-0.0063
============================================================


📊 Round 340 Test Metrics:
   Loss: 0.0814, RMSE: 0.2852, MAE: 0.2476, R²: -0.0001

============================================================
🔄 Round 342 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 342 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0075
   Val:   Loss=0.0770, RMSE=0.2775, R²=-0.0186
============================================================


============================================================
🔄 Round 343 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 343 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0039
   Val:   Loss=0.0767, RMSE=0.2769, R²=0.0040
============================================================


📊 Round 343 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2475, R²: -0.0002

============================================================
🔄 Round 344 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 344 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0007
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0217
============================================================


============================================================
🔄 Round 345 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 345 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0033
   Val:   Loss=0.0807, RMSE=0.2840, R²=0.0018
============================================================


📊 Round 345 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2475, R²: -0.0003

📊 Round 345 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2475, R²: -0.0002

📊 Round 345 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2475, R²: -0.0002

📊 Round 345 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2475, R²: -0.0002

============================================================
🔄 Round 351 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 351 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0060
   Val:   Loss=0.0827, RMSE=0.2875, R²=0.0061
============================================================


============================================================
🔄 Round 352 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 352 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0026
   Val:   Loss=0.0823, RMSE=0.2870, R²=-0.0107
============================================================


============================================================
🔄 Round 353 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 353 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0010
   Val:   Loss=0.0787, RMSE=0.2805, R²=-0.0080
============================================================


📊 Round 353 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2475, R²: -0.0002

📊 Round 353 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2475, R²: -0.0002

============================================================
🔄 Round 355 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 355 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0013
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0067
============================================================


📊 Round 355 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2475, R²: -0.0002

📊 Round 355 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2475, R²: -0.0002

📊 Round 355 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2475, R²: -0.0002

📊 Round 355 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2475, R²: -0.0005

============================================================
🔄 Round 364 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 364 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0026
   Val:   Loss=0.0841, RMSE=0.2899, R²=-0.0094
============================================================


📊 Round 364 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2475, R²: -0.0007

============================================================
🔄 Round 365 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 365 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0026
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0069
============================================================


📊 Round 365 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2475, R²: -0.0007

📊 Round 365 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2475, R²: -0.0007

============================================================
🔄 Round 367 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 367 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=-0.0007
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0130
============================================================


============================================================
🔄 Round 368 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 368 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=-0.0061
   Val:   Loss=0.0900, RMSE=0.3000, R²=-0.0073
============================================================


📊 Round 368 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2475, R²: -0.0006

📊 Round 368 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2475, R²: -0.0006

============================================================
🔄 Round 372 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 372 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0010
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0051
============================================================


============================================================
🔄 Round 375 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 375 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0014
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0065
============================================================


============================================================
🔄 Round 376 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 376 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0007
   Val:   Loss=0.0861, RMSE=0.2935, R²=-0.0100
============================================================


============================================================
🔄 Round 378 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 378 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0015
   Val:   Loss=0.0768, RMSE=0.2770, R²=-0.0049
============================================================


📊 Round 378 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2475, R²: -0.0007

📊 Round 378 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2475, R²: -0.0008

📊 Round 378 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2475, R²: -0.0007

📊 Round 378 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2475, R²: -0.0010

============================================================
🔄 Round 388 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 388 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0012
   Val:   Loss=0.0741, RMSE=0.2722, R²=-0.0028
============================================================


📊 Round 388 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2475, R²: -0.0006

============================================================
🔄 Round 390 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0710 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0710, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0710, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0710, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0710, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0710, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0710)

============================================================
📊 Round 390 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0003
   Val:   Loss=0.0710, RMSE=0.2665, R²=-0.0203
============================================================


============================================================
🔄 Round 391 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 391 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0012
   Val:   Loss=0.0766, RMSE=0.2768, R²=-0.0051
============================================================


📊 Round 391 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2475, R²: -0.0007

📊 Round 391 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2475, R²: -0.0008

============================================================
🔄 Round 393 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 393 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=-0.0012
   Val:   Loss=0.0805, RMSE=0.2838, R²=-0.0034
============================================================


📊 Round 393 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2475, R²: -0.0007

📊 Round 393 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2475, R²: -0.0007

============================================================
🔄 Round 396 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 396 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0011
   Val:   Loss=0.0802, RMSE=0.2833, R²=-0.0371
============================================================


============================================================
🔄 Round 397 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 397 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=-0.0018
   Val:   Loss=0.0873, RMSE=0.2954, R²=-0.0025
============================================================


============================================================
🔄 Round 399 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 399 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=-0.0002
   Val:   Loss=0.0894, RMSE=0.2989, R²=-0.0230
============================================================


============================================================
🔄 Round 402 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 402 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2808, R²=0.0007
   Val:   Loss=0.0895, RMSE=0.2991, R²=-0.0191
============================================================


📊 Round 402 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2475, R²: -0.0005

============================================================
🔄 Round 403 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 403 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0024
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0031
============================================================


📊 Round 403 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2475, R²: -0.0005

============================================================
🔄 Round 405 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 405 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0047
   Val:   Loss=0.0783, RMSE=0.2798, R²=-0.0058
============================================================


============================================================
🔄 Round 406 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 406 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0049
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0218
============================================================


📊 Round 406 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0004

============================================================
🔄 Round 407 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 407 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=-0.0024
   Val:   Loss=0.0874, RMSE=0.2957, R²=-0.0070
============================================================


============================================================
🔄 Round 408 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0936 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0936, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0936, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0936, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0936, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0935, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0936)

============================================================
📊 Round 408 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2790, R²=0.0005
   Val:   Loss=0.0936, RMSE=0.3059, R²=-0.0219
============================================================


📊 Round 408 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0004

📊 Round 408 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0004

📊 Round 408 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0004

📊 Round 408 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0004

📊 Round 408 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0004

📊 Round 408 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0005

============================================================
🔄 Round 418 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 418 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0024
   Val:   Loss=0.0743, RMSE=0.2725, R²=0.0007
============================================================


📊 Round 418 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2475, R²: -0.0006

============================================================
🔄 Round 421 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 421 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0001
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0087
============================================================


📊 Round 421 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2475, R²: -0.0006

📊 Round 421 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0006

============================================================
🔄 Round 423 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 423 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0020
   Val:   Loss=0.0754, RMSE=0.2745, R²=-0.0011
============================================================


============================================================
🔄 Round 424 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 424 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0032
   Val:   Loss=0.0785, RMSE=0.2802, R²=-0.0224
============================================================


============================================================
🔄 Round 425 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 425 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2842, R²=-0.0003
   Val:   Loss=0.0819, RMSE=0.2863, R²=-0.0144
============================================================


📊 Round 425 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0005

============================================================
🔄 Round 427 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 427 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0049
   Val:   Loss=0.0730, RMSE=0.2702, R²=0.0054
============================================================


============================================================
🔄 Round 428 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 428 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0022
   Val:   Loss=0.0734, RMSE=0.2709, R²=-0.0277
============================================================


📊 Round 428 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0004

📊 Round 428 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0004

============================================================
🔄 Round 431 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0937 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0937, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0937, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0937, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0937, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0937, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0937)

============================================================
📊 Round 431 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=-0.0036
   Val:   Loss=0.0937, RMSE=0.3062, R²=-0.0036
============================================================


📊 Round 431 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0004

============================================================
🔄 Round 432 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 432 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0013
   Val:   Loss=0.0899, RMSE=0.2998, R²=-0.0130
============================================================


============================================================
🔄 Round 434 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 434 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2826, R²=-0.0018
   Val:   Loss=0.0855, RMSE=0.2925, R²=-0.0044
============================================================


📊 Round 434 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0004

============================================================
🔄 Round 435 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 435 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0009
   Val:   Loss=0.0821, RMSE=0.2866, R²=-0.0147
============================================================


📊 Round 435 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0004

📊 Round 435 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0004

📊 Round 435 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0004

📊 Round 435 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0004

📊 Round 435 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0005

============================================================
🔄 Round 444 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 444 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=-0.0085
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0167
============================================================


============================================================
🔄 Round 446 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 446 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0015
   Val:   Loss=0.0811, RMSE=0.2847, R²=-0.0020
============================================================


📊 Round 446 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0006

📊 Round 446 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0006

============================================================
🔄 Round 448 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 448 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0050
   Val:   Loss=0.0816, RMSE=0.2856, R²=-0.0034
============================================================


📊 Round 448 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0006

============================================================
🔄 Round 449 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 449 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0000
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0276
============================================================


============================================================
🔄 Round 450 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 450 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0029
   Val:   Loss=0.0809, RMSE=0.2844, R²=-0.0099
============================================================


📊 Round 450 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0005

============================================================
🔄 Round 452 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 452 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0037
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0006
============================================================


📊 Round 452 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0006

📊 Round 452 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0005

📊 Round 452 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0005

============================================================
🔄 Round 455 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 455 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=-0.0018
   Val:   Loss=0.0827, RMSE=0.2875, R²=-0.0018
============================================================


📊 Round 455 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0005

============================================================
🔄 Round 458 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 458 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=-0.0053
   Val:   Loss=0.0881, RMSE=0.2969, R²=-0.0093
============================================================


📊 Round 458 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0005

============================================================
🔄 Round 459 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 459 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0022
   Val:   Loss=0.0726, RMSE=0.2695, R²=-0.0019
============================================================


============================================================
🔄 Round 462 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 462 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0034
   Val:   Loss=0.0777, RMSE=0.2788, R²=0.0007
============================================================


📊 Round 462 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0004

📊 Round 462 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0005

📊 Round 462 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0004

📊 Round 462 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0004

============================================================
🔄 Round 468 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 468 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=-0.0016
   Val:   Loss=0.0807, RMSE=0.2842, R²=-0.0031
============================================================


============================================================
🔄 Round 469 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 469 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0021
   Val:   Loss=0.0829, RMSE=0.2880, R²=-0.0049
============================================================


============================================================
🔄 Round 470 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 470 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0023
   Val:   Loss=0.0749, RMSE=0.2737, R²=0.0006
============================================================


============================================================
🔄 Round 471 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 471 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0007
   Val:   Loss=0.0819, RMSE=0.2861, R²=-0.0159
============================================================


============================================================
🔄 Round 472 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 472 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0041
   Val:   Loss=0.0724, RMSE=0.2690, R²=0.0039
============================================================


============================================================
🔄 Round 474 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 474 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0011
   Val:   Loss=0.0787, RMSE=0.2806, R²=-0.0042
============================================================


============================================================
🔄 Round 476 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 476 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0025
   Val:   Loss=0.0769, RMSE=0.2772, R²=0.0020
============================================================


============================================================
🔄 Round 477 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 477 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0014
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0024
============================================================


============================================================
🔄 Round 478 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 478 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=-0.0000
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0117
============================================================


============================================================
🔄 Round 481 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 481 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0006
   Val:   Loss=0.0852, RMSE=0.2920, R²=-0.0160
============================================================


============================================================
🔄 Round 482 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 482 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0027
   Val:   Loss=0.0822, RMSE=0.2866, R²=0.0025
============================================================


📊 Round 482 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0004

📊 Round 482 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0004

📊 Round 482 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0004

📊 Round 482 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0004

============================================================
🔄 Round 489 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 489 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0015
   Val:   Loss=0.0810, RMSE=0.2845, R²=-0.0050
============================================================


📊 Round 489 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0004

============================================================
🔄 Round 492 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 492 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0026
   Val:   Loss=0.0800, RMSE=0.2829, R²=-0.0146
============================================================


📊 Round 492 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0004

📊 Round 492 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0004

📊 Round 492 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0004

============================================================
🔄 Round 495 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 495 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0022
   Val:   Loss=0.0772, RMSE=0.2778, R²=-0.0008
============================================================


📊 Round 495 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0005

============================================================
🔄 Round 500 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 500 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0014
   Val:   Loss=0.0781, RMSE=0.2795, R²=-0.0053
============================================================


============================================================
🔄 Round 501 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 501 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0019
   Val:   Loss=0.0772, RMSE=0.2779, R²=-0.0007
============================================================


📊 Round 501 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0004

============================================================
🔄 Round 503 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 503 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0018
   Val:   Loss=0.0774, RMSE=0.2782, R²=-0.0057
============================================================


============================================================
🔄 Round 504 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 504 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=-0.0010
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0110
============================================================


📊 Round 504 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0005

📊 Round 504 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0005

📊 Round 504 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0004

============================================================
🔄 Round 507 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 507 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2849, R²=-0.0001
   Val:   Loss=0.0803, RMSE=0.2833, R²=-0.0089
============================================================


📊 Round 507 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0004

============================================================
🔄 Round 509 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 509 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0008
   Val:   Loss=0.0829, RMSE=0.2880, R²=-0.0073
============================================================


📊 Round 509 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0004

============================================================
🔄 Round 511 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 511 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0001
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0189
============================================================


============================================================
🔄 Round 513 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 513 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=-0.0047
   Val:   Loss=0.0871, RMSE=0.2950, R²=-0.0016
============================================================


============================================================
🔄 Round 514 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 514 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0041
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0028
============================================================


============================================================
🔄 Round 515 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 515 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0013
   Val:   Loss=0.0914, RMSE=0.3024, R²=-0.0221
============================================================


============================================================
🔄 Round 516 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 516 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=-0.0070
   Val:   Loss=0.0824, RMSE=0.2870, R²=0.0010
============================================================


📊 Round 516 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0004

============================================================
🔄 Round 519 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 519 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0006
   Val:   Loss=0.0823, RMSE=0.2868, R²=-0.0063
============================================================


============================================================
🔄 Round 522 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 522 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0052
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0016
============================================================


============================================================
🔄 Round 523 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 523 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0033
   Val:   Loss=0.0812, RMSE=0.2849, R²=0.0024
============================================================


📊 Round 523 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0003

============================================================
🔄 Round 525 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 525 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0005
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0111
============================================================


📊 Round 525 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0002

============================================================
🔄 Round 527 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 527 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0029
   Val:   Loss=0.0734, RMSE=0.2709, R²=0.0000
============================================================


============================================================
🔄 Round 529 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 529 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0011
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0182
============================================================


📊 Round 529 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0003

============================================================
🔄 Round 531 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 531 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0001
   Val:   Loss=0.0798, RMSE=0.2824, R²=-0.0093
============================================================


============================================================
🔄 Round 532 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 532 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0016
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0034
============================================================


📊 Round 532 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0005

📊 Round 532 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0005

============================================================
🔄 Round 534 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 534 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0003
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0089
============================================================


📊 Round 534 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0007

============================================================
🔄 Round 535 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 535 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0028
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0030
============================================================


📊 Round 535 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0007

============================================================
🔄 Round 536 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 536 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0028
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0010
============================================================


============================================================
🔄 Round 537 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 537 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0007
   Val:   Loss=0.0764, RMSE=0.2763, R²=-0.0234
============================================================


============================================================
🔄 Round 540 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 540 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0023
   Val:   Loss=0.0777, RMSE=0.2788, R²=0.0015
============================================================


📊 Round 540 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0003

============================================================
🔄 Round 541 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 541 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0012
   Val:   Loss=0.0784, RMSE=0.2799, R²=-0.0038
============================================================


📊 Round 541 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0004

============================================================
🔄 Round 544 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 544 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=-0.0040
   Val:   Loss=0.0878, RMSE=0.2964, R²=-0.0201
============================================================


📊 Round 544 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0005

============================================================
🔄 Round 545 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 545 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0004
   Val:   Loss=0.0785, RMSE=0.2801, R²=-0.0229
============================================================


============================================================
🔄 Round 548 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 548 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=-0.0004
   Val:   Loss=0.0891, RMSE=0.2984, R²=-0.0272
============================================================


📊 Round 548 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0005

============================================================
🔄 Round 549 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 549 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=-0.0017
   Val:   Loss=0.0908, RMSE=0.3013, R²=-0.0059
============================================================


============================================================
🔄 Round 550 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 550 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2849, R²=-0.0014
   Val:   Loss=0.0802, RMSE=0.2833, R²=-0.0073
============================================================


📊 Round 550 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0004

============================================================
🔄 Round 555 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 555 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0005
   Val:   Loss=0.0786, RMSE=0.2804, R²=-0.0073
============================================================


📊 Round 555 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0004

📊 Round 555 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0004

============================================================
🔄 Round 561 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 561 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=-0.0018
   Val:   Loss=0.0886, RMSE=0.2976, R²=-0.0153
============================================================


📊 Round 561 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0005

============================================================
🔄 Round 562 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 562 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0019
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0041
============================================================


============================================================
🔄 Round 564 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 564 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0005
   Val:   Loss=0.0792, RMSE=0.2815, R²=-0.0078
============================================================


============================================================
🔄 Round 565 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 565 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0007
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0109
============================================================


📊 Round 565 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0005

============================================================
🔄 Round 566 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 566 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0000
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0075
============================================================


============================================================
🔄 Round 570 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 570 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=-0.0007
   Val:   Loss=0.0778, RMSE=0.2789, R²=-0.0252
============================================================


============================================================
🔄 Round 571 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 571 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0035
   Val:   Loss=0.0767, RMSE=0.2770, R²=0.0043
============================================================


============================================================
🔄 Round 572 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 572 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2877, R²=-0.0052
   Val:   Loss=0.0738, RMSE=0.2717, R²=0.0148
============================================================


📊 Round 572 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0004

============================================================
🔄 Round 574 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 574 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0023
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0036
============================================================


📊 Round 574 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0006

============================================================
🔄 Round 578 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 578 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0032
   Val:   Loss=0.0820, RMSE=0.2863, R²=0.0048
============================================================


============================================================
🔄 Round 579 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 579 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0044
   Val:   Loss=0.0861, RMSE=0.2934, R²=0.0034
============================================================


📊 Round 579 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0005

============================================================
🔄 Round 581 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 581 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0015
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0016
============================================================


============================================================
🔄 Round 584 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 584 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0009
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0055
============================================================


📊 Round 584 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0003

📊 Round 584 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0003

📊 Round 584 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0003

============================================================
🔄 Round 592 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 592 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0004
   Val:   Loss=0.0829, RMSE=0.2880, R²=-0.0275
============================================================


============================================================
🔄 Round 593 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 593 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0014
   Val:   Loss=0.0814, RMSE=0.2853, R²=-0.0031
============================================================


============================================================
🔄 Round 594 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 594 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0013
   Val:   Loss=0.0787, RMSE=0.2805, R²=-0.0036
============================================================


📊 Round 594 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0003

============================================================
🔄 Round 598 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 598 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0002
   Val:   Loss=0.0750, RMSE=0.2738, R²=-0.0154
============================================================


📊 Round 598 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0004

============================================================
🔄 Round 600 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 600 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0014
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0475
============================================================


📊 Round 600 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0004

============================================================
🔄 Round 602 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 602 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0067
   Val:   Loss=0.0780, RMSE=0.2793, R²=0.0025
============================================================


📊 Round 602 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0004

📊 Round 602 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0004

============================================================
🔄 Round 605 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 605 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0013
   Val:   Loss=0.0803, RMSE=0.2835, R²=-0.0043
============================================================


📊 Round 605 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0004

============================================================
🔄 Round 607 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 607 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0032
   Val:   Loss=0.0726, RMSE=0.2694, R²=-0.0216
============================================================


📊 Round 607 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0003

============================================================
🔄 Round 609 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 609 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0002
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0120
============================================================


📊 Round 609 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0005

============================================================
🔄 Round 614 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 614 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0000
   Val:   Loss=0.0772, RMSE=0.2779, R²=-0.0252
============================================================


📊 Round 614 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0006

============================================================
🔄 Round 615 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 615 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0002
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0160
============================================================


📊 Round 615 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0006

============================================================
🔄 Round 617 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 617 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=-0.0018
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0227
============================================================


============================================================
🔄 Round 618 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 618 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2828, R²=-0.0001
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0105
============================================================


📊 Round 618 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0005

============================================================
🔄 Round 619 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 619 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0015
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0437
============================================================


📊 Round 619 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0004

📊 Round 619 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0004

============================================================
🔄 Round 622 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 622 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0014
   Val:   Loss=0.0889, RMSE=0.2982, R²=-0.0187
============================================================


📊 Round 622 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0004

============================================================
🔄 Round 624 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 624 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0007
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0142
============================================================


============================================================
🔄 Round 625 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 625 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0029
   Val:   Loss=0.0754, RMSE=0.2746, R²=0.0038
============================================================


============================================================
🔄 Round 626 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 626 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0037
   Val:   Loss=0.0726, RMSE=0.2694, R²=-0.0217
============================================================


📊 Round 626 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0005

📊 Round 626 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0004

📊 Round 626 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0004

============================================================
🔄 Round 631 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 631 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0027
   Val:   Loss=0.0825, RMSE=0.2872, R²=0.0027
============================================================


============================================================
🔄 Round 632 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 632 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0058
   Val:   Loss=0.0748, RMSE=0.2736, R²=-0.0106
============================================================


============================================================
🔄 Round 634 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 634 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=-0.0032
   Val:   Loss=0.0838, RMSE=0.2895, R²=0.0038
============================================================


============================================================
🔄 Round 636 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 636 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=-0.0009
   Val:   Loss=0.0892, RMSE=0.2986, R²=-0.0228
============================================================


============================================================
🔄 Round 637 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 637 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=-0.0003
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0101
============================================================


============================================================
🔄 Round 638 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 638 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=-0.0055
   Val:   Loss=0.0826, RMSE=0.2874, R²=0.0090
============================================================


📊 Round 638 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0004

============================================================
🔄 Round 640 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 640 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0025
   Val:   Loss=0.0797, RMSE=0.2824, R²=0.0021
============================================================


📊 Round 640 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0004

============================================================
🔄 Round 641 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 641 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=-0.0026
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0022
============================================================


📊 Round 641 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0004

📊 Round 641 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0004

============================================================
🔄 Round 645 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 645 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2808, R²=-0.0014
   Val:   Loss=0.0894, RMSE=0.2990, R²=-0.0044
============================================================


📊 Round 645 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0004

📊 Round 645 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0004

============================================================
🔄 Round 647 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 647 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0012
   Val:   Loss=0.0815, RMSE=0.2854, R²=-0.0056
============================================================


📊 Round 647 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0004

============================================================
🔄 Round 649 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 649 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0031
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.0030
============================================================


📊 Round 649 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0004

📊 Round 649 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0004

============================================================
🔄 Round 651 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 651 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0004
   Val:   Loss=0.0822, RMSE=0.2868, R²=-0.0062
============================================================


============================================================
🔄 Round 653 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 653 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0048
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0087
============================================================


============================================================
🔄 Round 656 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 656 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0036
   Val:   Loss=0.0749, RMSE=0.2737, R²=-0.0113
============================================================


============================================================
🔄 Round 657 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 657 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0045
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0085
============================================================


📊 Round 657 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0005

============================================================
🔄 Round 661 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 661 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=-0.0027
   Val:   Loss=0.0869, RMSE=0.2948, R²=0.0019
============================================================


📊 Round 661 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0006

============================================================
🔄 Round 663 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 663 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0000
   Val:   Loss=0.0788, RMSE=0.2806, R²=-0.0114
============================================================


📊 Round 663 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0007

============================================================
🔄 Round 665 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 665 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0009
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0029
============================================================


📊 Round 665 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0007

============================================================
🔄 Round 666 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 666 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0045
   Val:   Loss=0.0799, RMSE=0.2826, R²=0.0040
============================================================


📊 Round 666 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0007

📊 Round 666 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0006

📊 Round 666 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0006

============================================================
🔄 Round 670 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 670 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0012
   Val:   Loss=0.0842, RMSE=0.2901, R²=-0.0126
============================================================


============================================================
🔄 Round 671 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 671 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0099
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0238
============================================================


📊 Round 671 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0006

============================================================
🔄 Round 673 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 673 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0022
   Val:   Loss=0.0740, RMSE=0.2719, R²=0.0014
============================================================


============================================================
🔄 Round 674 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 674 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2826, R²=-0.0010
   Val:   Loss=0.0854, RMSE=0.2923, R²=-0.0034
============================================================


📊 Round 674 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0005

============================================================
🔄 Round 675 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 675 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0002
   Val:   Loss=0.0760, RMSE=0.2757, R²=-0.0620
============================================================


📊 Round 675 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0004

============================================================
🔄 Round 678 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 678 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0004
   Val:   Loss=0.0787, RMSE=0.2805, R²=-0.0063
============================================================


📊 Round 678 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2477, R²: -0.0004

============================================================
🔄 Round 683 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 683 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=-0.0016
   Val:   Loss=0.0903, RMSE=0.3005, R²=-0.0058
============================================================


📊 Round 683 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2477, R²: -0.0004

============================================================
🔄 Round 684 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 684 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0000
   Val:   Loss=0.0831, RMSE=0.2882, R²=-0.0310
============================================================


============================================================
🔄 Round 685 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 685 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0012
   Val:   Loss=0.0821, RMSE=0.2866, R²=-0.0056
============================================================


📊 Round 685 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2477, R²: -0.0005

============================================================
🔄 Round 686 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 686 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0024
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0014
============================================================


============================================================
🔄 Round 688 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 688 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2870, R²=-0.0019
   Val:   Loss=0.0754, RMSE=0.2746, R²=0.0002
============================================================


📊 Round 688 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2477, R²: -0.0005

============================================================
🔄 Round 689 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 689 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0021
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0002
============================================================


📊 Round 689 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2477, R²: -0.0004

============================================================
🔄 Round 691 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 691 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2870, R²=-0.0021
   Val:   Loss=0.0755, RMSE=0.2747, R²=-0.0031
============================================================


📊 Round 691 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2477, R²: -0.0005

============================================================
🔄 Round 693 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 693 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2871, R²=-0.0018
   Val:   Loss=0.0750, RMSE=0.2738, R²=0.0002
============================================================


📊 Round 693 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2477, R²: -0.0005

============================================================
🔄 Round 694 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 694 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0025
   Val:   Loss=0.0747, RMSE=0.2732, R²=0.0031
============================================================


📊 Round 694 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2477, R²: -0.0005

📊 Round 694 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0007

📊 Round 694 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0006

============================================================
🔄 Round 699 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 699 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=-0.0020
   Val:   Loss=0.0790, RMSE=0.2810, R²=-0.0050
============================================================


📊 Round 699 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0006

============================================================
🔄 Round 700 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 700 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0016
   Val:   Loss=0.0883, RMSE=0.2972, R²=-0.0125
============================================================


============================================================
🔄 Round 703 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 703 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0052
   Val:   Loss=0.0774, RMSE=0.2782, R²=0.0054
============================================================


📊 Round 703 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0007

📊 Round 703 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0007

============================================================
🔄 Round 707 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 707 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0011
   Val:   Loss=0.0782, RMSE=0.2796, R²=-0.0021
============================================================


📊 Round 707 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0007

📊 Round 707 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0006

============================================================
🔄 Round 710 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 710 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0009
   Val:   Loss=0.0818, RMSE=0.2859, R²=-0.0234
============================================================


📊 Round 710 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0007

📊 Round 710 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0007

============================================================
🔄 Round 714 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 714 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0010
   Val:   Loss=0.0784, RMSE=0.2800, R²=-0.0024
============================================================


============================================================
🔄 Round 718 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 718 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2810, R²=-0.0003
   Val:   Loss=0.0888, RMSE=0.2980, R²=-0.0035
============================================================


============================================================
🔄 Round 720 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 720 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0012
   Val:   Loss=0.0725, RMSE=0.2692, R²=-0.0086
============================================================


📊 Round 720 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0008

============================================================
🔄 Round 721 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 721 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0021
   Val:   Loss=0.0782, RMSE=0.2797, R²=-0.0143
============================================================


📊 Round 721 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0007

============================================================
🔄 Round 723 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 723 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=0.0003
   Val:   Loss=0.0744, RMSE=0.2728, R²=-0.0248
============================================================


📊 Round 723 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2476, R²: -0.0007

============================================================
🔄 Round 724 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 724 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0008
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0051
============================================================


============================================================
🔄 Round 725 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 725 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=-0.0018
   Val:   Loss=0.0871, RMSE=0.2950, R²=0.0011
============================================================


============================================================
🔄 Round 728 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 728 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0001
   Val:   Loss=0.0814, RMSE=0.2854, R²=-0.0129
============================================================


============================================================
🔄 Round 730 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 730 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0016
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0004
============================================================


============================================================
🔄 Round 734 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 734 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0013
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0181
============================================================


📊 Round 734 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2477, R²: -0.0004

📊 Round 734 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2477, R²: -0.0004

============================================================
🔄 Round 736 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 736 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=-0.0026
   Val:   Loss=0.0866, RMSE=0.2942, R²=0.0017
============================================================


📊 Round 736 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2477, R²: -0.0004

============================================================
🔄 Round 737 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 737 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0013
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0133
============================================================


📊 Round 737 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2477, R²: -0.0007

============================================================
🔄 Round 740 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 740 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0046
   Val:   Loss=0.0748, RMSE=0.2735, R²=0.0031
============================================================


📊 Round 740 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2477, R²: -0.0005

============================================================
🔄 Round 743 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 743 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0024
   Val:   Loss=0.0756, RMSE=0.2749, R²=0.0013
============================================================


📊 Round 743 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2477, R²: -0.0005

📊 Round 743 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2477, R²: -0.0005

📊 Round 743 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2477, R²: -0.0005

📊 Round 743 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2477, R²: -0.0003

============================================================
🔄 Round 749 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 749 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0042
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0039
============================================================


📊 Round 749 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2477, R²: -0.0003

============================================================
🔄 Round 750 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 750 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0013
   Val:   Loss=0.0857, RMSE=0.2928, R²=-0.0042
============================================================


============================================================
🔄 Round 752 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 752 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0017
   Val:   Loss=0.0751, RMSE=0.2740, R²=-0.0011
============================================================


📊 Round 752 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2477, R²: -0.0005

============================================================
🔄 Round 753 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 753 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0033
   Val:   Loss=0.0735, RMSE=0.2711, R²=0.0068
============================================================


📊 Round 753 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2477, R²: -0.0007

============================================================
🔄 Round 755 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 755 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0018
   Val:   Loss=0.0775, RMSE=0.2785, R²=-0.0035
============================================================


📊 Round 755 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2477, R²: -0.0007

📊 Round 755 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2477, R²: -0.0007

============================================================
🔄 Round 757 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 757 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0004
   Val:   Loss=0.0746, RMSE=0.2732, R²=-0.0106
============================================================


============================================================
🔄 Round 759 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 759 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=-0.0000
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0084
============================================================


📊 Round 759 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2477, R²: -0.0010

============================================================
🔄 Round 763 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 763 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=-0.0014
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0422
============================================================


============================================================
🔄 Round 764 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 764 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0011
   Val:   Loss=0.0839, RMSE=0.2896, R²=-0.0098
============================================================


============================================================
🔄 Round 765 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 765 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0002
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0055
============================================================


📊 Round 765 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2477, R²: -0.0009

============================================================
🔄 Round 766 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 766 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0012
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0062
============================================================


📊 Round 766 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2477, R²: -0.0009

📊 Round 766 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2477, R²: -0.0008

============================================================
🔄 Round 771 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 771 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0007
   Val:   Loss=0.0815, RMSE=0.2856, R²=-0.0074
============================================================


📊 Round 771 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2477, R²: -0.0008

📊 Round 771 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2477, R²: -0.0008

📊 Round 771 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2477, R²: -0.0007

📊 Round 771 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2477, R²: -0.0007

📊 Round 771 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2477, R²: -0.0007

📊 Round 771 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2477, R²: -0.0005

============================================================
🔄 Round 780 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 780 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=-0.0006
   Val:   Loss=0.0869, RMSE=0.2947, R²=-0.0068
============================================================


❌ Client client_9 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8692 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8692 {grpc_message:"Socket closed", grpc_status:14}"
>
